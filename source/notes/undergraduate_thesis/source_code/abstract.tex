\chapter*{Abstract}\label{abstract}

\addcontentsline{toc}{chapter}{Abstract}


Expectation lies at the foundation of probability, but its centrality belies its contingency. Abstractly, the expectation of a random variable is a real number that measures some information about the variable, and one may well explore the consequences of replacing expectation by some alternative.

Certain alternatives to expectation, termed "coherent risk measures", have been well-investigated in financial engineering, but they are relatively unknown in the field of machine learning. Here, we collect and prove some fundamental properties of coherent risk measures that we believe would be applicable to machine learning.

In Chapter 1, we give a guide to the thesis, then we review the concept of risk measures, point out possible deficiencies of the expectation as a risk measure, and provide a historical overview of the study of risk measures in finance and other areas.

In Chapter 2, we review basic probability concepts, then define the concept of coherent risk measures and study the geometric properties of their envelope representations. Armed with geometric insight, we prove a Kusuoka representation theorem when the underlying sample space is finite and uniform, and construct counterexamples when it is finite but nonuniform.

In Chapter 3, we generalize some basic probability inequalities and concentration inequalities from expectation to conditional value at risk. Then we review statistical learning theory and generalize its basic concepts and its fundamental theorem by replacing expectation with spectral risk measures.

In Chapter 4, we review limit theorems in probability, give a new and intuitive proof of the central limit theorem for the empirical estimator of CVaR. We also prove the uniform strong law of large numbers for the empirical estimator of spectral risk measures. We provide numerical evidence to support our results and generate conjectures.

In Chapter 5, we summarize the main theorems and conjectures of the thesis, review the literature on applications of general risk measures to machine learning, and point to possible future research directions.