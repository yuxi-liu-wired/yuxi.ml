<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ray Solomonoff">
<meta name="dcterms.date" content="1985-06-01">
<meta name="description" content="Ray Solomonoff’s 1985 essay on forecasting the progress towards AGI, reaching AGI around 2022–2076.">

<title>The time scale of artificial intelligence – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-493ec8732bc442be923a7677f0a4f8b4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="The time scale of artificial intelligence – Yuxi on the Wired">
<meta property="og:description" content="Ray Solomonoff’s 1985 essay on forecasting the progress towards AGI, reaching AGI around 2022–2076.">
<meta property="og:image" content="https://yuxi.ml/docs/posts/1985-ray-solomonoff/img/blog icon.jpg">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta name="twitter:title" content="The time scale of artificial intelligence – Yuxi on the Wired">
<meta name="twitter:description" content="Ray Solomonoff’s 1985 essay on forecasting the progress towards AGI, reaching AGI around 2022–2076.">
<meta name="twitter:image" content="https://yuxi.ml/docs/posts/1985-ray-solomonoff/img/blog icon.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../logs/index.html"> 
<span class="menu-text">Logs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi_liu@berkeley.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../feeds.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">The time scale of artificial intelligence</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Reflections on social effects</p>
                  <div>
        <div class="description">
          Ray Solomonoff’s 1985 essay on forecasting the progress towards AGI, reaching AGI around 2022–2076.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ray Solomonoff </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 1, 1985</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#transcribers-notes" id="toc-transcribers-notes" class="nav-link active" data-scroll-target="#transcribers-notes">Transcriber’s notes</a>
  <ul class="collapse">
  <li><a href="#explicit-numerical-predictions" id="toc-explicit-numerical-predictions" class="nav-link" data-scroll-target="#explicit-numerical-predictions">Explicit numerical predictions</a></li>
  </ul></li>
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#essay" id="toc-essay" class="nav-link" data-scroll-target="#essay">Essay</a>
  <ul class="collapse">
  <li><a href="#theory-of-agi" id="toc-theory-of-agi" class="nav-link" data-scroll-target="#theory-of-agi">Theory of AGI</a></li>
  <li><a href="#understanding-natural-language" id="toc-understanding-natural-language" class="nav-link" data-scroll-target="#understanding-natural-language">Understanding natural language</a></li>
  <li><a href="#the-first-agi" id="toc-the-first-agi" class="nav-link" data-scroll-target="#the-first-agi">The first AGI</a></li>
  <li><a href="#growth-economics-of-the-agi-society" id="toc-growth-economics-of-the-agi-society" class="nav-link" data-scroll-target="#growth-economics-of-the-agi-society">Growth economics of the AGI society</a></li>
  <li><a href="#effects-of-a-large-agi-society-upon-human-society" id="toc-effects-of-a-large-agi-society-upon-human-society" class="nav-link" data-scroll-target="#effects-of-a-large-agi-society-upon-human-society">Effects of a large AGI society upon human society</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#afterthoughts-on-the-time-scale-of-a.i." id="toc-afterthoughts-on-the-time-scale-of-a.i." class="nav-link" data-scroll-target="#afterthoughts-on-the-time-scale-of-a.i.">Afterthoughts on the time scale of A.I.</a></li>
  <li><a href="#appendix-metadata" id="toc-appendix-metadata" class="nav-link" data-scroll-target="#appendix-metadata">Appendix: metadata</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="transcribers-notes" class="level2">
<h2 class="anchored" data-anchor-id="transcribers-notes">Transcriber’s notes</h2>
<p>Other than adding in the subsection titles, I preserved the original text.</p>
<section id="explicit-numerical-predictions" class="level3">
<h3 class="anchored" data-anchor-id="explicit-numerical-predictions">Explicit numerical predictions</h3>
<p>Milestones:</p>
<ul>
<li><strong>1956</strong>: Milestone A (Dartmouth Summer Study Group).</li>
<li><strong>1985</strong>: (the point at which this article was written)</li>
<li><strong>1986–2035</strong>: Milestone B (a general theory of problem solving in AI), 1 to 50 years after Milestone A.</li>
<li><strong>1991–2045</strong>: Milestones C (self-improving AI) and D (English comprehension) after Milestone B, 5 to 10 years after Milestone B.</li>
<li><strong>2005</strong>: Hardware cost of a Milestone E machine to be <span class="math inline">\(\sim 10^5\)</span> USD.</li>
<li><strong>2001–2055</strong>: Milestone E (human-level AI in specific fields), “a few years” (10 years?) after Milestones C and D.</li>
<li><strong>2011–2065</strong>: Milestone F (same number of human-level AI as human computer scientists), 10 years after achieving Milestone E.
<ul>
<li>Solomonoff assumed that the computer scientist community has 10,000 people.</li>
</ul></li>
<li><strong>2022–2076</strong>: Milestone G (AI greatly surpassing human scientific community), 11 years after Milestone F.
<ul>
<li>It is modelled as the point where 10,000 human-brain-equivalent machines cost 100 million dollars, at an investment rate of 10 million dollars per year.</li>
<li>The idea of Milestone G is that, assuming Moore’s law (the growth rate of <code>FLOP per second per USD</code>) is proportional to the number of computer scientists, then after AI computer scientists occur, the growth rate becomes hyperbolic, and it diverges to infinity in 11 years.</li>
</ul></li>
</ul>
<p>Compute cost</p>
<ul>
<li><strong>4 years</strong>: Moore’s law, i.e.&nbsp;the time it takes to double <code>FLOP per second per USD</code>.</li>
<li><strong>10 million USD</strong>: Estimated cost of 1 human-brain-equivalent machine in 1985.</li>
<li><strong>100 million USD</strong>: Projected cost of 10,000 human-brain-equivalent machines in 2025.</li>
</ul>
</section>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Six future milestones in AI are discussed. These range from the development of a very general theory of problem solving to the creation of machines with capacities well beyond those of a single human. Estimates are made for when these milestones will occur, followed by some suggestions for the more effective utilization of the extremely rapid technological growth that is expected.</p>
<p>Keywords: Artificial intelligence, social effects, future developments.</p>
</section>
<section id="essay" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="essay">Essay</h2>
<p>I will first give a brief discussion of recent developments in AI, and then a description of the expected future milestones with estimates of when they will occur and some expected social effects.</p>
<p><em>Milestone A</em>. The ‘modern’ phase of AI can be regarded as beginning in <a href="https://en.wikipedia.org/wiki/Dartmouth_workshop">1956 at the Dartmouth Summer Study Group on Artificial Intelligence</a>. At that time many people in this field came from all over to talk about what they were doing and what they expected to do. It marked the beginning of the much accelerated work in this area.</p>
<p>One of the earliest developments was the ‘<a href="https://en.wikipedia.org/wiki/General_Problem_Solver">General Problem Solver</a>’ of <a href="https://en.wikipedia.org/wiki/Allen_Newell">Newell</a> and <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon">Simon</a> – a first attempt at a general theory of AI. From this beginning, they moved on to study human problem solving – which developed into what is now called ‘cognitive psychology’. Parallel with this work, was the development of ‘<a href="https://en.wikipedia.org/wiki/Expert_system">expert systems</a>’, which depend not so much on general principles, but on knowledge of many facts in a particular field. Public awareness of these expert systems has grown rapidly in recent years<sub>1985</sub>, as has the fraction of AI manpower devoted to them.</p>
<p>Another very relevant development has been the study of large parallel computers with novel architectures. These studies are important because, first, the human brain is a very large parallel computer and the design and study of computers of this type can give the needed insight on how the human brain works. Another point is that the information processing capacity of present-day serial machines seems to be less than that of the human brain. If we are to emulate its behavior, we must have at least its computing capacity, and large parallel machines are most certainly the least expensive way to do this.</p>
<p><em>Milestone B</em>. The next milestone in the development of AI might be a general theory of problem solving. Here ‘problem solving’ is to be understood in a very general sense, and includes processes which, if they were performed by a human, would be regarded as ‘creative’ or ‘insightful’.</p>
<p>Some areas that would have to be covered by such a theory are:</p>
<ol type="1">
<li>Learning: based both on input data, and the machine’s own experience in problem solving;</li>
<li>Devising and testing new concepts to be used in solving problems;</li>
<li>Taking in information and storing it in a manner useful for problem solving; and</li>
<li>Methods of implementation on existing computers and/or the design of new kinds of computers that would be needed.</li>
</ol>
<p><em>Milestone C</em>. A critical point in AI development would be a machine that could usefully work on the problem of self-improvement. Newell and Simon were not successful in their attempts to get their ‘General Problem Solver’ to improve it’s own methods of operation. While <a href="https://en.wikipedia.org/wiki/Douglas_Lenat">Lenat</a>‘s’<a href="https://en.wikipedia.org/wiki/Eurisko">Eurisko</a>’ has been successful in several problem areas, he has not been able to get it to devise good heuristics for itself. He is, however, optimistic about the progress that has been made and is continuing this work.</p>
<p><em>Milestone D</em>. Another milestone will be a computer that can read almost any English text and incorporate most of the material into its data base – just as a human does. It would have to store the information in a form that is useful for solving whatever kinds of problems it is normally given.</p>
<p>Since there is an enormous amount of information available in electronic data bases all over the world, a machine with useful access to this information could grow very rapidly in its ability to solve problems and in a real sense in its understanding of the world.</p>
<p><em>Milestone E</em> will be a machine that has a general problem solving capacity near that of a human, in the areas for which it has been designed presumably in mathematics, science and industrial applications.</p>
<p><em>Milestone F</em> will be a machine with a capacity near that of the computer science community.</p>
<p><em>Milestone G</em> will be a machine with a capacity many times that of the computer science community.</p>
<section id="theory-of-agi" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="theory-of-agi">Theory of AGI</h3>
<p>Can we estimate when these milestones will occur?</p>
<p>For Milestone B – a general theory for AI – I feel that anything between 1 and 50 years is possible, with 2 to 25 years being much more likely. At present, there are too few people in AI working on theories of this sort. To aggravate the problem, recent commercial success of AI – mainly expert systems – has lured many bright graduate students away from general theory, to work on industrial applications.</p>
<p>Some promising work on general theory at the present time are: Lenat’s work, which I’ve mentioned <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>; and Bradshaw, Langley and Simon on how scientists discover scientific laws <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Lenat, D. and J. Brown, <em>Why AM and Eurisko appear to work</em>, in: Proceedings Nat. Conf. on AI, 22-26 August (1983) 236–240.</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Bradshaw, G., P. Langley and H. Simon, <em>Studying scientific discovery by computer simulation</em>, Science 222, 4627 (December 1983) 971–974.</p></div></div><p>Neither of these are explicit attempts at a general theory of intelligence, but they work on problems in ways that are readily generalized.</p>
<p>Some more direct work on general theory are: Minsky’s work ‘<a href="https://en.wikipedia.org/wiki/Society_of_Mind">The Society of Mind</a>’ is an attempt to describe the operation of the human brain in terms of a large number of small problem solvers working parallel with relatively infrequent intercommunication <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>; and my own work on training sequences, problem solving and learning <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Minsky, M., <em>The society of mind</em>, forthcoming.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;Solomonoff, R., <em>Perfect training sequences</em> (Oxbridge Research, Cambridge, MA, 1982).</p></div></div><p>It may be possible to get something that is superficially like Milestone E without a general theory. The current <a href="https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems">Japanese ‘5 th generation computer’ project</a> attempts to program a large number of ‘expert systems’ and put them all in a very large, very fast computer. Though expert systems all try to simulate parts of the human conscious mind, many of the more interesting human activities are mainly performed by the unconscious mind. If the unconscious mind works very much like the conscious mind (but we are merely less aware of its workings), then there is no difficulty here. However, if as is widely suspected, the unconscious mind is significantly different from the conscious – then the present expansion of expert systems will have serious limitations.</p>
<p>It is not necessary to know just how the unconscious mind works in order to emulate it – but slavishly imitating the workings of human consciousness would seem to be a poor approach.</p>
</section>
<section id="understanding-natural-language" class="level3">
<h3 class="anchored" data-anchor-id="understanding-natural-language">Understanding natural language</h3>
<p>Milestone D – understanding English – is being approached from several directions.</p>
<p>One is the study of ethnic languages, their grammars and semantics.</p>
<p>A somewhat different approach has been developed within the AI-community, in which machines are programmed to respond to commands or questions in English. The emphasis is on whether the program responds in the desired way, not on whether it ‘understands’ the input in terms of traditional grammatical and semantic concepts.</p>
<p>A third approach is through learning. The machine is taught English starting with very simple sentences. After it has learned to respond to them properly, it is given somewhat more complex sentences – just as a child learns language.</p>
<p>Most likely these three methods should be combined to obtain a system that acquires most rapidly, an understanding of English. The learning component is, I think, essential. The meaning of words and phrases vary considerably with context sometimes grossly, other times subtly. Programming all of these nuances into a machine would seem to be too arduous a task to be done well by a human. It would be far better and less subject to error, if the machine learned as humans do, how the larger context of a phrase controls its meaning.</p>
</section>
<section id="the-first-agi" class="level3">
<h3 class="anchored" data-anchor-id="the-first-agi">The first AGI</h3>
<p>When can we achieve Milestone E? Milestone B seems to be the most critical bottleneck. From that point to achieving both C and D might be as little as five or ten years, and from there to milestone E , only a few years more.</p>
<p>Let us examine the significance of Milestone E. At such a time we would have a machine with the problem-solving capability of a human, in several fields. For reasons that will become clear later, we will at first want to emphasize mathematics and science – computer science in particular.</p>
<p>Twenty years from now, the hardware cost of such a machine might be as little as several hundred thousand dollars, and it will be halved every four years or so.</p>
<p>At this rate, artificial intelligence will eventually cost less then human intelligence. Note that while the cost of training a very intelligent machine is very large, the cost of training the next one is very small, since the information in memory can be rapidly transferred from one machine to another.</p>
<p>The most important features of very intelligent machines are not related to their cost however. Machines of this sort are able to do things far beyond the capabilities of humans or groups of humans. For example, they can be designed to process information from many modalities very rapidly – optical, radar, sound, radio, telephone, etc. As our machines become faster, such processing would become invaluable in weather prediction or the administration and control of very large projects, such as space programs, the construction of ever-larger computers, and providing food and shelter for billions of people.</p>
</section>
<section id="growth-economics-of-the-agi-society" class="level3">
<h3 class="anchored" data-anchor-id="growth-economics-of-the-agi-society">Growth economics of the AGI society</h3>
<p>Some of the most critical capabilities of very intelligent machines depend on their being much more intelligent than humans. How long will it take to go to Milestone F and then to G?</p>
<p>The number of creative scientists and engineers that are responsible for the advancement of computer science, are at most several thousand. After we have reached Milestone E, it shouldn’t take much more than ten years to construct ten thousand duplicates of our original ‘Milestone E’ machine, and have a total computing capability close to that of the computer science community. The ten year figure seems reasonable when one notes that the cost of these machines will keep halving every four years or so, and also that the new ‘artificial’ computer scientists will help speed the construction of the new machines.</p>
<p>While there is normally an exponential decrease in computing cost with time (halving every four years or so), when the artificial intelligence community is as large as the human scientific community, the halving time itself will halve, so we get halving in two years instead of four.</p>
<p>Suppose <span class="math inline">\(c\)</span> is the size of our computer science community at time <span class="math inline">\(t\)</span>. We define this to be 1 at time zero. <span class="math inline">\(R\)</span> is the rate at which we expend money on our AI computers to effectively increase the size of our computer science community. <span class="math inline">\(t\)</span> is the time in years, from our origin point. <span class="math inline">\(x\)</span> is the amount of computing power we get for a dollar at a particular time. We will set <span class="math inline">\(x=1\)</span> at <span class="math inline">\(t=0\)</span>. First,</p>
<p><span class="math display">\[\mathrm{d} c / \mathrm{d} t=R x.\]</span></p>
<p>The rate of increase of our (partly artificial) computer science community is the product of our rate of expenditure times the efficiency of that expenditure. Next</p>
<p><span class="math display">\[\mathrm{d} \ln x / \mathrm{d} t=A c.\]</span></p>
<p>This says that the rate of change of the log of our efficiency is proportional to the size of our computer science community. If <span class="math inline">\(c\)</span> were to be kept constant at 1 , then we would want eq. (2) to give a doubling of <span class="math inline">\(x\)</span> every four years. This gives <span class="math inline">\(A=\)</span> (In 2) <span class="math inline">\(/ 4=0.1733\)</span>. With conditions <span class="math inline">\(c=1\)</span> and <span class="math inline">\(x=1\)</span> at <span class="math inline">\(t=0\)</span>, we obtain from (1) and (2)</p>
<p><span class="math display">\[
\mathrm{d} c / \mathrm{d} t=A\left(c^2-1\right) / 2+R
\]</span></p>
<p>This equation has the property that for any positive value of <span class="math inline">\(R\)</span>, the value of <span class="math inline">\(c\)</span> will at some finite time <span class="math inline">\(t=T\)</span>, approach infinity.</p>
<p><span class="math display">\[
\begin{aligned}
\text{For }R=1, &amp;T=4.62\text{ years},\\
\text{For }R=0.1, &amp;T=11.11\text{ years},\\
\text{For }R=0.01, &amp;T=21.51\text{ years},\\
\end{aligned}
\]</span></p>
<p>A value of <span class="math inline">\(R=1\)</span> means that if we kept <span class="math inline">\(x\)</span> constant at 1, at the end of one year we would have invested enough in our AI computer to equal its capacity to that of the human computer science community.</p>
<p>Usually, when infinities like this one occur in science, they indicate a breakdown of the validity of the equations as we approach the infinity point. The critical part of the equations appears to be continued exponential decrease in computation cost. So far, this rate of improvement has been possible only because of radically new technologies that were introduced – i.e.&nbsp;first vacuum tubes, then transistors, then integrated circuits, and then large scale integrated circuits. There appear to be several new technologies on the horizon that are adequate for maintaining the progress for several more orders of magnitude – as for the technologies over the horizon that have not yet been discovered, we only have a faith based on performance of the past.</p>
<p>A decrease in computation cost by a factor of 1000 would, at the present rate of progress, take about 40 years. At the present time, a reasonable guess at the cost of hardware with the computing power of a human brain might be ten million dollars. Ten thousand of such machines would cost 100 billion dollars now, and 100 million dollars forty years from now. This 100 million would put us at <span class="math inline">\(t=0\)</span> for eq. (3). At a continued expenditure of ten million dollars a year, it would take about 11 more years to get to the ‘infinity point’. Though infinity is a bit high, it seems very likely that we could achieve a growth factor of at least 100 in these 11 years – and so we reach Milestone G.</p>
</section>
<section id="effects-of-a-large-agi-society-upon-human-society" class="level3">
<h3 class="anchored" data-anchor-id="effects-of-a-large-agi-society-upon-human-society">Effects of a large AGI society upon human society</h3>
<p>What would be the effect of a scientific community equivalent that is 100 times as large as what we have now?</p>
<p>The last 100 years have seen the introduction of special and general relativity, automobiles, airplanes, quantum mechanics, large rockets and space travel, fission power, fusion bombs, lasers, and large digital computers. Any one of these might take a person years to appreciate and understand. Suppose that they had all been presented to mankind in a single year! This is the magnitude of ‘<a href="https://en.wikipedia.org/wiki/Future_Shock">future shock</a>’ that we can expect from our AI-expanded scientific community.</p>
<p>In the past, introduction of a new technology into the culture has usually been rather slow, so we had time to develop some understanding of its effect on us, to adjust the technology and culture for an optimum ‘coming together’. Even with a slow introduction, our use of a new technology has sometimes been very poor.</p>
<p>The use of nuclear energy for military purposes has been expensive, difficult to control and has obtained us neither military goals nor security of any sort. Nuclear energy for power generation in the United States, has cost much more than expected. In both cases we have had many years to consider how to use this technology best – yet, perhaps because of the difficulties of the problems involved, we have not done very well. We have spent enormous amounts of money and manpower and have attained relatively little of value.</p>
<p>Can we use very intelligent machines to help us solve the problems associated with the surfeit of new technologies of the future?</p>
<p>There appear to be at least two ways to do this.</p>
<p>First, attainment of Milestone B is likely to give us a much better understanding of the human mind than we have ever had. We should be able to get our intelligent machines to explain each new technology in a way that is intelligible to man. If this can’t be done, and the new technology is essentially un-understandable to man, then man would be foolish indeed to use it in any way!</p>
<p>However, understanding does not always assure success in dealing with very complex problems. Mankind will continue to have to make decisions under conditions of uncertainty. In the past he has usually chosen his courses of action relatively blindly – controlled more by his own perceived wants and needs than by considerations of the likelihoods of alternative possible futures and their effects upon him.</p>
<p>In this area, very intelligent machines can help us in one very important way – they can predict the results of social action.</p>
<p>Normally, there are several limitations, both theoretical and practical on our ability to predict the future accurately. These limitations are:</p>
<ol type="1">
<li>The models we use for prediction are not the best possible, and we are unable to find better ones;</li>
<li>We have a limited computing capacity and have already used all of it;</li>
<li>Predictions can be self-modifying: we can make the prediction, but as soon as we make it public, this brings about conditions that invalidate it;</li>
<li>Quantum mechanical limitation on prediction. This is to some extent similar to (3); and</li>
<li>Selectively feeding data to our predictor so that it obtains the result we think we want, or by otherwise biasing the prediction process.</li>
</ol>
<p>Difficulties 1 and 2 are both inherent in the nature of all real-world predictions. No matter how long we search for good models of our system, there is always the possibility that if we looked a little longer we would find a much better model. At Milestone G we will have much better models than we have now, as well as a much greater computing capacity for applying them.</p>
<p>Difficulty 3 is very important in predicting social action. If the prediction is self-denying, then there may exist no public prediction that is correct. If it is self-conforming, there may be several different predictions that can be made – any of which would be correct if made public. For example, one prediction might be that many people would be hurt and another might be that no-one was hurt. Under these conditions we would want to give the predictor ‘ethical guidelines’ upon which to make a choice, or have a human intermediary decide what prediction to make public.</p>
<p>Difficulty 5 is less of a problem if the machine has independent access to all available information. However, it is often possible for a human to inadvertently define a question so that the reply must be badly biased.</p>
<p>Within these necessary limitations we will be able to obtain much better predictions than ever before. And, as before, it is not certain that even this capability will be used wisely.</p>
<p>What seems most certain is that the future of man – both scientific and social – will be far more exciting than the wildest eras of the past.</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
</section>
<section id="afterthoughts-on-the-time-scale-of-a.i." class="level2">
<h2 class="anchored" data-anchor-id="afterthoughts-on-the-time-scale-of-a.i.">Afterthoughts on the time scale of A.I.</h2>
<p>“Better to have two experts in the same head than two in the same room.”</p>
<p>Often, after final corrections have been made on a paper, when it is no longer possible to make changes in it, one has second thoughts on some of the theorems or conjectures that were made.</p>
<p>In the present case, I have two afterthoughts which, to some extent have effects that cancel each other.</p>
<p>My estimate for the present day hardware cost of a machine having the information processing capacity of a human, may have been low by a factor of anywhere from 3 to 10.</p>
<p>On the other hand, I feel that my estimate of the machine size necessary to emulate the community of computer scientists may have been high by a factor of at least the same amount and probably much more.</p>
<p>The reason is that multiplying the information processing capacity of a machine by <span class="math inline">\(n\)</span> increases its scientific productivity by a factor of much more than <span class="math inline">\(n\)</span>. In the case of humans, two scientists, working more or less independently, will have about twice the productivity of one.</p>
<p>If, however, these scientists are able to communicate very well, the productivity is far greater. Note that this communication is largely verbal via channels of very small capacity. They have very poor access to non-verbal concepts used in each others “internal language”.</p>
<p>In a large intelligent machine having many times single human information processing capacity, we expect that all parts of the machine will have very rapid access to each other, in all conceivable detail. This facilitates cooperation between these parts that is considerably more productive than communication between individual humans.</p>
</section>
<section id="appendix-metadata" class="level2">
<h2 class="anchored" data-anchor-id="appendix-metadata">Appendix: metadata</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Issue title: Artificial Intelligence</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>Guest editors: R.K. Lindsay</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Article type: Other</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Authors: Solomonoff, R.J.</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Affiliations: Oxbridge Research, P.O. Box 559, Cambridge, MA 02238, USA</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Keywords: Artificial intelligence, social effects, future developments</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>DOI: 10.3233/HSM-1985-5207</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>Journal: Human Systems Management, vol. 5, no. 2, pp. 149-153, 1985</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>Published: 1 June 1985</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The original paper has the following description of Solomonoff:</p>
<blockquote class="blockquote">
<p>R. Solomonoff was graduated from the University of Chicago in 1951 with a degree in Physics. Since that time he has mainly been working on the mechanization of inductive inference – the most successful approach being algorithmic complexity theory. He has extended this theory to include the optimization of both hardware and software for general problem solving. He is now a principal scientist at Oxbridge Research, Cambridge, MA.</p>
</blockquote>


<!-- -->

</section>


</main> <!-- /main -->
<!-- file: html/copy‑anchors-js.html -->

<script type="module">

document.addEventListener("DOMContentLoaded", () => {

  // 1. All little ¶ icons Quarto/AnchorJS adds

  document.querySelectorAll("a.anchorjs-link").forEach(anchor => {

    anchor.addEventListener("click", async (evt) => {

      // Keep normal scroll behaviour but stop full page reload

      evt.preventDefault();



      // Build absolute URL: origin + path + #hash

      const url = `${location.origin}${location.pathname}${anchor.getAttribute("href")}`;



      // 2. Try modern Clipboard API first

      try {

        await navigator.clipboard.writeText(url);

      } catch {

        // 3. Fallback for legacy browsers

        const helper = Object.assign(document.createElement("input"), { value: url });

        document.body.appendChild(helper);

        helper.select();

        document.execCommand("copy");

        helper.remove();

      }

      // TODO: The following two doesn't work yet

      // 4. Brief visual confirmation (optional)

      anchor.dataset.tooltip = "Copied!";

      setTimeout(() => delete anchor.dataset.tooltip, 1500);



      // 5. Still jump to the heading

      history.pushState(null, "", anchor.getAttribute("href"));

    }, false);

  });

});

</script>

<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yuxi\.ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb2" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "The time scale of artificial intelligence"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Reflections on social effects"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ray Solomonoff"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "1985-06-01"</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [AI]</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"> html:</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">  toc: true</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Ray Solomonoff's 1985 essay on forecasting the progress towards AGI, reaching AGI around 2022--2076."</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "finished"</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "log"</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 10</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transcriber's notes</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>Other than adding in the subsection titles, I preserved the original text.</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explicit numerical predictions</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>Milestones:</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**1956**: Milestone A (Dartmouth Summer Study Group).</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**1985**: (the point at which this article was written)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**1986--2035**: Milestone B (a general theory of problem solving in AI), 1 to 50 years after Milestone A.</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**1991--2045**: Milestones C (self-improving AI) and D (English comprehension) after Milestone B, 5 to 10 years after Milestone B.</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**2005**: Hardware cost of a Milestone E machine to be $\sim 10^5$ USD.</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**2001--2055**: Milestone E (human-level AI in specific fields), "a few years" (10 years?) after Milestones C and D.</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**2011--2065**: Milestone F (same number of human-level AI as human computer scientists), 10 years after achieving Milestone E.</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Solomonoff assumed that the computer scientist community has 10,000 people.</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**2022--2076**: Milestone G (AI greatly surpassing human scientific community), 11 years after Milestone F.</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>It is modelled as the point where 10,000 human-brain-equivalent machines cost 100 million dollars, at an investment rate of 10 million dollars per year.</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>The idea of Milestone G is that, assuming Moore's law (the growth rate of <span class="in">`FLOP per second per USD`</span>) is proportional to the number of computer scientists, then after AI computer scientists occur, the growth rate becomes hyperbolic, and it diverges to infinity in 11 years.</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>Compute cost</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**4 years**: Moore's law, i.e. the time it takes to double <span class="in">`FLOP per second per USD`</span>.</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**10 million USD**: Estimated cost of 1 human-brain-equivalent machine in 1985.</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**100 million USD**: Projected cost of 10,000 human-brain-equivalent machines in 2025.</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Abstract</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>Six future milestones in AI are discussed. These range from the development of a very general theory of problem solving to the creation of machines with capacities well beyond those of a single human. Estimates are made for when these milestones will occur, followed by some suggestions for the more effective utilization of the extremely rapid technological growth that is expected.</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>Keywords: Artificial intelligence, social effects, future developments.</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="fu">## Essay</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>I will first give a brief discussion of recent developments in AI, and then a description of the expected future milestones with estimates of when they will occur and some expected social effects.</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>*Milestone A*. The 'modern' phase of AI can be regarded as beginning in <span class="co">[</span><span class="ot">1956 at the Dartmouth Summer Study Group on Artificial Intelligence</span><span class="co">](https://en.wikipedia.org/wiki/Dartmouth_workshop)</span>. At that time many people in this field came from all over to talk about what they were doing and what they expected to do. It marked the beginning of the much accelerated work in this area.</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>One of the earliest developments was the '<span class="co">[</span><span class="ot">General Problem Solver</span><span class="co">](https://en.wikipedia.org/wiki/General_Problem_Solver)</span>' of <span class="co">[</span><span class="ot">Newell</span><span class="co">](https://en.wikipedia.org/wiki/Allen_Newell)</span> and <span class="co">[</span><span class="ot">Simon</span><span class="co">](https://en.wikipedia.org/wiki/Herbert_A._Simon)</span> -- a first attempt at a general theory of AI. From this beginning, they moved on to study human problem solving -- which developed into what is now called 'cognitive psychology'. Parallel with this work, was the development of '<span class="co">[</span><span class="ot">expert systems</span><span class="co">](https://en.wikipedia.org/wiki/Expert_system)</span>', which depend not so much on general principles, but on knowledge of many facts in a particular field. Public awareness of these expert systems has grown rapidly in recent years<span class="dt">&lt;</span><span class="kw">sub</span><span class="dt">&gt;</span>1985<span class="dt">&lt;/</span><span class="kw">sub</span><span class="dt">&gt;</span>, as has the fraction of AI manpower devoted to them.</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>Another very relevant development has been the study of large parallel computers with novel architectures. These studies are important because, first, the human brain is a very large parallel computer and the design and study of computers of this type can give the needed insight on how the human brain works. Another point is that the information processing capacity of present-day serial machines seems to be less than that of the human brain. If we are to emulate its behavior, we must have at least its computing capacity, and large parallel machines are most certainly the least expensive way to do this.</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>*Milestone B*. The next milestone in the development of AI might be a general theory of problem solving. Here 'problem solving' is to be understood in a very general sense, and includes processes which, if they were performed by a human, would be regarded as 'creative' or 'insightful'.</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>Some areas that would have to be covered by such a theory are:</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Learning: based both on input data, and the machine's own experience in problem solving;</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Devising and testing new concepts to be used in solving problems;</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Taking in information and storing it in a manner useful for problem solving; and</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Methods of implementation on existing computers and/or the design of new kinds of computers that would be needed.</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>*Milestone C*. A critical point in AI development would be a machine that could usefully work on the problem of self-improvement. Newell and Simon were not successful in their attempts to get their 'General Problem Solver' to improve it's own methods of operation. While <span class="co">[</span><span class="ot">Lenat</span><span class="co">](https://en.wikipedia.org/wiki/Douglas_Lenat)</span>'s '<span class="co">[</span><span class="ot">Eurisko</span><span class="co">](https://en.wikipedia.org/wiki/Eurisko)</span>' has been successful in several problem areas, he has not been able to get it to devise good heuristics for itself. He is, however, optimistic about the progress that has been made and is continuing this work.</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>*Milestone D*. Another milestone will be a computer that can read almost any English text and incorporate most of the material into its data base -- just as a human does. It would have to store the information in a form that is useful for solving whatever kinds of problems it is normally given.</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>Since there is an enormous amount of information available in electronic data bases all over the world, a machine with useful access to this information could grow very rapidly in its ability to solve problems and in a real sense in its understanding of the world.</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>*Milestone E* will be a machine that has a general problem solving capacity near that of a human, in the areas for which it has been designed presumably in mathematics, science and industrial applications.</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>*Milestone F* will be a machine with a capacity near that of the computer science community.</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>*Milestone G* will be a machine with a capacity many times that of the computer science community.</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory of AGI</span></span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>Can we estimate when these milestones will occur?</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>For Milestone B -- a general theory for AI -- I feel that anything between 1 and 50 years is possible, with 2 to 25 years being much more likely. At present, there are too few people in AI working on theories of this sort. To aggravate the problem, recent commercial success of AI -- mainly expert systems -- has lured many bright graduate students away from general theory, to work on industrial applications.</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>Some promising work on general theory at the present time are: Lenat's work, which I've mentioned <span class="ot">[^1]</span>; and Bradshaw, Langley and Simon on how scientists discover scientific laws <span class="ot">[^2]</span>.</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>Neither of these are explicit attempts at a general theory of intelligence, but they work on problems in ways that are readily generalized.</span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>Some more direct work on general theory are: Minsky's work '<span class="co">[</span><span class="ot">The Society of Mind</span><span class="co">](https://en.wikipedia.org/wiki/Society_of_Mind)</span>' is an attempt to describe the operation of the human brain in terms of a large number of small problem solvers working parallel with relatively infrequent intercommunication <span class="ot">[^3]</span>; and my own work on training sequences, problem solving and learning <span class="ot">[^4]</span>.</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>It may be possible to get something that is superficially like Milestone E without a general theory. The current <span class="co">[</span><span class="ot">Japanese '5 th generation computer' project</span><span class="co">](https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Systems)</span> attempts to program a large number of 'expert systems' and put them all in a very large, very fast computer. Though expert systems all try to simulate parts of the human conscious mind, many of the more interesting human activities are mainly performed by the unconscious mind. If the unconscious mind works very much like the conscious mind (but we are merely less aware of its workings), then there is no difficulty here. However, if as is widely suspected, the unconscious mind is significantly different from the conscious -- then the present expansion of expert systems will have serious limitations.</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>It is not necessary to know just how the unconscious mind works in order to emulate it -- but slavishly imitating the workings of human consciousness would seem to be a poor approach.</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a><span class="fu">### Understanding natural language</span></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>Milestone D -- understanding English -- is being approached from several directions.</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>One is the study of ethnic languages, their grammars and semantics.</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>A somewhat different approach has been developed within the AI-community, in which machines are programmed to respond to commands or questions in English. The emphasis is on whether the program responds in the desired way, not on whether it 'understands' the input in terms of traditional grammatical and semantic concepts.</span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>A third approach is through learning. The machine is taught English starting with very simple sentences. After it has learned to respond to them properly, it is given somewhat more complex sentences -- just as a child learns language.</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>Most likely these three methods should be combined to obtain a system that acquires most rapidly, an understanding of English. The learning component is, I think, essential. The meaning of words and phrases vary considerably with context sometimes grossly, other times subtly. Programming all of these nuances into a machine would seem to be too arduous a task to be done well by a human. It would be far better and less subject to error, if the machine learned as humans do, how the larger context of a phrase controls its meaning.</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### The first AGI</span></span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>When can we achieve Milestone E? Milestone B seems to be the most critical bottleneck. From that point to achieving both C and D might be as little as five or ten years, and from there to milestone E , only a few years more.</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>Let us examine the significance of Milestone E. At such a time we would have a machine with the problem-solving capability of a human, in several fields. For reasons that will become clear later, we will at first want to emphasize mathematics and science -- computer science in particular.</span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>Twenty years from now, the hardware cost of such a machine might be as little as several hundred thousand dollars, and it will be halved every four years or so.</span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a>At this rate, artificial intelligence will eventually cost less then human intelligence. Note that while the cost of training a very intelligent machine is very large, the cost of training the next one is very small, since the information in memory can be rapidly transferred from one machine to another.</span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>The most important features of very intelligent machines are not related to their cost however. Machines of this sort are able to do things far beyond the capabilities of humans or groups of humans. For example, they can be designed to process information from many modalities very rapidly -- optical, radar, sound, radio, telephone, etc. As our machines become faster, such processing would become invaluable in weather prediction or the administration and control of very large projects, such as space programs, the construction of ever-larger computers, and providing food and shelter for billions of people.</span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a><span class="fu">### Growth economics of the AGI society</span></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a>Some of the most critical capabilities of very intelligent machines depend on their being much more intelligent than humans. How long will it take to go to Milestone F and then to G?</span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>The number of creative scientists and engineers that are responsible for the advancement of computer science, are at most several thousand. After we have reached Milestone E, it shouldn't take much more than ten years to construct ten thousand duplicates of our original 'Milestone E' machine, and have a total computing capability close to that of the computer science community. The ten year figure seems reasonable when one notes that the cost of these machines will keep halving every four years or so, and also that the new 'artificial' computer scientists will help speed the construction of the new machines.</span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a>While there is normally an exponential decrease in computing cost with time (halving every four years or so), when the artificial intelligence community is as large as the human scientific community, the halving time itself will halve, so we get halving in two years instead of four.</span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>Suppose $c$ is the size of our computer science community at time $t$. We define this to be 1 at time zero. $R$ is the rate at which we expend money on our AI computers to effectively increase the size of our computer science community. $t$ is the time in years, from our origin point. $x$ is the amount of computing power we get for a dollar at a particular time. We will set $x=1$ at $t=0$. First, </span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a>$$\mathrm{d} c / \mathrm{d} t=R x.$$</span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>The rate of increase of our (partly artificial) computer science community is the product of our rate of expenditure times the efficiency of that expenditure. Next</span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a>$$\mathrm{d} \ln x / \mathrm{d} t=A c.$$</span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a>This says that the rate of change of the log of our efficiency is proportional to the size of our computer science community. If $c$ were to be kept constant at 1 , then we would want eq. (2) to give a doubling of $x$ every four years. This gives $A=$ (In 2) $/ 4=0.1733$. With conditions $c=1$ and $x=1$ at $t=0$, we obtain from (1) and (2)</span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>\mathrm{d} c / \mathrm{d} t=A\left(c^2-1\right) / 2+R</span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a>This equation has the property that for any positive value of $R$, the value of $c$ will at some finite time $t=T$, approach infinity.</span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>\text{For }R=1, &amp;T=4.62\text{ years},<span class="sc">\\</span></span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>\text{For }R=0.1, &amp;T=11.11\text{ years},<span class="sc">\\</span></span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a>\text{For }R=0.01, &amp;T=21.51\text{ years},<span class="sc">\\</span></span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a>A value of $R=1$ means that if we kept $x$ constant at 1, at the end of one year we would have invested enough in our AI computer to equal its capacity to that of the human computer science community.</span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a>Usually, when infinities like this one occur in science, they indicate a breakdown of the validity of the equations as we approach the infinity point. The critical part of the equations appears to be continued exponential decrease in computation cost. So far, this rate of improvement has been possible only because of radically new technologies that were introduced -- i.e. first vacuum tubes, then transistors, then integrated circuits, and then large scale integrated circuits. There appear to be several new technologies on the horizon that are adequate for maintaining the progress for several more orders of magnitude -- as for the technologies over the horizon that have not yet been discovered, we only have a faith based on performance of the past.</span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a>A decrease in computation cost by a factor of 1000 would, at the present rate of progress, take about 40 years. At the present time, a reasonable guess at the cost of hardware with the computing power of a human brain might be ten million dollars. Ten thousand of such machines would cost 100 billion dollars now, and 100 million dollars forty years from now. This 100 million would put us at $t=0$ for eq. (3). At a continued expenditure of ten million dollars a year, it would take about 11 more years to get to the 'infinity point'. Though infinity is a bit high, it seems very likely that we could achieve a growth factor of at least 100 in these 11 years -- and so we reach Milestone G.</span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a><span class="fu">### Effects of a large AGI society upon human society</span></span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a>What would be the effect of a scientific community equivalent that is 100 times as large as what we have now?</span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-162"><a href="#cb2-162" aria-hidden="true" tabindex="-1"></a>The last 100 years have seen the introduction of special and general relativity, automobiles, airplanes, quantum mechanics, large rockets and space travel, fission power, fusion bombs, lasers, and large digital computers. Any one of these might take a person years to appreciate and understand. Suppose that they had all been presented to mankind in a single year! This is the magnitude of '<span class="co">[</span><span class="ot">future shock</span><span class="co">](https://en.wikipedia.org/wiki/Future_Shock)</span>' that we can expect from our AI-expanded scientific community.</span>
<span id="cb2-163"><a href="#cb2-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-164"><a href="#cb2-164" aria-hidden="true" tabindex="-1"></a>In the past, introduction of a new technology into the culture has usually been rather slow, so we had time to develop some understanding of its effect on us, to adjust the technology and culture for an optimum 'coming together'. Even with a slow introduction, our use of a new technology has sometimes been very poor.</span>
<span id="cb2-165"><a href="#cb2-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-166"><a href="#cb2-166" aria-hidden="true" tabindex="-1"></a>The use of nuclear energy for military purposes has been expensive, difficult to control and has obtained us neither military goals nor security of any sort. Nuclear energy for power generation in the United States, has cost much more than expected. In both cases we have had many years to consider how to use this technology best -- yet, perhaps because of the difficulties of the problems involved, we have not done very well. We have spent enormous amounts of money and manpower and have attained relatively little of value.</span>
<span id="cb2-167"><a href="#cb2-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-168"><a href="#cb2-168" aria-hidden="true" tabindex="-1"></a>Can we use very intelligent machines to help us solve the problems associated with the surfeit of new technologies of the future?</span>
<span id="cb2-169"><a href="#cb2-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-170"><a href="#cb2-170" aria-hidden="true" tabindex="-1"></a>There appear to be at least two ways to do this.</span>
<span id="cb2-171"><a href="#cb2-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-172"><a href="#cb2-172" aria-hidden="true" tabindex="-1"></a>First, attainment of Milestone B is likely to give us a much better understanding of the human mind than we have ever had. We should be able to get our intelligent machines to explain each new technology in a way that is intelligible to man. If this can't be done, and the new technology is essentially un-understandable to man, then man would be foolish indeed to use it in any way!</span>
<span id="cb2-173"><a href="#cb2-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-174"><a href="#cb2-174" aria-hidden="true" tabindex="-1"></a>However, understanding does not always assure success in dealing with very complex problems. Mankind will continue to have to make decisions under conditions of uncertainty. In the past he has usually chosen his courses of action relatively blindly -- controlled more by his own perceived wants and needs than by considerations of the likelihoods of alternative possible futures and their effects upon him.</span>
<span id="cb2-175"><a href="#cb2-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-176"><a href="#cb2-176" aria-hidden="true" tabindex="-1"></a>In this area, very intelligent machines can help us in one very important way -- they can predict the results of social action.</span>
<span id="cb2-177"><a href="#cb2-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-178"><a href="#cb2-178" aria-hidden="true" tabindex="-1"></a>Normally, there are several limitations, both theoretical and practical on our ability to predict the future accurately.</span>
<span id="cb2-179"><a href="#cb2-179" aria-hidden="true" tabindex="-1"></a>These limitations are:</span>
<span id="cb2-180"><a href="#cb2-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-181"><a href="#cb2-181" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The models we use for prediction are not the best possible, and we are unable to find better ones;</span>
<span id="cb2-182"><a href="#cb2-182" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We have a limited computing capacity and have already used all of it;</span>
<span id="cb2-183"><a href="#cb2-183" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Predictions can be self-modifying: we can make the prediction, but as soon as we make it </span>
<span id="cb2-184"><a href="#cb2-184" aria-hidden="true" tabindex="-1"></a>public, this brings about conditions that invalidate it;</span>
<span id="cb2-185"><a href="#cb2-185" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Quantum mechanical limitation on prediction. This is to some extent similar to (3); and</span>
<span id="cb2-186"><a href="#cb2-186" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Selectively feeding data to our predictor so that it obtains the result we think we want, or by otherwise biasing the prediction process.</span>
<span id="cb2-187"><a href="#cb2-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-188"><a href="#cb2-188" aria-hidden="true" tabindex="-1"></a>Difficulties 1 and 2 are both inherent in the nature of all real-world predictions. No matter how long we search for good models of our system, there is always the possibility that if we looked a little longer we would find a much better model. At Milestone G we will have much better models than we have now, as well as a much greater computing capacity for applying them.</span>
<span id="cb2-189"><a href="#cb2-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-190"><a href="#cb2-190" aria-hidden="true" tabindex="-1"></a>Difficulty 3 is very important in predicting social action. If the prediction is self-denying, then there may exist no public prediction that is correct. If it is self-conforming, there may be several different predictions that can be made -- any of which would be correct if made public. For example, one prediction might be that many people would be hurt and another might be that no-one was hurt. Under these conditions we would want to give the predictor 'ethical guidelines' upon which to make a choice, or have a human intermediary decide what prediction to make public.</span>
<span id="cb2-191"><a href="#cb2-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-192"><a href="#cb2-192" aria-hidden="true" tabindex="-1"></a>Difficulty 5 is less of a problem if the machine has independent access to all available information. However, it is often possible for a human to inadvertently define a question so that the reply must be badly biased.</span>
<span id="cb2-193"><a href="#cb2-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-194"><a href="#cb2-194" aria-hidden="true" tabindex="-1"></a>Within these necessary limitations we will be able to obtain much better predictions than ever before. And, as before, it is not certain that even this capability will be used wisely.</span>
<span id="cb2-195"><a href="#cb2-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-196"><a href="#cb2-196" aria-hidden="true" tabindex="-1"></a>What seems most certain is that the future of man -- both scientific and social -- will be far more exciting than the wildest eras of the past.</span>
<span id="cb2-197"><a href="#cb2-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-198"><a href="#cb2-198" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb2-199"><a href="#cb2-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-200"><a href="#cb2-200" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Lenat, D. and J. Brown, *Why AM and Eurisko appear to work*, in: Proceedings Nat. Conf. on AI, 22-26 August (1983) 236--240.</span>
<span id="cb2-201"><a href="#cb2-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-202"><a href="#cb2-202" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Bradshaw, G., P. Langley and H. Simon, *Studying scientific discovery by computer simulation*, Science 222, 4627 (December 1983) 971--974.</span>
<span id="cb2-203"><a href="#cb2-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-204"><a href="#cb2-204" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: </span>Minsky, M., *The society of mind*, forthcoming.</span>
<span id="cb2-205"><a href="#cb2-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-206"><a href="#cb2-206" aria-hidden="true" tabindex="-1"></a><span class="ot">[^4]: </span>Solomonoff, R., *Perfect training sequences* (Oxbridge Research, Cambridge, MA, 1982).</span>
<span id="cb2-207"><a href="#cb2-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-208"><a href="#cb2-208" aria-hidden="true" tabindex="-1"></a><span class="fu">## Afterthoughts on the time scale of A.I.</span></span>
<span id="cb2-209"><a href="#cb2-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-210"><a href="#cb2-210" aria-hidden="true" tabindex="-1"></a>"Better to have two experts in the same head than two in the same room."</span>
<span id="cb2-211"><a href="#cb2-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-212"><a href="#cb2-212" aria-hidden="true" tabindex="-1"></a>Often, after final corrections have been made on a paper, when it is no longer possible to make changes in it, one has second thoughts on some of the theorems or conjectures that were made.</span>
<span id="cb2-213"><a href="#cb2-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-214"><a href="#cb2-214" aria-hidden="true" tabindex="-1"></a>In the present case, I have two afterthoughts which, to some extent have effects that cancel each other.</span>
<span id="cb2-215"><a href="#cb2-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-216"><a href="#cb2-216" aria-hidden="true" tabindex="-1"></a>My estimate for the present day hardware cost of a machine having the information processing capacity of a human, may have been low by a factor of anywhere from 3 to 10.</span>
<span id="cb2-217"><a href="#cb2-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-218"><a href="#cb2-218" aria-hidden="true" tabindex="-1"></a>On the other hand, I feel that my estimate of the machine size necessary to emulate the community of computer scientists may have been high by a factor of at least the same amount and probably much more.</span>
<span id="cb2-219"><a href="#cb2-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-220"><a href="#cb2-220" aria-hidden="true" tabindex="-1"></a>The reason is that multiplying the information processing capacity of a machine by $n$ increases its scientific productivity by a factor of much more than $n$. In the case of humans, two scientists, working more or less independently, will have about twice the productivity of one.</span>
<span id="cb2-221"><a href="#cb2-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-222"><a href="#cb2-222" aria-hidden="true" tabindex="-1"></a>If, however, these scientists are able to communicate very well, the productivity is far greater. Note that this communication is largely verbal via channels of very small capacity. They have very poor access to non-verbal concepts used in each others "internal language".</span>
<span id="cb2-223"><a href="#cb2-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-224"><a href="#cb2-224" aria-hidden="true" tabindex="-1"></a>In a large intelligent machine having many times single human information processing capacity, we expect that all parts of the machine will have very rapid access to each other, in all conceivable detail. This facilitates cooperation between these parts that is considerably more productive than communication between individual humans.</span>
<span id="cb2-225"><a href="#cb2-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-226"><a href="#cb2-226" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix: metadata</span></span>
<span id="cb2-227"><a href="#cb2-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-228"><a href="#cb2-228" aria-hidden="true" tabindex="-1"></a><span class="in">```txt</span></span>
<span id="cb2-229"><a href="#cb2-229" aria-hidden="true" tabindex="-1"></a><span class="in">Issue title: Artificial Intelligence</span></span>
<span id="cb2-230"><a href="#cb2-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-231"><a href="#cb2-231" aria-hidden="true" tabindex="-1"></a><span class="in">Guest editors: R.K. Lindsay</span></span>
<span id="cb2-232"><a href="#cb2-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-233"><a href="#cb2-233" aria-hidden="true" tabindex="-1"></a><span class="in">Article type: Other</span></span>
<span id="cb2-234"><a href="#cb2-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-235"><a href="#cb2-235" aria-hidden="true" tabindex="-1"></a><span class="in">Authors: Solomonoff, R.J.</span></span>
<span id="cb2-236"><a href="#cb2-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-237"><a href="#cb2-237" aria-hidden="true" tabindex="-1"></a><span class="in">Affiliations: Oxbridge Research, P.O. Box 559, Cambridge, MA 02238, USA</span></span>
<span id="cb2-238"><a href="#cb2-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-239"><a href="#cb2-239" aria-hidden="true" tabindex="-1"></a><span class="in">Keywords: Artificial intelligence, social effects, future developments</span></span>
<span id="cb2-240"><a href="#cb2-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-241"><a href="#cb2-241" aria-hidden="true" tabindex="-1"></a><span class="in">DOI: 10.3233/HSM-1985-5207</span></span>
<span id="cb2-242"><a href="#cb2-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-243"><a href="#cb2-243" aria-hidden="true" tabindex="-1"></a><span class="in">Journal: Human Systems Management, vol. 5, no. 2, pp. 149-153, 1985</span></span>
<span id="cb2-244"><a href="#cb2-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-245"><a href="#cb2-245" aria-hidden="true" tabindex="-1"></a><span class="in">Published: 1 June 1985</span></span>
<span id="cb2-246"><a href="#cb2-246" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb2-247"><a href="#cb2-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-248"><a href="#cb2-248" aria-hidden="true" tabindex="-1"></a>The original paper has the following description of Solomonoff:</span>
<span id="cb2-249"><a href="#cb2-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-250"><a href="#cb2-250" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; R. Solomonoff was graduated from the University of Chicago in 1951 with a degree in Physics. Since that time he has mainly been working on the mechanization of inductive inference -- the most successful approach being algorithmic complexity theory. He has extended this theory to include the optimization of both hardware and software for general problem solving. He is now a principal scientist at Oxbridge Research, Cambridge, MA.</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>