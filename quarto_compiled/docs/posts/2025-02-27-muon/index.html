<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jianlin Su">
<meta name="dcterms.date" content="2025-02-27">
<meta name="description" content="Translation of several blogposts by Su Jianlin, describing the intuition behind the development of Muon.">

<title>The Muon Anthology – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-493ec8732bc442be923a7677f0a4f8b4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js" integrity="sha512-EKW5YvKU3hpyyOcN6jQnAxO/L8gts+YdYV6Yymtl8pk9YlYFtqJgihORuRoBXK8/cOIlappdU6Ms8KdK6yBCgA==" crossorigin="anonymous" referrerpolicy="no-referrer">

    </script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">

<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">

</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="The Muon Anthology – Yuxi on the Wired">
<meta property="og:description" content="Translation of several blogposts by Su Jianlin, describing the intuition behind the development of Muon.">
<meta property="og:image" content="https://yuxi.ml/docs/posts/2025-02-27-muon/figure/125501438.jpeg">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta name="twitter:title" content="The Muon Anthology – Yuxi on the Wired">
<meta name="twitter:description" content="Translation of several blogposts by Su Jianlin, describing the intuition behind the development of Muon.">
<meta name="twitter:image" content="https://yuxi.ml/docs/posts/2025-02-27-muon/figure/125501438.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../logs/index.html"> 
<span class="menu-text">Logs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi_liu@berkeley.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../feeds.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">The Muon Anthology</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Translation of several blogposts by Su Jianlin, describing the intuition behind the development of Muon.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">scaling</div>
                <div class="quarto-category">translation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Jianlin Su </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 27, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 27, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-learning-rate-batch-size" id="toc-sec-learning-rate-batch-size" class="nav-link active" data-scroll-target="#sec-learning-rate-batch-size">How should the learning rate change as batch size increase?</a>
  <ul class="collapse">
  <li><a href="#from-the-perspective-of-variance" id="toc-from-the-perspective-of-variance" class="nav-link" data-scroll-target="#from-the-perspective-of-variance">From the perspective of variance</a>
  <ul class="collapse">
  <li><a href="#square-root" id="toc-square-root" class="nav-link" data-scroll-target="#square-root">Square root</a></li>
  <li><a href="#sec-linear-scaling" id="toc-sec-linear-scaling" class="nav-link" data-scroll-target="#sec-linear-scaling">Linear scaling</a></li>
  </ul></li>
  <li><a href="#facing-losses-head-on" id="toc-facing-losses-head-on" class="nav-link" data-scroll-target="#facing-losses-head-on">Facing losses head on</a>
  <ul class="collapse">
  <li><a href="#monotonic-convergence" id="toc-monotonic-convergence" class="nav-link" data-scroll-target="#monotonic-convergence">Monotonic convergence</a></li>
  <li><a href="#empirical-analysis" id="toc-empirical-analysis" class="nav-link" data-scroll-target="#empirical-analysis">Empirical analysis</a></li>
  <li><a href="#sample-efficiency" id="toc-sample-efficiency" class="nav-link" data-scroll-target="#sample-efficiency">Sample efficiency</a></li>
  </ul></li>
  <li><a href="#with-adaptive-learning-rates" id="toc-with-adaptive-learning-rates" class="nav-link" data-scroll-target="#with-adaptive-learning-rates">With adaptive learning rates</a>
  <ul class="collapse">
  <li><a href="#symbolic-approximation" id="toc-symbolic-approximation" class="nav-link" data-scroll-target="#symbolic-approximation">Symbolic approximation</a></li>
  <li><a href="#two-special-cases" id="toc-two-special-cases" class="nav-link" data-scroll-target="#two-special-cases">Two special cases</a></li>
  <li><a href="#surge-phenomenon" id="toc-surge-phenomenon" class="nav-link" data-scroll-target="#surge-phenomenon">Surge phenomenon</a></li>
  <li><a href="#efficiency-relation" id="toc-efficiency-relation" class="nav-link" data-scroll-target="#efficiency-relation">Efficiency relation</a></li>
  <li><a href="#one-more-thing" id="toc-one-more-thing" class="nav-link" data-scroll-target="#one-more-thing">One more thing</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-learning-rate-hessian-approximation" id="toc-sec-learning-rate-hessian-approximation" class="nav-link" data-scroll-target="#sec-learning-rate-hessian-approximation">Adaptive learning rate optimizers from a Hessian approximation point of view</a>
  <ul class="collapse">
  <li><a href="#newtons-method" id="toc-newtons-method" class="nav-link" data-scroll-target="#newtons-method">Newton’s method</a></li>
  <li><a href="#gradient-approximation" id="toc-gradient-approximation" class="nav-link" data-scroll-target="#gradient-approximation">Gradient approximation</a></li>
  <li><a href="#related-work" id="toc-related-work" class="nav-link" data-scroll-target="#related-work">Related work</a></li>
  <li><a href="#more-connections" id="toc-more-connections" class="nav-link" data-scroll-target="#more-connections">More connections</a></li>
  </ul></li>
  <li><a href="#sec-muon-appreciation" id="toc-sec-muon-appreciation" class="nav-link" data-scroll-target="#sec-muon-appreciation">Muon appreciation: a fundamental advance from vectors to matrices</a>
  <ul class="collapse">
  <li><a href="#first-taste" id="toc-first-taste" class="nav-link" data-scroll-target="#first-taste">First taste</a></li>
  <li><a href="#sign-function" id="toc-sign-function" class="nav-link" data-scroll-target="#sign-function">Sign function</a></li>
  <li><a href="#iterative-solution" id="toc-iterative-solution" class="nav-link" data-scroll-target="#iterative-solution">Iterative solution</a></li>
  <li><a href="#convergence-acceleration" id="toc-convergence-acceleration" class="nav-link" data-scroll-target="#convergence-acceleration">Convergence acceleration</a></li>
  <li><a href="#some-thoughts" id="toc-some-thoughts" class="nav-link" data-scroll-target="#some-thoughts">Some thoughts</a></li>
  <li><a href="#norm-perspective" id="toc-norm-perspective" class="nav-link" data-scroll-target="#norm-perspective">Norm perspective</a></li>
  <li><a href="#matrix-norms" id="toc-matrix-norms" class="nav-link" data-scroll-target="#matrix-norms">Matrix norms</a></li>
  <li><a href="#going-further-back" id="toc-going-further-back" class="nav-link" data-scroll-target="#going-further-back">Going further back</a></li>
  </ul></li>
  <li><a href="#thoughts-on-spectral-norm-gradients-and-new-forms-of-weight-decay" id="toc-thoughts-on-spectral-norm-gradients-and-new-forms-of-weight-decay" class="nav-link" data-scroll-target="#thoughts-on-spectral-norm-gradients-and-new-forms-of-weight-decay">Thoughts on spectral norm gradients and new forms of weight decay</a>
  <ul class="collapse">
  <li><a href="#basic-review" id="toc-basic-review" class="nav-link" data-scroll-target="#basic-review">Basic review</a></li>
  <li><a href="#gradient-derivation" id="toc-gradient-derivation" class="nav-link" data-scroll-target="#gradient-derivation">Gradient derivation</a></li>
  <li><a href="#weight-decay" id="toc-weight-decay" class="nav-link" data-scroll-target="#weight-decay">Weight decay</a></li>
  <li><a href="#numerical-computation" id="toc-numerical-computation" class="nav-link" data-scroll-target="#numerical-computation">Numerical computation</a></li>
  <li><a href="#proof-of-iteration" id="toc-proof-of-iteration" class="nav-link" data-scroll-target="#proof-of-iteration">Proof of iteration</a></li>
  <li><a href="#related-work-1" id="toc-related-work-1" class="nav-link" data-scroll-target="#related-work-1">Related Work</a></li>
  </ul></li>
  <li><a href="#why-is-the-default-scale-of-gradient-clipping-1" id="toc-why-is-the-default-scale-of-gradient-clipping-1" class="nav-link" data-scroll-target="#why-is-the-default-scale-of-gradient-clipping-1">Why is the default scale of gradient clipping 1?</a>
  <ul class="collapse">
  <li><a href="#what-does-it-mean" id="toc-what-does-it-mean" class="nav-link" data-scroll-target="#what-does-it-mean">What does it mean?</a></li>
  <li><a href="#why-does-this-happen" id="toc-why-does-this-happen" class="nav-link" data-scroll-target="#why-does-this-happen">Why does this happen?</a></li>
  <li><a href="#what-to-do" id="toc-what-to-do" class="nav-link" data-scroll-target="#what-to-do">What to do?</a></li>
  </ul></li>
  <li><a href="#sec-muon-sequel" id="toc-sec-muon-sequel" class="nav-link" data-scroll-target="#sec-muon-sequel">Muon sequel: Why did we choose to give Muon a try?</a>
  <ul class="collapse">
  <li><a href="#optimization-principles" id="toc-optimization-principles" class="nav-link" data-scroll-target="#optimization-principles">Optimization principles</a></li>
  <li><a href="#matrix-norms-1" id="toc-matrix-norms-1" class="nav-link" data-scroll-target="#matrix-norms-1">Matrix norms</a></li>
  <li><a href="#weight-decay-1" id="toc-weight-decay-1" class="nav-link" data-scroll-target="#weight-decay-1">Weight decay</a></li>
  <li><a href="#rms-alignment" id="toc-rms-alignment" class="nav-link" data-scroll-target="#rms-alignment">RMS alignment</a></li>
  <li><a href="#experiments" id="toc-experiments" class="nav-link" data-scroll-target="#experiments">Experiments</a></li>
  <li><a href="#some-more-thoughts" id="toc-some-more-thoughts" class="nav-link" data-scroll-target="#some-more-thoughts">Some more thoughts</a></li>
  
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="sec-learning-rate-batch-size" class="level1">
<h1>How should the learning rate change as batch size increase?</h1>
<p><a href="https://kexue.fm/archives/10542">当batch size增大时，学习率该如何随之变化？ - 科学空间|Scientific Spaces</a> (2024-11-14)</p>
<p>With the rapid advancement of computing power, we often want to “trade compute for time” – that is, reduce the wallclock time of model training by parallel-scaling the FLOP/sec with more chips. Ideally, we hope that with <span class="math inline">\(n\)</span> times the FLOP/sec, the time to achieve the same effect would be reduced to <span class="math inline">\(1/n\)</span>, keeping the total FLOP cost consistent. This hope seems reasonable and natural, but it’s actually non-trivial. Even if we don’t consider parallel bottlenecks like communication, when computing power exceeds a certain scale or when models are smaller than a certain size, we generally can only utilize further compute-scaling by scaling the batch size. However, does increasing batch size always reduce training time while maintaining performance?</p>
<p>This is the topic we’ll discuss: When batch size increases, how should various hyperparameters, especially the learning rate, be adjusted to maintain the original training effect and maximize training efficiency? We can also call this the <a href="https://en.wikipedia.org/wiki/Neural_scaling_law">scaling law</a> between batch size and learning rate.</p>
<section id="from-the-perspective-of-variance" class="level2">
<h2 class="anchored" data-anchor-id="from-the-perspective-of-variance">From the perspective of variance</h2>
<p>Intuitively, when batch size increases, the gradient of each batch will be more accurate, so we can take bigger steps, meaning increasing the learning rate, to reach the goal faster and shorten training time. Most people can generally understand this point. The question is, how much should we increase the learning rate to be most appropriate?</p>
<section id="square-root" class="level3">
<h3 class="anchored" data-anchor-id="square-root">Square root</h3>
<p>The earliest answer to this question might be square root scaling, meaning <span class="math inline">\(n\times\)</span> batch size should translate to <span class="math inline">\(\sqrt{n}\times\)</span> learning rate. This comes from the 2014 paper <a href="https://arxiv.org/abs/1404.5997"><em>One weird trick for parallelizing convolutional neural networks</em></a>, with the derivation principle being to keep the variance of SGD increments constant. Specifically, we denote the gradient from randomly sampling one sample as <span class="math inline">\(\tilde{\boldsymbol{g}}\)</span>, with its mean and covariance denoted as <span class="math inline">\(\boldsymbol{g}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> respectively, where <span class="math inline">\(\boldsymbol{g}\)</span> is the gradient of all samples. When we increase the sampling number to <span class="math inline">\(B\)</span>, we have:</p>
<p><span class="math display">\[
\begin{equation}\tilde{\boldsymbol{g}}_B \triangleq \frac{1}{B}\sum_{i=1}^B \tilde{\boldsymbol{g}}^{(i)},\quad \mathbb{E}[\tilde{\boldsymbol{g}}_B] = \boldsymbol{g},\quad \mathbb{E}[(\tilde{\boldsymbol{g}}_B-\boldsymbol{g})(\tilde{\boldsymbol{g}}_B-\boldsymbol{g})^{\top}]=\frac{\boldsymbol{\Sigma}}{B}\end{equation}
\]</span></p>
<p>That is, increasing the number of samples doesn’t change the mean, but the covariance shrinks to <span class="math inline">\(1/B\)</span>. For the SGD optimizer, the increment is <span class="math inline">\(-\eta \tilde{\boldsymbol{g}}_B\)</span>, and its covariance is proportional to <span class="math inline">\(\eta^2/B\)</span>. We believe that an appropriate amount of noise (neither too much nor too little) is necessary in the optimization process, so when batch size <span class="math inline">\(B\)</span> changes, we adjust the learning rate <span class="math inline">\(\eta\)</span> to keep the noise intensity, i.e., the covariance matrix of the increment, constant, which leads to:</p>
<p><span class="math display">\[
\begin{equation}\frac{\eta^2}{B} = \text{Constant}\quad\Rightarrow\quad \eta\propto \sqrt{B}\end{equation}
\]</span></p>
<p>This gives us the square root scaling law between learning rate and batch size. Later, <a href="https://arxiv.org/abs/1705.08741"><em>Train longer, generalize better: closing the generalization gap in large batch training of neural networks</em></a> also endorsed this choice.</p>
</section>
<section id="sec-linear-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-linear-scaling">Linear scaling</h3>
<p>Interestingly, linear scaling, i.e., <span class="math inline">\(\eta\propto B\)</span>, often performs better in practice. Even those who first proposed square root scaling in <a href="https://arxiv.org/abs/1404.5997"><em>One weird trick for parallelizing convolutional neural networks</em></a> pointed this out in their paper and stated they couldn’t provide a reasonable explanation for it.</p>
<p>In some sense, linear scaling better matches our intuitive understanding, especially as in <a href="https://arxiv.org/abs/1706.02677"><em>Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</em></a>. Indeed, if the gradient direction of <span class="math inline">\(n\)</span> consecutive minibatches doesn’t change much, then if we batch those <span class="math inline">\(n\)</span> minibatches into one batch, we would be dividing by <span class="math inline">\(\frac{1}{nB}\)</span>, yielding <span class="math inline">\(\approx \frac{1}{n} \sum_{i=1}^B g_i\)</span>. So to compensate for that, we should scale learnig rate by <span class="math inline">\(n\)</span>.</p>
<p>However, assuming that all <span class="math inline">\(g_i\)</span> should point in roughly the same direction is clearly too strong. Relaxing this assumption requires connecting SGD with SDE (Stochastic Differential Equations), which was accomplished by <a href="https://arxiv.org/abs/1811.01558"><em>Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations</em></a>, but the first paper to use this to analyze the relationship between learning rate and batch size should be <a href="https://arxiv.org/abs/2006.15081"><em>On the Generalization Benefit of Noise in Stochastic Gradient Descent</em></a>.</p>
<p>In hindsight, establishing this connection isn’t hard to understand. Let the model parameters be <span class="math inline">\(\boldsymbol{\theta}\)</span>, then the SGD update rule can be rewritten as:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{\theta}_{t+1} =\boldsymbol{\theta}_t - \eta \tilde{\boldsymbol{g}}_{B,t} =\boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta (\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t)\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t\)</span> is the noise in the gradient. Up to this point, we haven’t made any assumptions about the distribution of this noise, only knowing its mean is <span class="math inline">\(\boldsymbol{0}\)</span> and its covariance is <span class="math inline">\(\boldsymbol{\Sigma}_t/B\)</span>. Next, we assume this noise follows a normal distribution <span class="math inline">\(\mathcal{N}(\boldsymbol{0},\boldsymbol{\Sigma}_t/B)\)</span>, then the above iteration can be further rewritten as:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\boldsymbol{\theta}_{t+1} =&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta (\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t) \\
=&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta \sqrt{\frac{\boldsymbol{\Sigma}_t}{B}}\boldsymbol{z},\quad \boldsymbol{z}\sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I}) \\
=&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \sqrt{\eta} \sqrt{\frac{\eta\boldsymbol{\Sigma}_t}{B}}\boldsymbol{z},\quad \boldsymbol{z}\sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I}) \end{aligned}\end{equation}
\]</span></p>
<p>This means the SGD iteration format <span class="math inline">\(\boldsymbol{\theta}_{t+1} =\boldsymbol{\theta}_t - \eta \tilde{\boldsymbol{g}}_{B,t}\)</span> is actually approximating the solution to the SDE:</p>
<p><span class="math display">\[
\begin{equation}d\boldsymbol{\theta} = - \boldsymbol{g}_t dt - \sqrt{\frac{\eta\boldsymbol{\Sigma}_t}{B}}d\boldsymbol{w}\end{equation}
\]</span></p>
<p>Therefore, to ensure the running results don’t change significantly when <span class="math inline">\(B\)</span> changes, the form of the above SDE should remain unchanged, which gives us linear scaling <span class="math inline">\(\eta\propto B\)</span>. The most crucial step in this process is that <u>the step size of the noise term in SDE is the square root of the non-noise term</u>, thus separating out a term <span class="math inline">\(\sqrt{\eta}\)</span>. We’ve also commented on this in <a href="https://kexue.fm/archives/9209"><em>A Casual Discussion of Generative Diffusion Models (Part 5): General Framework SDE Chapter</em></a>. Simply put, zero-mean Gaussian noise has a certain cancellation effect over the long term, so the step size must be increased to manifest the noise effect.</p>
<p>The above conclusions are all based on the SGD optimizer. The paper <a href="https://arxiv.org/abs/2205.10287"><em>On the SDEs and Scaling Rules for Adaptive Gradient Algorithms</em></a> extended it to optimizers like RMSprop and Adam, resulting in <u>square root scaling</u>. Similarly, the slightly earlier <a href="https://arxiv.org/abs/1904.00962"><em>Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</em></a> also applied square root scaling when testing Adam and its variant LAMB. More content can be found in the blogpost <a href="https://www.cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/"><em>How to Scale Hyperparameters as Batch Size Increases</em></a>.</p>
</section>
</section>
<section id="facing-losses-head-on" class="level2">
<h2 class="anchored" data-anchor-id="facing-losses-head-on">Facing losses head on</h2>
<p>It’s certain that whether it’s square root scaling or linear scaling, they can only hold approximately within a local range, because they both include the conclusion that, as long as the batch size is large enough, the learning rate can be arbitrarily large. That is obviously impossible. Additionally, the previous two sections focused on variance, but our fundamental task is to reduce the loss function, so we should start with the loss function.</p>
<section id="monotonic-convergence" class="level3">
<h3 class="anchored" data-anchor-id="monotonic-convergence">Monotonic convergence</h3>
<p>A classic work from this perspective is OpenAI’s <a href="https://arxiv.org/abs/1812.06162"><em>An Empirical Model of Large-Batch Training</em></a>, which analyzes the optimal learning rate for SGD through a second-order approximation of the loss function, concluding that the learning rate increases monotonically with batch size, but has an upper bound. The same approach also appeared in the slightly earlier <a href="https://arxiv.org/abs/1705.07774"><em>Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients</em></a>, though that paper wasn’t used to analyze the role of batch size.</p>
<p>The key to the entire derivation is to view the learning rate as an optimization parameter: Let the loss function be <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta})\)</span>, the current batch’s gradient be <span class="math inline">\(\tilde{\boldsymbol{g}}_B\)</span>, then the loss function after SGD is <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)\)</span>. We view the solution of the optimal learning rate as an optimization problem:</p>
<p><span class="math display">\[
\begin{equation}\eta^* = \mathop{\text{argmin}}_{\eta} \mathbb{E}[\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)]\end{equation}
\]</span></p>
<p>This objective is obviously intuitive – choose the learning rate to make the training efficiency the highest (the loss function decreases the fastest) <u>on average</u>. To solve this problem, we approximately expand the loss function to the second order:</p>
<p><span class="math display">\[
\begin{equation}\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B) \approx \mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\underbrace{\frac{\partial \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}}_{= \boldsymbol{g}} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\underbrace{\frac{\partial^2 \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^2}}_{\triangleq \boldsymbol{H}}\tilde{\boldsymbol{g}}_B = \mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\boldsymbol{H}\)</span> is the Hessian matrix, and <span class="math inline">\(\frac{\partial \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}\)</span> is the gradient of the loss function. The ideal objective function <span class="math inline">\(\mathcal L\)</span> is the loss averaged over all samples, which is why its gradient <span class="math inline">\(\boldsymbol{g}\)</span> is the average of <span class="math inline">\(\tilde{\boldsymbol{g}}_B\)</span>. Taking the expectation, we get:</p>
<p><span class="math display">\[
\begin{equation}\mathbb{E}[\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)] \approx \mathbb{E}[\mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B] = \mathcal{L}(\boldsymbol{\theta}) - \eta\boldsymbol{g}^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \mathbb{E}[\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B]\end{equation}
\]</span></p>
<p>The last term involves tricks with the cyclic property of trace:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\mathbb{E}[\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B] =&amp;\, \mathbb{E}[\text{Tr}(\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B)]= \mathbb{E}[\text{Tr}(\tilde{\boldsymbol{g}}_B\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H})] = \text{Tr}(\mathbb{E}[\tilde{\boldsymbol{g}}_B\tilde{\boldsymbol{g}}_B^{\top}]\boldsymbol{H})\\
=&amp;\, \text{Tr}((\boldsymbol{g}\boldsymbol{g}^{\top} + \boldsymbol{\Sigma}/B)\boldsymbol{H}) = \boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g} + \text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})/B
\end{aligned}\end{equation}
\]</span></p>
<p>Now, assuming <span class="math inline">\(\boldsymbol{H}\)</span> is positive definite (i.e.&nbsp;the loss function looks like a bowl), the problem becomes finding the minimum of a quadratic function:</p>
<p><span id="eq-eta-opt"><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\boldsymbol{g}^{\top}\boldsymbol{g}}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g} + \text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})/B} = \frac{\eta_{\max}}{1 + \mathcal{B}_{\text{noise}}/B}\end{equation}
\tag{1}\]</span></span></p>
<p>We can state this as “the learning rate increases monotonically with <span class="math inline">\(B\)</span> but has an upper bound”, where:</p>
<p><span class="math display">\[
\begin{equation}\eta_{\max} = \frac{\boldsymbol{g}^{\top}\boldsymbol{g}}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}},\qquad\mathcal{B}_{\text{noise}} = \frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\end{equation}
\]</span></p>
</section>
<section id="empirical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="empirical-analysis">Empirical analysis</h3>
<p>When <span class="math inline">\(B \ll \mathcal{B}_{\text{noise}}\)</span>, <span class="math inline">\(1 + \mathcal{B}_{\text{noise}}/B\approx \mathcal{B}_{\text{noise}}/B\)</span>, so <span class="math inline">\(\eta^* \approx \eta_{\max}B/\mathcal{B}_{\text{noise}}\propto B\)</span>, i.e., linear scaling, which again shows that linear scaling is only a local approximation for small batch sizes. When <span class="math inline">\(B &gt; \mathcal{B}_{\text{noise}}\)</span>, <span class="math inline">\(\eta^*\)</span> gradually approaches the saturation value <span class="math inline">\(\eta_{\max}\)</span>, meaning the increase in training cost far outweighs the improvement in training efficiency. Therefore, <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span> serves as a watershed – once the batch size exceeds this value, there’s no need to continue investing computing power to increase the batch size.</p>
<p>For practitioners, the most crucial question is undoubtedly how to estimate <span class="math inline">\(\eta_{\max}\)</span> and <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>, especially since <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span> directly affects the scaling law of learning rates and the saturation of training efficiency. Direct calculation of both involves the Hessian matrix <span class="math inline">\(\boldsymbol{H}\)</span>, whose computational cost is proportional to the square of the parameter count. In today’s world, where models with hundreds of millions of parameters are considered small, computing the Hessian matrix is clearly impractical, so more effective calculation methods must be sought.</p>
<p>Let’s first look at <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>. Its expression is <span class="math inline">\(\frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\)</span>, with an <span class="math inline">\(\boldsymbol{H}\)</span> in both numerator and denominator, which undoubtedly tempts us to “cancel them out”. In fact, the simplification approach is similar – assuming <span class="math inline">\(\boldsymbol{H}\)</span> approximates some multiple of the identity matrix, we get:</p>
<p><span class="math display">\[
\begin{equation}\mathcal{B}_{\text{noise}} = \frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\approx \frac{\text{Tr}(\boldsymbol{\Sigma})}{\boldsymbol{g}^{\top}\boldsymbol{g}}\triangleq \mathcal{B}_{\text{simple}}\end{equation}
\]</span></p>
<p><span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> is more computationally feasible, and experiments have found it’s usually a good approximation of <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>. Therefore, we choose to estimate <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> rather than <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>. Note that <span class="math inline">\(\text{Tr}(\boldsymbol{\Sigma})\)</span> only needs the elements on the diagonal, so there’s no need to compute the full covariance matrix – just calculate the variance for each gradient component separately and sum them up. In data-parallel scenarios, the gradient variances can be directly estimated using the gradients computed on each device.</p>
<p>It’s worth noting that the results in <a href="#eq-eta-opt" class="quarto-xref">Equation&nbsp;1</a> are actually dynamic, meaning theoretically, <span class="math inline">\(\eta_{\max}\)</span>, <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>, and <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> are different at each training step. So if we want to derive a static pattern, we need to train for a period of time until the model’s training enters the “right track” for the calculated <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> to be reliable. Alternatively, we can continuously monitor <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> during training to judge the gap between the current settings and the optimal ones.</p>
<p>As for <span class="math inline">\(\eta_{\max}\)</span>, there’s no need to estimate it according to the formula. We can directly perform a grid search for the learning rate under a small batch size to find an approximate <span class="math inline">\(\eta^*\)</span>, and then use the estimated <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> to deduce <span class="math inline">\(\eta_{\max}\)</span>.</p>
</section>
<section id="sample-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="sample-efficiency">Sample efficiency</h3>
<p>Starting from the above results, we can also derive an asymptotic relationship between the amount of training data and the number of training steps. The derivation is simple: substituting <a href="#eq-eta-opt" class="quarto-xref">Equation&nbsp;1</a> into the loss function, we can calculate that the reduction in the loss function brought by each iteration at the optimal learning rate is:</p>
<p><span id="eq-Delta-L-sgd"><span class="math display">\[
\begin{equation}\Delta\mathcal{L} = \mathcal{L}(\boldsymbol{\theta}) - \mathbb{E}[\mathcal{L}(\boldsymbol{\theta} - \eta^*\tilde{\boldsymbol{g}}_B)] \approx \frac{\Delta\mathcal{L}_{\max}}{1 + \mathcal{B}_{\text{noise}}/B}\end{equation}
\tag{2}\]</span></span></p>
<p>where <span class="math inline">\(\Delta\mathcal{L}_{\max} = \frac{(\boldsymbol{g}^{\top}\boldsymbol{g})^2}{2\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\)</span>. The focus now is on interpreting this result.</p>
<p>When <span class="math inline">\(B\to\infty\)</span>, i.e., full-batch SGD, the reduction in the loss function at each step reaches the maximum <span class="math inline">\(\Delta\mathcal{L}_{\max}\)</span>, allowing us to reach the target point with the minimum number of training steps (denoted as <span class="math inline">\(S_{\min}\)</span>). When <span class="math inline">\(B\)</span> is finite, the average reduction in the loss function at each step is only <span class="math inline">\(\Delta\mathcal{L}\)</span>, meaning we need <span class="math inline">\(1 + \mathcal{B}_{\text{noise}}/B\)</span> steps to achieve the same reduction as a single step of full-batch SGD. So the total number of training steps is roughly <span class="math inline">\(S = (1 + \mathcal{B}_{\text{noise}}/B)S_{\min}\)</span>.</p>
<p>Since the batch size is <span class="math inline">\(B\)</span>, the total number of samples consumed in the training process is <span class="math inline">\(E = BS = (B + \mathcal{B}_{\text{noise}})S_{\min}\)</span>, which is an increasing function of <span class="math inline">\(B\)</span>. When <span class="math inline">\(B\to 0\)</span>, <span class="math inline">\(E_{\min} = \mathcal{B}_{\text{noise}}S_{\min}\)</span>, indicating that as long as we use a sufficiently small batch size to train the model, the total number of training samples E will also decrease accordingly, at the cost of a very large number of training steps <span class="math inline">\(S\)</span>. Furthermore, using these notations, we can write the relationship between them as:</p>
<p><span id="eq-E-S"><span class="math display">\[
\begin{equation}\left(\frac{S}{S_{\min}} - 1\right)\left(\frac{E}{E_{\min}} - 1\right) = 1\end{equation}
\tag{3}\]</span></span></p>
<p>This is the scaling law between the amount of training data and the number of training steps, indicating that with less data, we should reduce the batch size and increase the number of training steps to have a better chance of reaching a more optimal solution. The derivation here has been simplified by me, assuming the invariance of <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span> and <span class="math inline">\(\Delta\mathcal{L}_{\max}\)</span> throughout the training process. If necessary, the dynamic changes can be handled more precisely using integration as in the original paper’s appendix (but requires introducing the assumption <span class="math inline">\(B = \sqrt{r\mathcal{B}_{\text{noise}}}\)</span>), which we won’t expand on here.</p>
<p>Additionally, since <span class="math inline">\(\mathcal{B}_{\text{noise}} = E_{\min}/S_{\min}\)</span>, the above equation also provides another approach to estimate <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>: obtain multiple (S,E) pairs through multiple experiments and grid searches, then fit the above equation to estimate <span class="math inline">\(E_{\min}\)</span> and <span class="math inline">\(S_{\min}\)</span>, and subsequently calculate <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>.</p>
</section>
</section>
<section id="with-adaptive-learning-rates" class="level2">
<h2 class="anchored" data-anchor-id="with-adaptive-learning-rates">With adaptive learning rates</h2>
<p>It must be said that OpenAI, as one of the pioneers of various Scaling Laws, deserves its reputation. The aforementioned analysis is quite brilliant, and the results are quite rich. What’s even more remarkable is that the entire derivation process is not complicated, giving a sense of elegant necessity. However, the work we have just worked through is all based on SGD, not applicable to adaptive learning rate optimizers like Adam was still unclear. That analysis was done by <a href="https://arxiv.org/abs/2405.14578"><em>Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling</em></a>.</p>
<section id="symbolic-approximation" class="level3">
<h3 class="anchored" data-anchor-id="symbolic-approximation">Symbolic approximation</h3>
<p>Adam is analyzed similarly as SGD, by second-order expansion. The difference is that the direction vector changes from <span class="math inline">\(\tilde{\boldsymbol{g}}_B\)</span> to a general vector <span class="math inline">\(\tilde{\boldsymbol{u}}_B\)</span>. In this case, we have:</p>
<p><span class="math display">\[
\begin{equation}\mathbb{E}[\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{u}}_B)] \approx \mathcal{L}(\boldsymbol{\theta}) - \eta\mathbb{E}[\tilde{\boldsymbol{u}}_B]^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \text{Tr}(\mathbb{E}[\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}]\boldsymbol{H})\end{equation}
\]</span></p>
<p>Now we need to determine <span class="math inline">\(\tilde{\boldsymbol{u}}_B\)</span> and calculate the corresponding <span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{u}}_B]\)</span> and <span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}]\)</span>. Since we only need an asymptotic relationship, just like in <a href="https://kexue.fm/archives/10001"><em>Configuring Different Learning Rates, Can LoRA Rise a Bit More?</em></a>, we choose SignSGD, i.e., <span class="math inline">\(\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)\)</span>, as an approximation for Adam. The earliest source of this approach might be <a href="https://arxiv.org/abs/1705.07774"><em>Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients</em></a>. The reasonableness of this approximation is reflected in two points:</p>
<ol type="1">
<li>Regardless of the values of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>, the update vector for Adam’s first step is always <span class="math inline">\(\text{sign}(\tilde{\boldsymbol{g}}_B)\)</span>;</li>
<li>When <span class="math inline">\(\beta_1=\beta_2=0\)</span>, Adam’s update vector is always <span class="math inline">\(\text{sign}(\tilde{\boldsymbol{g}}_B)\)</span>.</li>
</ol>
<p>To calculate <span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{u}}_B]\)</span> and <span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}]\)</span>, we also need to assume, as in the <a href="#sec-linear-scaling">Linear scaling</a> section, that <span class="math inline">\(\tilde{\boldsymbol{g}}_B\)</span> follows the distribution <span class="math inline">\(\mathcal{N}(\boldsymbol{g},\boldsymbol{\Sigma}/B)\)</span>. To simplify the calculation, we further assume that <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is a diagonal matrix <span class="math inline">\(\text{diag}(\sigma_1^2,\sigma_2^2,\sigma_3^2,\cdots)\)</span>, meaning that the components are independent of each other, allowing us to process each component independently. By reparameterization, <span class="math inline">\(\tilde{g}_B\sim \mathcal{N}(g, \sigma^2/B)\)</span> is equivalent to <span class="math inline">\(\tilde{g}_B=g + \sigma z/\sqrt{B},z\sim\mathcal{N}(0,1)\)</span>, therefore:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\mathbb{E}[\tilde{u}_B] =&amp;\, \mathbb{E}[\text{sign}(g + \sigma z/\sqrt{B})] = \mathbb{E}[\text{sign}(g\sqrt{B}/\sigma + z)] \\
=&amp;\,\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} \text{sign}(g\sqrt{B}/\sigma + z) e^{-z^2/2}dz \\
=&amp;\,\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{-g\sqrt{B}/\sigma}  (-1)\times e^{-z^2/2}dz + \frac{1}{\sqrt{2\pi}}\int_{-g\sqrt{B}/\sigma}^{\infty}  1\times e^{-z^2/2}dz \\
=&amp;\,\text{erf}\left(\frac{g}{\sigma}\sqrt{\frac{B}{2}}\right)
\end{aligned}\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\text{erf}\)</span> is the <a href="https://en.wikipedia.org/wiki/Error_function">error function</a>, which is an S-shaped function with a range of <span class="math inline">\((-1,1)\)</span> similar to <span class="math inline">\(\tanh\)</span>, and can serve as a smooth approximation of <span class="math inline">\(\text{sign}\)</span>. But since <span class="math inline">\(\text{erf}\)</span> itself doesn’t have an elementary function expression, it’s better to find an elementary function approximation to more intuitively observe the pattern of change. We’ve discussed this topic before in <a href="https://kexue.fm/archives/7309"><em>How the Two Elementary Function Approximations of GELU Came About</em></a>, but the approximations there are still too complex (involving exponential operations). Here we’ll use something simpler:</p>
<p><span class="math display">\[
\begin{equation}\text{erf}(x)\approx \text{sign}(x) = \frac{x}{|x|} = \frac{x}{\sqrt{x^2}}\approx \frac{x}{\sqrt{x^2+c}}\end{equation}
\]</span></p>
<p>We choose <span class="math inline">\(c=\pi/4\)</span> so that the first-order approximation of this approximation at <span class="math inline">\(x=0\)</span> equals the first-order approximation of <span class="math inline">\(\text{erf}\)</span>. Of course, after making so many approximations, the value of <span class="math inline">\(c\)</span> is not very important; we just need to know that such a <span class="math inline">\(c &gt; 0\)</span> exists. Based on this approximation, we get:</p>
<p><span class="math display">\[
\begin{equation}\mathbb{E}[\tilde{u}_B] \approx \frac{g/\sigma}{\sqrt{\pi/2B+(g/\sigma)^2}}\quad\Rightarrow\quad\mathbb{E}[\tilde{\boldsymbol{u}}_B]_i \approx \frac{g_i/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}}\triangleq \mu_i\end{equation}
\]</span></p>
<p>We can find that one obvious difference between Adam and SGD is that <span class="math inline">\(\mathbb{E}[\tilde{\boldsymbol{u}}_B]\)</span> is already related to <span class="math inline">\(B\)</span> at this step. However, the second moment is simpler now, because the square of <span class="math inline">\(\text{sign}(x)\)</span> is always 1, so:</p>
<p><span class="math display">\[
\begin{equation}\mathbb{E}[\tilde{u}_B^2] = 1\quad\Rightarrow\quad\mathbb{E}[\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}]_{i,j} \to\left\{\begin{aligned}&amp;=1, &amp; i = j \\
&amp;\approx\mu_i \mu_j,&amp;\,i\neq j\end{aligned}\right.\end{equation}
\]</span></p>
<p>Using these results, we can obtain:</p>
<p><span id="eq-eta-opt-sign"><span class="math display">\[
\eta^* \approx \frac{\mathbb{E}[\tilde{\boldsymbol{u}}_B]^{\top}\boldsymbol{g}}{\text{Tr}(\mathbb{E}[\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}]\boldsymbol{H})} \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}}
\tag{4}\]</span></span></p>
<p><span id="eq-Delta-L-sign"><span class="math display">\[
\Delta \mathcal{L} = \mathcal{L}(\boldsymbol{\theta}) - \mathbb{E}[\mathcal{L}(\boldsymbol{\theta} - \eta^*\tilde{\boldsymbol{u}}_B)] \approx \frac{1}{2}\frac{(\sum_i \mu_i g_i)^2}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}}
\tag{5}\]</span></span></p>
</section>
<section id="two-special-cases" class="level3">
<h3 class="anchored" data-anchor-id="two-special-cases">Two special cases</h3>
<p>Compared to SGD’s <a href="#eq-eta-opt" class="quarto-xref">Equation&nbsp;1</a>, Adam’s <a href="#eq-eta-opt-sign" class="quarto-xref">Equation&nbsp;4</a> is more complex, making it difficult to intuitively see its dependency pattern on <span class="math inline">\(B\)</span>. So we’ll start with a few special examples.</p>
<p>First, consider <span class="math inline">\(B\to\infty\)</span>. In this case, <span class="math inline">\(\mu_i = \text{sign}(g_i)\)</span>, so:</p>
<p><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\sum_i |g_i|}{\sum_i H_{i,i} + \sum_{i\neq j} \text{sign}(g_i g_j) H_{i,j}}\end{equation}
\]</span></p>
<p>The difference between this and SGD’s <span class="math inline">\(\eta_{\max}\)</span> is that it is not homogeneous with respect to the gradient, but proportional to the gradient’s scale.</p>
<p>Next, let’s consider the example where <span class="math inline">\(\boldsymbol{H}\)</span> is a diagonal matrix, i.e., <span class="math inline">\(H_{i,j}=0\)</span> when <span class="math inline">\(i\neq j\)</span>. In this case:</p>
<p><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i}}=\frac{1}{\sum_i H_{i,i}}\sum_i \frac{g_i^2/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}}\end{equation}
\]</span></p>
<p>Each term in the sum is monotonically increasing with an upper bound with respect to <span class="math inline">\(B\)</span>, so the total result is also like this. To capture the most essential pattern, we can consider further simplifying <span class="math inline">\(\mu_i\)</span> (this is where it starts to differ from the original paper):</p>
<p><span id="eq-mu-approx"><span class="math display">\[
\begin{equation}\mu_i = \frac{g_i/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}} = \frac{\text{sign}(g_i)}{\sqrt{1 + \pi(\sigma_i/g_i)^2/2B}} \approx \frac{\text{sign}(g_i)}{\sqrt{1 + \pi\kappa^2/2B}}\end{equation}
\tag{6}\]</span></span></p>
<p>The assumption here is that there exists a constant <span class="math inline">\(\kappa^2\)</span> independent of <span class="math inline">\(i\)</span> [for example, we can consider taking some kind of average of all <span class="math inline">\((\sigma_i/g_i)^2\)</span>; actually, this <span class="math inline">\(\kappa^2\)</span> is similar to the <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span> mentioned earlier, and it can also be estimated according to the definition of <span class="math inline">\(\mathcal{B}_{\text{simple}}\)</span>], such that replacing <span class="math inline">\((\sigma_i/g_i)^2\)</span> with <span class="math inline">\(\kappa^2\)</span> is a good approximation for any <span class="math inline">\(i\)</span>. Thus:</p>
<p><span id="eq-eta-opt-sign-diag"><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i}}\approx \frac{\sum_i |g_i|}{\sum_i H_{i,i}}\frac{1}{\sqrt{1 + \pi\kappa^2/2B}}\end{equation}
\tag{7}\]</span></span></p>
<p>When <span class="math inline">\(\pi\kappa^2\gg 2B\)</span>, i.e., <span class="math inline">\(B \ll \pi\kappa^2/2\)</span>, we can further write the approximation:</p>
<p><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\sum_i \sigma_i}{\kappa\sum_i H_{i,i}}\sqrt{\frac{2B}{\pi}} \propto \sqrt{B}\end{equation}
\]</span></p>
<p>This indicates that when the batch size itself is relatively small, Adam indeed applies to the square root scaling law.</p>
</section>
<section id="surge-phenomenon" class="level3">
<h3 class="anchored" data-anchor-id="surge-phenomenon">Surge phenomenon</h3>
<p>If we apply the approximation <a href="#eq-mu-approx" class="quarto-xref">Equation&nbsp;6</a> to the original <a href="#eq-eta-opt-sign" class="quarto-xref">Equation&nbsp;4</a>, we’ll find it exhibits some entirely new characteristics. Specifically, we have:</p>
<p><span id="eq-eta-opt-beta"><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}} \approx \frac{\eta_{\max}}{\frac{1}{2}\left(\frac{\beta_{\text{noise}}}{\beta} + \frac{\beta}{\beta_{\text{noise}}}\right)}\end{equation}
\tag{8}\]</span></span></p>
<p>where <span class="math inline">\(\beta = (1 + \pi\kappa^2/2B)^{-1/2}\)</span>, and:</p>
<p><span class="math display">\[
\begin{equation}\beta_{\text{noise}} = \sqrt{\frac{\sum_i H_{i,i}}{\sum_{i\neq j}\text{sign}(g_i g_j) H_{i,j}}},\quad \eta_{\max} = \frac{\sum_i |g_i|}{2\sqrt{\left(\sum_i H_{i,i}\right)\left(\sum_{i\neq j} \text{sign}(g_i g_j) H_{i,j}\right)}}\end{equation}
\]</span></p>
<p>Note that <span class="math inline">\(\beta\)</span> is a monotonically increasing function of <span class="math inline">\(B\)</span>, but the final approximation in <a href="#eq-eta-opt-beta" class="quarto-xref">Equation&nbsp;8</a> is not a monotonically increasing function of <span class="math inline">\(\beta\)</span>. Instead, it first increases and then decreases, reaching its maximum value at <span class="math inline">\(\beta=\beta_{\text{noise}}\)</span>. This implies that there exists a corresponding <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span> such that when the batch size exceeds this <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>, the optimal learning rate should not increase but rather decrease! This is the “surge phenomenon” mentioned in the title of the original paper. (Of course, there’s a limitation here: <span class="math inline">\(\beta\)</span> is always less than <span class="math inline">\(1\)</span>. If <span class="math inline">\(\beta_{\text{noise}} \geq 1\)</span>, then the relationship between the optimal learning rate and batch size remains monotonically increasing.)</p>
<p>Regarding Adam’s <span class="math inline">\(\eta^*\)</span>, OpenAI actually made an unproven conjecture in their paper’s appendix that Adam’s optimal learning rate should be:</p>
<p><span id="eq-openai-adam"><span class="math display">\[
\begin{equation}\eta^* \approx \frac{\eta_{\max}}{(1 + \mathcal{B}_{\text{noise}}/B)^{\alpha}}\end{equation}
\tag{9}\]</span></span></p>
<p>where <span class="math inline">\(0.5 &lt; \alpha &lt; 1\)</span>. It now appears that this form is only an approximate result when the diagonal elements of the Hessian matrix dominate. When the effect of non-diagonal elements cannot be ignored, the “surge phenomenon” may occur, that is, the learning rate should actually decrease when the batch size is large enough.</p>
<p>How can we intuitively understand the surge phenomenon? I believe it essentially reflects the <strong>suboptimality</strong> of adaptive learning rate strategies. Still taking the approximation <span class="math inline">\(\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)\)</span> as an example, the larger <span class="math inline">\(B\)</span> is, the more accurate <span class="math inline">\(\tilde{\boldsymbol{g}}_B\)</span> becomes. As <span class="math inline">\(B\to \infty\)</span>, we get <span class="math inline">\(\text{sign}(\boldsymbol{g})\)</span>, but is <span class="math inline">\(\text{sign}(\boldsymbol{g})\)</span> the most scientific update direction? Not necessarily, especially in the later stages of training where such adaptive strategies might even have negative effects. Therefore, when <span class="math inline">\(B\)</span> takes an appropriate value, the noise in <span class="math inline">\(\text{sign}(\tilde{\boldsymbol{g}}_B)\)</span> might actually correct this suboptimality. As <span class="math inline">\(B\)</span> continues to increase, the noise decreases, reducing the opportunity for correction, thus requiring more caution by lowering the learning rate.</p>
</section>
<section id="efficiency-relation" class="level3">
<h3 class="anchored" data-anchor-id="efficiency-relation">Efficiency relation</h3>
<p>Similar to the SGD analysis, we can also consider <span class="math inline">\(\Delta\mathcal{L}\)</span> by substituting <a href="#eq-eta-opt-beta" class="quarto-xref">Equation&nbsp;8</a> into <a href="#eq-Delta-L-sign" class="quarto-xref">Equation&nbsp;5</a>, restoring the notation <span class="math inline">\(B\)</span> and then simplifying (the simplification process doesn’t require any approximations) to get:</p>
<p><span id="eq-Delta-L-sign-2"><span class="math display">\[
\begin{equation}\Delta \mathcal{L} \approx \frac{\Delta \mathcal{L}_{\max}}{1 + \mathcal{B}_{\text{noise-2}}/B}\end{equation}
\tag{10}\]</span></span></p>
<p>where:</p>
<p><span id="eq-beta-B-noise"><span class="math display">\[
\begin{equation}\Delta \mathcal{L}_{\max} = \frac{\beta_{\text{noise}}\eta_{\max}\sum_i|g_i|}{1 + \beta_{\text{noise}}^2},\quad \mathcal{B}_{\text{noise-2}} = \frac{\pi\kappa^2\beta_{\text{noise}}^2}{2(1 + \beta_{\text{noise}}^2)}\end{equation}
\tag{11}\]</span></span></p>
<p>Note that <span class="math inline">\(\mathcal{B}_{\text{noise-2}}\)</span> is a new notation; it’s not <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>. The latter is derived by solving <span class="math inline">\(\beta=\beta_{\text{noise}}\)</span> for the theoretical optimal batch size, which gives:</p>
<p><span class="math display">\[
\begin{equation}\mathcal{B}_{\text{noise}} = \frac{\pi\kappa^2\beta_{\text{noise}}^2}{2(1 - \beta_{\text{noise}}^2)}\end{equation}
\]</span></p>
<p>The relationship between them is:</p>
<p><span id="eq-B-1-2"><span class="math display">\[
\begin{equation}\frac{1}{\mathcal{B}_{\text{noise-2}}} - \frac{1}{\mathcal{B}_{\text{noise}}} = \frac{4}{\pi\kappa^2}\quad\Rightarrow\quad \mathcal{B}_{\text{noise}} = \left(\frac{1}{\mathcal{B}_{\text{noise-2}}} - \frac{4}{\pi\kappa^2}\right)^{-1}\end{equation}
\tag{12}\]</span></span></p>
<p>Since <a href="#eq-Delta-L-sign-2" class="quarto-xref">Equation&nbsp;10</a> is formally the same as SGD’s <a href="#eq-Delta-L-sgd" class="quarto-xref">Equation&nbsp;2</a>, the analysis in that section applies here as well, and we can derive <a href="#eq-E-S" class="quarto-xref">Equation&nbsp;3</a>:</p>
<p><span class="math display">\[
\begin{equation}\left(\frac{S}{S_{\min}} - 1\right)\left(\frac{E}{E_{\min}} - 1\right) = 1\end{equation}
\]</span></p>
<p>Except now <span class="math inline">\(E_{\min}/S_{\min} = \mathcal{B}_{\text{noise-2}}\)</span>. This gives us a method to estimate <span class="math inline">\(\beta_{\text{noise}}\)</span> and <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>: conduct multiple experiments to obtain several <span class="math inline">\((S,E)\)</span> pairs, simultaneously estimating <span class="math inline">\(\kappa^2\)</span> during the experiments, then fit the above equation to get <span class="math inline">\(E_{\min},S_{\min}\)</span>, thereby estimating <span class="math inline">\(\mathcal{B}_{\text{noise-2}}\)</span>, and finally solve for <span class="math inline">\(\beta_{\text{noise}}\)</span> using <a href="#eq-beta-B-noise" class="quarto-xref">Equation&nbsp;11</a>.</p>
<p>If <span class="math inline">\(\beta_{\text{noise}} \geq 1\)</span>, there is no optimal <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span>. If <span class="math inline">\(\beta_{\text{noise}} \gg 1\)</span>, it indicates that the diagonal elements of the Hessian matrix dominate, in which case the scaling rule <a href="#eq-eta-opt-sign-diag" class="quarto-xref">Equation&nbsp;7</a> applies, and increasing the batch size can always appropriately increase the learning rate. When <span class="math inline">\(\beta_{\text{noise}} &lt; 1\)</span>, the optimal <span class="math inline">\(\mathcal{B}_{\text{noise}}\)</span> can be solved using <a href="#eq-B-1-2" class="quarto-xref">Equation&nbsp;12</a>, and if the batch size exceeds this value, the learning rate should actually decrease.</p>
</section>
<section id="one-more-thing" class="level3">
<h3 class="anchored" data-anchor-id="one-more-thing">One more thing</h3>
<p>It’s worth noting that the starting point and final conclusions of the analysis in the above sections are actually quite similar to those in the original paper <a href="https://arxiv.org/abs/2405.14578"><em>Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling</em></a>, although the approximation methods used in the intermediate process differ.</p>
<p>Most of the conclusions in the original paper are approximate results under the assumption that <span class="math inline">\(B \ll \pi(\sigma_i/g_i)^2/2\)</span>, which leads to the conclusion that the surge phenomenon almost always occurs. This is not very scientific. Most obviously, the form of the assumption <span class="math inline">\(B \ll \pi(\sigma_i/g_i)^2/2\)</span> itself is somewhat problematic, as its right side depends on <span class="math inline">\(i\)</span>. We can’t assign a separate batch size to each component, so to obtain a global result, we would need <span class="math inline">\(B \ll \min_i \pi(\sigma_i/g_i)^2/2\)</span>, which is rather stringent.</p>
<p>The approach in this article introduces the approximation <a href="#eq-mu-approx" class="quarto-xref">Equation&nbsp;6</a>, which can be seen as a mean-field approximation. Intuitively, it is more reasonable than the point-by-point assumption <span class="math inline">\(B \ll \pi(\sigma_i/g_i)^2/2\)</span>, so in principle, the conclusions should be more precise. For example, we can conclude that “even if the non-diagonal elements of the Hessian matrix cannot be ignored, the surge phenomenon may not necessarily occur” (depending on <span class="math inline">\(\beta_{\text{noise}}\)</span>). Importantly, this precision does not sacrifice simplicity. For instance, <a href="#eq-eta-opt-beta" class="quarto-xref">Equation&nbsp;8</a> is equally clear and concise, <a href="#eq-Delta-L-sign-2" class="quarto-xref">Equation&nbsp;10</a> has the same form as in the original paper, and no additional approximation assumptions are needed, and so on.</p>
<p>Finally, a small reflection: OpenAI’s analysis of SGD was actually done in 2018, while the surge phenomenon paper was only published in the middle of this year. It took 6 years to move from SGD to Adam, which is quite surprising. It seems that OpenAI’s prestige and their conjecture <a href="#eq-openai-adam" class="quarto-xref">Equation&nbsp;9</a> led people to believe that there wasn’t much more to do with Adam, not expecting that Adam might have some new properties. Of course, the question of how reasonable <span class="math inline">\(\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)\)</span> is as an approximation of Adam and to what extent it represents the actual situation is still worth further consideration.</p>
</section>
</section>
</section>
<section id="sec-learning-rate-hessian-approximation" class="level1 page-columns page-full">
<h1>Adaptive learning rate optimizers from a Hessian approximation point of view</h1>
<p>Source: <a href="https://kexue.fm/archives/10588">从Hessian近似看自适应学习率优化器 - 科学空间|Scientific Spaces</a> (2024-11-29)</p>
<p>These days I’ve been revisiting Meta’s paper from last year <a href="https://arxiv.org/abs/2304.09871">A Theory on Adam Instability in Large-Scale Machine Learning</a>, which presents a new perspective on adaptive learning rate optimizers like Adam: it points out that the moving average of squared gradients approximates the square of the Hessian matrix to some extent, making Adam, RMSprop and other optimizers actually approximate second-order Newton methods.</p>
<p>This perspective is quite novel and appears to differ significantly from previous Hessian approximations, making it worth studying and thinking about.</p>
<section id="newtons-method" class="level2">
<h2 class="anchored" data-anchor-id="newtons-method">Newton’s method</h2>
<p>Let the loss function be <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta})\)</span>, where the parameter to be optimized is <span class="math inline">\(\boldsymbol{\theta}\)</span>, and our optimization goal is</p>
<p><span id="eq-loss"><span class="math display">\[
\begin{equation}\boldsymbol{\theta}^* = \mathop{\text{argmin}}_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta})\end{equation}
\tag{13}\]</span></span></p>
<p>Assuming the current value of <span class="math inline">\(\boldsymbol{\theta}\)</span> is <span class="math inline">\(\boldsymbol{\theta}_t\)</span>, Newton’s method seeks <span class="math inline">\(\boldsymbol{\theta}_{t+1}\)</span> by expanding the loss function to the second order:</p>
<p><span class="math display">\[
\begin{equation}\mathcal{L}(\boldsymbol{\theta})\approx \mathcal{L}(\boldsymbol{\theta}_t) + \boldsymbol{g}_t^{\top}(\boldsymbol{\theta} - \boldsymbol{\theta}_t) + \frac{1}{2}(\boldsymbol{\theta} - \boldsymbol{\theta}_t)^{\top}\boldsymbol{\mathcal{H}}_t(\boldsymbol{\theta} - \boldsymbol{\theta}_t)\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{g}_t = \nabla_{\boldsymbol{\theta}_t}\mathcal{L}(\boldsymbol{\theta}_t)\)</span> is the gradient, and <span class="math inline">\(\boldsymbol{\mathcal{H}}_t=\nabla_{\boldsymbol{\theta}_t}^2\mathcal{L}(\boldsymbol{\theta}_t)\)</span> is the Hessian matrix. Assuming the positive definiteness of the Hessian matrix, the right side of the above equation has a unique minimum <span class="math inline">\(\boldsymbol{\theta}_t - \boldsymbol{\mathcal{H}}_t^{-1}\boldsymbol{g}_t\)</span>, which Newton’s method uses as the next step <span class="math inline">\(\boldsymbol{\theta}_{t+1}\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t-\boldsymbol{\mathcal{H}}_t^{-1}\boldsymbol{g}_t = \boldsymbol{\theta}_t - (\nabla_{\boldsymbol{\theta}_t}^2\mathcal{L})^{-1} \nabla_{\boldsymbol{\theta}_t}\mathcal{L}\end{equation}
\]</span></p>
<p>Note that the above equation does not have an additional learning rate parameter, so Newton’s method already has an adaptive learning rate. Of course, since the complexity of the Hessian matrix is proportional to the square of the parameter count, the complete Newton’s method has basically only theoretical value in deep learning. To apply Newton’s method in practice, significant simplifying assumptions about the Hessian matrix are needed, such as assuming it’s diagonal or low-rank.</p>
<p>From the Newton’s method perspective, SGD assumes <span class="math inline">\(\boldsymbol{\mathcal{H}}_t=\eta_t^{-1}\boldsymbol{I}\)</span>, while Adam assumes <span class="math inline">\(\boldsymbol{\mathcal{H}}_t=\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon)\)</span>, where</p>
<p><span class="math display">\[
\begin{equation}\text{Adam}\triangleq \left\{\begin{aligned}
&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t\\
&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t\odot\boldsymbol{g}_t\\
&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.\\
&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.\\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.
\end{aligned}\right.\end{equation}
\]</span></p>
<p>Next, we want to demonstrate that <span class="math inline">\(\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t})\)</span> is a better approximation of <span class="math inline">\(\boldsymbol{\mathcal{H}}_t\)</span>.</p>
</section>
<section id="gradient-approximation" class="level2">
<h2 class="anchored" data-anchor-id="gradient-approximation">Gradient approximation</h2>
<p>The key to the proof is using the first-order approximation of the gradient:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \approx \boldsymbol{g}_{\boldsymbol{\theta}^*} + \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{g}_{\boldsymbol{\theta}^*}\)</span> and <span class="math inline">\(\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\)</span> indicate that we expand at <span class="math inline">\(\boldsymbol{\theta}=\boldsymbol{\theta}^*\)</span>. Here, <span class="math inline">\(\boldsymbol{\theta}^*\)</span> is the target we are looking for <a href="#eq-loss" class="quarto-xref">Equation&nbsp;13</a>, at which point the model’s gradient is zero, so the above equation can be simplified to:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)\end{equation}
\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}}\boldsymbol{g}_{\boldsymbol{\theta}}^{\top} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)(\boldsymbol{\theta} - \boldsymbol{\theta}^*)^{\top}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}
\]</span></p>
<p>After training has entered the “grooves of convergence” like a train snapping to its rails, the model will be spiraling around <span class="math inline">\(\boldsymbol{\theta}^*\)</span> for a long time, converging slowly. To some extent, we can view <span class="math inline">\(\boldsymbol{\theta} - \boldsymbol{\theta}^*\)</span> as a random variable following a normal distribution <span class="math inline">\(\mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})\)</span>. Then:</p>
<p><span id="eq-hessian-2"><span class="math display">\[
\begin{equation}\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\boldsymbol{g}_{\boldsymbol{\theta}}^{\top}] \approx  \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\mathbb{E}[(\boldsymbol{\theta} - \boldsymbol{\theta}^*)(\boldsymbol{\theta} - \boldsymbol{\theta}^*)^{\top}]\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top} = \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}
\tag{14}\]</span></span></p>
<p>Assuming the Hessian matrix is diagonal, we can keep only the diagonal elements of the above equation:</p>
<p><span class="math display">\[
\begin{equation}\text{diag}(\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}]) \approx  \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^2\quad\Rightarrow\quad \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*} = \frac{1}{\sigma}\text{diag}(\sqrt{\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}]})\end{equation}
\]</span></p>
<p>Doesn’t that look a bit similar? Adam’s <span class="math inline">\(\hat{\boldsymbol{v}}_t\)</span> is a moving average of the squared gradient, which can be seen as an approximation of <span class="math inline">\(\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}]\)</span>. Finally, if we assume that <span class="math inline">\(\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\)</span>, we can conclude that <span class="math inline">\(\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t})\)</span> is an approximation of <span class="math inline">\(\boldsymbol{\mathcal{H}}_t\)</span>.</p>
<p>This can also explain why Adam’s <span class="math inline">\(\beta_2\)</span> is usually greater than <span class="math inline">\(\beta_1\)</span>. To estimate the Hessian more accurately, the moving average of <span class="math inline">\(\hat{\boldsymbol{v}}_t\)</span> should be as “long-term” as possible (close to uniform averaging), so <span class="math inline">\(\beta_2\)</span> should be very close to 1. However, if the momentum <span class="math inline">\(\hat{\boldsymbol{m}}_t\)</span>, which is a moving average of gradients, averages over too long a period, the result will approach <span class="math inline">\(\boldsymbol{g}_{\boldsymbol{\theta}^*}=\boldsymbol{0}\)</span>, which is not good. Therefore, the moving average for momentum should be more localized.</p>
</section>
<section id="related-work" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="related-work">Related work</h2>
<p>For readers familiar with Hessian matrix theory, their first reaction to the above conclusion might be confusion rather than recognition. This is because a classic approximation of the Hessian matrix is the outer product of the Jacobian matrix (similar to the gradient), while the Hessian approximation here is the square root of the gradient’s outer product – the two differ by a square root.</p>
<p>Specifically, consider the squared error loss:</p>
<p><span id="eq-loss-2"><span class="math display">\[
\begin{equation}\mathcal{L}(\boldsymbol{\theta}) = \frac{1}{2}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\Vert \boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})\Vert^2]\end{equation}
\tag{15}\]</span></span></p>
<p>Expanding at <span class="math inline">\(\boldsymbol{\theta}_t\)</span>, we have <span class="math inline">\(\boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})\approx \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x}) + \boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top} (\boldsymbol{\theta} - \boldsymbol{\theta}_t)\)</span>, where <span class="math inline">\(\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}=\nabla_{\boldsymbol{\theta}_t} \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x})\)</span> is the Jacobian matrix. Substituting into the above equation:</p>
<p><span class="math display">\[
\begin{equation}\mathcal{L}(\boldsymbol{\theta}) \approx \frac{1}{2}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\Vert \boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x}) - \boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top} (\boldsymbol{\theta} - \boldsymbol{\theta}_t)\Vert^2]\end{equation}
\]</span></p>
<p>After simplification, the above equation is just a quadratic form in <span class="math inline">\(\boldsymbol{\theta}\)</span>, so we can directly write out its Hessian matrix:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t} \approx \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top}]\end{equation}
\]</span></p>
<p>This is the Hessian approximation based on the outer product of the Jacobian matrix, which is the theoretical foundation of the Gauss–Newton method. Of course, <span class="math inline">\(\boldsymbol{\mathcal{J}}\)</span> is not yet <span class="math inline">\(\boldsymbol{g}\)</span>; we want to try to connect the result with <span class="math inline">\(\mathcal{g}\)</span>. Taking the derivative of <a href="#eq-loss-2" class="quarto-xref">Equation&nbsp;15</a> directly:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} = \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\end{equation}
\]</span></p>
<p>Thus:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top} =&amp;\,  \big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)\big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)^{\top} \\
=&amp;\,  \big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)\big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}]\big) \\
\approx&amp;\, \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\big] \\
\approx&amp;\, \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\Big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\big]\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\Big] \\
\end{aligned}\end{equation}
\]</span></p>
<p>The two approximation signs here don’t have much justification. We can loosely view them as <a href="https://en.wikipedia.org/wiki/Mean-field_theory">mean-field approximations</a>. And <span class="math inline">\(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})\)</span> is the residual of the regression prediction, which we typically assume follows <span class="math inline">\(\mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})\)</span>. Therefore:</p>
<p><span id="eq-hessian-t"><span class="math display">\[
\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top} \approx \sigma^2\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\big] \approx \sigma^2 \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t}\end{equation}
\tag{16}\]</span></span></p>
<p>This reveals the relationship between <span class="math inline">\(\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t}\)</span> and <span class="math inline">\(\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top}\)</span>. Comparing with <a href="#eq-hessian-2" class="quarto-xref">Equation&nbsp;14</a> from the previous section, we find that they appear to differ by a square.</p>
<p>Looking at the derivation process, neither result seems obviously wrong, so how do we understand this inconsistency? We can understand it this way: <a href="#eq-hessian-t" class="quarto-xref">Equation&nbsp;16</a> gives the Hessian approximation at time <span class="math inline">\(t\)</span>, which is an “instantaneous approximation”, while <a href="#eq-hessian-2" class="quarto-xref">Equation&nbsp;14</a> is a “long-term average” result over time steps. The long-term averaging effect cancels out some of the intensity (but theoretically would make the estimate more accurate), thus requiring an additional square root, as we know from the theory of random walks.</p>
<p>A similar effect also appears in the SDE introduced in <a href="https://kexue.fm/archives/9209">“Generative Diffusion Modeling (Part 5): the SDE part of a General Framework”</a>, where the strength of the noise term <span class="math inline">\(\epsilon\)</span> in SDE needs to be on the order of <span class="math inline">\(O(\sqrt{\delta t})\)</span>, while the non-random drift term needs to be on the order of <span class="math inline">\(O(\delta t)\)</span>. This is also because the noise terms partially cancel out when summed over time, so the noise needs to be of a higher order so that its effect will not be washed away in the final result.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;This explanation is wrong. The real explanation is very simple. In the derivation of Adam, we assumed <span class="math inline">\(\theta^* - \theta\sim \mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})\)</span>, whereas in the derivation of this section, we assumed <span class="math inline">\(\boldsymbol{f}_{\boldsymbol{\theta}^*}(\boldsymbol{x}) - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}) \sim \mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})\)</span>. The two assumptions are simply incompatible.</p></div></div></section>
<section id="more-connections" class="level2">
<h2 class="anchored" data-anchor-id="more-connections">More connections</h2>
<p>In the previous derivation, we assumed that <span class="math inline">\(\boldsymbol{\theta}^*\)</span> is the theoretical optimal point, so <span class="math inline">\(\boldsymbol{g} _{\boldsymbol{\theta}^*} = \boldsymbol{0}\)</span>. What if <span class="math inline">\(\boldsymbol{\theta}^*\)</span> is any arbitrary point? Then <a href="#eq-hessian-2" class="quarto-xref">Equation&nbsp;14</a> would become:</p>
<p><span class="math display">\[
\begin{equation}\mathbb{E}[(\boldsymbol{g}_{\boldsymbol{\theta}}-\boldsymbol{g} _{\boldsymbol{\theta}^*})(\boldsymbol{g}_{\boldsymbol{\theta}}-\boldsymbol{g} _{\boldsymbol{\theta}^*})^{\top}] \approx \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}
\]</span></p>
<p>This means that as long as we use a moving average of the covariance rather than the second moment, we can obtain a Hessian approximation within the local range. This corresponds exactly to the approach of the <a href="https://arxiv.org/abs/2010.07468">AdaBelief optimizer</a>, where <span class="math inline">\(\boldsymbol{v}\)</span> is a moving average of the square of the difference between <span class="math inline">\(\boldsymbol{g}\)</span> and <span class="math inline">\(\boldsymbol{m}\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\text{AdaBelief}\triangleq \left\{\begin{aligned}
&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t\\
&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) (\boldsymbol{g}_t - \boldsymbol{m}_t)\odot(\boldsymbol{g}_t - \boldsymbol{m}_t)\\
&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.\\
&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.\\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.
\end{aligned}\right.\end{equation}
\]</span></p>
</section>
</section>
<section id="sec-muon-appreciation" class="level1 page-columns page-full">
<h1>Muon appreciation: a fundamental advance from vectors to matrices</h1>
<p>Source: <a href="https://kexue.fm/archives/10592">Muon优化器赏析：从向量到矩阵的本质跨越 - 科学空间|Scientific Spaces</a> (2024-12-10)</p>
<p>Since the advent of the LLM era, the academic community’s enthusiasm for optimizer research seems to have diminished. This is mainly because the current mainstream AdamW can already meet most needs, and any major “surgery” to optimizers would cost enormously to validate. Therefore, current optimizer variations are mostly small patches applied to AdamW by people in the industry based on their practical training experience.</p>
<p>However, recently “<a href="https://github.com/KellerJordan/Muon">Muon</a>” has generated quite a buzz on Twitter. It claims to be more efficient than AdamW, and is not just a minor tweak to Adam, but rather embodies some principles regarding the differences between vectors and matrices that are worth pondering. Let’s appreciate it together in this article.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/125501438.jpeg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Muon vs AdamW (Source: <a href="https://x.com/Yuchenj_UW">@Yuchenj_UW on Twitter</a>)</figcaption>
</figure>
</div>
<section id="first-taste" class="level2">
<h2 class="anchored" data-anchor-id="first-taste">First taste</h2>
<pre class="pseudocode"><code>\begin{algorithm}
\caption{Muon}
\begin{algorithmic}
\REQUIRE Learning rate $\eta$, momentum $\mu$
    \STATE Initialize $B_0 \leftarrow 0$
    \FOR{$t=1, \ldots$} 
        \STATE Compute gradient $G_t \leftarrow \nabla_{\theta}\mathcal{L}_t(\theta_{t-1})$
        \STATE $B_t \leftarrow \mu B_{t-1} + G_t$
        \STATE $O_t \leftarrow \text{NewtonSchulz5}(B_t)$
        \STATE Update parameters $\theta_t \leftarrow \theta_{t-1} - \eta O_t$
    \ENDFOR
    \RETURN $\theta_t$
\end{algorithmic}
\end{algorithm}</code></pre>
<p>Muon stands for “<font color="red">M</font>oment<font color="red">u</font>m <font color="red">O</font>rthogonalized by <font color="red">N</font>ewton–Schulz”. Unlike typical gradient descent, which applies to any kind of parameter, whether it be scalar, vector, or matrix, Muon applies to only matrix parameters.</p>
<p>Let <span class="math inline">\(\boldsymbol{W}\in\mathbb{R}^{n\times m}\)</span> be such a matrix parameter, then the Muon update rule states that:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\boldsymbol{G}_t =&amp;\, \nabla_\theta \mathcal L_t(\theta_{t-1})\\
\boldsymbol{M}_t =&amp;\, \beta\boldsymbol{M}_{t-1} + \boldsymbol{G}_t \\
\boldsymbol{W}_t =&amp;\, \boldsymbol{W}_{t-1} - \eta_t [\text{msign}(\boldsymbol{M}_t) + \lambda \boldsymbol{W}_{t-1}] \\
\end{aligned}\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\text{msign}\)</span> is the <a href="https://en.wikipedia.org/wiki/Matrix_sign_function">matrix sign function</a>, which is not simply applying the <span class="math inline">\(\text{sign}\)</span> operation to each component of the matrix, but rather a matrix generalization of the <span class="math inline">\(\text{sign}\)</span> function. It can be defined via <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">SVD</a>:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}^{\top} = SVD(\boldsymbol{M}) \quad\Rightarrow\quad \text{msign}(\boldsymbol{M}) = \boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top}\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{U}\in\mathbb{R}^{n\times n},\boldsymbol{\Sigma}\in\mathbb{R}^{r \times r},\boldsymbol{V}\in\mathbb{R}^{m\times m}\)</span>, and <span class="math inline">\(r\)</span> is the rank of <span class="math inline">\(\boldsymbol{M}\)</span>. We will expand on more theoretical details later, but first let’s try to intuitively grasp the following fact:</p>
<blockquote class="blockquote">
<p>Muon is an adaptive learning rate optimizer, like Adam.</p>
</blockquote>
<p>The common trait of adaptive learning rate optimizers like Adagrad, RMSprop, and Adam is that the update for each parameter is divided by the “standard deviation of gradient” <span class="math inline">\(\sqrt{\overline{(\nabla \mathcal L)^2}}\)</span>, that is, the square root of the moving average of squared gradients. This ensures two essential properties:</p>
<ol type="1">
<li>Constant scaling of the loss function <span class="math inline">\(\mathcal L \mapsto c\mathcal L\)</span> does not change the parameter updates.</li>
<li>The change in each parameter is approximately equalized. That is, <span class="math inline">\(|\theta_{t, i} - \theta_{t-1, i}| \sim \eta_t\)</span> for all <span class="math inline">\(i\)</span>.</li>
</ol>
<p>Muon reproduces the two essential properties for matrices, even though it does not keep track of <span class="math inline">\(\sqrt{\overline{(\nabla \mathcal L)^2}}\)</span>:</p>
<ol type="1">
<li>If the loss function <span class="math inline">\(\mathcal L\)</span> is multiplied by some constant <span class="math inline">\(c\)</span>, <span class="math inline">\(\boldsymbol{M}\)</span> will also be multiplied by <span class="math inline">\(c\)</span>, but <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span> remains unchanged.</li>
<li>When <span class="math inline">\(\boldsymbol{M}\)</span> is decomposed by SVD into <span class="math inline">\(\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}\)</span>, the different singular values of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> reflect the “anisotropy” of <span class="math inline">\(\boldsymbol{M}\)</span>, and setting them all to <u>one</u> makes it more isotropic, which also serves to synchronize update magnitudes.</li>
</ol>
<p>(By the way, did point 2 remind anyone of <a href="https://kexue.fm/archives/8069">BERT-whitening</a>?)</p>
<p>Stated in another way, consider what happens with Adam: We divide each component of the gradient <span class="math inline">\(\nabla \mathcal L\)</span> by <span class="math inline">\(\sqrt{\overline{(\nabla \mathcal L)^2}}\)</span>, which approximately gives us just the sign of <span class="math inline">\(\nabla \mathcal L\)</span>. That is, if <span class="math inline">\(\partial_{\theta_i} \mathcal L &gt; 0\)</span>, then we should get <span class="math inline">\(\sim +1\)</span> after dividing, and if <span class="math inline">\(\partial_{\theta_i} \mathcal L &lt; 0\)</span>, then we should get <span class="math inline">\(\sim -1\)</span> after dividing. The use of the matrix sign reproduces this effect.</p>
<p>Muon has a Nesterov version, which simply replaces <span class="math inline">\(\text{msign}(\boldsymbol{M}_t)\)</span> with <span class="math inline">\(\text{msign}(\beta\boldsymbol{M}_t + \boldsymbol{G}_t)\)</span> in the update rule, with everything else remaining identical. Since it’s tangential to our point, we won’t expand on this.</p>
</section>
<section id="sign-function" class="level2">
<h2 class="anchored" data-anchor-id="sign-function">Sign function</h2>
<p>Using SVD, we can also prove the identity:</p>
<p><span id="eq-msign-id"><span class="math display">\[
\begin{equation}\text{msign}(\boldsymbol{M}) = (\boldsymbol{M}\boldsymbol{M}^{\top})^{-1/2}\boldsymbol{M}= \boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}\end{equation}
\tag{17}\]</span></span></p>
<p>where <span class="math inline">\({}^{-1/2}\)</span> is the inverse of the matrix raised to the power of <span class="math inline">\(1/2\)</span>, or the <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">pseudoinverse</a> if it’s not invertible. This identity helps us better understand why <span class="math inline">\(\text{msign}\)</span> is a matrix generalization of <span class="math inline">\(\text{sign}\)</span>: for a scalar <span class="math inline">\(x\)</span>, we have <span class="math inline">\(\text{sign}(x)=x(x^2)^{-1/2}\)</span>, which is precisely a special case of the above equation (when <span class="math inline">\(\boldsymbol{M}\)</span> is a <span class="math inline">\(1\times 1\)</span> matrix). This special example can also be generalized to diagonal matrices <span class="math inline">\(\boldsymbol{M}=\text{diag}(\boldsymbol{m})\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\text{msign}(\boldsymbol{M}) = \text{diag}(\boldsymbol{m})[\text{diag}(\boldsymbol{m})^2]^{-1/2} = \text{diag}(\text{sign}(\boldsymbol{m}))=\text{sign}(\boldsymbol{M})\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\text{sign}(\boldsymbol{m})\)</span> and <span class="math inline">\(\text{sign}(\boldsymbol{M})\)</span> refer to taking <span class="math inline">\(\text{sign}\)</span> of each component of the vector/matrix. The above equation means that when <span class="math inline">\(\boldsymbol{M}\)</span> is a diagonal matrix, Muon degenerates to <a href="https://arxiv.org/abs/2302.06675">Lion</a>, <a href="https://kexue.fm/archives/9512">Tiger</a>, or <a href="https://arxiv.org/abs/1802.04434">Signum</a>, obtained by successive simplification from of AdamW:</p>
<p><span class="math display">\[
\begin{array}{c|c|c|c}
\hline
\text{Signum} &amp; \text{Tiger} &amp; \text{Lion} &amp; \text{AdamW} \\
\hline
\begin{aligned}
&amp;\boldsymbol{m}_t = \beta \boldsymbol{m}_{t-1} + \left(1 - \beta\right) \boldsymbol{g}_t \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \text{sign}(\boldsymbol{m}_t) \\
\end{aligned} &amp;
\begin{aligned}
&amp;\boldsymbol{m}_t = \beta \boldsymbol{m}_{t-1} + \left(1 - \beta\right) \boldsymbol{g}_t \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \left[\text{sign}(\boldsymbol{m}_t) \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}}\right] \\
\end{aligned} &amp;
\begin{aligned}
&amp;\boldsymbol{u}_t = \text{sign}\big(\beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t\big) \\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t (\boldsymbol{u}_t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}}) \\
&amp;\boldsymbol{m}_t = \beta_2 \boldsymbol{m}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t
\end{aligned} &amp;
\begin{aligned}
&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t\\
&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t^2\\
&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.\\
&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.\\
&amp;\boldsymbol{u}_t =\hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.\\
&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t (\boldsymbol{u}_t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}})
\end{aligned} \\
\hline
\end{array}
\]</span></p>
<p>Conversely, the difference between Muon and Signum/Tiger is that the elementwise <span class="math inline">\(\text{sign}(\boldsymbol{M})\)</span> is replaced with the matrix version <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span>.</p>
<p>For an <span class="math inline">\(n\)</span>-dimensional vector, we can also view it as an <span class="math inline">\(n\times 1\)</span> matrix, in which case <span class="math inline">\(\text{msign}(\boldsymbol{m}) = \boldsymbol{m}/\Vert\boldsymbol{m}\Vert_2\)</span> is exactly <span class="math inline">\(l_2\)</span> normalization. So, in the Muon framework, we have two perspectives for vectors: one as a diagonal matrix, like the <span class="math inline">\(\gamma\)</span> parameter in LayerNorm, resulting in taking <span class="math inline">\(\text{sign}\)</span> of the momentum; the other as an <span class="math inline">\(n\times 1\)</span> matrix, resulting in <span class="math inline">\(l_2\)</span> normalization of the momentum. Additionally, although input and output embeddings are also matrices, they are used sparsely, so a more reasonable approach is to treat them as lists of independent vectors.</p>
<p><span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span> also has the meaning of “optimal orthogonal approximation”:</p>
<p><span id="eq-nearest-orth"><span class="math display">\[
\begin{equation}\text{msign}(\boldsymbol{M}) = \mathop{\text{argmin}}\Vert \boldsymbol{M} - \boldsymbol{O}\Vert_F^2 \end{equation}
\tag{18}\]</span></span></p>
<p>where <span class="math inline">\(\boldsymbol{O}\)</span> is constrained by over <span class="math inline">\(\boldsymbol{O}^{\top}\boldsymbol{O} = \boldsymbol{I}\)</span> if <span class="math inline">\(\boldsymbol{M}\)</span> is a tall matrix, or <span class="math inline">\(\boldsymbol{O}\boldsymbol{O}^{\top} = \boldsymbol{I}\)</span> if <span class="math inline">\(\boldsymbol{M}\)</span> is a fat matrix. Furthermore, if the matrix is full-ranked, that is, <span class="math inline">\(r = \min(m, n)\)</span>, then <span class="math inline">\(\boldsymbol{O}\)</span> is the <em>unique</em> minimizer of the equation.</p>
<p>This is analogous to how</p>
<p><span class="math display">\[
\begin{equation}\text{sign}(\boldsymbol{M}) = \mathop{\text{argmin}}_{\boldsymbol{O}\in\{-1,1\}^{n\times m}}\Vert \boldsymbol{M} - \boldsymbol{O}\Vert_F^2\end{equation}
\]</span></p>
<p>and how <span class="math inline">\(\text{sign}(\boldsymbol{M})\)</span> is the unique solution when <span class="math inline">\(\boldsymbol{M}\)</span> has only nonzero entries.</p>
<p>Whether it’s <span class="math inline">\(\boldsymbol{O}^{\top}\boldsymbol{O} = \boldsymbol{I}\)</span> or <span class="math inline">\(\boldsymbol{O}\in\{-1,1\}^{n\times m}\)</span>, we can view both as a kind of regularization constraint on the update amount. So Muon and Signum/Tiger can be seen as optimizers under the same approach: they all start from momentum <span class="math inline">\(\boldsymbol{M}\)</span> to construct the update amount, but choose different regularization methods for the update.</p>
<p>To prove <a href="#eq-nearest-orth" class="quarto-xref">Equation&nbsp;18</a>, note that the Frobenius norm is preserved by left and right multiplication of orthogonal matrices. That is, <span class="math inline">\(\|\boldsymbol{V}\boldsymbol{A}\|_F = \|\boldsymbol{A}\|_F = |\boldsymbol{A}\boldsymbol{U}\|_F\)</span> for any orthogonal matrices <span class="math inline">\(\boldsymbol{U}, \boldsymbol{V}\)</span> of the suitable shapes. Thus it reduces to the special case where <span class="math inline">\(\boldsymbol{M} = \boldsymbol{\Sigma}\)</span>. Now, use the fact that <span class="math inline">\(\|\boldsymbol{A}\|_F^2\)</span> is the sum of its column vectors’ norm-squared.</p>
</section>
<section id="iterative-solution" class="level2">
<h2 class="anchored" data-anchor-id="iterative-solution">Iterative solution</h2>
<p>In practice, if we compute <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span> by performing SVD on <span class="math inline">\(\boldsymbol{M}\)</span> at each step, the computational cost would be quite high. Therefore, the authors of Muon proposed using Newton–Schulz iteration to approximately calculate <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span>.</p>
<p>The starting point of the iteration is the identity <a href="#eq-msign-id" class="quarto-xref">Equation&nbsp;17</a>. Without loss of generality, we assume <span class="math inline">\(n\geq m\)</span> and consider the Taylor expansion of <span class="math inline">\((\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}\)</span> at <span class="math inline">\(\boldsymbol{M}^{\top}\boldsymbol{M}=\boldsymbol{I}\)</span>. The expansion is done by doing a matrix Taylor expanion. Specifically, consider a symmetric <span class="math inline">\(\boldsymbol{A} = \boldsymbol{I} + \delta\boldsymbol{A}\)</span>, where <span class="math inline">\(\delta\boldsymbol{A}\)</span> is a small symmetric matrix. Then by direct multiplication, we have</p>
<p><span class="math display">\[
\boldsymbol{A}^{-1/2} = \boldsymbol{I} - \frac 12 \delta \boldsymbol{A} + \frac 38 \delta \boldsymbol{A}^2 + O(\delta \boldsymbol{A}^3)
\]</span></p>
<p>Thus, up to 2th order,</p>
<p><span class="math display">\[
\begin{equation}\text{msign}(\boldsymbol{M}) = \boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}\approx \frac{15}{8}\boldsymbol{M} - \frac{5}{4}\boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M}) + \frac{3}{8}\boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^2\end{equation}
\]</span></p>
<p>If <span class="math inline">\(\boldsymbol{X}_t\)</span> is an approximation of <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span>, we believe that substituting it into the above equation will yield a better approximation of <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span>. Thus, we obtain a usable iteration format:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{X}_{t+1} = a \boldsymbol{X}_t + b\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t) + c\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^2\end{equation}
\]</span> with <span class="math inline">\((a,b,c) = (15/8, -5/4, 3/8) = (1.875, -1.25, 0.375)\)</span></p>
<p>But if we look up the official code for Muon, we’d see that the Newton–Schulz iteration does appear in this form, but with <span class="math inline">\((a,b,c) = (3.4445, -4.7750,  2.0315)\)</span>. Further, the original author made no attempt to derive this mathematically, but just wrote it in as a magic constant:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zeropower_via_newtonschulz5(G, steps<span class="op">=</span><span class="dv">10</span>, eps<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    zero even beyond the point where the iteration no longer converges all the way to one everywhere</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    where S' is diagonal with S_{ii}' </span><span class="er">\</span><span class="co">sim Uniform(0.5, 1.5), which turns out not to hurt model</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">    performance at all relative to UV^T, where USV^T = G is the SVD.</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(G.shape) <span class="op">==</span> <span class="dv">2</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    a, b, c <span class="op">=</span> (<span class="fl">3.4445</span>, <span class="op">-</span><span class="fl">4.7750</span>,  <span class="fl">2.0315</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> G.bfloat16()</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    X <span class="op">/=</span> (X.norm() <span class="op">+</span> eps) <span class="co"># ensure top singular value &lt;= 1</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> X.T</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> X <span class="op">@</span> X.T</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        B <span class="op">=</span> A <span class="op">@</span> X</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> a <span class="op">*</span> X <span class="op">+</span> b <span class="op">*</span> B <span class="op">+</span> c <span class="op">*</span> A <span class="op">@</span> B</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> X.T</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="convergence-acceleration" class="level2">
<h2 class="anchored" data-anchor-id="convergence-acceleration">Convergence acceleration</h2>
<p>To guess the origin of the official iteration algorithm, we consider a general iteration process:</p>
<p><span id="eq-iteration"><span class="math display">\[
\begin{equation}\boldsymbol{X}_{t+1} = a\boldsymbol{X}_t + b\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t) + c\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^2\end{equation}
\tag{19}\]</span></span></p>
<p>where <span class="math inline">\((a,b,c)\)</span> are to be determined. If we want a higher-order iteration algorithm, we can also successively add terms like <span class="math inline">\(\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^3\)</span>, <span class="math inline">\(\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^4\)</span>, etc. The following analysis process is universal.</p>
<p>We choose the initial value as <span class="math inline">\(\boldsymbol{X}_0=\boldsymbol{M}/\Vert\boldsymbol{M}\Vert_F\)</span>, where <span class="math inline">\(\Vert\cdot\Vert_F\)</span> is the Frobenius norm of the matrix. The rationale is that dividing by <span class="math inline">\(\Vert\boldsymbol{M}\Vert_F\)</span> does not change the <span class="math inline">\(\boldsymbol{U}\)</span> and <span class="math inline">\(\boldsymbol{V}\)</span> in the SVD, but can make all singular values of <span class="math inline">\(\boldsymbol{X}_0\)</span> lie in the interval <span class="math inline">\([0,1]\)</span>, standardizing the initial singular values for iteration. Now, assuming <span class="math inline">\(\boldsymbol{X}_t\)</span> can be decomposed by SVD as <span class="math inline">\(\boldsymbol{U}\boldsymbol{\Sigma}_t\boldsymbol{V}^{\top}\)</span>, substituting into the above equation gives:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{X}_{t+1} = \boldsymbol{U}_{[:,:r]}(a \boldsymbol{\Sigma}_{t,[:r,:r]} + b \boldsymbol{\Sigma}_{t,[:r,:r]}^3 + c \boldsymbol{\Sigma}_{t,[:r,:r]}^5)\boldsymbol{V}_{[:,:r]}^{\top}\end{equation}
\]</span></p>
<p>Therefore, <a href="#eq-iteration" class="quarto-xref">Equation&nbsp;19</a> is actually iterating on the diagonal matrix <span class="math inline">\(\boldsymbol{\Sigma}_{[:r,:r]}\)</span> composed of singular values. If we denote <span class="math inline">\(\boldsymbol{X}_t=\boldsymbol{U}_{[:,:r]}\boldsymbol{\Sigma}_{t,[:r,:r]}\boldsymbol{V}_{[:,:r]}^{\top}\)</span>, then <span class="math inline">\(\boldsymbol{\Sigma}_{t+1,[:r,:r]} = g(\boldsymbol{\Sigma}_{t,[:r,:r]})\)</span>, where <span class="math inline">\(g(x) = ax + bx^3 + cx^5\)</span>. Since the power of a diagonal matrix equals each diagonal element raised to that power, the problem simplifies to the iteration of a single singular value <span class="math inline">\(\sigma\)</span>. Our goal is to compute <span class="math inline">\(\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top}\)</span>, in other words, we hope to transform <span class="math inline">\(\boldsymbol{\Sigma}_{[:r,:r]}\)</span> into an identity matrix through iteration, which can be further simplified to iterating <span class="math inline">\(\sigma_{t+1} = g(\sigma_t)\)</span> to change a single singular value to 1.</p>
<p>Inspired by <a href="https://x.com/leloykun/status/1846165001746501899">@leloykun</a>, we view the selection of <span class="math inline">\((a,b,c)\)</span> as an optimization problem, with the objective of making the iteration process converge as quickly as possible for any initial singular value. First, we reparameterize <span class="math inline">\(g(x)\)</span> as:</p>
<p><span class="math display">\[
\begin{equation}g(x) = x + \kappa x(x^2 - x_1^2)(x^2 - x_2^2)\end{equation}
\]</span></p>
<p>where <span class="math inline">\(x_1 \leq x_2\)</span>. The advantage of this parameterization is that it explicitly represents the 5 fixed points of the iteration: <span class="math inline">\(0, \pm x_1, \pm x_2\)</span>. Since our goal is to converge to 1, we initially choose <span class="math inline">\(x_1 &lt; 1 &lt; x_2\)</span>, with the idea that regardless of whether the iteration process moves toward <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span>, the result will be near 1.</p>
<p>Next, we determine the number of iterations <span class="math inline">\(T\)</span>, so that the iteration process becomes a deterministic function. Once we fix the shape of the matrix (i.e., <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>), we can sample a batch of matrices and compute the singular values through SVD. Finally, we treat these singular values as inputs, with the target output being 1, and the loss function being the squared error. The entire model is fully differentiable and can be solved using gradient descent. Note that <a href="https://x.com/leloykun/status/1846165001746501899">@leloykun</a> assumed <span class="math inline">\(x_1 + x_2 = 2\)</span> and used grid search to solve it.</p>
<p><span class="math display">\[
\begin{array}{ccc|ccc|ccc|c|c}
\hline
n &amp; m &amp; T &amp; \kappa &amp; x_1 &amp; x_2 &amp; a &amp; b &amp; c &amp; \text{mse} &amp; \text{mse}_{\text{Muon}}\\
\hline
1024 &amp; 1024 &amp; 3 &amp; 7.020 &amp; 0.830 &amp; 0.830 &amp; 4.328 &amp; -9.666 &amp; 7.020 &amp; 0.10257 &amp; 0.18278 \\
1024 &amp; 1024 &amp; 5 &amp; 1.724 &amp; 0.935 &amp; 1.235 &amp; 3.297 &amp; -4.136 &amp; 1.724 &amp; 0.02733 &amp; 0.04431 \\
2048 &amp; 1024 &amp; 3 &amp; 7.028 &amp; 0.815 &amp; 0.815 &amp; 4.095 &amp; -9.327 &amp; 7.028 &amp; 0.01628 &amp; 0.06171 \\
2048 &amp; 1024 &amp; 5 &amp; 1.476 &amp; 0.983 &amp; 1.074 &amp; 2.644 &amp; -3.128 &amp; 1.476 &amp; 0.00038 &amp; 0.02954 \\
4096 &amp; 1024 &amp; 3 &amp; 6.948 &amp; 0.802 &amp; 0.804 &amp; 3.886 &amp; -8.956 &amp; 6.948 &amp; 0.00371 &amp; 0.02574 \\
4096 &amp; 1024 &amp; 5 &amp; 1.214 &amp; 1.047 &amp; 1.048 &amp; 2.461 &amp; -2.663 &amp; 1.214 &amp; 0.00008 &amp; 0.02563 \\
\hline
2048 &amp; 2048 &amp; 3 &amp; 11.130 &amp; 0.767 &amp; 0.767 &amp; 4.857 &amp; -13.103 &amp; 11.130 &amp; 0.10739 &amp; 0.24410 \\
2048 &amp; 2048 &amp; 5 &amp; 1.779 &amp; 0.921 &amp; 1.243 &amp; 3.333 &amp; -4.259 &amp; 1.779 &amp; 0.03516 &amp; 0.04991 \\
4096 &amp; 4096 &amp; 3 &amp; 18.017 &amp; 0.705 &amp; 0.705 &amp; 5.460 &amp; -17.929 &amp; 18.017 &amp; 0.11303 &amp; 0.33404 \\
4096 &amp; 4096 &amp; 5 &amp; 2.057 &amp; 0.894 &amp; 1.201 &amp; 3.373 &amp; -4.613 &amp; 2.057 &amp; 0.04700 &amp; 0.06372 \\
8192 &amp; 8192 &amp; 3 &amp; 30.147 &amp; 0.643 &amp; 0.643 &amp; 6.139 &amp; -24.893 &amp; 30.147 &amp; 0.11944 &amp; 0.44843 \\
8192 &amp; 8192 &amp; 5 &amp; 2.310 &amp; 0.871 &amp; 1.168 &amp; 3.389 &amp; -4.902 &amp; 2.310 &amp; 0.05869 &amp; 0.07606 \\
\hline
\end{array}
\]</span></p>
<p>Here, <span class="math inline">\(\text{mse}_{\text{Muon}}\)</span> is the result of computation done according to the <span class="math inline">\((a,b,c)\)</span> provided by the Muon authors. Looking through the table, which choice of <span class="math inline">\((a, b, c)\)</span> is the best clearly depends on both the matrix size <span class="math inline">\((m, n)\)</span> and the number of iterations <span class="math inline">\(T\)</span>. Looking at the loss function, non-square matrices converge more readily than square matrices. The <span class="math inline">\((a, b, c)\)</span> given by the authors of Muon are probably the optimal solution for square matrices <span class="math inline">\(m = n\)</span> when the number of iterations is <span class="math inline">\(T = 5\)</span>.</p>
<p>For a fixed number of iterations <span class="math inline">\(T\)</span>, the result depends on the size of the matrix, which essentially depends on the distribution of singular values. One result worth mentioning about this distribution is that for any fixed “aspect ratio” <span class="math inline">\(r \in (0, \infty)\)</span>, if at the <span class="math inline">\(n \to \infty\)</span> limit, <span class="math inline">\(\frac{m}{n} \to r\)</span>, then the singular values of the matrix converges to a <a href="https://en.wikipedia.org/wiki/Marchenko%E2%80%93Pastur_distribution">Marchenko–Pastur distribution</a>.</p>
<details>
<summary>
Code for generating the table above
</summary>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>n, m, T <span class="op">=</span> <span class="dv">1024</span>, <span class="dv">1024</span>, <span class="dv">5</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>key, data <span class="op">=</span> jax.random.key(<span class="dv">42</span>), jnp.array([])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">1000</span>), ncols<span class="op">=</span><span class="dv">0</span>, desc<span class="op">=</span><span class="st">'SVD'</span>):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    key, subkey <span class="op">=</span> jax.random.split(key)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> jax.random.normal(subkey, shape<span class="op">=</span>(n, m))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> jnp.linalg.svd(M, full_matrices<span class="op">=</span><span class="va">False</span>)[<span class="dv">1</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> jnp.concatenate([data, S <span class="op">/</span> (S<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()<span class="op">**</span><span class="fl">0.5</span>])</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="at">@jax.jit</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(w, x):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    k, x1, x2 <span class="op">=</span> w</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> k <span class="op">*</span> x <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> x1<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> x2<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((x <span class="op">-</span> <span class="dv">1</span>)<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>f_grad <span class="op">=</span> jax.grad(f)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>w, u <span class="op">=</span> jnp.array([<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">1.1</span>]), jnp.zeros(<span class="dv">3</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">100000</span>), ncols<span class="op">=</span><span class="dv">0</span>, desc<span class="op">=</span><span class="st">'SGD'</span>):</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> <span class="fl">0.9</span> <span class="op">*</span> u <span class="op">+</span> f_grad(w, data)  <span class="co"># Momentum acceleration</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> <span class="fl">0.01</span> <span class="op">*</span> u</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>k, x1, x2 <span class="op">=</span> w</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>a, b, c <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> k <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>, <span class="op">-</span>k <span class="op">*</span> (x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x2<span class="op">**</span><span class="dv">2</span>), k</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>m<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>T<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>k<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>x1<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>x2<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>a<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>b<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>c<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>f(w, data)<span class="sc">:.5f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</section>
<section id="some-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="some-thoughts">Some thoughts</h2>
<p>If we choose the default setting of <span class="math inline">\(T=5\)</span>, then for an <span class="math inline">\(n\times n\)</span> matrix parameter, each update step of Muon requires at least 15 matrix multiplications between <span class="math inline">\(n\times n\)</span> matrices:</p>
<p><span class="math display">\[
\boldsymbol{X}_t (a + (\boldsymbol{X}_t^\top \boldsymbol{X}_t) (b + c (\boldsymbol{X}_t^\top \boldsymbol{X}_t)) )
\]</span></p>
<p>which is undoubtedly a significantly larger computational cost than Adam. This might lead some readers to worry whether Muon is practically feasible.</p>
<p>In fact, such concerns are unnecessary. Although Muon’s computation is more complex than Adam’s, the additional time per step is minimal. My conclusion is that the additional wallclock time is <span class="math inline">\(\leq 5\%\)</span>. The Muon’s authors claim it can reach as low as <span class="math inline">\(2\%\)</span>. This is because Muon’s matrix multiplications occur after the current gradient computation and before the next gradient computation, during which almost all computational power would have sat idle anyway. Since these matrix multiplications are of static size and can be parallelized, they don’t significantly increase the wallclock time. Moreover, Muon uses one fewer set of cached variables than Adam, resulting in lower memory consumption.</p>
<p>The most thought-provoking aspect of Muon is actually the intrinsic difference between vectors and matrices, and its impact on optimization. Common optimizers like SGD, AdamW, and Lion update parameters in an elementwise manner, treating both vector and matrix parameters essentially the same, as lists of scalars being updated independently according to the same rules. Optimizers with this characteristic are often simpler to analyze theoretically and are convenient for tensor parallelism, since splitting a large matrix into two smaller matrices for independent processing doesn’t change the optimization trajectory.</p>
<p>But Muon is different, since it takes matrices as fundamental units, and exploits properties unique to matrices. Some readers might wonder: aren’t matrices and vectors just arrangements of numbers? How different can they be? But they are. For example, with matrices, we have the concept of <a href="https://en.wikipedia.org/wiki/Trace_(linear_algebra)">trace</a>, which is the sum of diagonal elements. This concept is a geometrically meaningful concept, since it is invariant under similarity transformation. In particular, it equals the sum of all eigenvalues of the matrix. The moral of this example is that the diagonal elements of a matrix should not be treated in the same way as its off-diagonal elements. Muon achieves better results because it treats them differently.</p>
<p>Of course, Muon is not a free lunch. In tensor-parallel training, Muon requires <a href="https://en.wikipedia.org/wiki/Collective_operation#All-Reduce">allreduce</a>. That is, the gradients need to be aggregated across the devices before the parameter update, rather than having each device update independently, which increases communication costs.</p>
<p>Even without tensor-parallelism, this issue persists in some other form. For instance, Multi-Head Attention is usually implemented by projecting the input with a single matrix <span class="math inline">\(W^Q\)</span> to obtain the query matrix <span class="math inline">\(Q\)</span> (and similarly for <span class="math inline">\(K\)</span> and <span class="math inline">\(V\)</span>), and then reshapes it to obtain the query matrices for each head. This creates a disconnect between the implementation and the semantics. Semantically, <span class="math inline">\(Q\)</span> really should be considered multiple matrices, but it is implemented as a single matrix. Therefore, when using Muon for MHA, one must take care to first split <span class="math inline">\(Q\)</span> into multiple small matrices before doing the Muon update.</p>
<p>In summary, Muon’s non-elementwise update rule, while capturing the essential differences between vectors and matrices, also introduces some minor issues, which might be aesthetically unsatisfying to some people.</p>
<p>(Addendum: Almost simultaneously with the publication of this blogpost, Muon’s author Keller Jordan published <a href="https://kellerjordan.github.io/posts/muon/"><em>Muon: An optimizer for hidden layers in neural networks</em></a>.)</p>
</section>
<section id="norm-perspective" class="level2">
<h2 class="anchored" data-anchor-id="norm-perspective">Norm perspective</h2>
<p>From a theoretical standpoint, what key characteristics of matrices does Muon capture? Perhaps the following norm perspective can answer our question.</p>
<p>This section’s discussion primarily references the papers <a href="https://ieeexplore.ieee.org/abstract/document/7347351"><em>Stochastic Spectral Descent for Discrete Graphical Models</em></a> and <a href="https://arxiv.org/abs/2409.20325"><em>Old Optimizer, New Norm: An Anthology</em></a>, especially the latter. However, the starting point is not new; we’ve already briefly touched upon it in <a href="https://kexue.fm/archives/9660"><em>Gradient Flow: Exploring the Path to Minimums</em></a>: for vector parameters <span class="math inline">\(\boldsymbol{w}\in\mathbb{R}^n\)</span>, we define the update rule for the next step as</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{w}} \left(\frac{\Vert\boldsymbol{w} - \boldsymbol{w}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{w})\right)\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\Vert\cdot\Vert\)</span> is some vector norm. This is norm-regularized gradient descent. Then, assuming <span class="math inline">\(\eta_t\)</span> is small enough, the regularization loss dominates, meaning <span class="math inline">\(\boldsymbol{w}_{t+1}\)</span> will be very close to <span class="math inline">\(\boldsymbol{w}_t\)</span>, so we assume a first-order approximation of <span class="math inline">\(\mathcal{L}(\boldsymbol{w})\)</span> is sufficient. The problem then simplifies to</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{w}}\left( \frac{\Vert\boldsymbol{w} - \boldsymbol{w}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{w}_t) + \nabla_{\boldsymbol{w}_t}\mathcal{L}(\boldsymbol{w}_t)^{\top}(\boldsymbol{w}-\boldsymbol{w}_t) \right)\end{equation}
\]</span></p>
<p>Denoting <span class="math inline">\(\Delta\boldsymbol{w}_{t+1} = \boldsymbol{w}_{t+1}-\boldsymbol{w}_t, \boldsymbol{g}_t = \nabla_{\boldsymbol{w}_t}\mathcal{L}(\boldsymbol{w}_t)\)</span>, we can simplify it as</p>
<p><span class="math display">\[
\begin{equation}
\Delta\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\Delta\boldsymbol{w}} \left( \frac{\Vert\Delta\boldsymbol{w}\Vert^2}{2\eta_t} + \boldsymbol{g}_t^{\top}\Delta\boldsymbol{w}\right)
\end{equation}
\]</span></p>
<p>The general approach to compute <span class="math inline">\(\Delta\boldsymbol{w}_{t+1}\)</span> is to take derivatives, but <a href="https://arxiv.org/abs/2409.20325"><em>Old Optimizer, New Norm: An Anthology</em></a> provides a unified solution without taking derivatives: decompose <span class="math inline">\(\Delta\boldsymbol{w}\)</span> into the norm <span class="math inline">\(\gamma = \Vert\Delta\boldsymbol{w}\Vert\)</span> and the direction vector <span class="math inline">\(\boldsymbol{\phi} = -\Delta\boldsymbol{w}/\Vert\Delta\boldsymbol{w}\Vert\)</span>, so</p>
<p><span class="math display">\[
\begin{equation}\min_{\Delta\boldsymbol{w}} \left(
    \frac{\Vert\Delta\boldsymbol{w}\Vert^2}{2\eta_t} +  \boldsymbol{g}_t^{\top}\Delta\boldsymbol{w} \right)
    = \min_{\gamma\geq 0, \Vert\boldsymbol{\phi}\Vert=1} \left(\frac{\gamma^2}{2\eta_t} -  \gamma\boldsymbol{g}_t^{\top}\boldsymbol{\phi}  \right)
    = \min_{\gamma\geq 0} \left( \frac{\gamma^2}{2\eta_t} -  \gamma\; \underbrace{\max_{\Vert\boldsymbol{\phi}\Vert=1}\boldsymbol{g}_t^{\top}\boldsymbol{\phi}}_{\triangleq \Vert \boldsymbol{g}_t\Vert^{\dagger}} \right)
\end{equation}
\]</span></p>
<p><span class="math inline">\(\gamma\)</span> is just a scalar, similar to the learning rate, and its optimal value is easily found to be <span class="math inline">\(\eta_t\Vert \boldsymbol{g}_t\Vert^{\dagger}\)</span>, while the update direction is the <span class="math inline">\(\boldsymbol{\phi}^*\)</span> that maximizes <span class="math inline">\(\boldsymbol{g}_t^{\top}\boldsymbol{\phi}\)</span> under constraint <span class="math inline">\(\Vert\boldsymbol{\phi}\Vert=1\)</span>. Now substituting the Euclidean norm, i.e., <span class="math inline">\(\Vert\boldsymbol{\phi}\Vert_2 = \sqrt{\boldsymbol{\phi}^{\top}\boldsymbol{\phi}}\)</span>, we have <span class="math inline">\(\Vert \boldsymbol{g}_t\Vert^{\dagger}=\Vert \boldsymbol{g}_t\Vert_2\)</span> and <span class="math inline">\(\boldsymbol{\phi}^* = \boldsymbol{g}_t/\Vert\boldsymbol{g}_t\Vert_2\)</span>, which gives <span class="math inline">\(\Delta\boldsymbol{w}_{t+1}=-\eta_t \boldsymbol{g}_t\)</span>, which is just SGD. Generally, define the <span class="math inline">\(p\)</span>-norm</p>
<p><span class="math display">\[
\begin{equation}\Vert\boldsymbol{\phi}\Vert_p = \sqrt[\uproot{10}p]{\sum_{i=1}^n |\phi_i|^p}\end{equation}
\]</span></p>
<p>then by the <a href="https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality">Hölder’s inequality duality</a> gives <span class="math inline">\(\boldsymbol{g}^{\top}\boldsymbol{\phi} \leq \Vert \boldsymbol{g}\Vert_q \Vert \boldsymbol{\phi}\Vert_p\)</span>, where <span class="math inline">\(1/p + 1/q = 1\)</span>. The equality is reached precisely at</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{\phi}^* = \frac{1}{\Vert\boldsymbol{g}\Vert_q^{q/p}}\Big[\text{sign}(g_1) |g_1|^{q/p},\text{sign}(g_2) |g_2|^{q/p},\cdots,\text{sign}(g_n) |g_n|^{q/p}\Big]\end{equation}
\]</span></p>
<p>at which point, <span class="math inline">\(\max_{\Vert\boldsymbol{\phi}\Vert_p=1}\boldsymbol{g}^{\top}\boldsymbol{\phi} = \Vert \boldsymbol{g}\Vert_q\)</span>.</p>
<p>The <a href="https://www.ijcai.org/proceedings/2020/451">pbSGD</a> optimizer uses this as the direction vector. In particular, when <span class="math inline">\(p\to\infty\)</span>, we have <span class="math inline">\(q\to 1\)</span> and <span class="math inline">\(|g_i|^{q/p}\to 1\)</span>, which degenerates to SignSGD, meaning that we can interpret SignSGD as SGD regularized by <span class="math inline">\(\|\cdot \|_\infty\)</span>.</p>
</section>
<section id="matrix-norms" class="level2">
<h2 class="anchored" data-anchor-id="matrix-norms">Matrix norms</h2>
<p>Now let’s switch our focus to matrix parameters <span class="math inline">\(\boldsymbol{W}\in\mathbb{R}^{n\times m}\)</span>. Similarly, we define its update rule as</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{W}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{W}} \left( \frac{\Vert\boldsymbol{W} - \boldsymbol{W}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{W}) \right) \end{equation}
\]</span></p>
<p>where <span class="math inline">\(\Vert\cdot\Vert\)</span> is some matrix norm. Again using a first-order approximation, we get</p>
<p><span class="math display">\[
\begin{equation}\Delta\boldsymbol{W}_{t+1} = \mathop{\text{argmin}}_{\Delta\boldsymbol{W}} \left( \frac{\Vert\Delta\boldsymbol{W}\Vert^2}{2\eta_t} + \text{Tr}(\boldsymbol{G}_t^{\top}\Delta\boldsymbol{W}) \right)
\end{equation}
\]</span></p>
<p>Here <span class="math inline">\(\Delta\boldsymbol{W}_{t+1} = \boldsymbol{W}_{t+1}-\boldsymbol{W}_t, \boldsymbol{G}_t = \nabla_{\boldsymbol{W}_t}\mathcal{L}(\boldsymbol{W}_t)\)</span>. Still using the “norm-direction” decoupling, i.e., setting <span class="math inline">\(\gamma = \Vert\Delta\boldsymbol{w}\Vert\)</span> and <span class="math inline">\(\boldsymbol{\Phi} = -\Delta\boldsymbol{W}/\Vert\Delta\boldsymbol{W}\Vert\)</span>, we get</p>
<p><span class="math display">\[
\begin{equation}\min_{\Delta\boldsymbol{W}} \left( \frac{\Vert\Delta\boldsymbol{W}\Vert^2}{2\eta_t} + \text{Tr}(\boldsymbol{G}_t^{\top}\Delta\boldsymbol{W}) \right) = \min_{\gamma\geq 0} \left( \frac{\gamma^2}{2\eta_t} -  \gamma \, \max_{\Vert\boldsymbol{\Phi}\Vert=1}\text{Tr}(\boldsymbol{G}_t^{\top}\boldsymbol{\Phi}) \right)
\end{equation}
\]</span></p>
<p>Then it’s a case-by-case analysis for specific norms. There are two commonly used matrix norms. One is the <a href="https://en.wikipedia.org/wiki/Hilbert%E2%80%93Schmidt_operator">Frobenius norm</a>, which is actually the Euclidean norm after flattening the matrix into a vector. In this case, the conclusion is the same as for vectors – the answer is SGD, which we won’t expand on here. The other is the 2-norm induced by the vector norm, also known as the <a href="https://en.wikipedia.org/wiki/Spectral_norm">spectral norm</a>:</p>
<p><span class="math display">\[
\begin{equation}\Vert \boldsymbol{\Phi}\Vert_2 = \max_{\Vert \boldsymbol{x}\Vert_2 = 1} \Vert \boldsymbol{\Phi}\boldsymbol{x}\Vert_2\end{equation}
\]</span></p>
<p>Note that the <span class="math inline">\(\Vert\cdot\Vert_2\)</span> on the right side applies to vectors, so the definition is clear. For more discussions on the 2-norm, refer to <a href="https://kexue.fm/archives/6051"><em>Lipschitz Constraints in Deep Learning: Generalization and Generative Models</em></a> and <a href="https://kexue.fm/archives/10407#矩阵范数"><em>The Path to Low-Rank Approximation (Part 2): SVD</em></a>. Since the 2-norm is induced by “matrix-vector” multiplication, it better aligns with matrix multiplication, and it always holds that <span class="math inline">\(\Vert\boldsymbol{\Phi}\Vert_2\leq \Vert\boldsymbol{\Phi}\Vert_F\)</span>, meaning the 2-norm is more compact compared to the Frobenius norm.</p>
<p>Next, the 2-norm. Let the SVD of <span class="math inline">\(\boldsymbol{G}\)</span> be <span class="math inline">\(\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top} = \sum\limits_{i=1}^r \sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top}\)</span>, then</p>
<p><span class="math display">\[
\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\boldsymbol{\Phi})=\text{Tr}\Big(\sum_{i=1}^r \sigma_i \boldsymbol{v}_i \boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\Big) = \sum_{i=1}^r \sigma_i \boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i\end{equation}
\]</span></p>
<p>By definition, when <span class="math inline">\(\Vert\boldsymbol{\Phi}\Vert_2=1\)</span>, we have <span class="math inline">\(\Vert\boldsymbol{\Phi}\boldsymbol{v}_i\Vert_2\leq \Vert\boldsymbol{v}_i\Vert_2=1\)</span>, so <span class="math inline">\(\boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i\leq 1\)</span>. Therefore,</p>
<p><span class="math display">\[
\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\boldsymbol{\Phi})\leq \sum_{i=1}^r \sigma_i\end{equation}
\]</span></p>
<p>The equality holds when all <span class="math inline">\(\boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i\)</span> equal 1, in which case</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{\Phi} = \sum_{i=1}^r \boldsymbol{u}_i \boldsymbol{v}_i^{\top} = \boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top} = \text{msign}(\boldsymbol{G})\end{equation}
\]</span></p>
<p>With this, we’ve proven that gradient descent under the 2-norm penalty is precisely the <span class="math inline">\(\beta=0\)</span> case of Muon!</p>
<p>When <span class="math inline">\(\beta &gt; 0\)</span>, the moving average takes effect, which can be viewed as a more accurate estimate of the gradient, so we take <span class="math inline">\(\text{msign}\)</span> of the momentum instead. Overall, Muon is equivalent to gradient descent under the 2-norm constraint. The 2-norm better measures the essential differences between matrices, making each step more precise and geometrically meaningful.</p>
</section>
<section id="going-further-back" class="level2">
<h2 class="anchored" data-anchor-id="going-further-back">Going further back</h2>
<p>A more ancient previous work is <a href="https://arxiv.org/abs/1802.09568"><em>Shampoo: Preconditioned Stochastic Tensor Optimization</em></a> (2018), which proposed the Shampoo optimizer, which shares a similar design philosophy with Muon.</p>
<p>The strategy of adapting learning rates through the average of squared gradients, first proposed in Adam, originated from the Adagrad paper <a href="https://jmlr.org/papers/v12/duchi11a.html"><em>Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</em></a> (2011), which suggested directly accumulating squared gradients – equivalent to a global equal-weight average. Later, RMSProp and Adam, inspired by momentum design, switched to moving averages, which were found to perform better in practice.</p>
<p>Moreover, Adagrad initially proposed accumulating the outer product <span class="math inline">\(\boldsymbol{g}\boldsymbol{g}^{\top}\)</span>, but due to the high space cost of caching outer products, it was changed to the Hadamard product <span class="math inline">\(\boldsymbol{g}\odot\boldsymbol{g}\)</span> in practice. What’s the theoretical basis for accumulating outer products? We derived this in <a href="#sec-learning-rate-hessian-approximation"><em>Adaptive learning rate optimizers from a Hessian approximation point of view</em></a>. The conclusion is that the long-term average of gradient outer products <span class="math inline">\(\mathbb{E}[\boldsymbol{g}\boldsymbol{g}^{\top}] \approx \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^2\)</span>. In other words, this is a <a href="https://en.wikipedia.org/wiki/Quasi-Newton_method">quasi-Newton method</a>.</p>
<p>Shampoo inherited Adagrad’s idea of caching outer products, but considering the cost, it took a compromise. Like Muon, it also optimizes matrices (and higher-order tensors), but its strategy is to cache matrix products <span class="math inline">\(\boldsymbol{G}\boldsymbol{G}^{\top}\)</span> and <span class="math inline">\(\boldsymbol{G}^{\top}\boldsymbol{G}\)</span>, not outer products. This way, the space cost is <span class="math inline">\(\mathcal{O}(n^2 + m^2)\)</span> rather than <span class="math inline">\(\mathcal{O}(n^2 m^2)\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\boldsymbol{L}_t =&amp;\, \beta\boldsymbol{L}_{t-1} + \boldsymbol{G}_t\boldsymbol{G}_t^{\top} \\
\boldsymbol{R}_t =&amp;\, \beta\boldsymbol{R}_{t-1} + \boldsymbol{G}_t^{\top}\boldsymbol{G}_t \\
\boldsymbol{W}_t =&amp;\, \boldsymbol{W}_{t-1} - \eta_t \boldsymbol{L}_t^{-1/4}\boldsymbol{G}_t\boldsymbol{R}_t^{-1/4} \\
\end{aligned}\end{equation}
\]</span></p>
<p>The <span class="math inline">\(\beta\)</span> here was added by me; Shampoo defaults to <span class="math inline">\(\beta=1\)</span>. The <span class="math inline">\({}^{-1/4}\)</span> is also a matrix power operation, which can be completed using SVD. Since Shampoo didn’t propose approximation schemes like Newton–Schulz iteration but directly calculated using SVD, to save computational cost, it doesn’t compute <span class="math inline">\(\boldsymbol{L}_t^{-1/4}\)</span> and <span class="math inline">\(\boldsymbol{R}_t^{-1/4}\)</span> at every step, but updates their results only after a certain number of steps.</p>
<p>Specifically, when <span class="math inline">\(\beta=0\)</span>, Shampoo’s update vector is <span class="math inline">\((\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/4}\boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/4}\)</span>. By performing SVD on <span class="math inline">\(\boldsymbol{G}\)</span>, we can prove</p>
<p><span class="math display">\[
\begin{equation}(\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/4}\boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/4} = (\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/2}\boldsymbol{G}= \boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/2}=\text{msign}(\boldsymbol{G})\end{equation}
\]</span></p>
<p>This indicates that when <span class="math inline">\(\beta=0\)</span>, Shampoo and Muon are theoretically equivalent! Therefore, Shampoo and Muon have common design principles.</p>
</section>
</section>
<section id="thoughts-on-spectral-norm-gradients-and-new-forms-of-weight-decay" class="level1">
<h1>Thoughts on spectral norm gradients and new forms of weight decay</h1>
<p><a href="https://kexue.fm/archives/10648">从谱范数梯度到新式权重衰减的思考 - 科学空间|Scientific Spaces</a> (2024-12-25)</p>
<p>In <a href="#sec-muon-appreciation"><em>Muon Appreciation</em></a>, we introduced a new optimizer called “Muon”, which can be viewed as gradient descent under spectral norm regularization, which seems a more geometrically meaningful approach for optimizing matrix parameters. As is well known, we often add weight decay for matrix parameters, which can be understood as <span class="math inline">\(\nabla_M \|M\|_F^2\)</span>, the gradient of the squared Frobenius norm. From Muon’s perspective, would constructing a new weight decay through the gradient of the squared spectral norm produce better results?</p>
<p>So the question arises: what does the gradient or derivative of the spectral norm look like? And what would a new weight decay designed with it look like? We’ll explore these questions below.</p>
<section id="basic-review" class="level2">
<h2 class="anchored" data-anchor-id="basic-review">Basic review</h2>
<p>The spectral norm <span class="math inline">\(\|\cdot\|_2\)</span> (also known as the 2-norm) is one of the most commonly used matrix norms. Compared to the simpler Frobenius norm <span class="math inline">\(\|\cdot\|_F\)</span>, it often reveals more essential signals related to matrix multiplication, because its definition is directly related to matrix multiplication: for a matrix parameter <span class="math inline">\(\boldsymbol{W}\in\mathbb{R}^{n\times m}\)</span>, its spectral norm is defined as</p>
<p><span class="math display">\[
\begin{equation}\Vert\boldsymbol{W}\Vert_2 \triangleq \max_{\Vert\boldsymbol{x}\Vert=1} \Vert\boldsymbol{W}\boldsymbol{x}\Vert\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\boldsymbol{x}\in\mathbb{R}^m\)</span> is a column vector, and the <span class="math inline">\(\Vert\cdot\Vert\)</span> on the right side is the Euclidean norm of vectors. From another perspective, the spectral norm is the smallest constant <span class="math inline">\(C\)</span> such that the following inequality holds for <span class="math inline">\(\forall \boldsymbol{x}\in\mathbb{R}^m\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\Vert\boldsymbol{W}\boldsymbol{x}\Vert \leq C\Vert\boldsymbol{x}\Vert\end{equation}
\]</span></p>
<p>It’s not hard to prove that when <span class="math inline">\(C\)</span> takes the Frobenius norm <span class="math inline">\(\Vert W\Vert_F\)</span>, the above inequality still holds, so we can write <span class="math inline">\(\Vert \boldsymbol{W}\Vert_2\leq \Vert \boldsymbol{W}\Vert_F\)</span> (since <span class="math inline">\(\Vert \boldsymbol{W}\Vert_F\)</span> is just one of the <span class="math inline">\(C\)</span> values that makes the inequality hold, while <span class="math inline">\(\Vert \boldsymbol{W}\Vert_2\)</span> is the smallest such <span class="math inline">\(C\)</span>). This conclusion also suggests that if we want to control the magnitude of the output, using the spectral norm as a regularization term is more precise than using the Frobenius norm.</p>
<p>Six years ago, in <a href="https://kexue.fm/archives/6051"><em>Lipschitz Constraints in Deep Learning: Generalization and Generative Models</em></a>, I discussed the spectral norm in two application scenarios:</p>
<ol type="1">
<li>Wasserstein GAN explicitly proposed a Lipschitz constraint on the discriminator, and one implementation approach was based on spectral norm normalization.</li>
<li>Some empirical work showed that the spectral norm as a regularization term performs better compared to Frobenius norm regularization.</li>
</ol>
</section>
<section id="gradient-derivation" class="level2">
<h2 class="anchored" data-anchor-id="gradient-derivation">Gradient derivation</h2>
<p>Now let’s get to the main point and try to derive the gradient of the spectral norm <span class="math inline">\(\nabla_{\boldsymbol{W}} \Vert\boldsymbol{W}\Vert_2\)</span>. Since the spectral norm is equal to the largest singular value, if <span class="math inline">\(\boldsymbol{W}\)</span> can be decomposed by SVD as <span class="math inline">\(\sum\limits_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}\)</span>, then</p>
<p><span class="math display">\[
\begin{equation}\Vert\boldsymbol{W}\Vert_2 = \sigma_1 = \boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1\end{equation}
\]</span></p>
<p>where <span class="math inline">\(\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_{\min(n,m)} \geq 0\)</span> are the singular values of <span class="math inline">\(\boldsymbol{W}\)</span>. Taking the differential of both sides, we get</p>
<p><span class="math display">\[
\begin{equation}d\Vert\boldsymbol{W}\Vert_2 = d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1 + \boldsymbol{u}_1^{\top}d\boldsymbol{W}\boldsymbol{v}_1 + \boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1\end{equation}
\]</span></p>
<p>Note that</p>
<p><span class="math display">\[
\begin{equation}d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1 = d\boldsymbol{u}_1^{\top}\sum_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}\boldsymbol{v}_1 = d\boldsymbol{u}_1^{\top}\sigma_1 \boldsymbol{u}_1 = \frac{1}{2}\sigma_1 d(\Vert\boldsymbol{u}_1\Vert^2)=0\end{equation}
\]</span></p>
<p>Similarly, <span class="math inline">\(\boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1=0\)</span>, so</p>
<p><span class="math display">\[
\begin{equation}d\Vert\boldsymbol{W}\Vert_2 = \boldsymbol{u}_1^{\top}d\boldsymbol{W}\boldsymbol{v}_1 = \text{Tr}((\boldsymbol{u}_1 \boldsymbol{v}_1^{\top})^{\top} d\boldsymbol{W}) \quad\Rightarrow\quad \nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2 = \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\end{equation}
\]</span></p>
<p>Note that this proof process has a key condition: <span class="math inline">\(\sigma_1 &gt; \sigma_2\)</span>. If <span class="math inline">\(\sigma_1=\sigma_2\)</span>, then <span class="math inline">\(\Vert\boldsymbol{W}\Vert_2\)</span> can be expressed as both <span class="math inline">\(\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1\)</span> and <span class="math inline">\(\boldsymbol{u}_2^{\top}\boldsymbol{W}\boldsymbol{v}_2\)</span>, and the gradients calculated using the same method would be <span class="math inline">\(\boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\)</span> and <span class="math inline">\(\boldsymbol{u}_2 \boldsymbol{v}_2^{\top}\)</span> respectively. The non-uniqueness of the result means that the gradient does not exist. Of course, from a practical perspective, the probability of two numbers being exactly equal is very small, so this point can be ignored.</p>
<p>(This proof was based on an <a href="https://math.stackexchange.com/a/3000223">answer</a> on Stack Exchange, but that answer did not prove that <span class="math inline">\(d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1=0\)</span> and <span class="math inline">\(\boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1=0\)</span>. These were proved by me.)</p>
</section>
<section id="weight-decay" class="level2">
<h2 class="anchored" data-anchor-id="weight-decay">Weight decay</h2>
<p>Based on this result and the chain rule, we have</p>
<p><span id="eq-grad-2-2"><span class="math display">\[
\begin{equation}\nabla_{\boldsymbol{W}}\left(\frac{1}{2}\Vert\boldsymbol{W}\Vert_2^2\right) = \Vert\boldsymbol{W}\Vert_2\nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2 = \sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\end{equation}
\tag{20}\]</span></span></p>
<p>Comparing with the result under the Frobenius norm:</p>
<p><span class="math display">\[
\begin{equation}\nabla_{\boldsymbol{W}}\left(\frac{1}{2}\Vert\boldsymbol{W}\Vert_F^2\right) = \boldsymbol{W} = \sum_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top}\end{equation}
\]</span></p>
<p>Looking at it this way, it becomes very clear: weight decay derived from the squared Frobenius norm as a regularization term penalizes all singular values simultaneously; while weight decay corresponding to the squared spectral norm only penalizes the largest singular value. If our goal is to compress the size of the output, then compressing the maximum singular value is the “just right” approach. Compressing all singular values may achieve a similar purpose, but it might also compress the expressive power of the parameters.</p>
<p>By the <a href="https://en.wikipedia.org/wiki/Low-rank_approximation">Eckart–Young–Mirsky theorem</a>, the RHS of <a href="#eq-grad-2-2" class="quarto-xref">Equation&nbsp;20</a> is the optimal rank-1 approximation of <span class="math inline">\(\boldsymbol{W}\)</span>. In other words, spectral norm weight decay changes the operation from subtracting itself at each step to subtracting its optimal rank-1 approximation at each step, weakening the penalty strength, and to some extent allows the penalty to hit closer to the heart of the issue.</p>
</section>
<section id="numerical-computation" class="level2">
<h2 class="anchored" data-anchor-id="numerical-computation">Numerical computation</h2>
<p>For practical purposes, the key question arises: how to compute <span class="math inline">\(\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\)</span>? SVD is certainly the simplest and most direct solution, but its computational complexity is undoubtedly the highest. We must find a more efficient computation path.</p>
<p>Without loss of generality, let <span class="math inline">\(n\geq m\)</span>. First, note that</p>
<p><span class="math display">\[
\begin{equation}\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top} = \sum_{i=1}^m\sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top} \boldsymbol{v}_1 \boldsymbol{v}_1^{\top} = \boldsymbol{W}\boldsymbol{v}_1 \boldsymbol{v}_1^{\top}\end{equation}
\]</span></p>
<p>This shows that to compute <span class="math inline">\(\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\)</span>, we only need to know <span class="math inline">\(\boldsymbol{v}_1\)</span>, and <span class="math inline">\(\boldsymbol{v}_1\)</span> is actually the eigenvector corresponding to the largest eigenvalue of the matrix <span class="math inline">\(\boldsymbol{W}^{\top}\boldsymbol{W}\)</span>. In this way, we have transformed the problem from SVD of a general matrix <span class="math inline">\(\boldsymbol{W}\)</span> to eigenvalue decomposition of a real symmetric matrix <span class="math inline">\(\boldsymbol{W}^{\top}\boldsymbol{W}\)</span>, which has already reduced the complexity, because eigenvalue decomposition is usually significantly faster than SVD.</p>
<p>If you still think it’s slow, then apply the standard trick used in many eigenvalue decomposition algorithms, <a href="https://en.wikipedia.org/wiki/Power_iteration">power iteration</a>:</p>
<p>When <span class="math inline">\(\sigma_1 &gt; \sigma_2\)</span>, the iteration <span class="math display">\[
\begin{equation}\boldsymbol{x}_{t+1} = \frac{\boldsymbol{W}^{\top}\boldsymbol{W}\boldsymbol{x}_t}{\Vert\boldsymbol{W}^{\top}\boldsymbol{W}\boldsymbol{x}_t\Vert}\end{equation}
\]</span></p>
<p>converges to <span class="math inline">\(\boldsymbol{v}_1\)</span> at a rate of <span class="math inline">\((\sigma_2/\sigma_1)^{2t}\)</span>.</p>
<p>Each step of power iteration only requires computing two “matrix-vector” multiplications, with a complexity of <span class="math inline">\(\mathcal{O}(nm)\)</span>. The total complexity of <span class="math inline">\(t\)</span> iterations is <span class="math inline">\(\mathcal{O}(tnm)\)</span>, which is very ideal. The disadvantage is that convergence can be slow when <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> are close. But power iteration often performs better in practice than in theory. Many early works even achieved good results with just one iteration, because when <span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span> are close, it indicates that both values and their eigenvectors are somewhat interchangeable to some degree. Even if power iteration doesn’t fully converge, it still gives an average of their eigenvectors, which is often sufficient.</p>
</section>
<section id="proof-of-iteration" class="level2">
<h2 class="anchored" data-anchor-id="proof-of-iteration">Proof of iteration</h2>
<p>In this section, we’ll complete the proof of power iteration. It’s not hard to see that power iteration can be equivalently written as</p>
<p><span class="math display">\[
\begin{equation}\lim_{t\to\infty} \frac{(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0}{\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert} = \boldsymbol{v}_1\end{equation}
\]</span></p>
<p>To prove this limit, we start from <span class="math inline">\(\boldsymbol{W}=\sum\limits_{i=1}^m\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}\)</span>, substitute and calculate to get</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{W}^{\top}\boldsymbol{W} = \sum_{i=1}^m\sigma_i^2 \boldsymbol{v}_i\boldsymbol{v}_i^{\top},\qquad(\boldsymbol{W}^{\top}\boldsymbol{W})^t = \sum_{i=1}^m\sigma_i^{2t} \boldsymbol{v}_i\boldsymbol{v}_i^{\top}\end{equation}
\]</span></p>
<p>Since <span class="math inline">\(\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m\)</span> form an orthonormal basis of <span class="math inline">\(\mathbb{R}^m\)</span>, <span class="math inline">\(\boldsymbol{x}_0\)</span> can be written as <span class="math inline">\(\sum\limits_{j=1}^m c_j \boldsymbol{v}_j\)</span>, so we have</p>
<p><span class="math display">\[
\begin{equation}(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0 = \sum_{i=1}^m\sigma_i^{2t} \boldsymbol{v}_i\boldsymbol{v}_i^{\top}\sum_{j=1}^m c_j \boldsymbol{v}_j = \sum_{i=1}^m\sum_{j=1}^m c_j\sigma_i^{2t} \boldsymbol{v}_i\underbrace{\boldsymbol{v}_i^{\top}  \boldsymbol{v}_j}_{=\delta_{i,j}} = \sum_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i\end{equation}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\begin{equation}\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert = \left\Vert \sum_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i\right\Vert = \sqrt{\sum_{i=1}^m c_i^2\sigma_i^{4t}}\end{equation}
\]</span></p>
<p>Due to random initialization, the probability of <span class="math inline">\(c_1=0\)</span> is very small, so we can assume <span class="math inline">\(c_1\neq 0\)</span>. Then</p>
<p><span class="math display">\[
\begin{equation}\frac{(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0}{\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert} = \frac{\sum\limits_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i}{\sqrt{\sum\limits_{i=1}^m c_i^2\sigma_i^{4t}}} = \frac{\boldsymbol{v}_1 + \sum\limits_{i=2}^m (c_i/c_1)(\sigma_i/\sigma_1)^{2t} \boldsymbol{v}_i}{\sqrt{1 + \sum\limits_{i=2}^m (c_i/c_1)^2(\sigma_i/\sigma_1)^{4t}}}\end{equation}
\]</span></p>
<p>When <span class="math inline">\(\sigma_1 &gt; \sigma_2\)</span>, all <span class="math inline">\(\sigma_i/\sigma_1(i\geq 2)\)</span> are less than 1, so as <span class="math inline">\(t\to \infty\)</span>, the corresponding terms all become 0, and the final limit is <span class="math inline">\(\boldsymbol{v}_1\)</span>.</p>
</section>
<section id="related-work-1" class="level2">
<h2 class="anchored" data-anchor-id="related-work-1">Related Work</h2>
<p>The earliest paper proposing spectral norm regularization should be the 2017 paper <a href="https://arxiv.org/abs/1705.10941">Spectral Norm Regularization for Improving the Generalizability of Deep Learning</a>, which compared methods such as weight decay, adversarial training, and spectral norm regularization, finding that spectral norm regularization performed best in terms of generalization performance.</p>
<p>The approach in the paper at that time was not like this article’s approach of calculating <span class="math inline">\(\nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2^2 = 2\sigma_1\boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\)</span>, but rather directly estimating <span class="math inline">\(\Vert\boldsymbol{W}\Vert_2\)</span> through power iteration, then adding <span class="math inline">\(\Vert\boldsymbol{W}\Vert_2^2\)</span> to the loss function with a weight, letting the optimizer calculate the gradient itself. This approach is slightly less efficient and makes it harder to decouple from the optimizer in the form of weight decay. This article’s approach is relatively more flexible, allowing us, like AdamW, to keep weight decay independent from the optimization of the main loss function.</p>
<p>Of course, from today’s LLM perspective, the biggest problem with those early experiments was that they were all too small in scale to be sufficiently convincing. However, given the precedent of the spectral norm-based Muon optimizer, I believe it’s worth reconsidering and trying spectral norm weight decay. Certainly, whether it’s Frobenius norm or spectral norm weight decay, these techniques aimed at “generalization” often have some luck involved, so it’s best to maintain moderate expectations.</p>
<p>Initial experiments on language models show that there might be a slight improvement at the loss level. Hopefully this is not an illusion, but even if it’s an illusion, at least no degradation was observed. The experimental process involved using power iteration to approximate <span class="math inline">\(\boldsymbol{v}_1\)</span> (initialized as an all-ones vector, iterated 10 times), then changing the original weight decay <span class="math inline">\(-\lambda \boldsymbol{W}\)</span> to <span class="math inline">\(-\lambda \boldsymbol{W}\boldsymbol{v}_1\boldsymbol{v}_1^{\top}\)</span>, keeping the value of <span class="math inline">\(\lambda\)</span> unchanged.</p>
</section>
</section>
<section id="why-is-the-default-scale-of-gradient-clipping-1" class="level1">
<h1>Why is the default scale of gradient clipping 1?</h1>
<p><a href="https://kexue.fm/archives/10657">为什么梯度裁剪的默认模长是1？ - 科学空间|Scientific Spaces</a> (2025-01-02)</p>
<p>We know that gradient clipping is a common technique to make model training more stable. The commonly used gradient clipping method clips gradients based on the total norm of all parameter gradients, and its operation can be expressed as:</p>
<p><span class="math display">\[
\begin{equation}\text{clip}(\boldsymbol{g},\tau)=\left\{\begin{aligned}&amp;\boldsymbol{g}, &amp;\Vert\boldsymbol{g}\Vert\leq \tau \\
&amp;\frac{\tau}{\Vert\boldsymbol{g}\Vert}\boldsymbol{g},&amp;\Vert\boldsymbol{g}\Vert &gt; \tau
\end{aligned}\right.\end{equation}
\]</span></p>
<p>In this way, <span class="math inline">\(\text{clip}(\boldsymbol{g},\tau)\)</span> maintains the same direction as <span class="math inline">\(\boldsymbol{g}\)</span>, but the norm does not exceed <span class="math inline">\(\tau\)</span>. Note that <span class="math inline">\(\Vert\boldsymbol{g}\Vert\)</span> here is the norm calculated by treating all parameter gradients of the entire model together as a single vector, which is the so-called Global Gradient Norm.</p>
<p>Have you noticed a detail: whether it’s a model with hundreds of millions of parameters or tens of billions of parameters, the value of <span class="math inline">\(\tau\)</span> is often 1 in many cases. What does this imply? Is it simply reusing the default value, or is there some profound principle behind it?</p>
<section id="what-does-it-mean" class="level2">
<h2 class="anchored" data-anchor-id="what-does-it-mean">What does it mean?</h2>
<p>Some readers might think, the default value is not necessarily the optimal value, so why bother with it? Indeed, <span class="math inline">\(\tau=1\)</span> may not be the optimal choice, but it is the default choice for many models, and these models perform reasonably well with this default choice, which in turn suggests that <span class="math inline">\(\tau=1\)</span> is a “universally reasonable” choice.</p>
<p>What does it mean to say a choice of <span class="math inline">\(\tau\)</span> is “reasonable”? Let’s return to the <span class="math inline">\(\text{clip}\)</span> operation. If <span class="math inline">\(\Vert\boldsymbol{g}\Vert\)</span> is always less than <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\text{clip}\)</span> degenerates into an identity transformation; if <span class="math inline">\(\Vert\boldsymbol{g}\Vert\)</span> is always greater than <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\text{clip}\)</span> degenerates into L2 normalization. In other words, the reason <span class="math inline">\(\text{clip}\)</span> is <span class="math inline">\(\text{clip}\)</span> is because <span class="math inline">\(\tau\)</span> produces an appropriate level of distinction, making most <span class="math inline">\(\Vert\boldsymbol{g}\Vert\)</span> less than <span class="math inline">\(\tau\)</span>, with only a small portion greater than <span class="math inline">\(\tau\)</span> – this is the meaning of saying this <span class="math inline">\(\tau\)</span> is “reasonable”.</p>
<p>Of course, counterexamples can be found, and quite a few at that. Here, I mainly want to emphasize the universality of this phenomenon and the general applicability of this default setting, so meticulous readers need not be overly fixated on individual details.</p>
<p>Therefore, we believe that the universal reasonableness of <span class="math inline">\(\tau=1\)</span> means that regardless of the number of model parameters, how they are initialized, or what loss function is chosen, the total gradient norm can roughly use <span class="math inline">\(1\)</span> as the boundary point for “abnormal values” – this is undoubtedly an incredibly amazing property. This was precisely my feeling when I first realized this conclusion.</p>
</section>
<section id="why-does-this-happen" class="level2">
<h2 class="anchored" data-anchor-id="why-does-this-happen">Why does this happen?</h2>
<p><span class="math inline">\(\tau=1\)</span> seems way too nice. Why is Heaven so nice to us? My answer might be somewhat unexpected: because only in this way is stable training of the model possible.</p>
<p>Let’s consider the loss function <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta})\)</span>, with the optimizer update rule <span class="math inline">\(\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t - \eta\, \boldsymbol{u}_t\)</span>. Then the change in the loss function can be approximated as:</p>
<p><span class="math display">\[
\begin{equation}\Delta \mathcal{L} = \mathcal{L}(\boldsymbol{\theta}_{t+1}) - \mathcal{L}(\boldsymbol{\theta}_t) \approx (\boldsymbol{\theta}_{t+1} - \boldsymbol{\theta}_t)\cdot\nabla_{\boldsymbol{\theta}_t}\mathcal{L}(\boldsymbol{\theta}) = -\eta\, \boldsymbol{u}_t\cdot \boldsymbol{g}_t\end{equation}
\]</span></p>
<p>First, consider the simplest SGD, where <span class="math inline">\(\boldsymbol{u}_t = \boldsymbol{g}_t\)</span> and <span class="math inline">\(\Delta \mathcal{L}=-\eta\Vert\boldsymbol{g}_t\Vert^2\)</span>, meaning the change in the loss function is proportional to the square of the gradient norm. We know that, whether in CV or NLP, pure SGD (without momentum) is a very inefficient optimizer. In the middle and later stages of training, on average, the decrease in loss per step for most tasks is far less than the learning rate, i.e., <span class="math inline">\(|\Delta \mathcal{L}| &lt; \eta\)</span>, from which we can deduce <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert &lt; 1\)</span>. This indicates that <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert &lt; 1\)</span> is the long-term performance of a model that can converge normally.</p>
<p>Of course, in the early stages of training, the model may exhibit <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert &gt; 1\)</span>, which is normal, but it’s rare to have <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert \gg 1\)</span>. In other words, a good initialization should avoid <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert \gg 1\)</span>, which is the theoretical basis for methods like <a href="https://kexue.fm/archives/8978">DeepNorm</a>. The reason is similar: if the gradient norm is too large, then early learning will be too “aggressive”, leading to premature convergence to poor local minima. Another approach is to reduce <span class="math inline">\(\eta\)</span>, which can also reduce <span class="math inline">\(|\Delta \mathcal{L}|\)</span>. This is why we typically use Warmup in the early stages of training.</p>
<p>By the way, for understanding Warmup, readers can refer to the paper <a href="https://arxiv.org/abs/2310.07831">Optimal Linear Decay Learning Rate Schedules and Further Refinements</a>, which I consider to be the most reasonable analysis of Warmup.</p>
</section>
<section id="what-to-do" class="level2">
<h2 class="anchored" data-anchor-id="what-to-do">What to do?</h2>
<p>Simply put, since the change in the loss function is proportional to the square of the gradient norm, the stability of training determines that the gradient norm cannot be too large, and its long-term performance is less than 1. If significantly larger gradient norms appear in the early stage, the usual strategy is Warmup. Or a more general strategy can be considered: set another threshold <span class="math inline">\(\mathcal{T}\)</span> and clip <span class="math inline">\(\eta\)</span> based on the value of <span class="math inline">\(\boldsymbol{u}_t\cdot \boldsymbol{g}_t\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\eta_t = \left\{\begin{aligned}&amp;\eta,&amp; \boldsymbol{u}_t\cdot \boldsymbol{g}_t\leq \mathcal{T} \\ &amp;\frac{\mathcal{T}}{\boldsymbol{u}_t\cdot \boldsymbol{g}_t}\eta,&amp; \boldsymbol{u}_t\cdot \boldsymbol{g}_t &gt; \mathcal{T}
\end{aligned}\right.\end{equation}
\]</span></p>
<p>This eliminates the need for additional Warmup settings and is more adaptive.</p>
<p>For optimizers like Adam, we can use approximate analysis through <span class="math inline">\(\boldsymbol{u}_t=\text{sign}(\boldsymbol{g}_t)\)</span>, as <a href="#sec-learning-rate-batch-size">previously described</a>. In this case:</p>
<p><span class="math display">\[
\begin{equation}\Delta \mathcal{L} = -\eta\, \text{sign}(\boldsymbol{g}_t)\cdot \boldsymbol{g}_t = -\eta\, \Vert\boldsymbol{g}_t\Vert_1\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\Vert\cdot\Vert_1\)</span> is the L1 norm, i.e., the sum of the absolute values of the components. Since gradient components are generally less than 1, <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert_1 \gg \Vert\boldsymbol{g}_t\Vert\)</span>. Therefore, due to the requirement for stable training, the learning rate for Adam is typically significantly smaller than that for SGD. Additionally, the above equation can be rewritten as:</p>
<p><span class="math display">\[
\begin{equation}\Delta \mathcal{L} = -\eta\, \text{sign}(\boldsymbol{g}_t)\cdot \boldsymbol{g}_t = -\eta\, \sqrt{N}\Vert\boldsymbol{g}_t\Vert \cos(\text{sign}(\boldsymbol{g}_t), \boldsymbol{g}_t) \end{equation}
\]</span></p>
<p>This assumes that <span class="math inline">\(\boldsymbol{g}_t\)</span> has no zero components, so <span class="math inline">\(\Vert\text{sign}(\boldsymbol{g}_t)\Vert=\sqrt{N}\)</span>, where <span class="math inline">\(N\)</span> is the total number of model parameters. In practice, it’s found that <span class="math inline">\(\Vert\boldsymbol{g}_t\Vert\)</span> and <span class="math inline">\(\cos(\text{sign}(\boldsymbol{g}_t), \boldsymbol{g}_t)\)</span> are roughly constant across different model scales. Therefore, to maintain a constant <span class="math inline">\(\Delta \mathcal{L}\)</span>, <span class="math inline">\(\eta\)</span> should be inversely proportional to <span class="math inline">\(\sqrt{N}\)</span>, meaning that if the number of model parameters increases by a factor of 4, the learning rate could be halved.</p>
</section>
</section>
<section id="sec-muon-sequel" class="level1 page-columns page-full">
<h1>Muon sequel: Why did we choose to give Muon a try?</h1>
<p><a href="https://kexue.fm/archives/10739">Muon续集：为什么我们选择尝试Muon？ - 科学空间|Scientific Spaces</a> (2025-02-27)</p>
<p>This article explicates our latest technical report <a href="https://arxiv.org/abs/2502.16982"><em>Muon is Scalable for LLM Training</em></a>, which shares a relatively large-scale implementation of the Muon optimizer that we previously introduced in <a href="#sec-muon-appreciation"><em>Muon Appreciation</em></a>. We’ve also open-sourced the corresponding models (which we call “<a href="https://github.com/MoonshotAI/Moonlight">Moonlight</a>”, currently a 3B/16B MoE model).<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> We discovered a rather surprising conclusion: under our experimental settings, Muon can achieve nearly twice the training efficiency compared to Adam.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;It’s named “Moonlight” because the authors are from Moonshot AI, whose Chinese name is 月之暗面 (“Dark Side of the Moon”).</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/1300601661.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Muon scaling law and the MMLU scores of Moonlight.</figcaption>
</figure>
</div>
<p>Out of all the optimizers we could have tried, why Muon? How can we quickly switch from a well-tuned Adam optimizer to Muon for experimentation? How do the performance differences between Muon and Adam change as models scale up? Next, we will share our thought process.</p>
<section id="optimization-principles" class="level2">
<h2 class="anchored" data-anchor-id="optimization-principles">Optimization principles</h2>
<p>Regarding optimizers, I had already provided a brief assessment in <a href="#sec-muon-appreciation"><em>Muon Appreciation</em></a>. Most optimizer improvements are just tiny variants of the same basic thing. Not to say they’re worthless, but they won’t make a profound or stunning impression on you.</p>
<p>We need to think about what makes a good optimizer from principles closer to the essence. Intuitively, an ideal optimizer should have two characteristics: stable and fast. Specifically, each update of an ideal optimizer should satisfy two points:</p>
<ol type="1">
<li>Disturb the model as little as possible.</li>
<li>Contribute as much as possible to loss reduction. More directly, we don’t want to drastically change the model (stability), but we want to greatly reduce the loss (speed). It’s “both… and…”.</li>
</ol>
<p>How do we translate these two characteristics into mathematical language? We can understand <strong>stability</strong> as a constraint on the update magnitude, and <strong>speed</strong> as finding the update that makes the loss function decrease most rapidly. So this can be transformed into a constrained optimization problem. Using the notation from earlier, for a matrix parameter <span class="math inline">\(\boldsymbol{W}\in\mathbb{R}^{n\times m}\)</span> with gradient <span class="math inline">\(\boldsymbol{G}\in\mathbb{R}^{n\times m}\)</span>, when the parameter changes from <span class="math inline">\(\boldsymbol{W}\)</span> to <span class="math inline">\(\boldsymbol{W}+\Delta\boldsymbol{W}\)</span>, the change in the loss function is</p>
<p><span class="math display">\[
\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\end{equation}
\]</span></p>
<p>Therefore, conditional on being stable, the fastest update should satisfy</p>
<p><span id="eq-least-action"><span class="math display">\[
\begin{equation}\mathop{\text{argmin}}_{\Delta\boldsymbol{W}}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\quad\text{s.t.}\quad \rho(\Delta\boldsymbol{W})\leq \eta\end{equation}
\tag{21}\]</span></span></p>
<p>Here, <span class="math inline">\(\rho(\Delta\boldsymbol{W})\geq 0\)</span> is some metric of <strong>stability</strong>, where smaller values indicate greater stability, and <span class="math inline">\(\eta\)</span> is a constant less than 1, representing our requirement for <strong>stability</strong>. Later we’ll see that it’s actually the learning rate of the optimizer. If readers don’t mind, we can borrow concepts from theoretical physics and call it the “<strong><font color="orange">Least Action Principle</font></strong>” for optimizers.</p>
</section>
<section id="matrix-norms-1" class="level2">
<h2 class="anchored" data-anchor-id="matrix-norms-1">Matrix norms</h2>
<p>The only uncertainty in <a href="#eq-least-action" class="quarto-xref">Equation&nbsp;21</a> is the stability measure <span class="math inline">\(\rho(\Delta\boldsymbol{W})\)</span>. Once <span class="math inline">\(\rho(\Delta\boldsymbol{W})\)</span> is determined, <span class="math inline">\(\Delta\boldsymbol{W}\)</span> can be explicitly solved (at least theoretically). To some extent, we can consider that the essential difference between different optimizers is how they define <strong>stability</strong>.</p>
<p>Many readers probably encountered statements like “the negative gradient direction is the direction of steepest descent for the function value locally” when first learning SGD. In this framework, it actually means choosing the Frobenius norm <span class="math inline">\(\Vert\Delta\boldsymbol{W}\Vert_F\)</span> as the measure of <strong>stability</strong>. In other words, the “direction of steepest descent” is not immutable – it can only be determined after choosing a metric. Change the norm, and it may no longer be the negative gradient direction.</p>
<p>The next question naturally is: which norm most appropriately measures <strong>stability</strong>? If we impose strong constraints, sure, we will definitely achieve stability, but the optimizer will crawl like a snail, only converging to a suboptimal solution. Conversely, if we weaken the constraints, the optimizer will fly like a crazy bat, making the training process extremely unstable. So, ideally, we want to find the most precise index of <strong>stability</strong>. Considering that neural networks primarily involve matrix multiplication, let’s take <span class="math inline">\(\boldsymbol{y}=\boldsymbol{x}\boldsymbol{W}\)</span> as an example:</p>
<p><span class="math display">\[
\begin{equation}\Vert\Delta \boldsymbol{y}\Vert = \Vert\boldsymbol{x}(\boldsymbol{W} + \Delta\boldsymbol{W}) - \boldsymbol{x}\boldsymbol{W}\Vert = \Vert\boldsymbol{x} \Delta\boldsymbol{W}\Vert\leq \rho(\Delta\boldsymbol{W}) \Vert\boldsymbol{x}\Vert\end{equation}
\]</span></p>
<p>This means that when the parameter changes from <span class="math inline">\(\boldsymbol{W}\)</span> to <span class="math inline">\(\boldsymbol{W}+\Delta\boldsymbol{W}\)</span>, the change in model output is <span class="math inline">\(\Delta\boldsymbol{y}\)</span>. We hope that the magnitude of this change can be controlled by <span class="math inline">\(\Vert\boldsymbol{x}\Vert\)</span> and a function <span class="math inline">\(\rho(\Delta\boldsymbol{W})\)</span> related to <span class="math inline">\(\Delta\boldsymbol{W}\)</span>, and we use this function as an index of <strong>stability</strong>. From linear algebra, we know that the most accurate value for <span class="math inline">\(\rho(\Delta\boldsymbol{W})\)</span> is the spectral norm of <span class="math inline">\(\Delta\boldsymbol{W}\)</span>, denoted as <span class="math inline">\(\Vert\Delta\boldsymbol{W}\Vert_2\)</span>. Substituting into <a href="#eq-least-action" class="quarto-xref">Equation&nbsp;21</a>, we get:</p>
<p><span class="math display">\[
\begin{equation}\mathop{\text{argmin}}_{\Delta\boldsymbol{W}}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\quad\text{s.t.}\quad \Vert\Delta\boldsymbol{W}\Vert_2\leq \eta\end{equation}
\]</span></p>
<p>The solution to this optimization problem is Muon with <span class="math inline">\(\beta=0\)</span>:</p>
<p><span class="math display">\[
\begin{equation}\Delta\boldsymbol{W} = -\eta\, \text{msign}(\boldsymbol{G}) = -\eta\,\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top}, \quad \boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}^{\top} = SVD(\boldsymbol{G})\end{equation}
\]</span></p>
<p>When <span class="math inline">\(\beta &gt; 0\)</span>, <span class="math inline">\(\boldsymbol{G}\)</span> is replaced with momentum <span class="math inline">\(\boldsymbol{M}\)</span>, which can be seen as a smoother estimate of the gradient, so it can still be understood as the conclusion above. Therefore, we can say that “Muon is steepest descent under the spectral norm.” As for Newton–Schulz iterations and the like, they are computational approximations, which we won’t elaborate on here. We already provided detailed derivations in <a href="#sec-muon-appreciation"><em>Muon Appreciation</em></a>, so we won’t repeat them.</p>
</section>
<section id="weight-decay-1" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="weight-decay-1">Weight decay</h2>
<p>At this point, we can answer the first question: why try Muon? Like SGD, Muon also gives the direction of steepest descent, but its spectral norm constraint is more precise than SGD’s Frobenius norm, so it has better potential. On the other hand, improving optimizers from the perspective of “choosing the most appropriate constraint for different parameters” seems more fundamental than various small patches over the same thing.</p>
<p>Of course, potential doesn’t always translate to performance, and there are some annoying gotchas when validating Muon on larger models. First is the weight decay problem. Although I included weight decay when introducing Muon in <a href="#sec-muon-appreciation"><em>Muon Appreciation</em></a>, the authors of Muon didn’t include it when they first proposing Muon. We initially implemented it according to the official version and found that while Muon converged faster at the beginning, it was soon caught up by Adam, and various “internal issues” showed signs of collapse.</p>
<p>We quickly realized this might be a weight decay issue, so we added weight decay:</p>
<p><span class="math display">\[
\begin{equation}\Delta\boldsymbol{W} = -\eta\, [\text{msign}(\boldsymbol{M})+ \lambda \boldsymbol{W}]\end{equation}
\]</span></p>
<p>Continuing the experiment, sure enough, Muon consistently maintained its lead over Adam, as shown in Figure 2 of the paper:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/3675708776.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">With vs without weight decay.</figcaption>
</figure>
</div>
<p>What role does weight decay play? In retrospect, it should have been clear that we should keep the an upper bound on the norm of the matrix parameter:</p>
<p><span class="math display">\[
\begin{equation}\begin{aligned}
\Vert\boldsymbol{W}_t\Vert =&amp;\, \Vert\boldsymbol{W}_{t-1} - \eta_t (\boldsymbol{O}_t + \lambda \boldsymbol{W}_{t-1})\Vert \\
=&amp;\, \Vert(1 - \eta_t \lambda)\boldsymbol{W}_{t-1} - \eta_t \lambda (\boldsymbol{O}_t/\lambda)\Vert \\
\leq &amp;\,(1 - \eta_t \lambda)\Vert\boldsymbol{W}_{t-1}\Vert + \eta_t \lambda \Vert\boldsymbol{O}_t/\lambda\Vert \\
\leq &amp;\,\max(\Vert\boldsymbol{W}_{t-1}\Vert,\Vert\boldsymbol{O}_t/\lambda\Vert) \\
\end{aligned}\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\Vert\cdot\Vert\)</span> is any matrix norm, meaning the above inequality holds for any matrix norm. <span class="math inline">\(\boldsymbol{O}_t\)</span> is the update vector given by the optimizer, which is <span class="math inline">\(\text{msign}(\boldsymbol{M})\)</span> for Muon. When we take the spectral norm, <span class="math inline">\(\Vert\text{msign}(\boldsymbol{M})\Vert_2 = 1\)</span>, so for Muon, we have:</p>
<p><span class="math display">\[
\begin{equation}
\Vert\boldsymbol{W}_t\Vert_2 \leq \max(\Vert\boldsymbol{W}_{t-1}\Vert_2,1/\lambda)\leq\cdots \leq \max(\Vert\boldsymbol{W}_0\Vert_2,1/\lambda)\end{equation}
\]</span></p>
<p>This keeps the model “healthy on the inside”, because <span class="math inline">\(\Vert\boldsymbol{x}\boldsymbol{W}\Vert\leq \Vert\boldsymbol{x}\Vert\cdot\Vert\boldsymbol{W}\Vert_2\)</span>. When <span class="math inline">\(\Vert\boldsymbol{W}\Vert_2\)</span> is controlled, it means that <span class="math inline">\(\Vert\boldsymbol{x}\boldsymbol{W}\Vert\)</span> is also controlled, eliminating the risk of explosion, which is particularly important for issues like Attention Logits explosion. Of course, this upper bound is quite loose in most cases, and in practice, the spectral norm of parameters is often significantly smaller than this upper bound. This inequality simply shows that weight decay can control norms.</p>
</section>
<section id="rms-alignment" class="level2">
<h2 class="anchored" data-anchor-id="rms-alignment">RMS alignment</h2>
<p>When we decide to try a new optimizer, a challenging problem is how to quickly find near-optimal hyperparameters. For instance, Muon has at least two hyperparameters: learning rate <span class="math inline">\(\eta_t\)</span> and decay rate <span class="math inline">\(\lambda\)</span>. Grid search is certainly possible but time-consuming. Here, we propose the Update RMS alignment approach for hyperparameter transfer, which can apply well-tuned Adam hyperparameters to other optimizers.</p>
<p>First, for a matrix <span class="math inline">\(\boldsymbol{W}\in\mathbb{R}^{n\times m}\)</span>, its RMS (Root Mean Square) is defined as:</p>
<p><span class="math display">\[
\begin{equation}\text{RMS}(\boldsymbol{W}) = \frac{\Vert \boldsymbol{W}\Vert_F}{\sqrt{nm}} = \sqrt{\frac{1}{nm}\sum_{i=1}^n\sum_{j=1}^m W_{i,j}^2}\end{equation}
\]</span></p>
<p>Simply put, RMS measures the average size of each element in the matrix. We observed that the RMS of Adam’s update is relatively stable, usually between 0.2 and 0.4, which is why <a href="#sec-learning-rate-batch-size">theoretical analyses we described previously</a> often use SignSGD to approximate Adam. Based on this, we suggest aligning the Update RMS of the new optimizer to 0.2 through RMS normalization:</p>
<p><span class="math display">\[
\begin{gather}
\boldsymbol{W}_t =\boldsymbol{W}_{t-1} - \eta_t (\boldsymbol{O}_t + \lambda \boldsymbol{W}_{t-1}) \\[6pt]
\downarrow \notag\\[6pt]
\boldsymbol{W}_t = \boldsymbol{W}_{t-1} - \eta_t (0.2\, \boldsymbol{O}_t/\text{RMS}(\boldsymbol{O}_t) + \lambda \boldsymbol{W}_{t-1})
\end{gather}
\]</span></p>
<p>This way, we can reuse Adam’s <span class="math inline">\(\eta_t\)</span> and <span class="math inline">\(\lambda\)</span> to achieve roughly the same update magnitude to parameters at each step. Practice shows that transitioning from Adam to Muon through this simple strategy can produce results significantly better than Adam, approaching the results of further fine-tuning Muon’s hyperparameters. Specifically, Muon’s <span class="math inline">\(\text{RMS}(\boldsymbol{O}_t)=\text{RMS}(\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top})\)</span> can be calculated analytically:</p>
<p><span class="math display">\[
\begin{equation}nm\,\text{RMS}(\boldsymbol{O}_t)^2 = \sum_{i=1}^n\sum_{j=1}^m \sum_{k=1}^r U_{i,k}^2V_{k,j}^2 = \sum_{k=1}^r\left(\sum_{i=1}^n U_{i,k}^2\right)\left(\sum_{j=1}^m V_{k,j}^2\right) = \sum_{k=1}^r 1 = r\end{equation}
\]</span></p>
<p>That is, <span class="math inline">\(\text{RMS}(\boldsymbol{O}_t) = \sqrt{r/nm}\)</span>. In practice, the probability of a matrix being strictly low-rank is quite small, so we can assume <span class="math inline">\(r = \min(n,m)\)</span>, giving us <span class="math inline">\(\text{RMS}(\boldsymbol{O}_t) = \sqrt{1/\max(n,m)}\)</span>. Therefore, we ultimately used the equivalent analytical version instead of direct RMS normalization:</p>
<p><span class="math display">\[
\begin{equation}\boldsymbol{W}_t = \boldsymbol{W}_{t-1} - \eta_t (0.2\, \boldsymbol{O}_t\,\sqrt{\max(n,m)} + \lambda \boldsymbol{W}_{t-1})\end{equation}
\]</span></p>
<p>This final formula indicates that it’s not appropriate to use the same learning rate for all parameters in Muon. For example, Moonlight is an MoE model with many matrix parameters whose shapes deviate from square matrices, resulting in a wide range of <span class="math inline">\(\max(n,m)\)</span> values. Using a single learning rate would inevitably lead to asynchronous issues where some parameters learn too quickly or too slowly, affecting the final result.</p>
</section>
<section id="experiments" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="experiments">Experiments</h2>
<p>We conducted a fairly comprehensive comparison between Adam and Muon on MoE models of sizes 2.4B/16B and found that Muon has significant advantages in both convergence speed and final performance. For detailed comparison results, we recommend reading the original paper; here we only share some excerpts.</p>
<p>First, here’s a relatively objective comparison table, including our own controlled variable training comparing Muon and Adam, as well as comparisons with models trained by others (DeepSeek) using Adam with the same architecture (for ease of comparison, Moonlight’s architecture is identical to DSV3-Small), showing Muon’s unique advantages. The following table from the paper compares between Muon (Moonlight) and Adam (Moonlight-A and DSV3-small):</p>
<style>table { border-collapse: collapse; width: 100%; margin: 20px 0; font-family: Arial, sans-serif; } th, td { padding: 8px; text-align: center; } th.left-align, td.left-align { text-align: left; } .border-top { border-top: 2px solid black; } .border-bottom { border-bottom: 2px solid black; } .border-right { border-right: 2px solid black; } .border-left { border-left: 2px solid black; } .bold { font-weight: bold; } .category { text-align: center; }</style>


<table class="table-hover caption-top table" data-quarto-postprocess="true">
<caption>Table 4: Comparison of different models at around 1.2T tokens.</caption>
<thead>
<tr class="border-top header">
<th data-quarto-table-cell-role="th"></th>
<th class="left-align" data-quarto-table-cell-role="th">Benchmark (Metric)</th>
<th data-quarto-table-cell-role="th">DSV3-Small</th>
<th data-quarto-table-cell-role="th">Moonlight-A@1.2T</th>
<th data-quarto-table-cell-role="th">Moonlight@1.2T</th>
</tr>
</thead>
<tbody>
<tr class="border-top odd">
<td data-quarto-table-cell-role="th"></td>
<td class="left-align" data-quarto-table-cell-role="th">Activated Params<sup>†</sup></td>
<td>2.24B</td>
<td>2.24B</td>
<td>2.24B</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th"></td>
<td class="left-align" data-quarto-table-cell-role="th">Total Params<sup>†</sup></td>
<td>15.29B</td>
<td>15.29B</td>
<td>15.29B</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th"></td>
<td class="left-align" data-quarto-table-cell-role="th">Training Tokens</td>
<td>1.33T</td>
<td>1.2T</td>
<td>1.2T</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th"></td>
<td class="left-align" data-quarto-table-cell-role="th">Optimizer</td>
<td>AdamW</td>
<td>AdamW</td>
<td>Muon</td>
</tr>
<tr class="border-top odd">
<td rowspan="4" class="category" data-quarto-table-cell-role="th">English</td>
<td class="left-align" data-quarto-table-cell-role="th">MMLU</td>
<td>53.3</td>
<td>60.2</td>
<td class="bold">60.4</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">MMLU-pro</td>
<td>-</td>
<td>26.8</td>
<td class="bold">28.1</td>
</tr>
<tr class="odd">
<td class="left-align" data-quarto-table-cell-role="th">BBH</td>
<td>41.4</td>
<td class="bold">45.3</td>
<td>43.2</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">TriviaQA</td>
<td>-</td>
<td>57.4</td>
<td class="bold">58.1</td>
</tr>
<tr class="border-top odd">
<td rowspan="2" class="category" data-quarto-table-cell-role="th">Code</td>
<td class="left-align" data-quarto-table-cell-role="th">HumanEval</td>
<td>26.8</td>
<td>29.3</td>
<td class="bold">37.2</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">MBPP</td>
<td>36.8</td>
<td>49.2</td>
<td class="bold">52.9</td>
</tr>
<tr class="border-top odd">
<td rowspan="3" class="category" data-quarto-table-cell-role="th">Math</td>
<td class="left-align" data-quarto-table-cell-role="th">GSM8K</td>
<td>31.4</td>
<td>43.8</td>
<td class="bold">45.0</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">MATH</td>
<td>10.7</td>
<td>16.1</td>
<td class="bold">19.8</td>
</tr>
<tr class="odd">
<td class="left-align" data-quarto-table-cell-role="th">CMath</td>
<td>-</td>
<td>57.8</td>
<td class="bold">60.2</td>
</tr>
<tr class="border-top even">
<td rowspan="2" class="category" data-quarto-table-cell-role="th">Chinese</td>
<td class="left-align" data-quarto-table-cell-role="th">C-Eval</td>
<td>-</td>
<td>57.2</td>
<td class="bold">59.9</td>
</tr>
<tr class="border-bottom odd">
<td class="left-align" data-quarto-table-cell-role="th">CMMLU</td>
<td>-</td>
<td>58.2</td>
<td class="bold">58.8</td>
</tr>
</tbody>
</table>
<p><small><sup>†</sup>The reported parameter counts exclude the embedding parameters.</small></p>
<p>What’s different about models trained with Muon? Since we said earlier that Muon is steepest descent under the spectral norm, and the spectral norm is the largest singular value, we thought of monitoring and analyzing singular values. Indeed, we found some interesting signals: parameters trained by Muon have a more uniform distribution of singular values. We use singular value entropy to quantitatively describe this phenomenon:</p>
<p><span class="math display">\[
\begin{equation}H(\boldsymbol{\sigma}) = -\frac{1}{\log n}\sum_{i=1}^n \frac{\sigma_i^2}{\sum_{j=1}^n\sigma_j^2}\log \frac{\sigma_i^2}{\sum_{j=1}^n\sigma_j^2}\end{equation}
\]</span></p>
<p>Here, <span class="math inline">\(\boldsymbol{\sigma}=(\sigma_1,\sigma_2,\cdots,\sigma_n)\)</span> represents all the singular values of a parameter. Parameters trained by Muon have higher entropy, meaning a more uniform distribution of singular values, which indicates that these parameters are less easily compressed. This suggests that Muon more fully utilizes the potential of the parameters:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/3782823216.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Weights trained by Muon have higher singular value entropy.</figcaption>
</figure>
</div>
<p>Another interesting finding is that when we use Muon for fine-tuning (SFT), we might get suboptimal solutions if the pre-training didn’t use Muon. Specifically, if both pre-training and fine-tuning use Muon, the performance is the best. But for the other three combinations (Adam+Muon, Muon+Adam, Adam+Adam), the effectiveness doesn’t show a clear pattern.</p>
<style>
  table {   border-collapse: collapse;   width: 100%;   margin: 20px 0;   font-family: Arial, sans-serif;  }  caption {   margin-bottom: 10px;   font-weight: bold;  }  th, td {   padding: 8px;   text-align: center;   border: 1px solid #ddd;  }  th.left-align, td.left-align {   text-align: left;  }  .border-top {   border-top: 2px solid black;  }  .border-bottom {   border-bottom: 2px solid black;  }  .border-right {   border-right: 2px solid black;  }  .border-left {   border-left: 2px solid black;  }  .bold {   font-weight: bold;  }
</style>


<table class="table-hover caption-top table" data-quarto-postprocess="true">
<caption>Table 6: Examining the impact of optimizer interchangeability between pretraining and SFT phases.</caption>
<thead>
<tr class="border-top header">
<th class="left-align border-top" data-quarto-table-cell-role="th">Benchmark (Metric)</th>
<th class="border-top border-right" data-quarto-table-cell-role="th"># Shots</th>
<th colspan="4" class="border-top border-left" data-quarto-table-cell-role="th">Moonlight-1.2T</th>
</tr>
</thead>
<tbody>
<tr class="border-top odd">
<td class="left-align" data-quarto-table-cell-role="th">Pretraining Optimizer</td>
<td class="border-right">-</td>
<td class="border-right">Muon</td>
<td class="border-right">AdamW</td>
<td class="border-right">Muon</td>
<td>AdamW</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">SFT Optimzier</td>
<td class="border-right">-</td>
<td class="border-right">Muon</td>
<td class="border-right">Muon</td>
<td class="border-right">AdamW</td>
<td>AdamW</td>
</tr>
<tr class="border-top odd">
<td class="left-align" data-quarto-table-cell-role="th">MMLU (EM)</td>
<td class="border-right">0-shot (CoT)</td>
<td class="border-right bold">55.7</td>
<td class="border-right">55.3</td>
<td class="border-right">50.2</td>
<td>52.0</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">HumanEval (Pass@1)</td>
<td class="border-right">0-shot</td>
<td class="border-right bold">57.3</td>
<td class="border-right">53.7</td>
<td class="border-right">52.4</td>
<td>53.1</td>
</tr>
<tr class="odd">
<td class="left-align" data-quarto-table-cell-role="th">MBPP (Pass@1)</td>
<td class="border-right">0-shot</td>
<td class="border-right bold">55.6</td>
<td class="border-right">55.5</td>
<td class="border-right">55.2</td>
<td>55.2</td>
</tr>
<tr class="border-bottom even">
<td class="left-align border-bottom" data-quarto-table-cell-role="th">GSM8K (EM)</td>
<td class="border-right border-bottom">5-shot</td>
<td class="border-right border-bottom bold">68.0</td>
<td class="border-right border-bottom">62.1</td>
<td class="border-right border-bottom">64.9</td>
<td class="border-bottom">64.6</td>
</tr>
</tbody>
</table>

<style>
  table {   border-collapse: collapse;   width: 100%;   margin: 20px 0;   font-family: Arial, sans-serif;  }  caption {   margin-bottom: 10px;   font-weight: bold;  }  th, td {   padding: 8px;   text-align: center;   border: 1px solid #ddd;  }  th.left-align, td.left-align {   text-align: left;  }  .border-top {   border-top: 2px solid black;  }  .border-bottom {   border-bottom: 2px solid black;  }  .border-right {   border-right: 2px solid black;  }  .border-left {   border-left: 2px solid black;  }  .bold {   font-weight: bold;  }
</style>


<table class="table-hover caption-top table" data-quarto-postprocess="true">
<caption>Table 7: Comparison of Adam and Muon optimizers applied to the SFT of the Qwen2.5-7B pretrained model.</caption>
<thead>
<tr class="border-top header">
<th class="left-align border-top" data-quarto-table-cell-role="th">Benchmark (Metric)</th>
<th class="border-top border-right" data-quarto-table-cell-role="th"># Shots</th>
<th class="border-top border-right" data-quarto-table-cell-role="th">Adam-SFT</th>
<th class="border-top" data-quarto-table-cell-role="th">Muon-SFT</th>
</tr>
<tr class="border-top even">
<th class="left-align" data-quarto-table-cell-role="th">Pretrained Model</th>
<th class="border-right" data-quarto-table-cell-role="th">-</th>
<th colspan="2" class="border-left" data-quarto-table-cell-role="th">Qwen2.5-7B</th>
</tr>
</thead>
<tbody>
<tr class="border-top odd">
<td class="left-align" data-quarto-table-cell-role="th">MMLU (EM)</td>
<td class="border-right">0-shot (CoT)</td>
<td class="border-right bold">71.4</td>
<td>70.8</td>
</tr>
<tr class="even">
<td class="left-align" data-quarto-table-cell-role="th">HumanEval (Pass@1)</td>
<td class="border-right">0-shot</td>
<td class="border-right bold">79.3</td>
<td>77.4</td>
</tr>
<tr class="odd">
<td class="left-align" data-quarto-table-cell-role="th">MBPP (Pass@1)</td>
<td class="border-right">0-shot</td>
<td class="border-right bold">71.9</td>
<td>71.6</td>
</tr>
<tr class="border-bottom even">
<td class="left-align border-bottom" data-quarto-table-cell-role="th">GSM8K (EM)</td>
<td class="border-right border-bottom">5-shot</td>
<td class="border-right border-bottom bold">89.8</td>
<td class="border-bottom">85.8</td>
</tr>
</tbody>
</table>
<p>This phenomenon suggests that some special initializations are unfavorable for Muon, and conversely, there might be initializations that are more favorable for Muon. We are still exploring the underlying principles.</p>
</section>
<section id="some-more-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="some-more-thoughts">Some more thoughts</h2>
<p>Overall, in our experiments, Muon’s performance compared to Adam is very competitive. As a new optimizer that differs significantly from Adam in form, Muon’s performance is not just “noteworthy” but indicates that it might have captured some essential characteristics.</p>
<p>Previously, there was a view in the community that Adam performs well because mainstream model architecture improvements are “overfitting” to Adam. This view likely originated from <a href="https://parameterfree.com/2020/12/06/neural-network-maybe-evolved-to-make-adam-the-best-optimizer/"><em>Neural Networks (Maybe) Evolved to Make Adam The Best Optimizer</em></a>. It seems absurd at first glance but is actually profound. Think about it: when we try to improve a model, we train it once with Adam to see the effect, keeping it if it’s good and discarding it otherwise. But is the good effect due to its inherent superiority or because it matches Adam better?</p>
<p>This is quite thought-provoking. Certainly not all, but at least some works perform better because they align better with Adam, so over time, model architectures evolve in a direction favorable to Adam. In this context, an optimizer significantly different from Adam that can “break out” is particularly worth attention and reflection. Note that neither I nor my company are the proposers of Muon, so these remarks are purely “heartfelt words” without any self-promotion.</p>
<p>What work remains for Muon? Quite a bit remains. For instance, we need to analyze further the aforementioned issue that “Adam pre-training + Muon fine-tuning” does not work well, especially since most currently publicly available model weights are trained with Adam. If Muon fine-tuning doesn’t work well on Adam-pretrained models, it will hurt its popularity. Of course, we can also take this opportunity to deepen our understanding of Muon (this is bug-oriented learning).</p>
<p>Another thought I had is that Muon is based on the spectral norm, which is the maximum singular value. In fact, there are many norms based on singular values, such as the <a href="https://en.wikipedia.org/wiki/Schatten_norm">Schatten norms</a> and the <a href="https://en.wikipedia.org/wiki/Ky_Fan_norm">Ky Fan norms</a>. Generalizing to these more general norms and then tuning parameters could theoretically yield even better results. Additionally, after releasing Moonlight, some readers asked how to adapt <a href="https://papers.cool/arxiv/2203.03466">µP (maximal update parametrization)</a> to Muon, another problem for furher research.</p>
</section>

</section>


<div id="quarto-appendix" class="default"><section id="metadata" class="level2 appendix"><h2 class="anchored quarto-appendix-heading">Metadata</h2><div class="quarto-appendix-contents">

<p>These are several blogposts on the homepage of Jianlin Su (苏剑林) that I selected because they are relevant for understanding Muon. I organized them in a chronological sequence, and simplified certain derivations and made certain explanations easier to follow.</p>


<!-- -->

</div></section></div></main> <!-- /main -->
<!-- file: html/copy‑anchors-js.html -->

<script type="module">

document.addEventListener("DOMContentLoaded", () => {

  // 1. All little ¶ icons Quarto/AnchorJS adds

  document.querySelectorAll("a.anchorjs-link").forEach(anchor => {

    anchor.addEventListener("click", async (evt) => {

      // Keep normal scroll behaviour but stop full page reload

      evt.preventDefault();



      // Build absolute URL: origin + path + #hash

      const url = `${location.origin}${location.pathname}${anchor.getAttribute("href")}`;



      // 2. Try modern Clipboard API first

      try {

        await navigator.clipboard.writeText(url);

      } catch {

        // 3. Fallback for legacy browsers

        const helper = Object.assign(document.createElement("input"), { value: url });

        document.body.appendChild(helper);

        helper.select();

        document.execCommand("copy");

        helper.remove();

      }

      // TODO: The following two doesn't work yet

      // 4. Brief visual confirmation (optional)

      anchor.dataset.tooltip = "Copied!";

      setTimeout(() => delete anchor.dataset.tooltip, 1500);



      // 5. Still jump to the heading

      history.pushState(null, "", anchor.getAttribute("href"));

    }, false);

  });

});

</script>

<script>

    pseudocode.renderClass("pseudocode");

</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yuxi\.ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb4" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "The Muon Anthology"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Jianlin Su"</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-02-27"</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2025-02-27"</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [AI, scaling, translation]</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">    include-in-header: pseudocode_header.html</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">    include-after-body: pseudocode_footer.html</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Translation of several blogposts by Su Jianlin, describing the intuition behind the development of Muon."</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "finished"</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "certain"</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 3</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../static/_macros.tex &gt;}}</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="fu"># How should the learning rate change as batch size increase? {#sec-learning-rate-batch-size}</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">当batch size增大时，学习率该如何随之变化？ - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10542)</span> (2024-11-14)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>With the rapid advancement of computing power, we often want to "trade compute for time" -- that is, reduce the wallclock time of model training by parallel-scaling the FLOP/sec with more chips. Ideally, we hope that with $n$ times the FLOP/sec, the time to achieve the same effect would be reduced to $1/n$, keeping the total FLOP cost consistent. This hope seems reasonable and natural, but it's actually non-trivial. Even if we don't consider parallel bottlenecks like communication, when computing power exceeds a certain scale or when models are smaller than a certain size, we generally can only utilize further compute-scaling by scaling the batch size. However, does increasing batch size always reduce training time while maintaining performance?</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>This is the topic we'll discuss: When batch size increases, how should various hyperparameters, especially the learning rate, be adjusted to maintain the original training effect and maximize training efficiency? We can also call this the <span class="co">[</span><span class="ot">scaling law</span><span class="co">](https://en.wikipedia.org/wiki/Neural_scaling_law)</span> between batch size and learning rate.</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## From the perspective of variance</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>Intuitively, when batch size increases, the gradient of each batch will be more accurate, so we can take bigger steps, meaning increasing the learning rate, to reach the goal faster and shorten training time. Most people can generally understand this point. The question is, how much should we increase the learning rate to be most appropriate?</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### Square root</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>The earliest answer to this question might be square root scaling, meaning $n\times$ batch size should translate to $\sqrt{n}\times$ learning rate. This comes from the 2014 paper <span class="co">[</span><span class="ot">*One weird trick for parallelizing convolutional neural networks*</span><span class="co">](https://arxiv.org/abs/1404.5997)</span>, with the derivation principle being to keep the variance of SGD increments constant. Specifically, we denote the gradient from randomly sampling one sample as $\tilde{\boldsymbol{g}}$, with its mean and covariance denoted as $\boldsymbol{g}$ and $\boldsymbol{\Sigma}$ respectively, where $\boldsymbol{g}$ is the gradient of all samples. When we increase the sampling number to $B$, we have:</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>\begin{equation}\tilde{\boldsymbol{g}}_B \triangleq \frac{1}{B}\sum_{i=1}^B \tilde{\boldsymbol{g}}^{(i)},\quad \mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{g}}_B</span><span class="co">]</span> = \boldsymbol{g},\quad \mathbb{E}<span class="co">[</span><span class="ot">(\tilde{\boldsymbol{g}}_B-\boldsymbol{g})(\tilde{\boldsymbol{g}}_B-\boldsymbol{g})^{\top}</span><span class="co">]</span>=\frac{\boldsymbol{\Sigma}}{B}\end{equation}</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>That is, increasing the number of samples doesn't change the mean, but the covariance shrinks to $1/B$. For the SGD optimizer, the increment is $-\eta \tilde{\boldsymbol{g}}_B$, and its covariance is proportional to $\eta^2/B$. We believe that an appropriate amount of noise (neither too much nor too little) is necessary in the optimization process, so when batch size $B$ changes, we adjust the learning rate $\eta$ to keep the noise intensity, i.e., the covariance matrix of the increment, constant, which leads to:</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>\begin{equation}\frac{\eta^2}{B} = \text{Constant}\quad\Rightarrow\quad \eta\propto \sqrt{B}\end{equation}</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>This gives us the square root scaling law between learning rate and batch size. Later, <span class="co">[</span><span class="ot">*Train longer, generalize better: closing the generalization gap in large batch training of neural networks*</span><span class="co">](https://arxiv.org/abs/1705.08741)</span> also endorsed this choice.</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linear scaling {#sec-linear-scaling}</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>Interestingly, linear scaling, i.e., $\eta\propto B$, often performs better in practice. Even those who first proposed square root scaling in <span class="co">[</span><span class="ot">*One weird trick for parallelizing convolutional neural networks*</span><span class="co">](https://arxiv.org/abs/1404.5997)</span> pointed this out in their paper and stated they couldn't provide a reasonable explanation for it.</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>In some sense, linear scaling better matches our intuitive understanding, especially as in <span class="co">[</span><span class="ot">*Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour*</span><span class="co">](https://arxiv.org/abs/1706.02677)</span>. Indeed, if the gradient direction of $n$ consecutive minibatches doesn't change much, then if we batch those $n$ minibatches into one batch, we would be dividing by $\frac{1}{nB}$, yielding $\approx \frac{1}{n} \sum_{i=1}^B g_i$. So to compensate for that, we should scale learnig rate by $n$.</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>However, assuming that all $g_i$ should point in roughly the same direction is clearly too strong. Relaxing this assumption requires connecting SGD with SDE (Stochastic Differential Equations), which was accomplished by <span class="co">[</span><span class="ot">*Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations*</span><span class="co">](https://arxiv.org/abs/1811.01558)</span>, but the first paper to use this to analyze the relationship between learning rate and batch size should be <span class="co">[</span><span class="ot">*On the Generalization Benefit of Noise in Stochastic Gradient Descent*</span><span class="co">](https://arxiv.org/abs/2006.15081)</span>.</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>In hindsight, establishing this connection isn't hard to understand. Let the model parameters be $\boldsymbol{\theta}$, then the SGD update rule can be rewritten as:</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\theta}_{t+1} =\boldsymbol{\theta}_t - \eta \tilde{\boldsymbol{g}}_{B,t} =\boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta (\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t)\end{equation}</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>where $\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t$ is the noise in the gradient. Up to this point, we haven't made any assumptions about the distribution of this noise, only knowing its mean is $\boldsymbol{0}$ and its covariance is $\boldsymbol{\Sigma}_t/B$. Next, we assume this noise follows a normal distribution $\mathcal{N}(\boldsymbol{0},\boldsymbol{\Sigma}_t/B)$, then the above iteration can be further rewritten as:</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>\boldsymbol{\theta}_{t+1} =&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta (\tilde{\boldsymbol{g}}_{B,t} - \boldsymbol{g}_t) <span class="sc">\\</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>=&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \eta \sqrt{\frac{\boldsymbol{\Sigma}_t}{B}}\boldsymbol{z},\quad \boldsymbol{z}\sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I}) <span class="sc">\\</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>=&amp;\, \boldsymbol{\theta}_t - \eta \boldsymbol{g}_t - \sqrt{\eta} \sqrt{\frac{\eta\boldsymbol{\Sigma}_t}{B}}\boldsymbol{z},\quad \boldsymbol{z}\sim \mathcal{N}(\boldsymbol{0},\boldsymbol{I}) \end{aligned}\end{equation}</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>This means the SGD iteration format $\boldsymbol{\theta}_{t+1} =\boldsymbol{\theta}_t - \eta \tilde{\boldsymbol{g}}_{B,t}$ is actually approximating the solution to the SDE:</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>\begin{equation}d\boldsymbol{\theta} = - \boldsymbol{g}_t dt - \sqrt{\frac{\eta\boldsymbol{\Sigma}_t}{B}}d\boldsymbol{w}\end{equation}</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>Therefore, to ensure the running results don't change significantly when $B$ changes, the form of the above SDE should remain unchanged, which gives us linear scaling $\eta\propto B$. The most crucial step in this process is that <span class="dt">&lt;</span><span class="kw">u</span><span class="dt">&gt;</span>the step size of the noise term in SDE is the square root of the non-noise term<span class="dt">&lt;/</span><span class="kw">u</span><span class="dt">&gt;</span>, thus separating out a term $\sqrt{\eta}$. We've also commented on this in <span class="co">[</span><span class="ot">*A Casual Discussion of Generative Diffusion Models (Part 5): General Framework SDE Chapter*</span><span class="co">](https://kexue.fm/archives/9209)</span>. Simply put, zero-mean Gaussian noise has a certain cancellation effect over the long term, so the step size must be increased to manifest the noise effect.</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>The above conclusions are all based on the SGD optimizer. The paper <span class="co">[</span><span class="ot">*On the SDEs and Scaling Rules for Adaptive Gradient Algorithms*</span><span class="co">](https://arxiv.org/abs/2205.10287)</span> extended it to optimizers like RMSprop and Adam, resulting in <span class="dt">&lt;</span><span class="kw">u</span><span class="dt">&gt;</span>square root scaling<span class="dt">&lt;/</span><span class="kw">u</span><span class="dt">&gt;</span>. Similarly, the slightly earlier <span class="co">[</span><span class="ot">*Large Batch Optimization for Deep Learning: Training BERT in 76 minutes*</span><span class="co">](https://arxiv.org/abs/1904.00962)</span> also applied square root scaling when testing Adam and its variant LAMB. More content can be found in the blogpost <span class="co">[</span><span class="ot">*How to Scale Hyperparameters as Batch Size Increases*</span><span class="co">](https://www.cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/)</span>.</span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span class="fu">## Facing losses head on</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>It's certain that whether it's square root scaling or linear scaling, they can only hold approximately within a local range, because they both include the conclusion that, as long as the batch size is large enough, the learning rate can be arbitrarily large. That is obviously impossible. Additionally, the previous two sections focused on variance, but our fundamental task is to reduce the loss function, so we should start with the loss function.</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Monotonic convergence</span></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>A classic work from this perspective is OpenAI's <span class="co">[</span><span class="ot">*An Empirical Model of Large-Batch Training*</span><span class="co">](https://arxiv.org/abs/1812.06162)</span>, which analyzes the optimal learning rate for SGD through a second-order approximation of the loss function, concluding that the learning rate increases monotonically with batch size, but has an upper bound. The same approach also appeared in the slightly earlier <span class="co">[</span><span class="ot">*Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients*</span><span class="co">](https://arxiv.org/abs/1705.07774)</span>, though that paper wasn't used to analyze the role of batch size.</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>The key to the entire derivation is to view the learning rate as an optimization parameter: Let the loss function be $\mathcal{L}(\boldsymbol{\theta})$, the current batch's gradient be $\tilde{\boldsymbol{g}}_B$, then the loss function after SGD is $\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)$. We view the solution of the optimal learning rate as an optimization problem:</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* = \mathop{\text{argmin}}_{\eta} \mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)</span><span class="co">]</span>\end{equation}</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>This objective is obviously intuitive -- choose the learning rate to make the training efficiency the highest (the loss function decreases the fastest) <span class="dt">&lt;</span><span class="kw">u</span><span class="dt">&gt;</span>on average<span class="dt">&lt;/</span><span class="kw">u</span><span class="dt">&gt;</span>. To solve this problem, we approximately expand the loss function to the second order:</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B) \approx \mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\underbrace{\frac{\partial \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}}_{= \boldsymbol{g}} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\underbrace{\frac{\partial^2 \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^2}}_{\triangleq \boldsymbol{H}}\tilde{\boldsymbol{g}}_B = \mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B\end{equation}</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>Here, $\boldsymbol{H}$ is the Hessian matrix, and $\frac{\partial \mathcal{L}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}$ is the gradient of the loss function. The ideal objective function $\mathcal L$ is the loss averaged over all samples, which is why its gradient $\boldsymbol{g}$ is the average of $\tilde{\boldsymbol{g}}_B$. Taking the expectation, we get:</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{g}}_B)</span><span class="co">]</span> \approx \mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta}) - \eta\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B</span><span class="co">]</span> = \mathcal{L}(\boldsymbol{\theta}) - \eta\boldsymbol{g}^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B</span><span class="co">]</span>\end{equation}</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>The last term involves tricks with the cyclic property of trace:</span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B</span><span class="co">]</span> =&amp;\, \mathbb{E}<span class="co">[</span><span class="ot">\text{Tr}(\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H}\tilde{\boldsymbol{g}}_B)</span><span class="co">]</span>= \mathbb{E}<span class="co">[</span><span class="ot">\text{Tr}(\tilde{\boldsymbol{g}}_B\tilde{\boldsymbol{g}}_B^{\top}\boldsymbol{H})</span><span class="co">]</span> = \text{Tr}(\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{g}}_B\tilde{\boldsymbol{g}}_B^{\top}</span><span class="co">]</span>\boldsymbol{H})<span class="sc">\\</span></span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>=&amp;\, \text{Tr}((\boldsymbol{g}\boldsymbol{g}^{\top} + \boldsymbol{\Sigma}/B)\boldsymbol{H}) = \boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g} + \text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})/B</span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>Now, assuming $\boldsymbol{H}$ is positive definite (i.e. the loss function looks like a bowl), the problem becomes finding the minimum of a quadratic function:</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\boldsymbol{g}^{\top}\boldsymbol{g}}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g} + \text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})/B} = \frac{\eta_{\max}}{1 + \mathcal{B}_{\text{noise}}/B}\end{equation}</span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>$$ {#eq-eta-opt}</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>We can state this as "the learning rate increases monotonically with $B$ but has an upper bound", where:</span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta_{\max} = \frac{\boldsymbol{g}^{\top}\boldsymbol{g}}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}},\qquad\mathcal{B}_{\text{noise}} = \frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\end{equation}</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a><span class="fu">### Empirical analysis</span></span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>When $B \ll \mathcal{B}_{\text{noise}}$, $1 + \mathcal{B}_{\text{noise}}/B\approx \mathcal{B}_{\text{noise}}/B$, so $\eta^* \approx \eta_{\max}B/\mathcal{B}_{\text{noise}}\propto B$, i.e., linear scaling, which again shows that linear scaling is only a local approximation for small batch sizes. When $B &gt; \mathcal{B}_{\text{noise}}$, $\eta^*$ gradually approaches the saturation value $\eta_{\max}$, meaning the increase in training cost far outweighs the improvement in training efficiency. Therefore, $\mathcal{B}_{\text{noise}}$ serves as a watershed -- once the batch size exceeds this value, there's no need to continue investing computing power to increase the batch size.</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>For practitioners, the most crucial question is undoubtedly how to estimate $\eta_{\max}$ and $\mathcal{B}_{\text{noise}}$, especially since $\mathcal{B}_{\text{noise}}$ directly affects the scaling law of learning rates and the saturation of training efficiency. Direct calculation of both involves the Hessian matrix $\boldsymbol{H}$, whose computational cost is proportional to the square of the parameter count. In today's world, where models with hundreds of millions of parameters are considered small, computing the Hessian matrix is clearly impractical, so more effective calculation methods must be sought.</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>Let's first look at $\mathcal{B}_{\text{noise}}$. Its expression is $\frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}$, with an $\boldsymbol{H}$ in both numerator and denominator, which undoubtedly tempts us to "cancel them out". In fact, the simplification approach is similar -- assuming $\boldsymbol{H}$ approximates some multiple of the identity matrix, we get:</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{B}_{\text{noise}} = \frac{\text{Tr}(\boldsymbol{\Sigma}\boldsymbol{H})}{\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}\approx \frac{\text{Tr}(\boldsymbol{\Sigma})}{\boldsymbol{g}^{\top}\boldsymbol{g}}\triangleq \mathcal{B}_{\text{simple}}\end{equation}</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>$\mathcal{B}_{\text{simple}}$ is more computationally feasible, and experiments have found it's usually a good approximation of $\mathcal{B}_{\text{noise}}$. Therefore, we choose to estimate $\mathcal{B}_{\text{simple}}$ rather than $\mathcal{B}_{\text{noise}}$. Note that $\text{Tr}(\boldsymbol{\Sigma})$ only needs the elements on the diagonal, so there's no need to compute the full covariance matrix -- just calculate the variance for each gradient component separately and sum them up. In data-parallel scenarios, the gradient variances can be directly estimated using the gradients computed on each device.</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>It's worth noting that the results in @eq-eta-opt are actually dynamic, meaning theoretically, $\eta_{\max}$, $\mathcal{B}_{\text{noise}}$, and $\mathcal{B}_{\text{simple}}$ are different at each training step. So if we want to derive a static pattern, we need to train for a period of time until the model's training enters the "right track" for the calculated $\mathcal{B}_{\text{simple}}$ to be reliable. Alternatively, we can continuously monitor $\mathcal{B}_{\text{simple}}$ during training to judge the gap between the current settings and the optimal ones.</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>As for $\eta_{\max}$, there's no need to estimate it according to the formula. We can directly perform a grid search for the learning rate under a small batch size to find an approximate $\eta^*$, and then use the estimated $\mathcal{B}_{\text{simple}}$ to deduce $\eta_{\max}$.</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sample efficiency</span></span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>Starting from the above results, we can also derive an asymptotic relationship between the amount of training data and the number of training steps. The derivation is simple: substituting @eq-eta-opt into the loss function, we can calculate that the reduction in the loss function brought by each iteration at the optimal learning rate is:</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta\mathcal{L} = \mathcal{L}(\boldsymbol{\theta}) - \mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta} - \eta^*\tilde{\boldsymbol{g}}_B)</span><span class="co">]</span> \approx \frac{\Delta\mathcal{L}_{\max}}{1 + \mathcal{B}_{\text{noise}}/B}\end{equation}</span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>$$ {#eq-Delta-L-sgd}</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>where $\Delta\mathcal{L}_{\max} = \frac{(\boldsymbol{g}^{\top}\boldsymbol{g})^2}{2\boldsymbol{g}^{\top}\boldsymbol{H}\boldsymbol{g}}$. The focus now is on interpreting this result.</span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a>When $B\to\infty$, i.e., full-batch SGD, the reduction in the loss function at each step reaches the maximum $\Delta\mathcal{L}_{\max}$, allowing us to reach the target point with the minimum number of training steps (denoted as $S_{\min}$). When $B$ is finite, the average reduction in the loss function at each step is only $\Delta\mathcal{L}$, meaning we need $1 + \mathcal{B}_{\text{noise}}/B$ steps to achieve the same reduction as a single step of full-batch SGD. So the total number of training steps is roughly $S = (1 + \mathcal{B}_{\text{noise}}/B)S_{\min}$.</span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>Since the batch size is $B$, the total number of samples consumed in the training process is $E = BS = (B + \mathcal{B}_{\text{noise}})S_{\min}$, which is an increasing function of $B$. When $B\to 0$, $E_{\min} = \mathcal{B}_{\text{noise}}S_{\min}$, indicating that as long as we use a sufficiently small batch size to train the model, the total number of training samples E will also decrease accordingly, at the cost of a very large number of training steps $S$. Furthermore, using these notations, we can write the relationship between them as:</span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>\begin{equation}\left(\frac{S}{S_{\min}} - 1\right)\left(\frac{E}{E_{\min}} - 1\right) = 1\end{equation}</span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>$$ {#eq-E-S}</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a>This is the scaling law between the amount of training data and the number of training steps, indicating that with less data, we should reduce the batch size and increase the number of training steps to have a better chance of reaching a more optimal solution. The derivation here has been simplified by me, assuming the invariance of $\mathcal{B}_{\text{noise}}$ and $\Delta\mathcal{L}_{\max}$ throughout the training process. If necessary, the dynamic changes can be handled more precisely using integration as in the original paper's appendix (but requires introducing the assumption $B = \sqrt{r\mathcal{B}_{\text{noise}}}$), which we won't expand on here.</span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>Additionally, since $\mathcal{B}_{\text{noise}} = E_{\min}/S_{\min}$, the above equation also provides another approach to estimate $\mathcal{B}_{\text{noise}}$: obtain multiple (S,E) pairs through multiple experiments and grid searches, then fit the above equation to estimate $E_{\min}$ and $S_{\min}$, and subsequently calculate $\mathcal{B}_{\text{noise}}$.</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a><span class="fu">## With adaptive learning rates</span></span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>It must be said that OpenAI, as one of the pioneers of various Scaling Laws, deserves its reputation. The aforementioned analysis is quite brilliant, and the results are quite rich. What's even more remarkable is that the entire derivation process is not complicated, giving a sense of elegant necessity. However, the work we have just worked through is all based on SGD, not applicable to adaptive learning rate optimizers like Adam was still unclear. That analysis was done by <span class="co">[</span><span class="ot">*Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling*</span><span class="co">](https://arxiv.org/abs/2405.14578)</span>.</span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a><span class="fu">### Symbolic approximation</span></span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a>Adam is analyzed similarly as SGD, by second-order expansion. The difference is that the direction vector changes from $\tilde{\boldsymbol{g}}_B$ to a general vector $\tilde{\boldsymbol{u}}_B$. In this case, we have:</span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta} - \eta\tilde{\boldsymbol{u}}_B)</span><span class="co">]</span> \approx \mathcal{L}(\boldsymbol{\theta}) - \eta\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>^{\top}\boldsymbol{g} + \frac{1}{2}\eta^2 \text{Tr}(\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}</span><span class="co">]</span>\boldsymbol{H})\end{equation}</span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>Now we need to determine $\tilde{\boldsymbol{u}}_B$ and calculate the corresponding $\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>$ and $\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}</span><span class="co">]</span>$. Since we only need an asymptotic relationship, just like in <span class="co">[</span><span class="ot">*Configuring Different Learning Rates, Can LoRA Rise a Bit More?*</span><span class="co">](https://kexue.fm/archives/10001)</span>, we choose SignSGD, i.e., $\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)$, as an approximation for Adam. The earliest source of this approach might be <span class="co">[</span><span class="ot">*Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients*</span><span class="co">](https://arxiv.org/abs/1705.07774)</span>. The reasonableness of this approximation is reflected in two points:</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Regardless of the values of $\beta_1$ and $\beta_2$, the update vector for Adam's first step is always $\text{sign}(\tilde{\boldsymbol{g}}_B)$;</span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>When $\beta_1=\beta_2=0$, Adam's update vector is always $\text{sign}(\tilde{\boldsymbol{g}}_B)$.</span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>To calculate $\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>$ and $\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}</span><span class="co">]</span>$, we also need to assume, as in the <span class="co">[</span><span class="ot">Linear scaling</span><span class="co">](#sec-linear-scaling)</span> section, that $\tilde{\boldsymbol{g}}_B$ follows the distribution $\mathcal{N}(\boldsymbol{g},\boldsymbol{\Sigma}/B)$. To simplify the calculation, we further assume that $\boldsymbol{\Sigma}$ is a diagonal matrix $\text{diag}(\sigma_1^2,\sigma_2^2,\sigma_3^2,\cdots)$, meaning that the components are independent of each other, allowing us to process each component independently. By reparameterization, $\tilde{g}_B\sim \mathcal{N}(g, \sigma^2/B)$ is equivalent to $\tilde{g}_B=g + \sigma z/\sqrt{B},z\sim\mathcal{N}(0,1)$, therefore:</span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">\tilde{u}_B</span><span class="co">]</span> =&amp;\, \mathbb{E}<span class="co">[</span><span class="ot">\text{sign}(g + \sigma z/\sqrt{B})</span><span class="co">]</span> = \mathbb{E}<span class="co">[</span><span class="ot">\text{sign}(g\sqrt{B}/\sigma + z)</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>=&amp;\,\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} \text{sign}(g\sqrt{B}/\sigma + z) e^{-z^2/2}dz <span class="sc">\\</span></span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a>=&amp;\,\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{-g\sqrt{B}/\sigma}  (-1)\times e^{-z^2/2}dz + \frac{1}{\sqrt{2\pi}}\int_{-g\sqrt{B}/\sigma}^{\infty}  1\times e^{-z^2/2}dz <span class="sc">\\</span></span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>=&amp;\,\text{erf}\left(\frac{g}{\sigma}\sqrt{\frac{B}{2}}\right)</span>
<span id="cb4-194"><a href="#cb4-194" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-195"><a href="#cb4-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-196"><a href="#cb4-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-197"><a href="#cb4-197" aria-hidden="true" tabindex="-1"></a>Here, $\text{erf}$ is the <span class="co">[</span><span class="ot">error function</span><span class="co">](https://en.wikipedia.org/wiki/Error_function)</span>, which is an S-shaped function with a range of $(-1,1)$ similar to $\tanh$, and can serve as a smooth approximation of $\text{sign}$. But since $\text{erf}$ itself doesn't have an elementary function expression, it's better to find an elementary function approximation to more intuitively observe the pattern of change. We've discussed this topic before in <span class="co">[</span><span class="ot">*How the Two Elementary Function Approximations of GELU Came About*</span><span class="co">](https://kexue.fm/archives/7309)</span>, but the approximations there are still too complex (involving exponential operations). Here we'll use something simpler:</span>
<span id="cb4-198"><a href="#cb4-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-199"><a href="#cb4-199" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-200"><a href="#cb4-200" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{erf}(x)\approx \text{sign}(x) = \frac{x}{|x|} = \frac{x}{\sqrt{x^2}}\approx \frac{x}{\sqrt{x^2+c}}\end{equation}</span>
<span id="cb4-201"><a href="#cb4-201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-202"><a href="#cb4-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-203"><a href="#cb4-203" aria-hidden="true" tabindex="-1"></a>We choose $c=\pi/4$ so that the first-order approximation of this approximation at $x=0$ equals the first-order approximation of $\text{erf}$. Of course, after making so many approximations, the value of $c$ is not very important; we just need to know that such a $c &gt; 0$ exists. Based on this approximation, we get:</span>
<span id="cb4-204"><a href="#cb4-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-205"><a href="#cb4-205" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-206"><a href="#cb4-206" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">\tilde{u}_B</span><span class="co">]</span> \approx \frac{g/\sigma}{\sqrt{\pi/2B+(g/\sigma)^2}}\quad\Rightarrow\quad\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>_i \approx \frac{g_i/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}}\triangleq \mu_i\end{equation}</span>
<span id="cb4-207"><a href="#cb4-207" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-208"><a href="#cb4-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-209"><a href="#cb4-209" aria-hidden="true" tabindex="-1"></a>We can find that one obvious difference between Adam and SGD is that $\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>$ is already related to $B$ at this step. However, the second moment is simpler now, because the square of $\text{sign}(x)$ is always 1, so:</span>
<span id="cb4-210"><a href="#cb4-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-211"><a href="#cb4-211" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-212"><a href="#cb4-212" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">\tilde{u}_B^2</span><span class="co">]</span> = 1\quad\Rightarrow\quad\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}</span><span class="co">]</span>_{i,j} \to\left<span class="sc">\{</span>\begin{aligned}&amp;=1, &amp; i = j <span class="sc">\\</span></span>
<span id="cb4-213"><a href="#cb4-213" aria-hidden="true" tabindex="-1"></a>&amp;\approx\mu_i \mu_j,&amp;\,i\neq j\end{aligned}\right.\end{equation}</span>
<span id="cb4-214"><a href="#cb4-214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-215"><a href="#cb4-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-216"><a href="#cb4-216" aria-hidden="true" tabindex="-1"></a>Using these results, we can obtain:</span>
<span id="cb4-217"><a href="#cb4-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-218"><a href="#cb4-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-219"><a href="#cb4-219" aria-hidden="true" tabindex="-1"></a>\eta^* \approx \frac{\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B</span><span class="co">]</span>^{\top}\boldsymbol{g}}{\text{Tr}(\mathbb{E}<span class="co">[</span><span class="ot">\tilde{\boldsymbol{u}}_B\tilde{\boldsymbol{u}}_B^{\top}</span><span class="co">]</span>\boldsymbol{H})} \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}}</span>
<span id="cb4-220"><a href="#cb4-220" aria-hidden="true" tabindex="-1"></a>$$ {#eq-eta-opt-sign}</span>
<span id="cb4-221"><a href="#cb4-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-222"><a href="#cb4-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-223"><a href="#cb4-223" aria-hidden="true" tabindex="-1"></a>\Delta \mathcal{L} = \mathcal{L}(\boldsymbol{\theta}) - \mathbb{E}<span class="co">[</span><span class="ot">\mathcal{L}(\boldsymbol{\theta} - \eta^*\tilde{\boldsymbol{u}}_B)</span><span class="co">]</span> \approx \frac{1}{2}\frac{(\sum_i \mu_i g_i)^2}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}}</span>
<span id="cb4-224"><a href="#cb4-224" aria-hidden="true" tabindex="-1"></a>$$ {#eq-Delta-L-sign}</span>
<span id="cb4-225"><a href="#cb4-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-226"><a href="#cb4-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two special cases</span></span>
<span id="cb4-227"><a href="#cb4-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-228"><a href="#cb4-228" aria-hidden="true" tabindex="-1"></a>Compared to SGD's @eq-eta-opt, Adam's @eq-eta-opt-sign is more complex, making it difficult to intuitively see its dependency pattern on $B$. So we'll start with a few special examples.</span>
<span id="cb4-229"><a href="#cb4-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-230"><a href="#cb4-230" aria-hidden="true" tabindex="-1"></a>First, consider $B\to\infty$. In this case, $\mu_i = \text{sign}(g_i)$, so:</span>
<span id="cb4-231"><a href="#cb4-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-232"><a href="#cb4-232" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-233"><a href="#cb4-233" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\sum_i |g_i|}{\sum_i H_{i,i} + \sum_{i\neq j} \text{sign}(g_i g_j) H_{i,j}}\end{equation}</span>
<span id="cb4-234"><a href="#cb4-234" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-235"><a href="#cb4-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-236"><a href="#cb4-236" aria-hidden="true" tabindex="-1"></a>The difference between this and SGD's $\eta_{\max}$ is that it is not homogeneous with respect to the gradient, but proportional to the gradient's scale.</span>
<span id="cb4-237"><a href="#cb4-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-238"><a href="#cb4-238" aria-hidden="true" tabindex="-1"></a>Next, let's consider the example where $\boldsymbol{H}$ is a diagonal matrix, i.e., $H_{i,j}=0$ when $i\neq j$. In this case:</span>
<span id="cb4-239"><a href="#cb4-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-240"><a href="#cb4-240" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-241"><a href="#cb4-241" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i}}=\frac{1}{\sum_i H_{i,i}}\sum_i \frac{g_i^2/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}}\end{equation}</span>
<span id="cb4-242"><a href="#cb4-242" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-243"><a href="#cb4-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-244"><a href="#cb4-244" aria-hidden="true" tabindex="-1"></a>Each term in the sum is monotonically increasing with an upper bound with respect to $B$, so the total result is also like this. To capture the most essential pattern, we can consider further simplifying $\mu_i$ (this is where it starts to differ from the original paper):</span>
<span id="cb4-245"><a href="#cb4-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-246"><a href="#cb4-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-247"><a href="#cb4-247" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mu_i = \frac{g_i/\sigma_i}{\sqrt{\pi/2B+(g_i/\sigma_i)^2}} = \frac{\text{sign}(g_i)}{\sqrt{1 + \pi(\sigma_i/g_i)^2/2B}} \approx \frac{\text{sign}(g_i)}{\sqrt{1 + \pi\kappa^2/2B}}\end{equation}</span>
<span id="cb4-248"><a href="#cb4-248" aria-hidden="true" tabindex="-1"></a>$$ {#eq-mu-approx}</span>
<span id="cb4-249"><a href="#cb4-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-250"><a href="#cb4-250" aria-hidden="true" tabindex="-1"></a>The assumption here is that there exists a constant $\kappa^2$ independent of $i$ <span class="co">[</span><span class="ot">for example, we can consider taking some kind of average of all $(\sigma_i/g_i)^2$; actually, this $\kappa^2$ is similar to the $\mathcal{B}_{\text{simple}}$ mentioned earlier, and it can also be estimated according to the definition of $\mathcal{B}_{\text{simple}}$</span><span class="co">]</span>, such that replacing $(\sigma_i/g_i)^2$ with $\kappa^2$ is a good approximation for any $i$. Thus:</span>
<span id="cb4-251"><a href="#cb4-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-252"><a href="#cb4-252" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-253"><a href="#cb4-253" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i}}\approx \frac{\sum_i |g_i|}{\sum_i H_{i,i}}\frac{1}{\sqrt{1 + \pi\kappa^2/2B}}\end{equation}</span>
<span id="cb4-254"><a href="#cb4-254" aria-hidden="true" tabindex="-1"></a>$$ {#eq-eta-opt-sign-diag}</span>
<span id="cb4-255"><a href="#cb4-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-256"><a href="#cb4-256" aria-hidden="true" tabindex="-1"></a>When $\pi\kappa^2\gg 2B$, i.e., $B \ll \pi\kappa^2/2$, we can further write the approximation:</span>
<span id="cb4-257"><a href="#cb4-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-258"><a href="#cb4-258" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-259"><a href="#cb4-259" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\sum_i \sigma_i}{\kappa\sum_i H_{i,i}}\sqrt{\frac{2B}{\pi}} \propto \sqrt{B}\end{equation}</span>
<span id="cb4-260"><a href="#cb4-260" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-261"><a href="#cb4-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-262"><a href="#cb4-262" aria-hidden="true" tabindex="-1"></a>This indicates that when the batch size itself is relatively small, Adam indeed applies to the square root scaling law.</span>
<span id="cb4-263"><a href="#cb4-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-264"><a href="#cb4-264" aria-hidden="true" tabindex="-1"></a><span class="fu">### Surge phenomenon</span></span>
<span id="cb4-265"><a href="#cb4-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-266"><a href="#cb4-266" aria-hidden="true" tabindex="-1"></a>If we apply the approximation @eq-mu-approx to the original @eq-eta-opt-sign, we'll find it exhibits some entirely new characteristics. Specifically, we have:</span>
<span id="cb4-267"><a href="#cb4-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-268"><a href="#cb4-268" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-269"><a href="#cb4-269" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\sum_i \mu_i g_i}{\sum_i H_{i,i} + \sum_{i\neq j} \mu_i \mu_j H_{i,j}} \approx \frac{\eta_{\max}}{\frac{1}{2}\left(\frac{\beta_{\text{noise}}}{\beta} + \frac{\beta}{\beta_{\text{noise}}}\right)}\end{equation}</span>
<span id="cb4-270"><a href="#cb4-270" aria-hidden="true" tabindex="-1"></a>$$ {#eq-eta-opt-beta}</span>
<span id="cb4-271"><a href="#cb4-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-272"><a href="#cb4-272" aria-hidden="true" tabindex="-1"></a>where $\beta = (1 + \pi\kappa^2/2B)^{-1/2}$, and:</span>
<span id="cb4-273"><a href="#cb4-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-274"><a href="#cb4-274" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-275"><a href="#cb4-275" aria-hidden="true" tabindex="-1"></a>\begin{equation}\beta_{\text{noise}} = \sqrt{\frac{\sum_i H_{i,i}}{\sum_{i\neq j}\text{sign}(g_i g_j) H_{i,j}}},\quad \eta_{\max} = \frac{\sum_i |g_i|}{2\sqrt{\left(\sum_i H_{i,i}\right)\left(\sum_{i\neq j} \text{sign}(g_i g_j) H_{i,j}\right)}}\end{equation}</span>
<span id="cb4-276"><a href="#cb4-276" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-277"><a href="#cb4-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-278"><a href="#cb4-278" aria-hidden="true" tabindex="-1"></a>Note that $\beta$ is a monotonically increasing function of $B$, but the final approximation in @eq-eta-opt-beta is not a monotonically increasing function of $\beta$. Instead, it first increases and then decreases, reaching its maximum value at $\beta=\beta_{\text{noise}}$. This implies that there exists a corresponding $\mathcal{B}_{\text{noise}}$ such that when the batch size exceeds this $\mathcal{B}_{\text{noise}}$, the optimal learning rate should not increase but rather decrease! This is the "surge phenomenon" mentioned in the title of the original paper. (Of course, there's a limitation here: $\beta$ is always less than $1$. If $\beta_{\text{noise}} \geq 1$, then the relationship between the optimal learning rate and batch size remains monotonically increasing.)</span>
<span id="cb4-279"><a href="#cb4-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-280"><a href="#cb4-280" aria-hidden="true" tabindex="-1"></a>Regarding Adam's $\eta^*$, OpenAI actually made an unproven conjecture in their paper's appendix that Adam's optimal learning rate should be:</span>
<span id="cb4-281"><a href="#cb4-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-282"><a href="#cb4-282" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-283"><a href="#cb4-283" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta^* \approx \frac{\eta_{\max}}{(1 + \mathcal{B}_{\text{noise}}/B)^{\alpha}}\end{equation}</span>
<span id="cb4-284"><a href="#cb4-284" aria-hidden="true" tabindex="-1"></a>$$ {#eq-openai-adam}</span>
<span id="cb4-285"><a href="#cb4-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-286"><a href="#cb4-286" aria-hidden="true" tabindex="-1"></a>where $0.5 &lt; \alpha &lt; 1$. It now appears that this form is only an approximate result when the diagonal elements of the Hessian matrix dominate. When the effect of non-diagonal elements cannot be ignored, the "surge phenomenon" may occur, that is, the learning rate should actually decrease when the batch size is large enough.</span>
<span id="cb4-287"><a href="#cb4-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-288"><a href="#cb4-288" aria-hidden="true" tabindex="-1"></a>How can we intuitively understand the surge phenomenon? I believe it essentially reflects the **suboptimality** of adaptive learning rate strategies. Still taking the approximation $\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)$ as an example, the larger $B$ is, the more accurate $\tilde{\boldsymbol{g}}_B$ becomes. As $B\to \infty$, we get $\text{sign}(\boldsymbol{g})$, but is $\text{sign}(\boldsymbol{g})$ the most scientific update direction? Not necessarily, especially in the later stages of training where such adaptive strategies might even have negative effects. Therefore, when $B$ takes an appropriate value, the noise in $\text{sign}(\tilde{\boldsymbol{g}}_B)$ might actually correct this suboptimality. As $B$ continues to increase, the noise decreases, reducing the opportunity for correction, thus requiring more caution by lowering the learning rate.</span>
<span id="cb4-289"><a href="#cb4-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-290"><a href="#cb4-290" aria-hidden="true" tabindex="-1"></a><span class="fu">### Efficiency relation</span></span>
<span id="cb4-291"><a href="#cb4-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-292"><a href="#cb4-292" aria-hidden="true" tabindex="-1"></a>Similar to the SGD analysis, we can also consider $\Delta\mathcal{L}$ by substituting @eq-eta-opt-beta into @eq-Delta-L-sign, restoring the notation $B$ and then simplifying (the simplification process doesn't require any approximations) to get:</span>
<span id="cb4-293"><a href="#cb4-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-294"><a href="#cb4-294" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-295"><a href="#cb4-295" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta \mathcal{L} \approx \frac{\Delta \mathcal{L}_{\max}}{1 + \mathcal{B}_{\text{noise-2}}/B}\end{equation}</span>
<span id="cb4-296"><a href="#cb4-296" aria-hidden="true" tabindex="-1"></a>$$ {#eq-Delta-L-sign-2}</span>
<span id="cb4-297"><a href="#cb4-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-298"><a href="#cb4-298" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb4-299"><a href="#cb4-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-300"><a href="#cb4-300" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-301"><a href="#cb4-301" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta \mathcal{L}_{\max} = \frac{\beta_{\text{noise}}\eta_{\max}\sum_i|g_i|}{1 + \beta_{\text{noise}}^2},\quad \mathcal{B}_{\text{noise-2}} = \frac{\pi\kappa^2\beta_{\text{noise}}^2}{2(1 + \beta_{\text{noise}}^2)}\end{equation}</span>
<span id="cb4-302"><a href="#cb4-302" aria-hidden="true" tabindex="-1"></a>$$ {#eq-beta-B-noise}</span>
<span id="cb4-303"><a href="#cb4-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-304"><a href="#cb4-304" aria-hidden="true" tabindex="-1"></a>Note that $\mathcal{B}_{\text{noise-2}}$ is a new notation; it's not $\mathcal{B}_{\text{noise}}$. The latter is derived by solving $\beta=\beta_{\text{noise}}$ for the theoretical optimal batch size, which gives:</span>
<span id="cb4-305"><a href="#cb4-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-306"><a href="#cb4-306" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-307"><a href="#cb4-307" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{B}_{\text{noise}} = \frac{\pi\kappa^2\beta_{\text{noise}}^2}{2(1 - \beta_{\text{noise}}^2)}\end{equation}</span>
<span id="cb4-308"><a href="#cb4-308" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-309"><a href="#cb4-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-310"><a href="#cb4-310" aria-hidden="true" tabindex="-1"></a>The relationship between them is:</span>
<span id="cb4-311"><a href="#cb4-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-312"><a href="#cb4-312" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-313"><a href="#cb4-313" aria-hidden="true" tabindex="-1"></a>\begin{equation}\frac{1}{\mathcal{B}_{\text{noise-2}}} - \frac{1}{\mathcal{B}_{\text{noise}}} = \frac{4}{\pi\kappa^2}\quad\Rightarrow\quad \mathcal{B}_{\text{noise}} = \left(\frac{1}{\mathcal{B}_{\text{noise-2}}} - \frac{4}{\pi\kappa^2}\right)^{-1}\end{equation}</span>
<span id="cb4-314"><a href="#cb4-314" aria-hidden="true" tabindex="-1"></a>$$ {#eq-B-1-2}</span>
<span id="cb4-315"><a href="#cb4-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-316"><a href="#cb4-316" aria-hidden="true" tabindex="-1"></a>Since @eq-Delta-L-sign-2 is formally the same as SGD's @eq-Delta-L-sgd, the analysis in that section applies here as well, and we can derive @eq-E-S:</span>
<span id="cb4-317"><a href="#cb4-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-318"><a href="#cb4-318" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-319"><a href="#cb4-319" aria-hidden="true" tabindex="-1"></a>\begin{equation}\left(\frac{S}{S_{\min}} - 1\right)\left(\frac{E}{E_{\min}} - 1\right) = 1\end{equation}</span>
<span id="cb4-320"><a href="#cb4-320" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-321"><a href="#cb4-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-322"><a href="#cb4-322" aria-hidden="true" tabindex="-1"></a>Except now $E_{\min}/S_{\min} = \mathcal{B}_{\text{noise-2}}$. This gives us a method to estimate $\beta_{\text{noise}}$ and $\mathcal{B}_{\text{noise}}$: conduct multiple experiments to obtain several $(S,E)$ pairs, simultaneously estimating $\kappa^2$ during the experiments, then fit the above equation to get $E_{\min},S_{\min}$, thereby estimating $\mathcal{B}_{\text{noise-2}}$, and finally solve for $\beta_{\text{noise}}$ using @eq-beta-B-noise.</span>
<span id="cb4-323"><a href="#cb4-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-324"><a href="#cb4-324" aria-hidden="true" tabindex="-1"></a>If $\beta_{\text{noise}} \geq 1$, there is no optimal $\mathcal{B}_{\text{noise}}$. If $\beta_{\text{noise}} \gg 1$, it indicates that the diagonal elements of the Hessian matrix dominate, in which case the scaling rule @eq-eta-opt-sign-diag applies, and increasing the batch size can always appropriately increase the learning rate. When $\beta_{\text{noise}} &lt; 1$, the optimal $\mathcal{B}_{\text{noise}}$ can be solved using @eq-B-1-2, and if the batch size exceeds this value, the learning rate should actually decrease.</span>
<span id="cb4-325"><a href="#cb4-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-326"><a href="#cb4-326" aria-hidden="true" tabindex="-1"></a><span class="fu">### One more thing</span></span>
<span id="cb4-327"><a href="#cb4-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-328"><a href="#cb4-328" aria-hidden="true" tabindex="-1"></a>It's worth noting that the starting point and final conclusions of the analysis in the above sections are actually quite similar to those in the original paper <span class="co">[</span><span class="ot">*Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling*</span><span class="co">](https://arxiv.org/abs/2405.14578)</span>, although the approximation methods used in the intermediate process differ.</span>
<span id="cb4-329"><a href="#cb4-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-330"><a href="#cb4-330" aria-hidden="true" tabindex="-1"></a>Most of the conclusions in the original paper are approximate results under the assumption that $B \ll \pi(\sigma_i/g_i)^2/2$, which leads to the conclusion that the surge phenomenon almost always occurs. This is not very scientific. Most obviously, the form of the assumption $B \ll \pi(\sigma_i/g_i)^2/2$ itself is somewhat problematic, as its right side depends on $i$. We can't assign a separate batch size to each component, so to obtain a global result, we would need $B \ll \min_i \pi(\sigma_i/g_i)^2/2$, which is rather stringent.</span>
<span id="cb4-331"><a href="#cb4-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-332"><a href="#cb4-332" aria-hidden="true" tabindex="-1"></a>The approach in this article introduces the approximation @eq-mu-approx, which can be seen as a mean-field approximation. Intuitively, it is more reasonable than the point-by-point assumption $B \ll \pi(\sigma_i/g_i)^2/2$, so in principle, the conclusions should be more precise. For example, we can conclude that "even if the non-diagonal elements of the Hessian matrix cannot be ignored, the surge phenomenon may not necessarily occur" (depending on $\beta_{\text{noise}}$). Importantly, this precision does not sacrifice simplicity. For instance, @eq-eta-opt-beta is equally clear and concise, @eq-Delta-L-sign-2 has the same form as in the original paper, and no additional approximation assumptions are needed, and so on.</span>
<span id="cb4-333"><a href="#cb4-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-334"><a href="#cb4-334" aria-hidden="true" tabindex="-1"></a>Finally, a small reflection: OpenAI's analysis of SGD was actually done in 2018, while the surge phenomenon paper was only published in the middle of this year. It took 6 years to move from SGD to Adam, which is quite surprising. It seems that OpenAI's prestige and their conjecture @eq-openai-adam led people to believe that there wasn't much more to do with Adam, not expecting that Adam might have some new properties. Of course, the question of how reasonable $\tilde{\boldsymbol{u}}_B = \text{sign}(\tilde{\boldsymbol{g}}_B)$ is as an approximation of Adam and to what extent it represents the actual situation is still worth further consideration.</span>
<span id="cb4-335"><a href="#cb4-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-336"><a href="#cb4-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-337"><a href="#cb4-337" aria-hidden="true" tabindex="-1"></a><span class="fu"># Adaptive learning rate optimizers from a Hessian approximation point of view {#sec-learning-rate-hessian-approximation}</span></span>
<span id="cb4-338"><a href="#cb4-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-339"><a href="#cb4-339" aria-hidden="true" tabindex="-1"></a>Source: <span class="co">[</span><span class="ot">从Hessian近似看自适应学习率优化器 - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10588)</span> (2024-11-29)</span>
<span id="cb4-340"><a href="#cb4-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-341"><a href="#cb4-341" aria-hidden="true" tabindex="-1"></a>These days I've been revisiting Meta's paper from last year <span class="co">[</span><span class="ot">A Theory on Adam Instability in Large-Scale Machine Learning</span><span class="co">](https://arxiv.org/abs/2304.09871)</span>, which presents a new perspective on adaptive learning rate optimizers like Adam: it points out that the moving average of squared gradients approximates the square of the Hessian matrix to some extent, making Adam, RMSprop and other optimizers actually approximate second-order Newton methods.</span>
<span id="cb4-342"><a href="#cb4-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-343"><a href="#cb4-343" aria-hidden="true" tabindex="-1"></a>This perspective is quite novel and appears to differ significantly from previous Hessian approximations, making it worth studying and thinking about.</span>
<span id="cb4-344"><a href="#cb4-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-345"><a href="#cb4-345" aria-hidden="true" tabindex="-1"></a><span class="fu">## Newton's method</span></span>
<span id="cb4-346"><a href="#cb4-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-347"><a href="#cb4-347" aria-hidden="true" tabindex="-1"></a>Let the loss function be $\mathcal{L}(\boldsymbol{\theta})$, where the parameter to be optimized is $\boldsymbol{\theta}$, and our optimization goal is</span>
<span id="cb4-348"><a href="#cb4-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-349"><a href="#cb4-349" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-350"><a href="#cb4-350" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\theta}^* = \mathop{\text{argmin}}_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta})\end{equation}</span>
<span id="cb4-351"><a href="#cb4-351" aria-hidden="true" tabindex="-1"></a>$$ {#eq-loss}</span>
<span id="cb4-352"><a href="#cb4-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-353"><a href="#cb4-353" aria-hidden="true" tabindex="-1"></a>Assuming the current value of $\boldsymbol{\theta}$ is $\boldsymbol{\theta}_t$, Newton's method seeks $\boldsymbol{\theta}_{t+1}$ by expanding the loss function to the second order:</span>
<span id="cb4-354"><a href="#cb4-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-355"><a href="#cb4-355" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-356"><a href="#cb4-356" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{L}(\boldsymbol{\theta})\approx \mathcal{L}(\boldsymbol{\theta}_t) + \boldsymbol{g}_t^{\top}(\boldsymbol{\theta} - \boldsymbol{\theta}_t) + \frac{1}{2}(\boldsymbol{\theta} - \boldsymbol{\theta}_t)^{\top}\boldsymbol{\mathcal{H}}_t(\boldsymbol{\theta} - \boldsymbol{\theta}_t)\end{equation}</span>
<span id="cb4-357"><a href="#cb4-357" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-358"><a href="#cb4-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-359"><a href="#cb4-359" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{g}_t = \nabla_{\boldsymbol{\theta}_t}\mathcal{L}(\boldsymbol{\theta}_t)$ is the gradient, and $\boldsymbol{\mathcal{H}}_t=\nabla_{\boldsymbol{\theta}_t}^2\mathcal{L}(\boldsymbol{\theta}_t)$ is the Hessian matrix. Assuming the positive definiteness of the Hessian matrix, the right side of the above equation has a unique minimum $\boldsymbol{\theta}_t - \boldsymbol{\mathcal{H}}_t^{-1}\boldsymbol{g}_t$, which Newton's method uses as the next step $\boldsymbol{\theta}_{t+1}$:</span>
<span id="cb4-360"><a href="#cb4-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-361"><a href="#cb4-361" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-362"><a href="#cb4-362" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t-\boldsymbol{\mathcal{H}}_t^{-1}\boldsymbol{g}_t = \boldsymbol{\theta}_t - (\nabla_{\boldsymbol{\theta}_t}^2\mathcal{L})^{-1} \nabla_{\boldsymbol{\theta}_t}\mathcal{L}\end{equation}</span>
<span id="cb4-363"><a href="#cb4-363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-364"><a href="#cb4-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-365"><a href="#cb4-365" aria-hidden="true" tabindex="-1"></a>Note that the above equation does not have an additional learning rate parameter, so Newton's method already has an adaptive learning rate. Of course, since the complexity of the Hessian matrix is proportional to the square of the parameter count, the complete Newton's method has basically only theoretical value in deep learning. To apply Newton's method in practice, significant simplifying assumptions about the Hessian matrix are needed, such as assuming it's diagonal or low-rank.</span>
<span id="cb4-366"><a href="#cb4-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-367"><a href="#cb4-367" aria-hidden="true" tabindex="-1"></a>From the Newton's method perspective, SGD assumes $\boldsymbol{\mathcal{H}}_t=\eta_t^{-1}\boldsymbol{I}$, while Adam assumes $\boldsymbol{\mathcal{H}}_t=\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon)$, where</span>
<span id="cb4-368"><a href="#cb4-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-369"><a href="#cb4-369" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-370"><a href="#cb4-370" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{Adam}\triangleq \left<span class="sc">\{</span>\begin{aligned}</span>
<span id="cb4-371"><a href="#cb4-371" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t<span class="sc">\\</span></span>
<span id="cb4-372"><a href="#cb4-372" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t\odot\boldsymbol{g}_t<span class="sc">\\</span></span>
<span id="cb4-373"><a href="#cb4-373" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-374"><a href="#cb4-374" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-375"><a href="#cb4-375" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.</span>
<span id="cb4-376"><a href="#cb4-376" aria-hidden="true" tabindex="-1"></a>\end{aligned}\right.\end{equation}</span>
<span id="cb4-377"><a href="#cb4-377" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-378"><a href="#cb4-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-379"><a href="#cb4-379" aria-hidden="true" tabindex="-1"></a>Next, we want to demonstrate that $\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t})$ is a better approximation of $\boldsymbol{\mathcal{H}}_t$.</span>
<span id="cb4-380"><a href="#cb4-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-381"><a href="#cb4-381" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient approximation</span></span>
<span id="cb4-382"><a href="#cb4-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-383"><a href="#cb4-383" aria-hidden="true" tabindex="-1"></a>The key to the proof is using the first-order approximation of the gradient:</span>
<span id="cb4-384"><a href="#cb4-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-385"><a href="#cb4-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-386"><a href="#cb4-386" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \approx \boldsymbol{g}_{\boldsymbol{\theta}^*} + \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)\end{equation}</span>
<span id="cb4-387"><a href="#cb4-387" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-388"><a href="#cb4-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-389"><a href="#cb4-389" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{g}_{\boldsymbol{\theta}^*}$ and $\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}$ indicate that we expand at $\boldsymbol{\theta}=\boldsymbol{\theta}^*$. Here, $\boldsymbol{\theta}^*$ is the target we are looking for @eq-loss, at which point the model's gradient is zero, so the above equation can be simplified to:</span>
<span id="cb4-390"><a href="#cb4-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-391"><a href="#cb4-391" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-392"><a href="#cb4-392" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)\end{equation}</span>
<span id="cb4-393"><a href="#cb4-393" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-394"><a href="#cb4-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-395"><a href="#cb4-395" aria-hidden="true" tabindex="-1"></a>Thus:</span>
<span id="cb4-396"><a href="#cb4-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-397"><a href="#cb4-397" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-398"><a href="#cb4-398" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}}\boldsymbol{g}_{\boldsymbol{\theta}}^{\top} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}(\boldsymbol{\theta} - \boldsymbol{\theta}^*)(\boldsymbol{\theta} - \boldsymbol{\theta}^*)^{\top}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}</span>
<span id="cb4-399"><a href="#cb4-399" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-400"><a href="#cb4-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-401"><a href="#cb4-401" aria-hidden="true" tabindex="-1"></a>After training has entered the "grooves of convergence" like a train snapping to its rails, the model will be spiraling around $\boldsymbol{\theta}^*$ for a long time, converging slowly. To some extent, we can view $\boldsymbol{\theta} - \boldsymbol{\theta}^*$ as a random variable following a normal distribution $\mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})$. Then:</span>
<span id="cb4-402"><a href="#cb4-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-403"><a href="#cb4-403" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-404"><a href="#cb4-404" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">\boldsymbol{g}_{\boldsymbol{\theta}}\boldsymbol{g}_{\boldsymbol{\theta}}^{\top}</span><span class="co">]</span> \approx  \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\mathbb{E}[(\boldsymbol{\theta} - \boldsymbol{\theta}^*)(\boldsymbol{\theta} - \boldsymbol{\theta}^*)^{\top}]\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top} = \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}</span>
<span id="cb4-405"><a href="#cb4-405" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hessian-2}</span>
<span id="cb4-406"><a href="#cb4-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-407"><a href="#cb4-407" aria-hidden="true" tabindex="-1"></a>Assuming the Hessian matrix is diagonal, we can keep only the diagonal elements of the above equation:</span>
<span id="cb4-408"><a href="#cb4-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-409"><a href="#cb4-409" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-410"><a href="#cb4-410" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{diag}(\mathbb{E}<span class="co">[</span><span class="ot">\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}</span><span class="co">]</span>) \approx  \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^2\quad\Rightarrow\quad \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*} = \frac{1}{\sigma}\text{diag}(\sqrt{\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}]})\end{equation}</span>
<span id="cb4-411"><a href="#cb4-411" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-412"><a href="#cb4-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-413"><a href="#cb4-413" aria-hidden="true" tabindex="-1"></a>Doesn't that look a bit similar? Adam's $\hat{\boldsymbol{v}}_t$ is a moving average of the squared gradient, which can be seen as an approximation of $\mathbb{E}[\boldsymbol{g}_{\boldsymbol{\theta}}\odot\boldsymbol{g}_{\boldsymbol{\theta}}]$. Finally, if we assume that $\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t} \approx \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}$, we can conclude that $\eta_t^{-1}\text{diag}(\sqrt{\hat{\boldsymbol{v}}_t})$ is an approximation of $\boldsymbol{\mathcal{H}}_t$.</span>
<span id="cb4-414"><a href="#cb4-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-415"><a href="#cb4-415" aria-hidden="true" tabindex="-1"></a>This can also explain why Adam's $\beta_2$ is usually greater than $\beta_1$. To estimate the Hessian more accurately, the moving average of $\hat{\boldsymbol{v}}_t$ should be as "long-term" as possible (close to uniform averaging), so $\beta_2$ should be very close to 1. However, if the momentum $\hat{\boldsymbol{m}}_t$, which is a moving average of gradients, averages over too long a period, the result will approach $\boldsymbol{g}_{\boldsymbol{\theta}^*}=\boldsymbol{0}$, which is not good. Therefore, the moving average for momentum should be more localized.</span>
<span id="cb4-416"><a href="#cb4-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-417"><a href="#cb4-417" aria-hidden="true" tabindex="-1"></a><span class="fu">## Related work</span></span>
<span id="cb4-418"><a href="#cb4-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-419"><a href="#cb4-419" aria-hidden="true" tabindex="-1"></a>For readers familiar with Hessian matrix theory, their first reaction to the above conclusion might be confusion rather than recognition. This is because a classic approximation of the Hessian matrix is the outer product of the Jacobian matrix (similar to the gradient), while the Hessian approximation here is the square root of the gradient's outer product -- the two differ by a square root.</span>
<span id="cb4-420"><a href="#cb4-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-421"><a href="#cb4-421" aria-hidden="true" tabindex="-1"></a>Specifically, consider the squared error loss:</span>
<span id="cb4-422"><a href="#cb4-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-423"><a href="#cb4-423" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-424"><a href="#cb4-424" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{L}(\boldsymbol{\theta}) = \frac{1}{2}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\Vert \boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})\Vert^2]\end{equation}</span>
<span id="cb4-425"><a href="#cb4-425" aria-hidden="true" tabindex="-1"></a>$$ {#eq-loss-2}</span>
<span id="cb4-426"><a href="#cb4-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-427"><a href="#cb4-427" aria-hidden="true" tabindex="-1"></a>Expanding at $\boldsymbol{\theta}_t$, we have $\boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})\approx \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x}) + \boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top} (\boldsymbol{\theta} - \boldsymbol{\theta}_t)$, where $\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}=\nabla_{\boldsymbol{\theta}_t} \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x})$ is the Jacobian matrix. Substituting into the above equation:</span>
<span id="cb4-428"><a href="#cb4-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-429"><a href="#cb4-429" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-430"><a href="#cb4-430" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathcal{L}(\boldsymbol{\theta}) \approx \frac{1}{2}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\Vert \boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}_t}(\boldsymbol{x}) - \boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top} (\boldsymbol{\theta} - \boldsymbol{\theta}_t)\Vert^2]\end{equation}</span>
<span id="cb4-431"><a href="#cb4-431" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-432"><a href="#cb4-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-433"><a href="#cb4-433" aria-hidden="true" tabindex="-1"></a>After simplification, the above equation is just a quadratic form in $\boldsymbol{\theta}$, so we can directly write out its Hessian matrix:</span>
<span id="cb4-434"><a href="#cb4-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-435"><a href="#cb4-435" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-436"><a href="#cb4-436" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t} \approx \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}_t}^{\top}]\end{equation}</span>
<span id="cb4-437"><a href="#cb4-437" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-438"><a href="#cb4-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-439"><a href="#cb4-439" aria-hidden="true" tabindex="-1"></a>This is the Hessian approximation based on the outer product of the Jacobian matrix, which is the theoretical foundation of the Gauss--Newton method. Of course, $\boldsymbol{\mathcal{J}}$ is not yet $\boldsymbol{g}$; we want to try to connect the result with $\mathcal{g}$. Taking the derivative of @eq-loss-2 directly:</span>
<span id="cb4-440"><a href="#cb4-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-441"><a href="#cb4-441" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-442"><a href="#cb4-442" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} = \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\end{equation}</span>
<span id="cb4-443"><a href="#cb4-443" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-444"><a href="#cb4-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-445"><a href="#cb4-445" aria-hidden="true" tabindex="-1"></a>Thus:</span>
<span id="cb4-446"><a href="#cb4-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-447"><a href="#cb4-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-448"><a href="#cb4-448" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-449"><a href="#cb4-449" aria-hidden="true" tabindex="-1"></a>\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top} =&amp;\,  \big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)\big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)^{\top} <span class="sc">\\</span></span>
<span id="cb4-450"><a href="#cb4-450" aria-hidden="true" tabindex="-1"></a>=&amp;\,  \big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))]\big)\big(\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}[(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}]\big) <span class="sc">\\</span></span>
<span id="cb4-451"><a href="#cb4-451" aria-hidden="true" tabindex="-1"></a>\approx&amp;\, \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\big] <span class="sc">\\</span></span>
<span id="cb4-452"><a href="#cb4-452" aria-hidden="true" tabindex="-1"></a>\approx&amp;\, \mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\Big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))(\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}))^{\top}\big]\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\Big] <span class="sc">\\</span></span>
<span id="cb4-453"><a href="#cb4-453" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-454"><a href="#cb4-454" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-455"><a href="#cb4-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-456"><a href="#cb4-456" aria-hidden="true" tabindex="-1"></a>The two approximation signs here don't have much justification. We can loosely view them as <span class="co">[</span><span class="ot">mean-field approximations</span><span class="co">](https://en.wikipedia.org/wiki/Mean-field_theory)</span>. And $\boldsymbol{y} - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x})$ is the residual of the regression prediction, which we typically assume follows $\mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})$. Therefore:</span>
<span id="cb4-457"><a href="#cb4-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-458"><a href="#cb4-458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-459"><a href="#cb4-459" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top} \approx \sigma^2\mathbb{E}_{(\boldsymbol{x},\boldsymbol{y})\sim\mathcal{D}}\big[\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}\boldsymbol{\mathcal{J}}_{\boldsymbol{\theta}}^{\top}\big] \approx \sigma^2 \boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t}\end{equation}</span>
<span id="cb4-460"><a href="#cb4-460" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hessian-t}</span>
<span id="cb4-461"><a href="#cb4-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-462"><a href="#cb4-462" aria-hidden="true" tabindex="-1"></a>This reveals the relationship between $\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}_t}$ and $\boldsymbol{g}_{\boldsymbol{\theta}} \boldsymbol{g}_{\boldsymbol{\theta}}^{\top}$. Comparing with @eq-hessian-2 from the previous section, we find that they appear to differ by a square.</span>
<span id="cb4-463"><a href="#cb4-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-464"><a href="#cb4-464" aria-hidden="true" tabindex="-1"></a>Looking at the derivation process, neither result seems obviously wrong, so how do we understand this inconsistency? We can understand it this way: @eq-hessian-t gives the Hessian approximation at time $t$, which is an "instantaneous approximation", while @eq-hessian-2 is a "long-term average" result over time steps. The long-term averaging effect cancels out some of the intensity (but theoretically would make the estimate more accurate), thus requiring an additional square root, as we know from the theory of random walks.</span>
<span id="cb4-465"><a href="#cb4-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-466"><a href="#cb4-466" aria-hidden="true" tabindex="-1"></a>A similar effect also appears in the SDE introduced in <span class="co">[</span><span class="ot">"Generative Diffusion Modeling (Part 5): the SDE part of a General Framework"</span><span class="co">](https://kexue.fm/archives/9209)</span>, where the strength of the noise term $\epsilon$ in SDE needs to be on the order of $O(\sqrt{\delta t})$, while the non-random drift term needs to be on the order of $O(\delta t)$. This is also because the noise terms partially cancel out when summed over time, so the noise needs to be of a higher order so that its effect will not be washed away in the final result.<span class="ot">[^comment-1]</span></span>
<span id="cb4-467"><a href="#cb4-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-468"><a href="#cb4-468" aria-hidden="true" tabindex="-1"></a><span class="ot">[^comment-1]: </span>This explanation is wrong. The real explanation is very simple. In the derivation of Adam, we assumed $\theta^* - \theta\sim \mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})$, whereas in the derivation of this section, we assumed $\boldsymbol{f}_{\boldsymbol{\theta}^*}(\boldsymbol{x}) - \boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{x}) \sim \mathcal{N}(\boldsymbol{0},\sigma^2\boldsymbol{I})$. The two assumptions are simply incompatible.</span>
<span id="cb4-469"><a href="#cb4-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-470"><a href="#cb4-470" aria-hidden="true" tabindex="-1"></a><span class="fu">## More connections</span></span>
<span id="cb4-471"><a href="#cb4-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-472"><a href="#cb4-472" aria-hidden="true" tabindex="-1"></a>In the previous derivation, we assumed that $\boldsymbol{\theta}^*$ is the theoretical optimal point, so $\boldsymbol{g} _{\boldsymbol{\theta}^*} = \boldsymbol{0}$. What if $\boldsymbol{\theta}^*$ is any arbitrary point? Then @eq-hessian-2 would become:</span>
<span id="cb4-473"><a href="#cb4-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-474"><a href="#cb4-474" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-475"><a href="#cb4-475" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathbb{E}<span class="co">[</span><span class="ot">(\boldsymbol{g}_{\boldsymbol{\theta}}-\boldsymbol{g} _{\boldsymbol{\theta}^*})(\boldsymbol{g}_{\boldsymbol{\theta}}-\boldsymbol{g} _{\boldsymbol{\theta}^*})^{\top}</span><span class="co">]</span> \approx \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^{\top}\end{equation}</span>
<span id="cb4-476"><a href="#cb4-476" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-477"><a href="#cb4-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-478"><a href="#cb4-478" aria-hidden="true" tabindex="-1"></a>This means that as long as we use a moving average of the covariance rather than the second moment, we can obtain a Hessian approximation within the local range. This corresponds exactly to the approach of the <span class="co">[</span><span class="ot">AdaBelief optimizer</span><span class="co">](https://arxiv.org/abs/2010.07468)</span>, where $\boldsymbol{v}$ is a moving average of the square of the difference between $\boldsymbol{g}$ and $\boldsymbol{m}$:</span>
<span id="cb4-479"><a href="#cb4-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-480"><a href="#cb4-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-481"><a href="#cb4-481" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{AdaBelief}\triangleq \left<span class="sc">\{</span>\begin{aligned}</span>
<span id="cb4-482"><a href="#cb4-482" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t<span class="sc">\\</span></span>
<span id="cb4-483"><a href="#cb4-483" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) (\boldsymbol{g}_t - \boldsymbol{m}_t)\odot(\boldsymbol{g}_t - \boldsymbol{m}_t)<span class="sc">\\</span></span>
<span id="cb4-484"><a href="#cb4-484" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-485"><a href="#cb4-485" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-486"><a href="#cb4-486" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.</span>
<span id="cb4-487"><a href="#cb4-487" aria-hidden="true" tabindex="-1"></a>\end{aligned}\right.\end{equation}</span>
<span id="cb4-488"><a href="#cb4-488" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-489"><a href="#cb4-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-490"><a href="#cb4-490" aria-hidden="true" tabindex="-1"></a><span class="fu"># Muon appreciation: a fundamental advance from vectors to matrices {#sec-muon-appreciation}</span></span>
<span id="cb4-491"><a href="#cb4-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-492"><a href="#cb4-492" aria-hidden="true" tabindex="-1"></a>Source: <span class="co">[</span><span class="ot">Muon优化器赏析：从向量到矩阵的本质跨越 - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10592)</span> (2024-12-10)</span>
<span id="cb4-493"><a href="#cb4-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-494"><a href="#cb4-494" aria-hidden="true" tabindex="-1"></a>Since the advent of the LLM era, the academic community's enthusiasm for optimizer research seems to have diminished. This is mainly because the current mainstream AdamW can already meet most needs, and any major "surgery" to optimizers would cost enormously to validate. Therefore, current optimizer variations are mostly small patches applied to AdamW by people in the industry based on their practical training experience.</span>
<span id="cb4-495"><a href="#cb4-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-496"><a href="#cb4-496" aria-hidden="true" tabindex="-1"></a>However, recently "<span class="co">[</span><span class="ot">Muon</span><span class="co">](https://github.com/KellerJordan/Muon)</span>" has generated quite a buzz on Twitter. It claims to be more efficient than AdamW, and is not just a minor tweak to Adam, but rather embodies some principles regarding the differences between vectors and matrices that are worth pondering. Let's appreciate it together in this article.</span>
<span id="cb4-497"><a href="#cb4-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-498"><a href="#cb4-498" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Muon vs AdamW (Source: [\@Yuchenj_UW on Twitter](https://x.com/Yuchenj_UW))</span><span class="co">](figure/125501438.jpeg)</span></span>
<span id="cb4-499"><a href="#cb4-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-500"><a href="#cb4-500" aria-hidden="true" tabindex="-1"></a><span class="fu">## First taste</span></span>
<span id="cb4-501"><a href="#cb4-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-502"><a href="#cb4-502" aria-hidden="true" tabindex="-1"></a><span class="in">```{.pseudocode}</span></span>
<span id="cb4-503"><a href="#cb4-503" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb4-504"><a href="#cb4-504" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Muon}</span></span>
<span id="cb4-505"><a href="#cb4-505" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb4-506"><a href="#cb4-506" aria-hidden="true" tabindex="-1"></a><span class="in">\REQUIRE Learning rate $\eta$, momentum $\mu$</span></span>
<span id="cb4-507"><a href="#cb4-507" aria-hidden="true" tabindex="-1"></a><span class="in">    \STATE Initialize $B_0 \leftarrow 0$</span></span>
<span id="cb4-508"><a href="#cb4-508" aria-hidden="true" tabindex="-1"></a><span class="in">    \FOR{$t=1, \ldots$} </span></span>
<span id="cb4-509"><a href="#cb4-509" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE Compute gradient $G_t \leftarrow \nabla_{\theta}\mathcal{L}_t(\theta_{t-1})$</span></span>
<span id="cb4-510"><a href="#cb4-510" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE $B_t \leftarrow \mu B_{t-1} + G_t$</span></span>
<span id="cb4-511"><a href="#cb4-511" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE $O_t \leftarrow \text{NewtonSchulz5}(B_t)$</span></span>
<span id="cb4-512"><a href="#cb4-512" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE Update parameters $\theta_t \leftarrow \theta_{t-1} - \eta O_t$</span></span>
<span id="cb4-513"><a href="#cb4-513" aria-hidden="true" tabindex="-1"></a><span class="in">    \ENDFOR</span></span>
<span id="cb4-514"><a href="#cb4-514" aria-hidden="true" tabindex="-1"></a><span class="in">    \RETURN $\theta_t$</span></span>
<span id="cb4-515"><a href="#cb4-515" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb4-516"><a href="#cb4-516" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb4-517"><a href="#cb4-517" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-518"><a href="#cb4-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-519"><a href="#cb4-519" aria-hidden="true" tabindex="-1"></a>Muon stands for "<span class="dt">&lt;</span><span class="kw">font</span><span class="ot"> color</span><span class="op">=</span><span class="st">red</span><span class="dt">&gt;</span>M<span class="dt">&lt;/</span><span class="kw">font</span><span class="dt">&gt;</span>oment<span class="dt">&lt;</span><span class="kw">font</span><span class="ot"> color</span><span class="op">=</span><span class="st">red</span><span class="dt">&gt;</span>u<span class="dt">&lt;/</span><span class="kw">font</span><span class="dt">&gt;</span>m <span class="dt">&lt;</span><span class="kw">font</span><span class="ot"> color</span><span class="op">=</span><span class="st">red</span><span class="dt">&gt;</span>O<span class="dt">&lt;/</span><span class="kw">font</span><span class="dt">&gt;</span>rthogonalized by <span class="dt">&lt;</span><span class="kw">font</span><span class="ot"> color</span><span class="op">=</span><span class="st">red</span><span class="dt">&gt;</span>N<span class="dt">&lt;/</span><span class="kw">font</span><span class="dt">&gt;</span>ewton--Schulz". Unlike typical gradient descent, which applies to any kind of parameter, whether it be scalar, vector, or matrix, Muon applies to only matrix parameters.</span>
<span id="cb4-520"><a href="#cb4-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-521"><a href="#cb4-521" aria-hidden="true" tabindex="-1"></a>Let $\boldsymbol{W}\in\mathbb{R}^{n\times m}$ be such a matrix parameter, then the Muon update rule states that:</span>
<span id="cb4-522"><a href="#cb4-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-523"><a href="#cb4-523" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-524"><a href="#cb4-524" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-525"><a href="#cb4-525" aria-hidden="true" tabindex="-1"></a>\boldsymbol{G}_t =&amp;\, \nabla_\theta \mathcal L_t(\theta_{t-1})<span class="sc">\\</span></span>
<span id="cb4-526"><a href="#cb4-526" aria-hidden="true" tabindex="-1"></a>\boldsymbol{M}_t =&amp;\, \beta\boldsymbol{M}_{t-1} + \boldsymbol{G}_t <span class="sc">\\</span></span>
<span id="cb4-527"><a href="#cb4-527" aria-hidden="true" tabindex="-1"></a>\boldsymbol{W}_t =&amp;\, \boldsymbol{W}_{t-1} - \eta_t [\text{msign}(\boldsymbol{M}_t) + \lambda \boldsymbol{W}_{t-1}] <span class="sc">\\</span></span>
<span id="cb4-528"><a href="#cb4-528" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-529"><a href="#cb4-529" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-530"><a href="#cb4-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-531"><a href="#cb4-531" aria-hidden="true" tabindex="-1"></a>Here, $\text{msign}$ is the <span class="co">[</span><span class="ot">matrix sign function</span><span class="co">](https://en.wikipedia.org/wiki/Matrix_sign_function)</span>, which is not simply applying the $\text{sign}$ operation to each component of the matrix, but rather a matrix generalization of the $\text{sign}$ function. It can be defined via <span class="co">[</span><span class="ot">SVD</span><span class="co">](https://en.wikipedia.org/wiki/Singular_value_decomposition)</span>:</span>
<span id="cb4-532"><a href="#cb4-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-533"><a href="#cb4-533" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-534"><a href="#cb4-534" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}^{\top} = SVD(\boldsymbol{M}) \quad\Rightarrow\quad \text{msign}(\boldsymbol{M}) = \boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{<span class="co">[</span><span class="ot">:,:r</span><span class="co">]</span>}^{\top}\end{equation}</span>
<span id="cb4-535"><a href="#cb4-535" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-536"><a href="#cb4-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-537"><a href="#cb4-537" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{U}\in\mathbb{R}^{n\times n},\boldsymbol{\Sigma}\in\mathbb{R}^{r \times r},\boldsymbol{V}\in\mathbb{R}^{m\times m}$, and $r$ is the rank of $\boldsymbol{M}$. We will expand on more theoretical details later, but first let's try to intuitively grasp the following fact:</span>
<span id="cb4-538"><a href="#cb4-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-539"><a href="#cb4-539" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Muon is an adaptive learning rate optimizer, like Adam.</span></span>
<span id="cb4-540"><a href="#cb4-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-541"><a href="#cb4-541" aria-hidden="true" tabindex="-1"></a>The common trait of adaptive learning rate optimizers like Adagrad, RMSprop, and Adam is that the update for each parameter is divided by the "standard deviation of gradient" $\sqrt{\overline{(\nabla \mathcal L)^2}}$, that is, the square root of the moving average of squared gradients. This ensures two essential properties: </span>
<span id="cb4-542"><a href="#cb4-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-543"><a href="#cb4-543" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Constant scaling of the loss function $\mathcal L \mapsto c\mathcal L$ does not change the parameter updates.</span>
<span id="cb4-544"><a href="#cb4-544" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The change in each parameter is approximately equalized. That is, $|\theta_{t, i} - \theta_{t-1, i}| \sim \eta_t$ for all $i$.</span>
<span id="cb4-545"><a href="#cb4-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-546"><a href="#cb4-546" aria-hidden="true" tabindex="-1"></a>Muon reproduces the two essential properties for matrices, even though it does not keep track of $\sqrt{\overline{(\nabla \mathcal L)^2}}$:</span>
<span id="cb4-547"><a href="#cb4-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-548"><a href="#cb4-548" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>If the loss function $\mathcal L$ is multiplied by some constant $c$, $\boldsymbol{M}$ will also be multiplied by $c$, but $\text{msign}(\boldsymbol{M})$ remains unchanged.</span>
<span id="cb4-549"><a href="#cb4-549" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>When $\boldsymbol{M}$ is decomposed by SVD into $\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top}$, the different singular values of $\boldsymbol{\Sigma}$ reflect the "anisotropy" of $\boldsymbol{M}$, and setting them all to <span class="dt">&lt;</span><span class="kw">u</span><span class="dt">&gt;</span>one<span class="dt">&lt;/</span><span class="kw">u</span><span class="dt">&gt;</span> makes it more isotropic, which also serves to synchronize update magnitudes.</span>
<span id="cb4-550"><a href="#cb4-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-551"><a href="#cb4-551" aria-hidden="true" tabindex="-1"></a>(By the way, did point 2 remind anyone of <span class="co">[</span><span class="ot">BERT-whitening</span><span class="co">](https://kexue.fm/archives/8069)</span>?)</span>
<span id="cb4-552"><a href="#cb4-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-553"><a href="#cb4-553" aria-hidden="true" tabindex="-1"></a>Stated in another way, consider what happens with Adam: We divide each component of the gradient $\nabla \mathcal L$ by $\sqrt{\overline{(\nabla \mathcal L)^2}}$, which approximately gives us just the sign of $\nabla \mathcal L$. That is, if $\partial_{\theta_i} \mathcal L &gt; 0$, then we should get $\sim +1$ after dividing, and if $\partial_{\theta_i} \mathcal L &lt; 0$, then we should get $\sim -1$ after dividing. The use of the matrix sign reproduces this effect.</span>
<span id="cb4-554"><a href="#cb4-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-555"><a href="#cb4-555" aria-hidden="true" tabindex="-1"></a>Muon has a Nesterov version, which simply replaces $\text{msign}(\boldsymbol{M}_t)$ with $\text{msign}(\beta\boldsymbol{M}_t + \boldsymbol{G}_t)$ in the update rule, with everything else remaining identical. Since it's tangential to our point, we won't expand on this.</span>
<span id="cb4-556"><a href="#cb4-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-557"><a href="#cb4-557" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sign function</span></span>
<span id="cb4-558"><a href="#cb4-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-559"><a href="#cb4-559" aria-hidden="true" tabindex="-1"></a>Using SVD, we can also prove the identity:</span>
<span id="cb4-560"><a href="#cb4-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-561"><a href="#cb4-561" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-562"><a href="#cb4-562" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{msign}(\boldsymbol{M}) = (\boldsymbol{M}\boldsymbol{M}^{\top})^{-1/2}\boldsymbol{M}= \boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}\end{equation}</span>
<span id="cb4-563"><a href="#cb4-563" aria-hidden="true" tabindex="-1"></a>$$ {#eq-msign-id}</span>
<span id="cb4-564"><a href="#cb4-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-565"><a href="#cb4-565" aria-hidden="true" tabindex="-1"></a>where ${}^{-1/2}$ is the inverse of the matrix raised to the power of $1/2$, or the <span class="co">[</span><span class="ot">pseudoinverse</span><span class="co">](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse)</span> if it's not invertible. This identity helps us better understand why $\text{msign}$ is a matrix generalization of $\text{sign}$: for a scalar $x$, we have $\text{sign}(x)=x(x^2)^{-1/2}$, which is precisely a special case of the above equation (when $\boldsymbol{M}$ is a $1\times 1$ matrix). This special example can also be generalized to diagonal matrices $\boldsymbol{M}=\text{diag}(\boldsymbol{m})$:</span>
<span id="cb4-566"><a href="#cb4-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-567"><a href="#cb4-567" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-568"><a href="#cb4-568" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{msign}(\boldsymbol{M}) = \text{diag}(\boldsymbol{m})<span class="co">[</span><span class="ot">\text{diag}(\boldsymbol{m})^2</span><span class="co">]</span>^{-1/2} = \text{diag}(\text{sign}(\boldsymbol{m}))=\text{sign}(\boldsymbol{M})\end{equation}</span>
<span id="cb4-569"><a href="#cb4-569" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-570"><a href="#cb4-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-571"><a href="#cb4-571" aria-hidden="true" tabindex="-1"></a>where $\text{sign}(\boldsymbol{m})$ and $\text{sign}(\boldsymbol{M})$ refer to taking $\text{sign}$ of each component of the vector/matrix. The above equation means that when $\boldsymbol{M}$ is a diagonal matrix, Muon degenerates to <span class="co">[</span><span class="ot">Lion</span><span class="co">](https://arxiv.org/abs/2302.06675)</span>, <span class="co">[</span><span class="ot">Tiger</span><span class="co">](https://kexue.fm/archives/9512)</span>, or <span class="co">[</span><span class="ot">Signum</span><span class="co">](https://arxiv.org/abs/1802.04434)</span>, obtained by successive simplification from of AdamW:</span>
<span id="cb4-572"><a href="#cb4-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-573"><a href="#cb4-573" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-574"><a href="#cb4-574" aria-hidden="true" tabindex="-1"></a>\begin{array}{c|c|c|c}</span>
<span id="cb4-575"><a href="#cb4-575" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-576"><a href="#cb4-576" aria-hidden="true" tabindex="-1"></a>\text{Signum} &amp; \text{Tiger} &amp; \text{Lion} &amp; \text{AdamW} <span class="sc">\\</span></span>
<span id="cb4-577"><a href="#cb4-577" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-578"><a href="#cb4-578" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb4-579"><a href="#cb4-579" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta \boldsymbol{m}_{t-1} + \left(1 - \beta\right) \boldsymbol{g}_t <span class="sc">\\</span></span>
<span id="cb4-580"><a href="#cb4-580" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \text{sign}(\boldsymbol{m}_t) <span class="sc">\\</span></span>
<span id="cb4-581"><a href="#cb4-581" aria-hidden="true" tabindex="-1"></a>\end{aligned} &amp; </span>
<span id="cb4-582"><a href="#cb4-582" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb4-583"><a href="#cb4-583" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta \boldsymbol{m}_{t-1} + \left(1 - \beta\right) \boldsymbol{g}_t <span class="sc">\\</span></span>
<span id="cb4-584"><a href="#cb4-584" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t \left[\text{sign}(\boldsymbol{m}_t) \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}}\right] <span class="sc">\\</span></span>
<span id="cb4-585"><a href="#cb4-585" aria-hidden="true" tabindex="-1"></a>\end{aligned} &amp;</span>
<span id="cb4-586"><a href="#cb4-586" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb4-587"><a href="#cb4-587" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{u}_t = \text{sign}\big(\beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t\big) <span class="sc">\\</span></span>
<span id="cb4-588"><a href="#cb4-588" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t (\boldsymbol{u}_t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}}) <span class="sc">\\</span></span>
<span id="cb4-589"><a href="#cb4-589" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta_2 \boldsymbol{m}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t</span>
<span id="cb4-590"><a href="#cb4-590" aria-hidden="true" tabindex="-1"></a>\end{aligned} &amp;</span>
<span id="cb4-591"><a href="#cb4-591" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb4-592"><a href="#cb4-592" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{m}_t = \beta_1 \boldsymbol{m}_{t-1} + \left(1 - \beta_1\right) \boldsymbol{g}_t<span class="sc">\\</span></span>
<span id="cb4-593"><a href="#cb4-593" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{v}_t = \beta_2 \boldsymbol{v}_{t-1} + \left(1 - \beta_2\right) \boldsymbol{g}_t^2<span class="sc">\\</span></span>
<span id="cb4-594"><a href="#cb4-594" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{m}}_t = \boldsymbol{m}_t\left/\left(1 - \beta_1^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-595"><a href="#cb4-595" aria-hidden="true" tabindex="-1"></a>&amp;\hat{\boldsymbol{v}}_t = \boldsymbol{v}_t\left/\left(1 - \beta_2^t\right)\right.<span class="sc">\\</span></span>
<span id="cb4-596"><a href="#cb4-596" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{u}_t =\hat{\boldsymbol{m}}_t\left/\left(\sqrt{\hat{\boldsymbol{v}}_t} + \epsilon\right)\right.<span class="sc">\\</span></span>
<span id="cb4-597"><a href="#cb4-597" aria-hidden="true" tabindex="-1"></a>&amp;\boldsymbol{\theta}_t = \boldsymbol{\theta}_{t-1} - \eta_t (\boldsymbol{u}_t \color{skyblue}{ + \lambda_t \boldsymbol{\theta}_{t-1}})</span>
<span id="cb4-598"><a href="#cb4-598" aria-hidden="true" tabindex="-1"></a>\end{aligned} <span class="sc">\\</span></span>
<span id="cb4-599"><a href="#cb4-599" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-600"><a href="#cb4-600" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb4-601"><a href="#cb4-601" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-602"><a href="#cb4-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-603"><a href="#cb4-603" aria-hidden="true" tabindex="-1"></a>Conversely, the difference between Muon and Signum/Tiger is that the elementwise $\text{sign}(\boldsymbol{M})$ is replaced with the matrix version $\text{msign}(\boldsymbol{M})$.</span>
<span id="cb4-604"><a href="#cb4-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-605"><a href="#cb4-605" aria-hidden="true" tabindex="-1"></a>For an $n$-dimensional vector, we can also view it as an $n\times 1$ matrix, in which case $\text{msign}(\boldsymbol{m}) = \boldsymbol{m}/\Vert\boldsymbol{m}\Vert_2$ is exactly $l_2$ normalization. So, in the Muon framework, we have two perspectives for vectors: one as a diagonal matrix, like the $\gamma$ parameter in LayerNorm, resulting in taking $\text{sign}$ of the momentum; the other as an $n\times 1$ matrix, resulting in $l_2$ normalization of the momentum. Additionally, although input and output embeddings are also matrices, they are used sparsely, so a more reasonable approach is to treat them as lists of independent vectors.</span>
<span id="cb4-606"><a href="#cb4-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-607"><a href="#cb4-607" aria-hidden="true" tabindex="-1"></a>$\text{msign}(\boldsymbol{M})$ also has the meaning of "optimal orthogonal approximation":</span>
<span id="cb4-608"><a href="#cb4-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-609"><a href="#cb4-609" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-610"><a href="#cb4-610" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{msign}(\boldsymbol{M}) = \mathop{\text{argmin}}\Vert \boldsymbol{M} - \boldsymbol{O}\Vert_F^2 \end{equation}</span>
<span id="cb4-611"><a href="#cb4-611" aria-hidden="true" tabindex="-1"></a>$$ {#eq-nearest-orth}</span>
<span id="cb4-612"><a href="#cb4-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-613"><a href="#cb4-613" aria-hidden="true" tabindex="-1"></a>where $\boldsymbol{O}$ is constrained by over $\boldsymbol{O}^{\top}\boldsymbol{O} = \boldsymbol{I}$ if $\boldsymbol{M}$ is a tall matrix, or $\boldsymbol{O}\boldsymbol{O}^{\top} = \boldsymbol{I}$ if $\boldsymbol{M}$ is a fat matrix. Furthermore, if the matrix is full-ranked, that is, $r = \min(m, n)$, then $\boldsymbol{O}$ is the *unique* minimizer of the equation.</span>
<span id="cb4-614"><a href="#cb4-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-615"><a href="#cb4-615" aria-hidden="true" tabindex="-1"></a>This is analogous to how</span>
<span id="cb4-616"><a href="#cb4-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-617"><a href="#cb4-617" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-618"><a href="#cb4-618" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{sign}(\boldsymbol{M}) = \mathop{\text{argmin}}_{\boldsymbol{O}\in<span class="sc">\{</span>-1,1<span class="sc">\}</span>^{n\times m}}\Vert \boldsymbol{M} - \boldsymbol{O}\Vert_F^2\end{equation}</span>
<span id="cb4-619"><a href="#cb4-619" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-620"><a href="#cb4-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-621"><a href="#cb4-621" aria-hidden="true" tabindex="-1"></a>and how $\text{sign}(\boldsymbol{M})$ is the unique solution when $\boldsymbol{M}$ has only nonzero entries.</span>
<span id="cb4-622"><a href="#cb4-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-623"><a href="#cb4-623" aria-hidden="true" tabindex="-1"></a>Whether it's $\boldsymbol{O}^{\top}\boldsymbol{O} = \boldsymbol{I}$ or $\boldsymbol{O}\in<span class="sc">\{</span>-1,1<span class="sc">\}</span>^{n\times m}$, we can view both as a kind of regularization constraint on the update amount. So Muon and Signum/Tiger can be seen as optimizers under the same approach: they all start from momentum $\boldsymbol{M}$ to construct the update amount, but choose different regularization methods for the update.</span>
<span id="cb4-624"><a href="#cb4-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-625"><a href="#cb4-625" aria-hidden="true" tabindex="-1"></a>To prove @eq-nearest-orth, note that the Frobenius norm is preserved by left and right multiplication of orthogonal matrices. That is, $<span class="sc">\|</span>\boldsymbol{V}\boldsymbol{A}<span class="sc">\|</span>_F = <span class="sc">\|</span>\boldsymbol{A}<span class="sc">\|</span>_F = |\boldsymbol{A}\boldsymbol{U}<span class="sc">\|</span>_F$ for any orthogonal matrices $\boldsymbol{U}, \boldsymbol{V}$ of the suitable shapes. Thus it reduces to the special case where $\boldsymbol{M} = \boldsymbol{\Sigma}$. Now, use the fact that $<span class="sc">\|</span>\boldsymbol{A}<span class="sc">\|</span>_F^2$ is the sum of its column vectors' norm-squared.</span>
<span id="cb4-626"><a href="#cb4-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-627"><a href="#cb4-627" aria-hidden="true" tabindex="-1"></a><span class="fu">## Iterative solution</span></span>
<span id="cb4-628"><a href="#cb4-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-629"><a href="#cb4-629" aria-hidden="true" tabindex="-1"></a>In practice, if we compute $\text{msign}(\boldsymbol{M})$ by performing SVD on $\boldsymbol{M}$ at each step, the computational cost would be quite high. Therefore, the authors of Muon proposed using Newton--Schulz iteration to approximately calculate $\text{msign}(\boldsymbol{M})$.</span>
<span id="cb4-630"><a href="#cb4-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-631"><a href="#cb4-631" aria-hidden="true" tabindex="-1"></a>The starting point of the iteration is the identity @eq-msign-id. Without loss of generality, we assume $n\geq m$ and consider the Taylor expansion of $(\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}$ at $\boldsymbol{M}^{\top}\boldsymbol{M}=\boldsymbol{I}$. The expansion is done by doing a matrix Taylor expanion. Specifically, consider a symmetric $\boldsymbol{A} = \boldsymbol{I} + \delta\boldsymbol{A}$, where $\delta\boldsymbol{A}$ is a small symmetric matrix. Then by direct multiplication, we have</span>
<span id="cb4-632"><a href="#cb4-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-633"><a href="#cb4-633" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-634"><a href="#cb4-634" aria-hidden="true" tabindex="-1"></a>\boldsymbol{A}^{-1/2} = \boldsymbol{I} - \frac 12 \delta \boldsymbol{A} + \frac 38 \delta \boldsymbol{A}^2 + O(\delta \boldsymbol{A}^3)</span>
<span id="cb4-635"><a href="#cb4-635" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-636"><a href="#cb4-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-637"><a href="#cb4-637" aria-hidden="true" tabindex="-1"></a>Thus, up to 2th order,</span>
<span id="cb4-638"><a href="#cb4-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-639"><a href="#cb4-639" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-640"><a href="#cb4-640" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{msign}(\boldsymbol{M}) = \boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^{-1/2}\approx \frac{15}{8}\boldsymbol{M} - \frac{5}{4}\boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M}) + \frac{3}{8}\boldsymbol{M}(\boldsymbol{M}^{\top}\boldsymbol{M})^2\end{equation}</span>
<span id="cb4-641"><a href="#cb4-641" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-642"><a href="#cb4-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-643"><a href="#cb4-643" aria-hidden="true" tabindex="-1"></a>If $\boldsymbol{X}_t$ is an approximation of $\text{msign}(\boldsymbol{M})$, we believe that substituting it into the above equation will yield a better approximation of $\text{msign}(\boldsymbol{M})$. Thus, we obtain a usable iteration format:</span>
<span id="cb4-644"><a href="#cb4-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-645"><a href="#cb4-645" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-646"><a href="#cb4-646" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{X}_{t+1} = a \boldsymbol{X}_t + b\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t) + c\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^2\end{equation}</span>
<span id="cb4-647"><a href="#cb4-647" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-648"><a href="#cb4-648" aria-hidden="true" tabindex="-1"></a>with $(a,b,c) = (15/8, -5/4, 3/8) = (1.875, -1.25, 0.375)$</span>
<span id="cb4-649"><a href="#cb4-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-650"><a href="#cb4-650" aria-hidden="true" tabindex="-1"></a>But if we look up the official code for Muon, we'd see that the Newton--Schulz iteration does appear in this form, but with $(a,b,c) = (3.4445, -4.7750,  2.0315)$. Further, the original author made no attempt to derive this mathematically, but just wrote it in as a magic constant:</span>
<span id="cb4-651"><a href="#cb4-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-652"><a href="#cb4-652" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb4-653"><a href="#cb4-653" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zeropower_via_newtonschulz5(G, steps<span class="op">=</span><span class="dv">10</span>, eps<span class="op">=</span><span class="fl">1e-7</span>):</span>
<span id="cb4-654"><a href="#cb4-654" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-655"><a href="#cb4-655" aria-hidden="true" tabindex="-1"></a><span class="co">    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a</span></span>
<span id="cb4-656"><a href="#cb4-656" aria-hidden="true" tabindex="-1"></a><span class="co">    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose</span></span>
<span id="cb4-657"><a href="#cb4-657" aria-hidden="true" tabindex="-1"></a><span class="co">    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at</span></span>
<span id="cb4-658"><a href="#cb4-658" aria-hidden="true" tabindex="-1"></a><span class="co">    zero even beyond the point where the iteration no longer converges all the way to one everywhere</span></span>
<span id="cb4-659"><a href="#cb4-659" aria-hidden="true" tabindex="-1"></a><span class="co">    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T</span></span>
<span id="cb4-660"><a href="#cb4-660" aria-hidden="true" tabindex="-1"></a><span class="co">    where S' is diagonal with S_{ii}' </span><span class="er">\</span><span class="co">sim Uniform(0.5, 1.5), which turns out not to hurt model</span></span>
<span id="cb4-661"><a href="#cb4-661" aria-hidden="true" tabindex="-1"></a><span class="co">    performance at all relative to UV^T, where USV^T = G is the SVD.</span></span>
<span id="cb4-662"><a href="#cb4-662" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-663"><a href="#cb4-663" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">len</span>(G.shape) <span class="op">==</span> <span class="dv">2</span></span>
<span id="cb4-664"><a href="#cb4-664" aria-hidden="true" tabindex="-1"></a>    a, b, c <span class="op">=</span> (<span class="fl">3.4445</span>, <span class="op">-</span><span class="fl">4.7750</span>,  <span class="fl">2.0315</span>)</span>
<span id="cb4-665"><a href="#cb4-665" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> G.bfloat16()</span>
<span id="cb4-666"><a href="#cb4-666" aria-hidden="true" tabindex="-1"></a>    X <span class="op">/=</span> (X.norm() <span class="op">+</span> eps) <span class="co"># ensure top singular value &lt;= 1</span></span>
<span id="cb4-667"><a href="#cb4-667" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb4-668"><a href="#cb4-668" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> X.T</span>
<span id="cb4-669"><a href="#cb4-669" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(steps):</span>
<span id="cb4-670"><a href="#cb4-670" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> X <span class="op">@</span> X.T</span>
<span id="cb4-671"><a href="#cb4-671" aria-hidden="true" tabindex="-1"></a>        B <span class="op">=</span> A <span class="op">@</span> X</span>
<span id="cb4-672"><a href="#cb4-672" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> a <span class="op">*</span> X <span class="op">+</span> b <span class="op">*</span> B <span class="op">+</span> c <span class="op">*</span> A <span class="op">@</span> B</span>
<span id="cb4-673"><a href="#cb4-673" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> G.size(<span class="dv">0</span>) <span class="op">&gt;</span> G.size(<span class="dv">1</span>):</span>
<span id="cb4-674"><a href="#cb4-674" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> X.T</span>
<span id="cb4-675"><a href="#cb4-675" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X</span>
<span id="cb4-676"><a href="#cb4-676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-677"><a href="#cb4-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-678"><a href="#cb4-678" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convergence acceleration</span></span>
<span id="cb4-679"><a href="#cb4-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-680"><a href="#cb4-680" aria-hidden="true" tabindex="-1"></a>To guess the origin of the official iteration algorithm, we consider a general iteration process:</span>
<span id="cb4-681"><a href="#cb4-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-682"><a href="#cb4-682" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-683"><a href="#cb4-683" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{X}_{t+1} = a\boldsymbol{X}_t + b\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t) + c\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^2\end{equation}</span>
<span id="cb4-684"><a href="#cb4-684" aria-hidden="true" tabindex="-1"></a>$$ {#eq-iteration}</span>
<span id="cb4-685"><a href="#cb4-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-686"><a href="#cb4-686" aria-hidden="true" tabindex="-1"></a>where $(a,b,c)$ are to be determined. If we want a higher-order iteration algorithm, we can also successively add terms like $\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^3$, $\boldsymbol{X}_t(\boldsymbol{X}_t^{\top}\boldsymbol{X}_t)^4$, etc. The following analysis process is universal.</span>
<span id="cb4-687"><a href="#cb4-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-688"><a href="#cb4-688" aria-hidden="true" tabindex="-1"></a>We choose the initial value as $\boldsymbol{X}_0=\boldsymbol{M}/\Vert\boldsymbol{M}\Vert_F$, where $\Vert\cdot\Vert_F$ is the Frobenius norm of the matrix. The rationale is that dividing by $\Vert\boldsymbol{M}\Vert_F$ does not change the $\boldsymbol{U}$ and $\boldsymbol{V}$ in the SVD, but can make all singular values of $\boldsymbol{X}_0$ lie in the interval $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, standardizing the initial singular values for iteration. Now, assuming $\boldsymbol{X}_t$ can be decomposed by SVD as $\boldsymbol{U}\boldsymbol{\Sigma}_t\boldsymbol{V}^{\top}$, substituting into the above equation gives:</span>
<span id="cb4-689"><a href="#cb4-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-690"><a href="#cb4-690" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-691"><a href="#cb4-691" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{X}_{t+1} = \boldsymbol{U}_{[:,:r]}(a \boldsymbol{\Sigma}_{t,[:r,:r]} + b \boldsymbol{\Sigma}_{t,[:r,:r]}^3 + c \boldsymbol{\Sigma}_{t,[:r,:r]}^5)\boldsymbol{V}_{<span class="co">[</span><span class="ot">:,:r</span><span class="co">]</span>}^{\top}\end{equation}</span>
<span id="cb4-692"><a href="#cb4-692" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-693"><a href="#cb4-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-694"><a href="#cb4-694" aria-hidden="true" tabindex="-1"></a>Therefore, @eq-iteration is actually iterating on the diagonal matrix $\boldsymbol{\Sigma}_{[:r,:r]}$ composed of singular values. If we denote $\boldsymbol{X}_t=\boldsymbol{U}_{[:,:r]}\boldsymbol{\Sigma}_{t,[:r,:r]}\boldsymbol{V}_{[:,:r]}^{\top}$, then $\boldsymbol{\Sigma}_{t+1,[:r,:r]} = g(\boldsymbol{\Sigma}_{t,[:r,:r]})$, where $g(x) = ax + bx^3 + cx^5$. Since the power of a diagonal matrix equals each diagonal element raised to that power, the problem simplifies to the iteration of a single singular value $\sigma$. Our goal is to compute $\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{[:,:r]}^{\top}$, in other words, we hope to transform $\boldsymbol{\Sigma}_{[:r,:r]}$ into an identity matrix through iteration, which can be further simplified to iterating $\sigma_{t+1} = g(\sigma_t)$ to change a single singular value to 1.</span>
<span id="cb4-695"><a href="#cb4-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-696"><a href="#cb4-696" aria-hidden="true" tabindex="-1"></a>Inspired by <span class="co">[</span><span class="ot">\@leloykun</span><span class="co">](https://x.com/leloykun/status/1846165001746501899)</span>, we view the selection of $(a,b,c)$ as an optimization problem, with the objective of making the iteration process converge as quickly as possible for any initial singular value. First, we reparameterize $g(x)$ as:</span>
<span id="cb4-697"><a href="#cb4-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-698"><a href="#cb4-698" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-699"><a href="#cb4-699" aria-hidden="true" tabindex="-1"></a>\begin{equation}g(x) = x + \kappa x(x^2 - x_1^2)(x^2 - x_2^2)\end{equation}</span>
<span id="cb4-700"><a href="#cb4-700" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-701"><a href="#cb4-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-702"><a href="#cb4-702" aria-hidden="true" tabindex="-1"></a>where $x_1 \leq x_2$. The advantage of this parameterization is that it explicitly represents the 5 fixed points of the iteration: $0, \pm x_1, \pm x_2$. Since our goal is to converge to 1, we initially choose $x_1 &lt; 1 &lt; x_2$, with the idea that regardless of whether the iteration process moves toward $x_1$ or $x_2$, the result will be near 1.</span>
<span id="cb4-703"><a href="#cb4-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-704"><a href="#cb4-704" aria-hidden="true" tabindex="-1"></a>Next, we determine the number of iterations $T$, so that the iteration process becomes a deterministic function. Once we fix the shape of the matrix (i.e., $n$ and $m$), we can sample a batch of matrices and compute the singular values through SVD. Finally, we treat these singular values as inputs, with the target output being 1, and the loss function being the squared error. The entire model is fully differentiable and can be solved using gradient descent. Note that <span class="co">[</span><span class="ot">\@leloykun</span><span class="co">](https://x.com/leloykun/status/1846165001746501899)</span> assumed $x_1 + x_2 = 2$ and used grid search to solve it.</span>
<span id="cb4-705"><a href="#cb4-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-706"><a href="#cb4-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-707"><a href="#cb4-707" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-708"><a href="#cb4-708" aria-hidden="true" tabindex="-1"></a>\begin{array}{ccc|ccc|ccc|c|c}</span>
<span id="cb4-709"><a href="#cb4-709" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-710"><a href="#cb4-710" aria-hidden="true" tabindex="-1"></a>n &amp; m &amp; T &amp; \kappa &amp; x_1 &amp; x_2 &amp; a &amp; b &amp; c &amp; \text{mse} &amp; \text{mse}_{\text{Muon}}<span class="sc">\\</span></span>
<span id="cb4-711"><a href="#cb4-711" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-712"><a href="#cb4-712" aria-hidden="true" tabindex="-1"></a>1024 &amp; 1024 &amp; 3 &amp; 7.020 &amp; 0.830 &amp; 0.830 &amp; 4.328 &amp; -9.666 &amp; 7.020 &amp; 0.10257 &amp; 0.18278 <span class="sc">\\</span></span>
<span id="cb4-713"><a href="#cb4-713" aria-hidden="true" tabindex="-1"></a>1024 &amp; 1024 &amp; 5 &amp; 1.724 &amp; 0.935 &amp; 1.235 &amp; 3.297 &amp; -4.136 &amp; 1.724 &amp; 0.02733 &amp; 0.04431 <span class="sc">\\</span></span>
<span id="cb4-714"><a href="#cb4-714" aria-hidden="true" tabindex="-1"></a>2048 &amp; 1024 &amp; 3 &amp; 7.028 &amp; 0.815 &amp; 0.815 &amp; 4.095 &amp; -9.327 &amp; 7.028 &amp; 0.01628 &amp; 0.06171 <span class="sc">\\</span></span>
<span id="cb4-715"><a href="#cb4-715" aria-hidden="true" tabindex="-1"></a>2048 &amp; 1024 &amp; 5 &amp; 1.476 &amp; 0.983 &amp; 1.074 &amp; 2.644 &amp; -3.128 &amp; 1.476 &amp; 0.00038 &amp; 0.02954 <span class="sc">\\</span></span>
<span id="cb4-716"><a href="#cb4-716" aria-hidden="true" tabindex="-1"></a>4096 &amp; 1024 &amp; 3 &amp; 6.948 &amp; 0.802 &amp; 0.804 &amp; 3.886 &amp; -8.956 &amp; 6.948 &amp; 0.00371 &amp; 0.02574 <span class="sc">\\</span></span>
<span id="cb4-717"><a href="#cb4-717" aria-hidden="true" tabindex="-1"></a>4096 &amp; 1024 &amp; 5 &amp; 1.214 &amp; 1.047 &amp; 1.048 &amp; 2.461 &amp; -2.663 &amp; 1.214 &amp; 0.00008 &amp; 0.02563 <span class="sc">\\</span></span>
<span id="cb4-718"><a href="#cb4-718" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-719"><a href="#cb4-719" aria-hidden="true" tabindex="-1"></a>2048 &amp; 2048 &amp; 3 &amp; 11.130 &amp; 0.767 &amp; 0.767 &amp; 4.857 &amp; -13.103 &amp; 11.130 &amp; 0.10739 &amp; 0.24410 <span class="sc">\\</span></span>
<span id="cb4-720"><a href="#cb4-720" aria-hidden="true" tabindex="-1"></a>2048 &amp; 2048 &amp; 5 &amp; 1.779 &amp; 0.921 &amp; 1.243 &amp; 3.333 &amp; -4.259 &amp; 1.779 &amp; 0.03516 &amp; 0.04991 <span class="sc">\\</span></span>
<span id="cb4-721"><a href="#cb4-721" aria-hidden="true" tabindex="-1"></a>4096 &amp; 4096 &amp; 3 &amp; 18.017 &amp; 0.705 &amp; 0.705 &amp; 5.460 &amp; -17.929 &amp; 18.017 &amp; 0.11303 &amp; 0.33404 <span class="sc">\\</span></span>
<span id="cb4-722"><a href="#cb4-722" aria-hidden="true" tabindex="-1"></a>4096 &amp; 4096 &amp; 5 &amp; 2.057 &amp; 0.894 &amp; 1.201 &amp; 3.373 &amp; -4.613 &amp; 2.057 &amp; 0.04700 &amp; 0.06372 <span class="sc">\\</span></span>
<span id="cb4-723"><a href="#cb4-723" aria-hidden="true" tabindex="-1"></a>8192 &amp; 8192 &amp; 3 &amp; 30.147 &amp; 0.643 &amp; 0.643 &amp; 6.139 &amp; -24.893 &amp; 30.147 &amp; 0.11944 &amp; 0.44843 <span class="sc">\\</span></span>
<span id="cb4-724"><a href="#cb4-724" aria-hidden="true" tabindex="-1"></a>8192 &amp; 8192 &amp; 5 &amp; 2.310 &amp; 0.871 &amp; 1.168 &amp; 3.389 &amp; -4.902 &amp; 2.310 &amp; 0.05869 &amp; 0.07606 <span class="sc">\\</span></span>
<span id="cb4-725"><a href="#cb4-725" aria-hidden="true" tabindex="-1"></a>\hline</span>
<span id="cb4-726"><a href="#cb4-726" aria-hidden="true" tabindex="-1"></a>\end{array}</span>
<span id="cb4-727"><a href="#cb4-727" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-728"><a href="#cb4-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-729"><a href="#cb4-729" aria-hidden="true" tabindex="-1"></a>Here, $\text{mse}_{\text{Muon}}$ is the result of computation done according to the $(a,b,c)$ provided by the Muon authors. Looking through the table, which choice of $(a, b, c)$ is the best clearly depends on both the matrix size $(m, n)$ and the number of iterations $T$. Looking at the loss function, non-square matrices converge more readily than square matrices. The $(a, b, c)$ given by the authors of Muon are probably the optimal solution for square matrices $m = n$ when the number of iterations is $T = 5$. </span>
<span id="cb4-730"><a href="#cb4-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-731"><a href="#cb4-731" aria-hidden="true" tabindex="-1"></a>For a fixed number of iterations $T$, the result depends on the size of the matrix, which essentially depends on the distribution of singular values. One result worth mentioning about this distribution is that for any fixed "aspect ratio" $r \in (0, \infty)$, if at the $n \to \infty$ limit, $\frac{m}{n} \to r$, then the singular values of the matrix converges to a <span class="co">[</span><span class="ot">Marchenko–Pastur distribution</span><span class="co">](https://en.wikipedia.org/wiki/Marchenko%E2%80%93Pastur_distribution)</span>.</span>
<span id="cb4-732"><a href="#cb4-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-733"><a href="#cb4-733" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span> </span>
<span id="cb4-734"><a href="#cb4-734" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Code for generating the table above<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb4-735"><a href="#cb4-735" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb4-736"><a href="#cb4-736" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb4-737"><a href="#cb4-737" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb4-738"><a href="#cb4-738" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb4-739"><a href="#cb4-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-740"><a href="#cb4-740" aria-hidden="true" tabindex="-1"></a>n, m, T <span class="op">=</span> <span class="dv">1024</span>, <span class="dv">1024</span>, <span class="dv">5</span></span>
<span id="cb4-741"><a href="#cb4-741" aria-hidden="true" tabindex="-1"></a>key, data <span class="op">=</span> jax.random.key(<span class="dv">42</span>), jnp.array([])</span>
<span id="cb4-742"><a href="#cb4-742" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">1000</span>), ncols<span class="op">=</span><span class="dv">0</span>, desc<span class="op">=</span><span class="st">'SVD'</span>):</span>
<span id="cb4-743"><a href="#cb4-743" aria-hidden="true" tabindex="-1"></a>    key, subkey <span class="op">=</span> jax.random.split(key)</span>
<span id="cb4-744"><a href="#cb4-744" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> jax.random.normal(subkey, shape<span class="op">=</span>(n, m))</span>
<span id="cb4-745"><a href="#cb4-745" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> jnp.linalg.svd(M, full_matrices<span class="op">=</span><span class="va">False</span>)[<span class="dv">1</span>]</span>
<span id="cb4-746"><a href="#cb4-746" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> jnp.concatenate([data, S <span class="op">/</span> (S<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()<span class="op">**</span><span class="fl">0.5</span>])</span>
<span id="cb4-747"><a href="#cb4-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-748"><a href="#cb4-748" aria-hidden="true" tabindex="-1"></a><span class="at">@jax.jit</span></span>
<span id="cb4-749"><a href="#cb4-749" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(w, x):</span>
<span id="cb4-750"><a href="#cb4-750" aria-hidden="true" tabindex="-1"></a>    k, x1, x2 <span class="op">=</span> w</span>
<span id="cb4-751"><a href="#cb4-751" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb4-752"><a href="#cb4-752" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> k <span class="op">*</span> x <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> x1<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> (x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> x2<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-753"><a href="#cb4-753" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((x <span class="op">-</span> <span class="dv">1</span>)<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb4-754"><a href="#cb4-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-755"><a href="#cb4-755" aria-hidden="true" tabindex="-1"></a>f_grad <span class="op">=</span> jax.grad(f)</span>
<span id="cb4-756"><a href="#cb4-756" aria-hidden="true" tabindex="-1"></a>w, u <span class="op">=</span> jnp.array([<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">1.1</span>]), jnp.zeros(<span class="dv">3</span>)</span>
<span id="cb4-757"><a href="#cb4-757" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">100000</span>), ncols<span class="op">=</span><span class="dv">0</span>, desc<span class="op">=</span><span class="st">'SGD'</span>):</span>
<span id="cb4-758"><a href="#cb4-758" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> <span class="fl">0.9</span> <span class="op">*</span> u <span class="op">+</span> f_grad(w, data)  <span class="co"># Momentum acceleration</span></span>
<span id="cb4-759"><a href="#cb4-759" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> <span class="fl">0.01</span> <span class="op">*</span> u</span>
<span id="cb4-760"><a href="#cb4-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-761"><a href="#cb4-761" aria-hidden="true" tabindex="-1"></a>k, x1, x2 <span class="op">=</span> w</span>
<span id="cb4-762"><a href="#cb4-762" aria-hidden="true" tabindex="-1"></a>a, b, c <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> k <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>, <span class="op">-</span>k <span class="op">*</span> (x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x2<span class="op">**</span><span class="dv">2</span>), k</span>
<span id="cb4-763"><a href="#cb4-763" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>m<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>T<span class="sc">}</span><span class="ss"> &amp; </span><span class="sc">{</span>k<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>x1<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>x2<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>a<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>b<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>c<span class="sc">:.3f}</span><span class="ss"> &amp; </span><span class="sc">{</span>f(w, data)<span class="sc">:.5f}</span><span class="ss">'</span>)</span>
<span id="cb4-764"><a href="#cb4-764" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-765"><a href="#cb4-765" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span> </span>
<span id="cb4-766"><a href="#cb4-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-767"><a href="#cb4-767" aria-hidden="true" tabindex="-1"></a><span class="fu">## Some thoughts</span></span>
<span id="cb4-768"><a href="#cb4-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-769"><a href="#cb4-769" aria-hidden="true" tabindex="-1"></a>If we choose the default setting of $T=5$, then for an $n\times n$ matrix parameter, each update step of Muon requires at least 15 matrix multiplications between $n\times n$ matrices:</span>
<span id="cb4-770"><a href="#cb4-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-771"><a href="#cb4-771" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-772"><a href="#cb4-772" aria-hidden="true" tabindex="-1"></a>\boldsymbol{X}_t (a + (\boldsymbol{X}_t^\top \boldsymbol{X}_t) (b + c (\boldsymbol{X}_t^\top \boldsymbol{X}_t)) )</span>
<span id="cb4-773"><a href="#cb4-773" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-774"><a href="#cb4-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-775"><a href="#cb4-775" aria-hidden="true" tabindex="-1"></a>which is undoubtedly a significantly larger computational cost than Adam. This might lead some readers to worry whether Muon is practically feasible.</span>
<span id="cb4-776"><a href="#cb4-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-777"><a href="#cb4-777" aria-hidden="true" tabindex="-1"></a>In fact, such concerns are unnecessary. Although Muon's computation is more complex than Adam's, the additional time per step is minimal. My conclusion is that the additional wallclock time is $\leq 5\%$. The Muon's authors claim it can reach as low as $2\%$. This is because Muon's matrix multiplications occur after the current gradient computation and before the next gradient computation, during which almost all computational power would have sat idle anyway. Since these matrix multiplications are of static size and can be parallelized, they don't significantly increase the wallclock time. Moreover, Muon uses one fewer set of cached variables than Adam, resulting in lower memory consumption.</span>
<span id="cb4-778"><a href="#cb4-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-779"><a href="#cb4-779" aria-hidden="true" tabindex="-1"></a>The most thought-provoking aspect of Muon is actually the intrinsic difference between vectors and matrices, and its impact on optimization. Common optimizers like SGD, AdamW, and Lion update parameters in an elementwise manner, treating both vector and matrix parameters essentially the same, as lists of scalars being updated independently according to the same rules. Optimizers with this characteristic are often simpler to analyze theoretically and are convenient for tensor parallelism, since splitting a large matrix into two smaller matrices for independent processing doesn't change the optimization trajectory.</span>
<span id="cb4-780"><a href="#cb4-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-781"><a href="#cb4-781" aria-hidden="true" tabindex="-1"></a>But Muon is different, since it takes matrices as fundamental units, and exploits properties unique to matrices. Some readers might wonder: aren't matrices and vectors just arrangements of numbers? How different can they be? But they are. For example, with matrices, we have the concept of <span class="co">[</span><span class="ot">trace</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Trace_(linear_algebra)), which is the sum of diagonal elements. This concept is a geometrically meaningful concept, since it is invariant under similarity transformation. In particular, it equals the sum of all eigenvalues of the matrix. The moral of this example is that the diagonal elements of a matrix should not be treated in the same way as its off-diagonal elements. Muon achieves better results because it treats them differently.</span>
<span id="cb4-782"><a href="#cb4-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-783"><a href="#cb4-783" aria-hidden="true" tabindex="-1"></a>Of course, Muon is not a free lunch. In tensor-parallel training, Muon requires <span class="co">[</span><span class="ot">allreduce</span><span class="co">](https://en.wikipedia.org/wiki/Collective_operation#All-Reduce)</span>. That is, the gradients need to be aggregated across the devices before the parameter update, rather than having each device update independently, which increases communication costs.</span>
<span id="cb4-784"><a href="#cb4-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-785"><a href="#cb4-785" aria-hidden="true" tabindex="-1"></a>Even without tensor-parallelism, this issue persists in some other form. For instance, Multi-Head Attention is usually implemented by projecting the input with a single matrix $W^Q$ to obtain the query matrix $Q$ (and similarly for $K$ and $V$), and then reshapes it to obtain the query matrices for each head. This creates a disconnect between the implementation and the semantics. Semantically, $Q$ really should be considered multiple matrices, but it is implemented as a single matrix. Therefore, when using Muon for MHA, one must take care to first split $Q$ into multiple small matrices before doing the Muon update.</span>
<span id="cb4-786"><a href="#cb4-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-787"><a href="#cb4-787" aria-hidden="true" tabindex="-1"></a>In summary, Muon's non-elementwise update rule, while capturing the essential differences between vectors and matrices, also introduces some minor issues, which might be aesthetically unsatisfying to some people.</span>
<span id="cb4-788"><a href="#cb4-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-789"><a href="#cb4-789" aria-hidden="true" tabindex="-1"></a>(Addendum: Almost simultaneously with the publication of this blogpost, Muon's author Keller Jordan published <span class="co">[</span><span class="ot">*Muon: An optimizer for hidden layers in neural networks*</span><span class="co">](https://kellerjordan.github.io/posts/muon/)</span>.)</span>
<span id="cb4-790"><a href="#cb4-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-791"><a href="#cb4-791" aria-hidden="true" tabindex="-1"></a><span class="fu">## Norm perspective</span></span>
<span id="cb4-792"><a href="#cb4-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-793"><a href="#cb4-793" aria-hidden="true" tabindex="-1"></a>From a theoretical standpoint, what key characteristics of matrices does Muon capture? Perhaps the following norm perspective can answer our question.</span>
<span id="cb4-794"><a href="#cb4-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-795"><a href="#cb4-795" aria-hidden="true" tabindex="-1"></a>This section's discussion primarily references the papers <span class="co">[</span><span class="ot">*Stochastic Spectral Descent for Discrete Graphical Models*</span><span class="co">](https://ieeexplore.ieee.org/abstract/document/7347351)</span> and <span class="co">[</span><span class="ot">*Old Optimizer, New Norm: An Anthology*</span><span class="co">](https://arxiv.org/abs/2409.20325)</span>, especially the latter. However, the starting point is not new; we've already briefly touched upon it in <span class="co">[</span><span class="ot">*Gradient Flow: Exploring the Path to Minimums*</span><span class="co">](https://kexue.fm/archives/9660)</span>: for vector parameters $\boldsymbol{w}\in\mathbb{R}^n$, we define the update rule for the next step as</span>
<span id="cb4-796"><a href="#cb4-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-797"><a href="#cb4-797" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-798"><a href="#cb4-798" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{w}} \left(\frac{\Vert\boldsymbol{w} - \boldsymbol{w}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{w})\right)\end{equation} </span>
<span id="cb4-799"><a href="#cb4-799" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-800"><a href="#cb4-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-801"><a href="#cb4-801" aria-hidden="true" tabindex="-1"></a>where $\Vert\cdot\Vert$ is some vector norm. This is norm-regularized gradient descent. Then, assuming $\eta_t$ is small enough, the regularization loss dominates, meaning $\boldsymbol{w}_{t+1}$ will be very close to $\boldsymbol{w}_t$, so we assume a first-order approximation of $\mathcal{L}(\boldsymbol{w})$ is sufficient. The problem then simplifies to</span>
<span id="cb4-802"><a href="#cb4-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-803"><a href="#cb4-803" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-804"><a href="#cb4-804" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{w}}\left( \frac{\Vert\boldsymbol{w} - \boldsymbol{w}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{w}_t) + \nabla_{\boldsymbol{w}_t}\mathcal{L}(\boldsymbol{w}_t)^{\top}(\boldsymbol{w}-\boldsymbol{w}_t) \right)\end{equation}</span>
<span id="cb4-805"><a href="#cb4-805" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-806"><a href="#cb4-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-807"><a href="#cb4-807" aria-hidden="true" tabindex="-1"></a>Denoting $\Delta\boldsymbol{w}_{t+1} = \boldsymbol{w}_{t+1}-\boldsymbol{w}_t, \boldsymbol{g}_t = \nabla_{\boldsymbol{w}_t}\mathcal{L}(\boldsymbol{w}_t)$, we can simplify it as</span>
<span id="cb4-808"><a href="#cb4-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-809"><a href="#cb4-809" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-810"><a href="#cb4-810" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb4-811"><a href="#cb4-811" aria-hidden="true" tabindex="-1"></a>\Delta\boldsymbol{w}_{t+1} = \mathop{\text{argmin}}_{\Delta\boldsymbol{w}} \left( \frac{\Vert\Delta\boldsymbol{w}\Vert^2}{2\eta_t} + \boldsymbol{g}_t^{\top}\Delta\boldsymbol{w}\right)</span>
<span id="cb4-812"><a href="#cb4-812" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb4-813"><a href="#cb4-813" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-814"><a href="#cb4-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-815"><a href="#cb4-815" aria-hidden="true" tabindex="-1"></a>The general approach to compute $\Delta\boldsymbol{w}_{t+1}$ is to take derivatives, but <span class="co">[</span><span class="ot">*Old Optimizer, New Norm: An Anthology*</span><span class="co">](https://arxiv.org/abs/2409.20325)</span> provides a unified solution without taking derivatives: decompose $\Delta\boldsymbol{w}$ into the norm $\gamma = \Vert\Delta\boldsymbol{w}\Vert$ and the direction vector $\boldsymbol{\phi} = -\Delta\boldsymbol{w}/\Vert\Delta\boldsymbol{w}\Vert$, so</span>
<span id="cb4-816"><a href="#cb4-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-817"><a href="#cb4-817" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-818"><a href="#cb4-818" aria-hidden="true" tabindex="-1"></a>\begin{equation}\min_{\Delta\boldsymbol{w}} \left(</span>
<span id="cb4-819"><a href="#cb4-819" aria-hidden="true" tabindex="-1"></a>    \frac{\Vert\Delta\boldsymbol{w}\Vert^2}{2\eta_t} +  \boldsymbol{g}_t^{\top}\Delta\boldsymbol{w} \right)</span>
<span id="cb4-820"><a href="#cb4-820" aria-hidden="true" tabindex="-1"></a>    = \min_{\gamma\geq 0, \Vert\boldsymbol{\phi}\Vert=1} \left(\frac{\gamma^2}{2\eta_t} -  \gamma\boldsymbol{g}_t^{\top}\boldsymbol{\phi}  \right)</span>
<span id="cb4-821"><a href="#cb4-821" aria-hidden="true" tabindex="-1"></a>    = \min_{\gamma\geq 0} \left( \frac{\gamma^2}{2\eta_t} -  \gamma\; \underbrace{\max_{\Vert\boldsymbol{\phi}\Vert=1}\boldsymbol{g}_t^{\top}\boldsymbol{\phi}}_{\triangleq \Vert \boldsymbol{g}_t\Vert^{\dagger}} \right)</span>
<span id="cb4-822"><a href="#cb4-822" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb4-823"><a href="#cb4-823" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-824"><a href="#cb4-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-825"><a href="#cb4-825" aria-hidden="true" tabindex="-1"></a>$\gamma$ is just a scalar, similar to the learning rate, and its optimal value is easily found to be $\eta_t\Vert \boldsymbol{g}_t\Vert^{\dagger}$, while the update direction is the $\boldsymbol{\phi}^*$ that maximizes $\boldsymbol{g}_t^{\top}\boldsymbol{\phi}$ under constraint $\Vert\boldsymbol{\phi}\Vert=1$. Now substituting the Euclidean norm, i.e., $\Vert\boldsymbol{\phi}\Vert_2 = \sqrt{\boldsymbol{\phi}^{\top}\boldsymbol{\phi}}$, we have $\Vert \boldsymbol{g}_t\Vert^{\dagger}=\Vert \boldsymbol{g}_t\Vert_2$ and $\boldsymbol{\phi}^* = \boldsymbol{g}_t/\Vert\boldsymbol{g}_t\Vert_2$, which gives $\Delta\boldsymbol{w}_{t+1}=-\eta_t \boldsymbol{g}_t$, which is just SGD. Generally, define the $p$-norm</span>
<span id="cb4-826"><a href="#cb4-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-827"><a href="#cb4-827" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-828"><a href="#cb4-828" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert\boldsymbol{\phi}\Vert_p = \sqrt<span class="co">[</span><span class="ot">\uproot{10}p</span><span class="co">]</span>{\sum_{i=1}^n |\phi_i|^p}\end{equation}</span>
<span id="cb4-829"><a href="#cb4-829" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-830"><a href="#cb4-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-831"><a href="#cb4-831" aria-hidden="true" tabindex="-1"></a>then by the <span class="co">[</span><span class="ot">Hölder's inequality duality</span><span class="co">](https://en.wikipedia.org/wiki/H%C3%B6lder%27s_inequality)</span> gives $\boldsymbol{g}^{\top}\boldsymbol{\phi} \leq \Vert \boldsymbol{g}\Vert_q \Vert \boldsymbol{\phi}\Vert_p$, where $1/p + 1/q = 1$. The equality is reached precisely at</span>
<span id="cb4-832"><a href="#cb4-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-833"><a href="#cb4-833" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-834"><a href="#cb4-834" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\phi}^* = \frac{1}{\Vert\boldsymbol{g}\Vert_q^{q/p}}\Big<span class="co">[</span><span class="ot">\text{sign}(g_1) |g_1|^{q/p},\text{sign}(g_2) |g_2|^{q/p},\cdots,\text{sign}(g_n) |g_n|^{q/p}\Big</span><span class="co">]</span>\end{equation}</span>
<span id="cb4-835"><a href="#cb4-835" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-836"><a href="#cb4-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-837"><a href="#cb4-837" aria-hidden="true" tabindex="-1"></a>at which point, $\max_{\Vert\boldsymbol{\phi}\Vert_p=1}\boldsymbol{g}^{\top}\boldsymbol{\phi} = \Vert \boldsymbol{g}\Vert_q$.</span>
<span id="cb4-838"><a href="#cb4-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-839"><a href="#cb4-839" aria-hidden="true" tabindex="-1"></a>The <span class="co">[</span><span class="ot">pbSGD</span><span class="co">](https://www.ijcai.org/proceedings/2020/451)</span> optimizer uses this as the direction vector. In particular, when $p\to\infty$, we have $q\to 1$ and $|g_i|^{q/p}\to 1$, which degenerates to SignSGD, meaning that we can interpret SignSGD as SGD regularized by $<span class="sc">\|</span>\cdot <span class="sc">\|</span>_\infty$.</span>
<span id="cb4-840"><a href="#cb4-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-841"><a href="#cb4-841" aria-hidden="true" tabindex="-1"></a><span class="fu">## Matrix norms</span></span>
<span id="cb4-842"><a href="#cb4-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-843"><a href="#cb4-843" aria-hidden="true" tabindex="-1"></a>Now let's switch our focus to matrix parameters $\boldsymbol{W}\in\mathbb{R}^{n\times m}$. Similarly, we define its update rule as</span>
<span id="cb4-844"><a href="#cb4-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-845"><a href="#cb4-845" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-846"><a href="#cb4-846" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{W}_{t+1} = \mathop{\text{argmin}}_{\boldsymbol{W}} \left( \frac{\Vert\boldsymbol{W} - \boldsymbol{W}_t\Vert^2}{2\eta_t} + \mathcal{L}(\boldsymbol{W}) \right) \end{equation}</span>
<span id="cb4-847"><a href="#cb4-847" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-848"><a href="#cb4-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-849"><a href="#cb4-849" aria-hidden="true" tabindex="-1"></a>where $\Vert\cdot\Vert$ is some matrix norm. Again using a first-order approximation, we get</span>
<span id="cb4-850"><a href="#cb4-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-851"><a href="#cb4-851" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-852"><a href="#cb4-852" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta\boldsymbol{W}_{t+1} = \mathop{\text{argmin}}_{\Delta\boldsymbol{W}} \left( \frac{\Vert\Delta\boldsymbol{W}\Vert^2}{2\eta_t} + \text{Tr}(\boldsymbol{G}_t^{\top}\Delta\boldsymbol{W}) \right) </span>
<span id="cb4-853"><a href="#cb4-853" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb4-854"><a href="#cb4-854" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-855"><a href="#cb4-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-856"><a href="#cb4-856" aria-hidden="true" tabindex="-1"></a>Here $\Delta\boldsymbol{W}_{t+1} = \boldsymbol{W}_{t+1}-\boldsymbol{W}_t, \boldsymbol{G}_t = \nabla_{\boldsymbol{W}_t}\mathcal{L}(\boldsymbol{W}_t)$. Still using the "norm-direction" decoupling, i.e., setting $\gamma = \Vert\Delta\boldsymbol{w}\Vert$ and $\boldsymbol{\Phi} = -\Delta\boldsymbol{W}/\Vert\Delta\boldsymbol{W}\Vert$, we get</span>
<span id="cb4-857"><a href="#cb4-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-858"><a href="#cb4-858" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-859"><a href="#cb4-859" aria-hidden="true" tabindex="-1"></a>\begin{equation}\min_{\Delta\boldsymbol{W}} \left( \frac{\Vert\Delta\boldsymbol{W}\Vert^2}{2\eta_t} + \text{Tr}(\boldsymbol{G}_t^{\top}\Delta\boldsymbol{W}) \right) = \min_{\gamma\geq 0} \left( \frac{\gamma^2}{2\eta_t} -  \gamma \, \max_{\Vert\boldsymbol{\Phi}\Vert=1}\text{Tr}(\boldsymbol{G}_t^{\top}\boldsymbol{\Phi}) \right)</span>
<span id="cb4-860"><a href="#cb4-860" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb4-861"><a href="#cb4-861" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-862"><a href="#cb4-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-863"><a href="#cb4-863" aria-hidden="true" tabindex="-1"></a>Then it's a case-by-case analysis for specific norms. There are two commonly used matrix norms. One is the <span class="co">[</span><span class="ot">Frobenius norm</span><span class="co">](https://en.wikipedia.org/wiki/Hilbert%E2%80%93Schmidt_operator)</span>, which is actually the Euclidean norm after flattening the matrix into a vector. In this case, the conclusion is the same as for vectors -- the answer is SGD, which we won't expand on here. The other is the 2-norm induced by the vector norm, also known as the <span class="co">[</span><span class="ot">spectral norm</span><span class="co">](https://en.wikipedia.org/wiki/Spectral_norm)</span>:</span>
<span id="cb4-864"><a href="#cb4-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-865"><a href="#cb4-865" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-866"><a href="#cb4-866" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert \boldsymbol{\Phi}\Vert_2 = \max_{\Vert \boldsymbol{x}\Vert_2 = 1} \Vert \boldsymbol{\Phi}\boldsymbol{x}\Vert_2\end{equation}</span>
<span id="cb4-867"><a href="#cb4-867" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-868"><a href="#cb4-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-869"><a href="#cb4-869" aria-hidden="true" tabindex="-1"></a>Note that the $\Vert\cdot\Vert_2$ on the right side applies to vectors, so the definition is clear. For more discussions on the 2-norm, refer to <span class="co">[</span><span class="ot">*Lipschitz Constraints in Deep Learning: Generalization and Generative Models*</span><span class="co">](https://kexue.fm/archives/6051)</span> and <span class="co">[</span><span class="ot">*The Path to Low-Rank Approximation (Part 2): SVD*</span><span class="co">](https://kexue.fm/archives/10407#矩阵范数)</span>. Since the 2-norm is induced by "matrix-vector" multiplication, it better aligns with matrix multiplication, and it always holds that $\Vert\boldsymbol{\Phi}\Vert_2\leq \Vert\boldsymbol{\Phi}\Vert_F$, meaning the 2-norm is more compact compared to the Frobenius norm.</span>
<span id="cb4-870"><a href="#cb4-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-871"><a href="#cb4-871" aria-hidden="true" tabindex="-1"></a>Next, the 2-norm. Let the SVD of $\boldsymbol{G}$ be $\boldsymbol{U}\boldsymbol{\Sigma}\boldsymbol{V}^{\top} = \sum\limits_{i=1}^r \sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top}$, then</span>
<span id="cb4-872"><a href="#cb4-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-873"><a href="#cb4-873" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-874"><a href="#cb4-874" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\boldsymbol{\Phi})=\text{Tr}\Big(\sum_{i=1}^r \sigma_i \boldsymbol{v}_i \boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\Big) = \sum_{i=1}^r \sigma_i \boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i\end{equation}</span>
<span id="cb4-875"><a href="#cb4-875" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-876"><a href="#cb4-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-877"><a href="#cb4-877" aria-hidden="true" tabindex="-1"></a>By definition, when $\Vert\boldsymbol{\Phi}\Vert_2=1$, we have $\Vert\boldsymbol{\Phi}\boldsymbol{v}_i\Vert_2\leq \Vert\boldsymbol{v}_i\Vert_2=1$, so $\boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i\leq 1$. Therefore,</span>
<span id="cb4-878"><a href="#cb4-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-879"><a href="#cb4-879" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-880"><a href="#cb4-880" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\boldsymbol{\Phi})\leq \sum_{i=1}^r \sigma_i\end{equation}</span>
<span id="cb4-881"><a href="#cb4-881" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-882"><a href="#cb4-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-883"><a href="#cb4-883" aria-hidden="true" tabindex="-1"></a>The equality holds when all $\boldsymbol{u}_i^{\top}\boldsymbol{\Phi}\boldsymbol{v}_i$ equal 1, in which case</span>
<span id="cb4-884"><a href="#cb4-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-885"><a href="#cb4-885" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-886"><a href="#cb4-886" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{\Phi} = \sum_{i=1}^r \boldsymbol{u}_i \boldsymbol{v}_i^{\top} = \boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{<span class="co">[</span><span class="ot">:,:r</span><span class="co">]</span>}^{\top} = \text{msign}(\boldsymbol{G})\end{equation}</span>
<span id="cb4-887"><a href="#cb4-887" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-888"><a href="#cb4-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-889"><a href="#cb4-889" aria-hidden="true" tabindex="-1"></a>With this, we've proven that gradient descent under the 2-norm penalty is precisely the $\beta=0$ case of Muon!</span>
<span id="cb4-890"><a href="#cb4-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-891"><a href="#cb4-891" aria-hidden="true" tabindex="-1"></a>When $\beta &gt; 0$, the moving average takes effect, which can be viewed as a more accurate estimate of the gradient, so we take $\text{msign}$ of the momentum instead. Overall, Muon is equivalent to gradient descent under the 2-norm constraint. The 2-norm better measures the essential differences between matrices, making each step more precise and geometrically meaningful.</span>
<span id="cb4-892"><a href="#cb4-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-893"><a href="#cb4-893" aria-hidden="true" tabindex="-1"></a><span class="fu">## Going further back</span></span>
<span id="cb4-894"><a href="#cb4-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-895"><a href="#cb4-895" aria-hidden="true" tabindex="-1"></a>A more ancient previous work is <span class="co">[</span><span class="ot">*Shampoo: Preconditioned Stochastic Tensor Optimization*</span><span class="co">](https://arxiv.org/abs/1802.09568)</span> (2018), which proposed the Shampoo optimizer, which shares a similar design philosophy with Muon.</span>
<span id="cb4-896"><a href="#cb4-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-897"><a href="#cb4-897" aria-hidden="true" tabindex="-1"></a>The strategy of adapting learning rates through the average of squared gradients, first proposed in Adam, originated from the Adagrad paper <span class="co">[</span><span class="ot">*Adaptive Subgradient Methods for Online Learning and Stochastic Optimization*</span><span class="co">](https://jmlr.org/papers/v12/duchi11a.html)</span> (2011), which suggested directly accumulating squared gradients -- equivalent to a global equal-weight average. Later, RMSProp and Adam, inspired by momentum design, switched to moving averages, which were found to perform better in practice.</span>
<span id="cb4-898"><a href="#cb4-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-899"><a href="#cb4-899" aria-hidden="true" tabindex="-1"></a>Moreover, Adagrad initially proposed accumulating the outer product $\boldsymbol{g}\boldsymbol{g}^{\top}$, but due to the high space cost of caching outer products, it was changed to the Hadamard product $\boldsymbol{g}\odot\boldsymbol{g}$ in practice. What's the theoretical basis for accumulating outer products? We derived this in <span class="co">[</span><span class="ot">*Adaptive learning rate optimizers from a Hessian approximation point of view*</span><span class="co">](#sec-learning-rate-hessian-approximation)</span>. The conclusion is that the long-term average of gradient outer products $\mathbb{E}<span class="co">[</span><span class="ot">\boldsymbol{g}\boldsymbol{g}^{\top}</span><span class="co">]</span> \approx \sigma^2\boldsymbol{\mathcal{H}}_{\boldsymbol{\theta}^*}^2$. In other words, this is a <span class="co">[</span><span class="ot">quasi-Newton method</span><span class="co">](https://en.wikipedia.org/wiki/Quasi-Newton_method)</span>.</span>
<span id="cb4-900"><a href="#cb4-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-901"><a href="#cb4-901" aria-hidden="true" tabindex="-1"></a>Shampoo inherited Adagrad's idea of caching outer products, but considering the cost, it took a compromise. Like Muon, it also optimizes matrices (and higher-order tensors), but its strategy is to cache matrix products $\boldsymbol{G}\boldsymbol{G}^{\top}$ and $\boldsymbol{G}^{\top}\boldsymbol{G}$, not outer products. This way, the space cost is $\mathcal{O}(n^2 + m^2)$ rather than $\mathcal{O}(n^2 m^2)$:</span>
<span id="cb4-902"><a href="#cb4-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-903"><a href="#cb4-903" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-904"><a href="#cb4-904" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-905"><a href="#cb4-905" aria-hidden="true" tabindex="-1"></a>\boldsymbol{L}_t =&amp;\, \beta\boldsymbol{L}_{t-1} + \boldsymbol{G}_t\boldsymbol{G}_t^{\top} <span class="sc">\\</span></span>
<span id="cb4-906"><a href="#cb4-906" aria-hidden="true" tabindex="-1"></a>\boldsymbol{R}_t =&amp;\, \beta\boldsymbol{R}_{t-1} + \boldsymbol{G}_t^{\top}\boldsymbol{G}_t <span class="sc">\\</span></span>
<span id="cb4-907"><a href="#cb4-907" aria-hidden="true" tabindex="-1"></a>\boldsymbol{W}_t =&amp;\, \boldsymbol{W}_{t-1} - \eta_t \boldsymbol{L}_t^{-1/4}\boldsymbol{G}_t\boldsymbol{R}_t^{-1/4} <span class="sc">\\</span></span>
<span id="cb4-908"><a href="#cb4-908" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-909"><a href="#cb4-909" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-910"><a href="#cb4-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-911"><a href="#cb4-911" aria-hidden="true" tabindex="-1"></a>The $\beta$ here was added by me; Shampoo defaults to $\beta=1$. The ${}^{-1/4}$ is also a matrix power operation, which can be completed using SVD. Since Shampoo didn't propose approximation schemes like Newton--Schulz iteration but directly calculated using SVD, to save computational cost, it doesn't compute $\boldsymbol{L}_t^{-1/4}$ and $\boldsymbol{R}_t^{-1/4}$ at every step, but updates their results only after a certain number of steps.</span>
<span id="cb4-912"><a href="#cb4-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-913"><a href="#cb4-913" aria-hidden="true" tabindex="-1"></a>Specifically, when $\beta=0$, Shampoo's update vector is $(\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/4}\boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/4}$. By performing SVD on $\boldsymbol{G}$, we can prove</span>
<span id="cb4-914"><a href="#cb4-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-915"><a href="#cb4-915" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-916"><a href="#cb4-916" aria-hidden="true" tabindex="-1"></a>\begin{equation}(\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/4}\boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/4} = (\boldsymbol{G}\boldsymbol{G}^{\top})^{-1/2}\boldsymbol{G}= \boldsymbol{G}(\boldsymbol{G}^{\top}\boldsymbol{G})^{-1/2}=\text{msign}(\boldsymbol{G})\end{equation}</span>
<span id="cb4-917"><a href="#cb4-917" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-918"><a href="#cb4-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-919"><a href="#cb4-919" aria-hidden="true" tabindex="-1"></a>This indicates that when $\beta=0$, Shampoo and Muon are theoretically equivalent! Therefore, Shampoo and Muon have common design principles.</span>
<span id="cb4-920"><a href="#cb4-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-921"><a href="#cb4-921" aria-hidden="true" tabindex="-1"></a><span class="fu"># Thoughts on spectral norm gradients and new forms of weight decay</span></span>
<span id="cb4-922"><a href="#cb4-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-923"><a href="#cb4-923" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">从谱范数梯度到新式权重衰减的思考 - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10648)</span> (2024-12-25)</span>
<span id="cb4-924"><a href="#cb4-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-925"><a href="#cb4-925" aria-hidden="true" tabindex="-1"></a>In <span class="co">[</span><span class="ot">*Muon Appreciation*</span><span class="co">](#sec-muon-appreciation)</span>, we introduced a new optimizer called "Muon", which can be viewed as gradient descent under spectral norm regularization, which seems a more geometrically meaningful approach for optimizing matrix parameters. As is well known, we often add weight decay for matrix parameters, which can be understood as $\nabla_M <span class="sc">\|</span>M<span class="sc">\|</span>_F^2$, the gradient of the squared Frobenius norm. From Muon's perspective, would constructing a new weight decay through the gradient of the squared spectral norm produce better results?</span>
<span id="cb4-926"><a href="#cb4-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-927"><a href="#cb4-927" aria-hidden="true" tabindex="-1"></a>So the question arises: what does the gradient or derivative of the spectral norm look like? And what would a new weight decay designed with it look like? We'll explore these questions below.</span>
<span id="cb4-928"><a href="#cb4-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-929"><a href="#cb4-929" aria-hidden="true" tabindex="-1"></a><span class="fu">## Basic review</span></span>
<span id="cb4-930"><a href="#cb4-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-931"><a href="#cb4-931" aria-hidden="true" tabindex="-1"></a>The spectral norm $<span class="sc">\|</span>\cdot<span class="sc">\|</span>_2$ (also known as the 2-norm) is one of the most commonly used matrix norms. Compared to the simpler Frobenius norm $<span class="sc">\|</span>\cdot<span class="sc">\|</span>_F$, it often reveals more essential signals related to matrix multiplication, because its definition is directly related to matrix multiplication: for a matrix parameter $\boldsymbol{W}\in\mathbb{R}^{n\times m}$, its spectral norm is defined as</span>
<span id="cb4-932"><a href="#cb4-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-933"><a href="#cb4-933" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-934"><a href="#cb4-934" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert\boldsymbol{W}\Vert_2 \triangleq \max_{\Vert\boldsymbol{x}\Vert=1} \Vert\boldsymbol{W}\boldsymbol{x}\Vert\end{equation}</span>
<span id="cb4-935"><a href="#cb4-935" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-936"><a href="#cb4-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-937"><a href="#cb4-937" aria-hidden="true" tabindex="-1"></a>Here, $\boldsymbol{x}\in\mathbb{R}^m$ is a column vector, and the $\Vert\cdot\Vert$ on the right side is the Euclidean norm of vectors. From another perspective, the spectral norm is the smallest constant $C$ such that the following inequality holds for $\forall \boldsymbol{x}\in\mathbb{R}^m$:</span>
<span id="cb4-938"><a href="#cb4-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-939"><a href="#cb4-939" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-940"><a href="#cb4-940" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert\boldsymbol{W}\boldsymbol{x}\Vert \leq C\Vert\boldsymbol{x}\Vert\end{equation}</span>
<span id="cb4-941"><a href="#cb4-941" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-942"><a href="#cb4-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-943"><a href="#cb4-943" aria-hidden="true" tabindex="-1"></a>It's not hard to prove that when $C$ takes the Frobenius norm $\Vert W\Vert_F$, the above inequality still holds, so we can write $\Vert \boldsymbol{W}\Vert_2\leq \Vert \boldsymbol{W}\Vert_F$ (since $\Vert \boldsymbol{W}\Vert_F$ is just one of the $C$ values that makes the inequality hold, while $\Vert \boldsymbol{W}\Vert_2$ is the smallest such $C$). This conclusion also suggests that if we want to control the magnitude of the output, using the spectral norm as a regularization term is more precise than using the Frobenius norm.</span>
<span id="cb4-944"><a href="#cb4-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-945"><a href="#cb4-945" aria-hidden="true" tabindex="-1"></a>Six years ago, in <span class="co">[</span><span class="ot">*Lipschitz Constraints in Deep Learning: Generalization and Generative Models*</span><span class="co">](https://kexue.fm/archives/6051)</span>, I discussed the spectral norm in two application scenarios:</span>
<span id="cb4-946"><a href="#cb4-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-947"><a href="#cb4-947" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Wasserstein GAN explicitly proposed a Lipschitz constraint on the discriminator, and one implementation approach was based on spectral norm normalization.</span>
<span id="cb4-948"><a href="#cb4-948" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Some empirical work showed that the spectral norm as a regularization term performs better compared to Frobenius norm regularization.</span>
<span id="cb4-949"><a href="#cb4-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-950"><a href="#cb4-950" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient derivation</span></span>
<span id="cb4-951"><a href="#cb4-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-952"><a href="#cb4-952" aria-hidden="true" tabindex="-1"></a>Now let's get to the main point and try to derive the gradient of the spectral norm $\nabla_{\boldsymbol{W}} \Vert\boldsymbol{W}\Vert_2$. Since the spectral norm is equal to the largest singular value, if $\boldsymbol{W}$ can be decomposed by SVD as $\sum\limits_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}$, then</span>
<span id="cb4-953"><a href="#cb4-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-954"><a href="#cb4-954" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-955"><a href="#cb4-955" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert\boldsymbol{W}\Vert_2 = \sigma_1 = \boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1\end{equation}</span>
<span id="cb4-956"><a href="#cb4-956" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-957"><a href="#cb4-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-958"><a href="#cb4-958" aria-hidden="true" tabindex="-1"></a>where $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_{\min(n,m)} \geq 0$ are the singular values of $\boldsymbol{W}$. Taking the differential of both sides, we get</span>
<span id="cb4-959"><a href="#cb4-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-960"><a href="#cb4-960" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-961"><a href="#cb4-961" aria-hidden="true" tabindex="-1"></a>\begin{equation}d\Vert\boldsymbol{W}\Vert_2 = d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1 + \boldsymbol{u}_1^{\top}d\boldsymbol{W}\boldsymbol{v}_1 + \boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1\end{equation}</span>
<span id="cb4-962"><a href="#cb4-962" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-963"><a href="#cb4-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-964"><a href="#cb4-964" aria-hidden="true" tabindex="-1"></a>Note that</span>
<span id="cb4-965"><a href="#cb4-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-966"><a href="#cb4-966" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-967"><a href="#cb4-967" aria-hidden="true" tabindex="-1"></a>\begin{equation}d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1 = d\boldsymbol{u}_1^{\top}\sum_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}\boldsymbol{v}_1 = d\boldsymbol{u}_1^{\top}\sigma_1 \boldsymbol{u}_1 = \frac{1}{2}\sigma_1 d(\Vert\boldsymbol{u}_1\Vert^2)=0\end{equation}</span>
<span id="cb4-968"><a href="#cb4-968" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-969"><a href="#cb4-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-970"><a href="#cb4-970" aria-hidden="true" tabindex="-1"></a>Similarly, $\boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1=0$, so</span>
<span id="cb4-971"><a href="#cb4-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-972"><a href="#cb4-972" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-973"><a href="#cb4-973" aria-hidden="true" tabindex="-1"></a>\begin{equation}d\Vert\boldsymbol{W}\Vert_2 = \boldsymbol{u}_1^{\top}d\boldsymbol{W}\boldsymbol{v}_1 = \text{Tr}((\boldsymbol{u}_1 \boldsymbol{v}_1^{\top})^{\top} d\boldsymbol{W}) \quad\Rightarrow\quad \nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2 = \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\end{equation}</span>
<span id="cb4-974"><a href="#cb4-974" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-975"><a href="#cb4-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-976"><a href="#cb4-976" aria-hidden="true" tabindex="-1"></a>Note that this proof process has a key condition: $\sigma_1 &gt; \sigma_2$. If $\sigma_1=\sigma_2$, then $\Vert\boldsymbol{W}\Vert_2$ can be expressed as both $\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1$ and $\boldsymbol{u}_2^{\top}\boldsymbol{W}\boldsymbol{v}_2$, and the gradients calculated using the same method would be $\boldsymbol{u}_1 \boldsymbol{v}_1^{\top}$ and $\boldsymbol{u}_2 \boldsymbol{v}_2^{\top}$ respectively. The non-uniqueness of the result means that the gradient does not exist. Of course, from a practical perspective, the probability of two numbers being exactly equal is very small, so this point can be ignored.</span>
<span id="cb4-977"><a href="#cb4-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-978"><a href="#cb4-978" aria-hidden="true" tabindex="-1"></a>(This proof was based on an <span class="co">[</span><span class="ot">answer</span><span class="co">](https://math.stackexchange.com/a/3000223)</span> on Stack Exchange, but that answer did not prove that $d\boldsymbol{u}_1^{\top}\boldsymbol{W}\boldsymbol{v}_1=0$ and $\boldsymbol{u}_1^{\top}\boldsymbol{W}d\boldsymbol{v}_1=0$. These were proved by me.)</span>
<span id="cb4-979"><a href="#cb4-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-980"><a href="#cb4-980" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weight decay</span></span>
<span id="cb4-981"><a href="#cb4-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-982"><a href="#cb4-982" aria-hidden="true" tabindex="-1"></a>Based on this result and the chain rule, we have</span>
<span id="cb4-983"><a href="#cb4-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-984"><a href="#cb4-984" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-985"><a href="#cb4-985" aria-hidden="true" tabindex="-1"></a>\begin{equation}\nabla_{\boldsymbol{W}}\left(\frac{1}{2}\Vert\boldsymbol{W}\Vert_2^2\right) = \Vert\boldsymbol{W}\Vert_2\nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2 = \sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}\end{equation}</span>
<span id="cb4-986"><a href="#cb4-986" aria-hidden="true" tabindex="-1"></a>$$ {#eq-grad-2-2}</span>
<span id="cb4-987"><a href="#cb4-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-988"><a href="#cb4-988" aria-hidden="true" tabindex="-1"></a>Comparing with the result under the Frobenius norm:</span>
<span id="cb4-989"><a href="#cb4-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-990"><a href="#cb4-990" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-991"><a href="#cb4-991" aria-hidden="true" tabindex="-1"></a>\begin{equation}\nabla_{\boldsymbol{W}}\left(\frac{1}{2}\Vert\boldsymbol{W}\Vert_F^2\right) = \boldsymbol{W} = \sum_{i=1}^{\min(n,m)}\sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top}\end{equation}</span>
<span id="cb4-992"><a href="#cb4-992" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-993"><a href="#cb4-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-994"><a href="#cb4-994" aria-hidden="true" tabindex="-1"></a>Looking at it this way, it becomes very clear: weight decay derived from the squared Frobenius norm as a regularization term penalizes all singular values simultaneously; while weight decay corresponding to the squared spectral norm only penalizes the largest singular value. If our goal is to compress the size of the output, then compressing the maximum singular value is the "just right" approach. Compressing all singular values may achieve a similar purpose, but it might also compress the expressive power of the parameters.</span>
<span id="cb4-995"><a href="#cb4-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-996"><a href="#cb4-996" aria-hidden="true" tabindex="-1"></a>By the <span class="co">[</span><span class="ot">Eckart--Young--Mirsky theorem</span><span class="co">](https://en.wikipedia.org/wiki/Low-rank_approximation)</span>, the RHS of @eq-grad-2-2 is the optimal rank-1 approximation of $\boldsymbol{W}$. In other words, spectral norm weight decay changes the operation from subtracting itself at each step to subtracting its optimal rank-1 approximation at each step, weakening the penalty strength, and to some extent allows the penalty to hit closer to the heart of the issue.</span>
<span id="cb4-997"><a href="#cb4-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-998"><a href="#cb4-998" aria-hidden="true" tabindex="-1"></a><span class="fu">## Numerical computation</span></span>
<span id="cb4-999"><a href="#cb4-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1000"><a href="#cb4-1000" aria-hidden="true" tabindex="-1"></a>For practical purposes, the key question arises: how to compute $\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}$? SVD is certainly the simplest and most direct solution, but its computational complexity is undoubtedly the highest. We must find a more efficient computation path.</span>
<span id="cb4-1001"><a href="#cb4-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1002"><a href="#cb4-1002" aria-hidden="true" tabindex="-1"></a>Without loss of generality, let $n\geq m$. First, note that</span>
<span id="cb4-1003"><a href="#cb4-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1004"><a href="#cb4-1004" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1005"><a href="#cb4-1005" aria-hidden="true" tabindex="-1"></a>\begin{equation}\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top} = \sum_{i=1}^m\sigma_i \boldsymbol{u}_i \boldsymbol{v}_i^{\top} \boldsymbol{v}_1 \boldsymbol{v}_1^{\top} = \boldsymbol{W}\boldsymbol{v}_1 \boldsymbol{v}_1^{\top}\end{equation}</span>
<span id="cb4-1006"><a href="#cb4-1006" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1007"><a href="#cb4-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1008"><a href="#cb4-1008" aria-hidden="true" tabindex="-1"></a>This shows that to compute $\sigma_1 \boldsymbol{u}_1 \boldsymbol{v}_1^{\top}$, we only need to know $\boldsymbol{v}_1$, and $\boldsymbol{v}_1$ is actually the eigenvector corresponding to the largest eigenvalue of the matrix $\boldsymbol{W}^{\top}\boldsymbol{W}$. In this way, we have transformed the problem from SVD of a general matrix $\boldsymbol{W}$ to eigenvalue decomposition of a real symmetric matrix $\boldsymbol{W}^{\top}\boldsymbol{W}$, which has already reduced the complexity, because eigenvalue decomposition is usually significantly faster than SVD.</span>
<span id="cb4-1009"><a href="#cb4-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1010"><a href="#cb4-1010" aria-hidden="true" tabindex="-1"></a>If you still think it's slow, then apply the standard trick used in many eigenvalue decomposition algorithms, <span class="co">[</span><span class="ot">power iteration</span><span class="co">](https://en.wikipedia.org/wiki/Power_iteration)</span>:</span>
<span id="cb4-1011"><a href="#cb4-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1012"><a href="#cb4-1012" aria-hidden="true" tabindex="-1"></a>When $\sigma_1 &gt; \sigma_2$, the iteration</span>
<span id="cb4-1013"><a href="#cb4-1013" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1014"><a href="#cb4-1014" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{x}_{t+1} = \frac{\boldsymbol{W}^{\top}\boldsymbol{W}\boldsymbol{x}_t}{\Vert\boldsymbol{W}^{\top}\boldsymbol{W}\boldsymbol{x}_t\Vert}\end{equation}</span>
<span id="cb4-1015"><a href="#cb4-1015" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1016"><a href="#cb4-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1017"><a href="#cb4-1017" aria-hidden="true" tabindex="-1"></a>converges to $\boldsymbol{v}_1$ at a rate of $(\sigma_2/\sigma_1)^{2t}$.</span>
<span id="cb4-1018"><a href="#cb4-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1019"><a href="#cb4-1019" aria-hidden="true" tabindex="-1"></a>Each step of power iteration only requires computing two "matrix-vector" multiplications, with a complexity of $\mathcal{O}(nm)$. The total complexity of $t$ iterations is $\mathcal{O}(tnm)$, which is very ideal. The disadvantage is that convergence can be slow when $\sigma_1$ and $\sigma_2$ are close. But power iteration often performs better in practice than in theory. Many early works even achieved good results with just one iteration, because when $\sigma_1$ and $\sigma_2$ are close, it indicates that both values and their eigenvectors are somewhat interchangeable to some degree. Even if power iteration doesn't fully converge, it still gives an average of their eigenvectors, which is often sufficient.</span>
<span id="cb4-1020"><a href="#cb4-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1021"><a href="#cb4-1021" aria-hidden="true" tabindex="-1"></a><span class="fu">## Proof of iteration</span></span>
<span id="cb4-1022"><a href="#cb4-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1023"><a href="#cb4-1023" aria-hidden="true" tabindex="-1"></a>In this section, we'll complete the proof of power iteration. It's not hard to see that power iteration can be equivalently written as</span>
<span id="cb4-1024"><a href="#cb4-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1025"><a href="#cb4-1025" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1026"><a href="#cb4-1026" aria-hidden="true" tabindex="-1"></a>\begin{equation}\lim_{t\to\infty} \frac{(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0}{\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert} = \boldsymbol{v}_1\end{equation}</span>
<span id="cb4-1027"><a href="#cb4-1027" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1028"><a href="#cb4-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1029"><a href="#cb4-1029" aria-hidden="true" tabindex="-1"></a>To prove this limit, we start from $\boldsymbol{W}=\sum\limits_{i=1}^m\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^{\top}$, substitute and calculate to get</span>
<span id="cb4-1030"><a href="#cb4-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1031"><a href="#cb4-1031" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1032"><a href="#cb4-1032" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{W}^{\top}\boldsymbol{W} = \sum_{i=1}^m\sigma_i^2 \boldsymbol{v}_i\boldsymbol{v}_i^{\top},\qquad(\boldsymbol{W}^{\top}\boldsymbol{W})^t = \sum_{i=1}^m\sigma_i^{2t} \boldsymbol{v}_i\boldsymbol{v}_i^{\top}\end{equation}</span>
<span id="cb4-1033"><a href="#cb4-1033" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1034"><a href="#cb4-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1035"><a href="#cb4-1035" aria-hidden="true" tabindex="-1"></a>Since $\boldsymbol{v}_1,\boldsymbol{v}_2,\cdots,\boldsymbol{v}_m$ form an orthonormal basis of $\mathbb{R}^m$, $\boldsymbol{x}_0$ can be written as $\sum\limits_{j=1}^m c_j \boldsymbol{v}_j$, so we have</span>
<span id="cb4-1036"><a href="#cb4-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1037"><a href="#cb4-1037" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1038"><a href="#cb4-1038" aria-hidden="true" tabindex="-1"></a>\begin{equation}(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0 = \sum_{i=1}^m\sigma_i^{2t} \boldsymbol{v}_i\boldsymbol{v}_i^{\top}\sum_{j=1}^m c_j \boldsymbol{v}_j = \sum_{i=1}^m\sum_{j=1}^m c_j\sigma_i^{2t} \boldsymbol{v}_i\underbrace{\boldsymbol{v}_i^{\top}  \boldsymbol{v}_j}_{=\delta_{i,j}} = \sum_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i\end{equation}</span>
<span id="cb4-1039"><a href="#cb4-1039" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1040"><a href="#cb4-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1041"><a href="#cb4-1041" aria-hidden="true" tabindex="-1"></a>and</span>
<span id="cb4-1042"><a href="#cb4-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1043"><a href="#cb4-1043" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1044"><a href="#cb4-1044" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert = \left\Vert \sum_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i\right\Vert = \sqrt{\sum_{i=1}^m c_i^2\sigma_i^{4t}}\end{equation}</span>
<span id="cb4-1045"><a href="#cb4-1045" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1046"><a href="#cb4-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1047"><a href="#cb4-1047" aria-hidden="true" tabindex="-1"></a>Due to random initialization, the probability of $c_1=0$ is very small, so we can assume $c_1\neq 0$. Then</span>
<span id="cb4-1048"><a href="#cb4-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1049"><a href="#cb4-1049" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1050"><a href="#cb4-1050" aria-hidden="true" tabindex="-1"></a>\begin{equation}\frac{(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0}{\Vert(\boldsymbol{W}^{\top}\boldsymbol{W})^t \boldsymbol{x}_0\Vert} = \frac{\sum\limits_{i=1}^m c_i\sigma_i^{2t} \boldsymbol{v}_i}{\sqrt{\sum\limits_{i=1}^m c_i^2\sigma_i^{4t}}} = \frac{\boldsymbol{v}_1 + \sum\limits_{i=2}^m (c_i/c_1)(\sigma_i/\sigma_1)^{2t} \boldsymbol{v}_i}{\sqrt{1 + \sum\limits_{i=2}^m (c_i/c_1)^2(\sigma_i/\sigma_1)^{4t}}}\end{equation}</span>
<span id="cb4-1051"><a href="#cb4-1051" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1052"><a href="#cb4-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1053"><a href="#cb4-1053" aria-hidden="true" tabindex="-1"></a>When $\sigma_1 &gt; \sigma_2$, all $\sigma_i/\sigma_1(i\geq 2)$ are less than 1, so as $t\to \infty$, the corresponding terms all become 0, and the final limit is $\boldsymbol{v}_1$.</span>
<span id="cb4-1054"><a href="#cb4-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1055"><a href="#cb4-1055" aria-hidden="true" tabindex="-1"></a><span class="fu">## Related Work</span></span>
<span id="cb4-1056"><a href="#cb4-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1057"><a href="#cb4-1057" aria-hidden="true" tabindex="-1"></a>The earliest paper proposing spectral norm regularization should be the 2017 paper <span class="co">[</span><span class="ot">Spectral Norm Regularization for Improving the Generalizability of Deep Learning</span><span class="co">](https://arxiv.org/abs/1705.10941)</span>, which compared methods such as weight decay, adversarial training, and spectral norm regularization, finding that spectral norm regularization performed best in terms of generalization performance.</span>
<span id="cb4-1058"><a href="#cb4-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1059"><a href="#cb4-1059" aria-hidden="true" tabindex="-1"></a>The approach in the paper at that time was not like this article's approach of calculating $\nabla_{\boldsymbol{W}}\Vert\boldsymbol{W}\Vert_2^2 = 2\sigma_1\boldsymbol{u}_1 \boldsymbol{v}_1^{\top}$, but rather directly estimating $\Vert\boldsymbol{W}\Vert_2$ through power iteration, then adding $\Vert\boldsymbol{W}\Vert_2^2$ to the loss function with a weight, letting the optimizer calculate the gradient itself. This approach is slightly less efficient and makes it harder to decouple from the optimizer in the form of weight decay. This article's approach is relatively more flexible, allowing us, like AdamW, to keep weight decay independent from the optimization of the main loss function.</span>
<span id="cb4-1060"><a href="#cb4-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1061"><a href="#cb4-1061" aria-hidden="true" tabindex="-1"></a>Of course, from today's LLM perspective, the biggest problem with those early experiments was that they were all too small in scale to be sufficiently convincing. However, given the precedent of the spectral norm-based Muon optimizer, I believe it's worth reconsidering and trying spectral norm weight decay. Certainly, whether it's Frobenius norm or spectral norm weight decay, these techniques aimed at "generalization" often have some luck involved, so it's best to maintain moderate expectations.</span>
<span id="cb4-1062"><a href="#cb4-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1063"><a href="#cb4-1063" aria-hidden="true" tabindex="-1"></a>Initial experiments on language models show that there might be a slight improvement at the loss level. Hopefully this is not an illusion, but even if it's an illusion, at least no degradation was observed. The experimental process involved using power iteration to approximate $\boldsymbol{v}_1$ (initialized as an all-ones vector, iterated 10 times), then changing the original weight decay $-\lambda \boldsymbol{W}$ to $-\lambda \boldsymbol{W}\boldsymbol{v}_1\boldsymbol{v}_1^{\top}$, keeping the value of $\lambda$ unchanged.</span>
<span id="cb4-1064"><a href="#cb4-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1065"><a href="#cb4-1065" aria-hidden="true" tabindex="-1"></a><span class="fu"># Why is the default scale of gradient clipping 1?</span></span>
<span id="cb4-1066"><a href="#cb4-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1067"><a href="#cb4-1067" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">为什么梯度裁剪的默认模长是1？ - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10657)</span> (2025-01-02)</span>
<span id="cb4-1068"><a href="#cb4-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1069"><a href="#cb4-1069" aria-hidden="true" tabindex="-1"></a>We know that gradient clipping is a common technique to make model training more stable. The commonly used gradient clipping method clips gradients based on the total norm of all parameter gradients, and its operation can be expressed as:</span>
<span id="cb4-1070"><a href="#cb4-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1071"><a href="#cb4-1071" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1072"><a href="#cb4-1072" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{clip}(\boldsymbol{g},\tau)=\left<span class="sc">\{</span>\begin{aligned}&amp;\boldsymbol{g}, &amp;\Vert\boldsymbol{g}\Vert\leq \tau <span class="sc">\\</span></span>
<span id="cb4-1073"><a href="#cb4-1073" aria-hidden="true" tabindex="-1"></a>&amp;\frac{\tau}{\Vert\boldsymbol{g}\Vert}\boldsymbol{g},&amp;\Vert\boldsymbol{g}\Vert &gt; \tau</span>
<span id="cb4-1074"><a href="#cb4-1074" aria-hidden="true" tabindex="-1"></a>\end{aligned}\right.\end{equation}</span>
<span id="cb4-1075"><a href="#cb4-1075" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1076"><a href="#cb4-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1077"><a href="#cb4-1077" aria-hidden="true" tabindex="-1"></a>In this way, $\text{clip}(\boldsymbol{g},\tau)$ maintains the same direction as $\boldsymbol{g}$, but the norm does not exceed $\tau$. Note that $\Vert\boldsymbol{g}\Vert$ here is the norm calculated by treating all parameter gradients of the entire model together as a single vector, which is the so-called Global Gradient Norm.</span>
<span id="cb4-1078"><a href="#cb4-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1079"><a href="#cb4-1079" aria-hidden="true" tabindex="-1"></a>Have you noticed a detail: whether it's a model with hundreds of millions of parameters or tens of billions of parameters, the value of $\tau$ is often 1 in many cases. What does this imply? Is it simply reusing the default value, or is there some profound principle behind it?</span>
<span id="cb4-1080"><a href="#cb4-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1081"><a href="#cb4-1081" aria-hidden="true" tabindex="-1"></a><span class="fu">## What does it mean?</span></span>
<span id="cb4-1082"><a href="#cb4-1082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1083"><a href="#cb4-1083" aria-hidden="true" tabindex="-1"></a>Some readers might think, the default value is not necessarily the optimal value, so why bother with it? Indeed, $\tau=1$ may not be the optimal choice, but it is the default choice for many models, and these models perform reasonably well with this default choice, which in turn suggests that $\tau=1$ is a "universally reasonable" choice.</span>
<span id="cb4-1084"><a href="#cb4-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1085"><a href="#cb4-1085" aria-hidden="true" tabindex="-1"></a>What does it mean to say a choice of $\tau$ is "reasonable"? Let's return to the $\text{clip}$ operation. If $\Vert\boldsymbol{g}\Vert$ is always less than $\tau$, then $\text{clip}$ degenerates into an identity transformation; if $\Vert\boldsymbol{g}\Vert$ is always greater than $\tau$, then $\text{clip}$ degenerates into L2 normalization. In other words, the reason $\text{clip}$ is $\text{clip}$ is because $\tau$ produces an appropriate level of distinction, making most $\Vert\boldsymbol{g}\Vert$ less than $\tau$, with only a small portion greater than $\tau$ -- this is the meaning of saying this $\tau$ is "reasonable".</span>
<span id="cb4-1086"><a href="#cb4-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1087"><a href="#cb4-1087" aria-hidden="true" tabindex="-1"></a>Of course, counterexamples can be found, and quite a few at that. Here, I mainly want to emphasize the universality of this phenomenon and the general applicability of this default setting, so meticulous readers need not be overly fixated on individual details.</span>
<span id="cb4-1088"><a href="#cb4-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1089"><a href="#cb4-1089" aria-hidden="true" tabindex="-1"></a>Therefore, we believe that the universal reasonableness of $\tau=1$ means that regardless of the number of model parameters, how they are initialized, or what loss function is chosen, the total gradient norm can roughly use $1$ as the boundary point for "abnormal values" -- this is undoubtedly an incredibly amazing property. This was precisely my feeling when I first realized this conclusion.</span>
<span id="cb4-1090"><a href="#cb4-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1091"><a href="#cb4-1091" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why does this happen?</span></span>
<span id="cb4-1092"><a href="#cb4-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1093"><a href="#cb4-1093" aria-hidden="true" tabindex="-1"></a>$\tau=1$ seems way too nice. Why is Heaven so nice to us? My answer might be somewhat unexpected: because only in this way is stable training of the model possible.</span>
<span id="cb4-1094"><a href="#cb4-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1095"><a href="#cb4-1095" aria-hidden="true" tabindex="-1"></a>Let's consider the loss function $\mathcal{L}(\boldsymbol{\theta})$, with the optimizer update rule $\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t - \eta\, \boldsymbol{u}_t$. Then the change in the loss function can be approximated as:</span>
<span id="cb4-1096"><a href="#cb4-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1097"><a href="#cb4-1097" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1098"><a href="#cb4-1098" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta \mathcal{L} = \mathcal{L}(\boldsymbol{\theta}_{t+1}) - \mathcal{L}(\boldsymbol{\theta}_t) \approx (\boldsymbol{\theta}_{t+1} - \boldsymbol{\theta}_t)\cdot\nabla_{\boldsymbol{\theta}_t}\mathcal{L}(\boldsymbol{\theta}) = -\eta\, \boldsymbol{u}_t\cdot \boldsymbol{g}_t\end{equation}</span>
<span id="cb4-1099"><a href="#cb4-1099" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1100"><a href="#cb4-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1101"><a href="#cb4-1101" aria-hidden="true" tabindex="-1"></a>First, consider the simplest SGD, where $\boldsymbol{u}_t = \boldsymbol{g}_t$ and $\Delta \mathcal{L}=-\eta\Vert\boldsymbol{g}_t\Vert^2$, meaning the change in the loss function is proportional to the square of the gradient norm. We know that, whether in CV or NLP, pure SGD (without momentum) is a very inefficient optimizer. In the middle and later stages of training, on average, the decrease in loss per step for most tasks is far less than the learning rate, i.e., $|\Delta \mathcal{L}| &lt; \eta$, from which we can deduce $\Vert\boldsymbol{g}_t\Vert &lt; 1$. This indicates that $\Vert\boldsymbol{g}_t\Vert &lt; 1$ is the long-term performance of a model that can converge normally.</span>
<span id="cb4-1102"><a href="#cb4-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1103"><a href="#cb4-1103" aria-hidden="true" tabindex="-1"></a>Of course, in the early stages of training, the model may exhibit $\Vert\boldsymbol{g}_t\Vert &gt; 1$, which is normal, but it's rare to have $\Vert\boldsymbol{g}_t\Vert \gg 1$. In other words, a good initialization should avoid $\Vert\boldsymbol{g}_t\Vert \gg 1$, which is the theoretical basis for methods like <span class="co">[</span><span class="ot">DeepNorm</span><span class="co">](https://kexue.fm/archives/8978)</span>. The reason is similar: if the gradient norm is too large, then early learning will be too "aggressive", leading to premature convergence to poor local minima. Another approach is to reduce $\eta$, which can also reduce $|\Delta \mathcal{L}|$. This is why we typically use Warmup in the early stages of training.</span>
<span id="cb4-1104"><a href="#cb4-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1105"><a href="#cb4-1105" aria-hidden="true" tabindex="-1"></a>By the way, for understanding Warmup, readers can refer to the paper <span class="co">[</span><span class="ot">Optimal Linear Decay Learning Rate Schedules and Further Refinements</span><span class="co">](https://arxiv.org/abs/2310.07831)</span>, which I consider to be the most reasonable analysis of Warmup.</span>
<span id="cb4-1106"><a href="#cb4-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1107"><a href="#cb4-1107" aria-hidden="true" tabindex="-1"></a><span class="fu">## What to do?</span></span>
<span id="cb4-1108"><a href="#cb4-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1109"><a href="#cb4-1109" aria-hidden="true" tabindex="-1"></a>Simply put, since the change in the loss function is proportional to the square of the gradient norm, the stability of training determines that the gradient norm cannot be too large, and its long-term performance is less than 1. If significantly larger gradient norms appear in the early stage, the usual strategy is Warmup. Or a more general strategy can be considered: set another threshold $\mathcal{T}$ and clip $\eta$ based on the value of $\boldsymbol{u}_t\cdot \boldsymbol{g}_t$:</span>
<span id="cb4-1110"><a href="#cb4-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1111"><a href="#cb4-1111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1112"><a href="#cb4-1112" aria-hidden="true" tabindex="-1"></a>\begin{equation}\eta_t = \left<span class="sc">\{</span>\begin{aligned}&amp;\eta,&amp; \boldsymbol{u}_t\cdot \boldsymbol{g}_t\leq \mathcal{T} <span class="sc">\\</span> &amp;\frac{\mathcal{T}}{\boldsymbol{u}_t\cdot \boldsymbol{g}_t}\eta,&amp; \boldsymbol{u}_t\cdot \boldsymbol{g}_t &gt; \mathcal{T}</span>
<span id="cb4-1113"><a href="#cb4-1113" aria-hidden="true" tabindex="-1"></a>\end{aligned}\right.\end{equation}</span>
<span id="cb4-1114"><a href="#cb4-1114" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1115"><a href="#cb4-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1116"><a href="#cb4-1116" aria-hidden="true" tabindex="-1"></a>This eliminates the need for additional Warmup settings and is more adaptive.</span>
<span id="cb4-1117"><a href="#cb4-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1118"><a href="#cb4-1118" aria-hidden="true" tabindex="-1"></a>For optimizers like Adam, we can use approximate analysis through $\boldsymbol{u}_t=\text{sign}(\boldsymbol{g}_t)$, as <span class="co">[</span><span class="ot">previously described</span><span class="co">](#sec-learning-rate-batch-size)</span>. In this case:</span>
<span id="cb4-1119"><a href="#cb4-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1120"><a href="#cb4-1120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1121"><a href="#cb4-1121" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta \mathcal{L} = -\eta\, \text{sign}(\boldsymbol{g}_t)\cdot \boldsymbol{g}_t = -\eta\, \Vert\boldsymbol{g}_t\Vert_1\end{equation}</span>
<span id="cb4-1122"><a href="#cb4-1122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1123"><a href="#cb4-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1124"><a href="#cb4-1124" aria-hidden="true" tabindex="-1"></a>Here, $\Vert\cdot\Vert_1$ is the L1 norm, i.e., the sum of the absolute values of the components. Since gradient components are generally less than 1, $\Vert\boldsymbol{g}_t\Vert_1 \gg \Vert\boldsymbol{g}_t\Vert$. Therefore, due to the requirement for stable training, the learning rate for Adam is typically significantly smaller than that for SGD. Additionally, the above equation can be rewritten as:</span>
<span id="cb4-1125"><a href="#cb4-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1126"><a href="#cb4-1126" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1127"><a href="#cb4-1127" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta \mathcal{L} = -\eta\, \text{sign}(\boldsymbol{g}_t)\cdot \boldsymbol{g}_t = -\eta\, \sqrt{N}\Vert\boldsymbol{g}_t\Vert \cos(\text{sign}(\boldsymbol{g}_t), \boldsymbol{g}_t) \end{equation}</span>
<span id="cb4-1128"><a href="#cb4-1128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1129"><a href="#cb4-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1130"><a href="#cb4-1130" aria-hidden="true" tabindex="-1"></a>This assumes that $\boldsymbol{g}_t$ has no zero components, so $\Vert\text{sign}(\boldsymbol{g}_t)\Vert=\sqrt{N}$, where $N$ is the total number of model parameters. In practice, it's found that $\Vert\boldsymbol{g}_t\Vert$ and $\cos(\text{sign}(\boldsymbol{g}_t), \boldsymbol{g}_t)$ are roughly constant across different model scales. Therefore, to maintain a constant $\Delta \mathcal{L}$, $\eta$ should be inversely proportional to $\sqrt{N}$, meaning that if the number of model parameters increases by a factor of 4, the learning rate could be halved.</span>
<span id="cb4-1131"><a href="#cb4-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1132"><a href="#cb4-1132" aria-hidden="true" tabindex="-1"></a><span class="fu"># Muon sequel: Why did we choose to give Muon a try? {#sec-muon-sequel}</span></span>
<span id="cb4-1133"><a href="#cb4-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1134"><a href="#cb4-1134" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Muon续集：为什么我们选择尝试Muon？ - 科学空间|Scientific Spaces</span><span class="co">](https://kexue.fm/archives/10739)</span> (2025-02-27)</span>
<span id="cb4-1135"><a href="#cb4-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1136"><a href="#cb4-1136" aria-hidden="true" tabindex="-1"></a>This article explicates our latest technical report <span class="co">[</span><span class="ot">*Muon is Scalable for LLM Training*</span><span class="co">](https://arxiv.org/abs/2502.16982)</span>, which shares a relatively large-scale implementation of the Muon optimizer that we previously introduced in <span class="co">[</span><span class="ot">*Muon Appreciation*</span><span class="co">](#sec-muon-appreciation)</span>. We've also open-sourced the corresponding models (which we call "<span class="co">[</span><span class="ot">Moonlight</span><span class="co">](https://github.com/MoonshotAI/Moonlight)</span>", currently a 3B/16B MoE model).<span class="ot">[^moonlight-name]</span> We discovered a rather surprising conclusion: under our experimental settings, Muon can achieve nearly twice the training efficiency compared to Adam.</span>
<span id="cb4-1137"><a href="#cb4-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1138"><a href="#cb4-1138" aria-hidden="true" tabindex="-1"></a><span class="ot">[^moonlight-name]: </span>It's named "Moonlight" because the authors are from Moonshot AI, whose Chinese name is 月之暗面 ("Dark Side of the Moon").</span>
<span id="cb4-1139"><a href="#cb4-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1140"><a href="#cb4-1140" aria-hidden="true" tabindex="-1"></a><span class="al">![Muon scaling law and the MMLU scores of Moonlight.](figure/1300601661.png)</span></span>
<span id="cb4-1141"><a href="#cb4-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1142"><a href="#cb4-1142" aria-hidden="true" tabindex="-1"></a>Out of all the optimizers we could have tried, why Muon? How can we quickly switch from a well-tuned Adam optimizer to Muon for experimentation? How do the performance differences between Muon and Adam change as models scale up? Next, we will share our thought process.</span>
<span id="cb4-1143"><a href="#cb4-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1144"><a href="#cb4-1144" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimization principles</span></span>
<span id="cb4-1145"><a href="#cb4-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1146"><a href="#cb4-1146" aria-hidden="true" tabindex="-1"></a>Regarding optimizers, I had already provided a brief assessment in <span class="co">[</span><span class="ot">*Muon Appreciation*</span><span class="co">](#sec-muon-appreciation)</span>. Most optimizer improvements are just tiny variants of the same basic thing. Not to say they're worthless, but they won't make a profound or stunning impression on you.</span>
<span id="cb4-1147"><a href="#cb4-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1148"><a href="#cb4-1148" aria-hidden="true" tabindex="-1"></a>We need to think about what makes a good optimizer from principles closer to the essence. Intuitively, an ideal optimizer should have two characteristics: stable and fast. Specifically, each update of an ideal optimizer should satisfy two points: </span>
<span id="cb4-1149"><a href="#cb4-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1150"><a href="#cb4-1150" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Disturb the model as little as possible.</span>
<span id="cb4-1151"><a href="#cb4-1151" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Contribute as much as possible to loss reduction. More directly, we don't want to drastically change the model (stability), but we want to greatly reduce the loss (speed). It's "both... and...".</span>
<span id="cb4-1152"><a href="#cb4-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1153"><a href="#cb4-1153" aria-hidden="true" tabindex="-1"></a>How do we translate these two characteristics into mathematical language? We can understand **stability** as a constraint on the update magnitude, and **speed** as finding the update that makes the loss function decrease most rapidly. So this can be transformed into a constrained optimization problem. Using the notation from earlier, for a matrix parameter $\boldsymbol{W}\in\mathbb{R}^{n\times m}$ with gradient $\boldsymbol{G}\in\mathbb{R}^{n\times m}$, when the parameter changes from $\boldsymbol{W}$ to $\boldsymbol{W}+\Delta\boldsymbol{W}$, the change in the loss function is</span>
<span id="cb4-1154"><a href="#cb4-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1155"><a href="#cb4-1155" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1156"><a href="#cb4-1156" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\end{equation}</span>
<span id="cb4-1157"><a href="#cb4-1157" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1158"><a href="#cb4-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1159"><a href="#cb4-1159" aria-hidden="true" tabindex="-1"></a>Therefore, conditional on being stable, the fastest update should satisfy</span>
<span id="cb4-1160"><a href="#cb4-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1161"><a href="#cb4-1161" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1162"><a href="#cb4-1162" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathop{\text{argmin}}_{\Delta\boldsymbol{W}}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\quad\text{s.t.}\quad \rho(\Delta\boldsymbol{W})\leq \eta\end{equation}</span>
<span id="cb4-1163"><a href="#cb4-1163" aria-hidden="true" tabindex="-1"></a>$$ {#eq-least-action}</span>
<span id="cb4-1164"><a href="#cb4-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1165"><a href="#cb4-1165" aria-hidden="true" tabindex="-1"></a>Here, $\rho(\Delta\boldsymbol{W})\geq 0$ is some metric of **stability**, where smaller values indicate greater stability, and $\eta$ is a constant less than 1, representing our requirement for **stability**. Later we'll see that it's actually the learning rate of the optimizer. If readers don't mind, we can borrow concepts from theoretical physics and call it the "**&lt;font color="orange"&gt;Least Action Principle&lt;/font&gt;**" for optimizers.</span>
<span id="cb4-1166"><a href="#cb4-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1167"><a href="#cb4-1167" aria-hidden="true" tabindex="-1"></a><span class="fu">## Matrix norms</span></span>
<span id="cb4-1168"><a href="#cb4-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1169"><a href="#cb4-1169" aria-hidden="true" tabindex="-1"></a>The only uncertainty in @eq-least-action is the stability measure $\rho(\Delta\boldsymbol{W})$. Once $\rho(\Delta\boldsymbol{W})$ is determined, $\Delta\boldsymbol{W}$ can be explicitly solved (at least theoretically). To some extent, we can consider that the essential difference between different optimizers is how they define **stability**.</span>
<span id="cb4-1170"><a href="#cb4-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1171"><a href="#cb4-1171" aria-hidden="true" tabindex="-1"></a>Many readers probably encountered statements like "the negative gradient direction is the direction of steepest descent for the function value locally" when first learning SGD. In this framework, it actually means choosing the Frobenius norm $\Vert\Delta\boldsymbol{W}\Vert_F$ as the measure of **stability**. In other words, the "direction of steepest descent" is not immutable -- it can only be determined after choosing a metric. Change the norm, and it may no longer be the negative gradient direction.</span>
<span id="cb4-1172"><a href="#cb4-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1173"><a href="#cb4-1173" aria-hidden="true" tabindex="-1"></a>The next question naturally is: which norm most appropriately measures **stability**? If we impose strong constraints, sure, we will definitely achieve stability, but the optimizer will crawl like a snail, only converging to a suboptimal solution. Conversely, if we weaken the constraints, the optimizer will fly like a crazy bat, making the training process extremely unstable. So, ideally, we want to find the most precise index of **stability**. Considering that neural networks primarily involve matrix multiplication, let's take $\boldsymbol{y}=\boldsymbol{x}\boldsymbol{W}$ as an example:</span>
<span id="cb4-1174"><a href="#cb4-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1175"><a href="#cb4-1175" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1176"><a href="#cb4-1176" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Vert\Delta \boldsymbol{y}\Vert = \Vert\boldsymbol{x}(\boldsymbol{W} + \Delta\boldsymbol{W}) - \boldsymbol{x}\boldsymbol{W}\Vert = \Vert\boldsymbol{x} \Delta\boldsymbol{W}\Vert\leq \rho(\Delta\boldsymbol{W}) \Vert\boldsymbol{x}\Vert\end{equation}</span>
<span id="cb4-1177"><a href="#cb4-1177" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1178"><a href="#cb4-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1179"><a href="#cb4-1179" aria-hidden="true" tabindex="-1"></a>This means that when the parameter changes from $\boldsymbol{W}$ to $\boldsymbol{W}+\Delta\boldsymbol{W}$, the change in model output is $\Delta\boldsymbol{y}$. We hope that the magnitude of this change can be controlled by $\Vert\boldsymbol{x}\Vert$ and a function $\rho(\Delta\boldsymbol{W})$ related to $\Delta\boldsymbol{W}$, and we use this function as an index of **stability**. From linear algebra, we know that the most accurate value for $\rho(\Delta\boldsymbol{W})$ is the spectral norm of $\Delta\boldsymbol{W}$, denoted as $\Vert\Delta\boldsymbol{W}\Vert_2$. Substituting into @eq-least-action, we get:</span>
<span id="cb4-1180"><a href="#cb4-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1181"><a href="#cb4-1181" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1182"><a href="#cb4-1182" aria-hidden="true" tabindex="-1"></a>\begin{equation}\mathop{\text{argmin}}_{\Delta\boldsymbol{W}}\text{Tr}(\boldsymbol{G}^{\top}\Delta\boldsymbol{W})\quad\text{s.t.}\quad \Vert\Delta\boldsymbol{W}\Vert_2\leq \eta\end{equation}</span>
<span id="cb4-1183"><a href="#cb4-1183" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1184"><a href="#cb4-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1185"><a href="#cb4-1185" aria-hidden="true" tabindex="-1"></a>The solution to this optimization problem is Muon with $\beta=0$:</span>
<span id="cb4-1186"><a href="#cb4-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1187"><a href="#cb4-1187" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1188"><a href="#cb4-1188" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta\boldsymbol{W} = -\eta\, \text{msign}(\boldsymbol{G}) = -\eta\,\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{<span class="co">[</span><span class="ot">:,:r</span><span class="co">]</span>}^{\top}, \quad \boldsymbol{U},\boldsymbol{\Sigma},\boldsymbol{V}^{\top} = SVD(\boldsymbol{G})\end{equation}</span>
<span id="cb4-1189"><a href="#cb4-1189" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1190"><a href="#cb4-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1191"><a href="#cb4-1191" aria-hidden="true" tabindex="-1"></a>When $\beta &gt; 0$, $\boldsymbol{G}$ is replaced with momentum $\boldsymbol{M}$, which can be seen as a smoother estimate of the gradient, so it can still be understood as the conclusion above. Therefore, we can say that "Muon is steepest descent under the spectral norm." As for Newton--Schulz iterations and the like, they are computational approximations, which we won't elaborate on here. We already provided detailed derivations in <span class="co">[</span><span class="ot">*Muon Appreciation*</span><span class="co">](#sec-muon-appreciation)</span>, so we won't repeat them.</span>
<span id="cb4-1192"><a href="#cb4-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1193"><a href="#cb4-1193" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weight decay</span></span>
<span id="cb4-1194"><a href="#cb4-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1195"><a href="#cb4-1195" aria-hidden="true" tabindex="-1"></a>At this point, we can answer the first question: why try Muon? Like SGD, Muon also gives the direction of steepest descent, but its spectral norm constraint is more precise than SGD's Frobenius norm, so it has better potential. On the other hand, improving optimizers from the perspective of "choosing the most appropriate constraint for different parameters" seems more fundamental than various small patches over the same thing.</span>
<span id="cb4-1196"><a href="#cb4-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1197"><a href="#cb4-1197" aria-hidden="true" tabindex="-1"></a>Of course, potential doesn't always translate to performance, and there are some annoying gotchas when validating Muon on larger models. First is the weight decay problem. Although I included weight decay when introducing Muon in <span class="co">[</span><span class="ot">*Muon Appreciation*</span><span class="co">](#sec-muon-appreciation)</span>, the authors of Muon didn't include it when they first proposing Muon. We initially implemented it according to the official version and found that while Muon converged faster at the beginning, it was soon caught up by Adam, and various "internal issues" showed signs of collapse.</span>
<span id="cb4-1198"><a href="#cb4-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1199"><a href="#cb4-1199" aria-hidden="true" tabindex="-1"></a>We quickly realized this might be a weight decay issue, so we added weight decay:</span>
<span id="cb4-1200"><a href="#cb4-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1201"><a href="#cb4-1201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1202"><a href="#cb4-1202" aria-hidden="true" tabindex="-1"></a>\begin{equation}\Delta\boldsymbol{W} = -\eta\, <span class="co">[</span><span class="ot">\text{msign}(\boldsymbol{M})+ \lambda \boldsymbol{W}</span><span class="co">]</span>\end{equation}</span>
<span id="cb4-1203"><a href="#cb4-1203" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1204"><a href="#cb4-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1205"><a href="#cb4-1205" aria-hidden="true" tabindex="-1"></a>Continuing the experiment, sure enough, Muon consistently maintained its lead over Adam, as shown in Figure 2 of the paper:</span>
<span id="cb4-1206"><a href="#cb4-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1207"><a href="#cb4-1207" aria-hidden="true" tabindex="-1"></a><span class="al">![With vs without weight decay.](figure/3675708776.png)</span></span>
<span id="cb4-1208"><a href="#cb4-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1209"><a href="#cb4-1209" aria-hidden="true" tabindex="-1"></a>What role does weight decay play? In retrospect, it should have been clear that we should keep the an upper bound on the norm of the matrix parameter:</span>
<span id="cb4-1210"><a href="#cb4-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1211"><a href="#cb4-1211" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1212"><a href="#cb4-1212" aria-hidden="true" tabindex="-1"></a>\begin{equation}\begin{aligned}</span>
<span id="cb4-1213"><a href="#cb4-1213" aria-hidden="true" tabindex="-1"></a>\Vert\boldsymbol{W}_t\Vert =&amp;\, \Vert\boldsymbol{W}_{t-1} - \eta_t (\boldsymbol{O}_t + \lambda \boldsymbol{W}_{t-1})\Vert <span class="sc">\\</span></span>
<span id="cb4-1214"><a href="#cb4-1214" aria-hidden="true" tabindex="-1"></a>=&amp;\, \Vert(1 - \eta_t \lambda)\boldsymbol{W}_{t-1} - \eta_t \lambda (\boldsymbol{O}_t/\lambda)\Vert <span class="sc">\\</span></span>
<span id="cb4-1215"><a href="#cb4-1215" aria-hidden="true" tabindex="-1"></a>\leq &amp;\,(1 - \eta_t \lambda)\Vert\boldsymbol{W}_{t-1}\Vert + \eta_t \lambda \Vert\boldsymbol{O}_t/\lambda\Vert <span class="sc">\\</span></span>
<span id="cb4-1216"><a href="#cb4-1216" aria-hidden="true" tabindex="-1"></a>\leq &amp;\,\max(\Vert\boldsymbol{W}_{t-1}\Vert,\Vert\boldsymbol{O}_t/\lambda\Vert) <span class="sc">\\</span></span>
<span id="cb4-1217"><a href="#cb4-1217" aria-hidden="true" tabindex="-1"></a>\end{aligned}\end{equation}</span>
<span id="cb4-1218"><a href="#cb4-1218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1219"><a href="#cb4-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1220"><a href="#cb4-1220" aria-hidden="true" tabindex="-1"></a>Here, $\Vert\cdot\Vert$ is any matrix norm, meaning the above inequality holds for any matrix norm. $\boldsymbol{O}_t$ is the update vector given by the optimizer, which is $\text{msign}(\boldsymbol{M})$ for Muon. When we take the spectral norm, $\Vert\text{msign}(\boldsymbol{M})\Vert_2 = 1$, so for Muon, we have:</span>
<span id="cb4-1221"><a href="#cb4-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1222"><a href="#cb4-1222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1223"><a href="#cb4-1223" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb4-1224"><a href="#cb4-1224" aria-hidden="true" tabindex="-1"></a>\Vert\boldsymbol{W}_t\Vert_2 \leq \max(\Vert\boldsymbol{W}_{t-1}\Vert_2,1/\lambda)\leq\cdots \leq \max(\Vert\boldsymbol{W}_0\Vert_2,1/\lambda)\end{equation}</span>
<span id="cb4-1225"><a href="#cb4-1225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1226"><a href="#cb4-1226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1227"><a href="#cb4-1227" aria-hidden="true" tabindex="-1"></a>This keeps the model "healthy on the inside", because $\Vert\boldsymbol{x}\boldsymbol{W}\Vert\leq \Vert\boldsymbol{x}\Vert\cdot\Vert\boldsymbol{W}\Vert_2$. When $\Vert\boldsymbol{W}\Vert_2$ is controlled, it means that $\Vert\boldsymbol{x}\boldsymbol{W}\Vert$ is also controlled, eliminating the risk of explosion, which is particularly important for issues like Attention Logits explosion. Of course, this upper bound is quite loose in most cases, and in practice, the spectral norm of parameters is often significantly smaller than this upper bound. This inequality simply shows that weight decay can control norms.</span>
<span id="cb4-1228"><a href="#cb4-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1229"><a href="#cb4-1229" aria-hidden="true" tabindex="-1"></a><span class="fu">## RMS alignment</span></span>
<span id="cb4-1230"><a href="#cb4-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1231"><a href="#cb4-1231" aria-hidden="true" tabindex="-1"></a>When we decide to try a new optimizer, a challenging problem is how to quickly find near-optimal hyperparameters. For instance, Muon has at least two hyperparameters: learning rate $\eta_t$ and decay rate $\lambda$. Grid search is certainly possible but time-consuming. Here, we propose the Update RMS alignment approach for hyperparameter transfer, which can apply well-tuned Adam hyperparameters to other optimizers.</span>
<span id="cb4-1232"><a href="#cb4-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1233"><a href="#cb4-1233" aria-hidden="true" tabindex="-1"></a>First, for a matrix $\boldsymbol{W}\in\mathbb{R}^{n\times m}$, its RMS (Root Mean Square) is defined as:</span>
<span id="cb4-1234"><a href="#cb4-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1235"><a href="#cb4-1235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1236"><a href="#cb4-1236" aria-hidden="true" tabindex="-1"></a>\begin{equation}\text{RMS}(\boldsymbol{W}) = \frac{\Vert \boldsymbol{W}\Vert_F}{\sqrt{nm}} = \sqrt{\frac{1}{nm}\sum_{i=1}^n\sum_{j=1}^m W_{i,j}^2}\end{equation}</span>
<span id="cb4-1237"><a href="#cb4-1237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1238"><a href="#cb4-1238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1239"><a href="#cb4-1239" aria-hidden="true" tabindex="-1"></a>Simply put, RMS measures the average size of each element in the matrix. We observed that the RMS of Adam's update is relatively stable, usually between 0.2 and 0.4, which is why <span class="co">[</span><span class="ot">theoretical analyses we described previously</span><span class="co">](#sec-learning-rate-batch-size)</span> often use SignSGD to approximate Adam. Based on this, we suggest aligning the Update RMS of the new optimizer to 0.2 through RMS normalization:</span>
<span id="cb4-1240"><a href="#cb4-1240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1241"><a href="#cb4-1241" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1242"><a href="#cb4-1242" aria-hidden="true" tabindex="-1"></a>\begin{gather}</span>
<span id="cb4-1243"><a href="#cb4-1243" aria-hidden="true" tabindex="-1"></a>\boldsymbol{W}_t =\boldsymbol{W}_{t-1} - \eta_t (\boldsymbol{O}_t + \lambda \boldsymbol{W}_{t-1}) <span class="sc">\\</span><span class="co">[</span><span class="ot">6pt</span><span class="co">]</span></span>
<span id="cb4-1244"><a href="#cb4-1244" aria-hidden="true" tabindex="-1"></a>\downarrow \notag<span class="sc">\\</span><span class="co">[</span><span class="ot">6pt</span><span class="co">]</span></span>
<span id="cb4-1245"><a href="#cb4-1245" aria-hidden="true" tabindex="-1"></a>\boldsymbol{W}_t = \boldsymbol{W}_{t-1} - \eta_t (0.2\, \boldsymbol{O}_t/\text{RMS}(\boldsymbol{O}_t) + \lambda \boldsymbol{W}_{t-1})</span>
<span id="cb4-1246"><a href="#cb4-1246" aria-hidden="true" tabindex="-1"></a>\end{gather}</span>
<span id="cb4-1247"><a href="#cb4-1247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1248"><a href="#cb4-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1249"><a href="#cb4-1249" aria-hidden="true" tabindex="-1"></a>This way, we can reuse Adam's $\eta_t$ and $\lambda$ to achieve roughly the same update magnitude to parameters at each step. Practice shows that transitioning from Adam to Muon through this simple strategy can produce results significantly better than Adam, approaching the results of further fine-tuning Muon's hyperparameters. Specifically, Muon's $\text{RMS}(\boldsymbol{O}_t)=\text{RMS}(\boldsymbol{U}_{[:,:r]}\boldsymbol{V}_{<span class="co">[</span><span class="ot">:,:r</span><span class="co">]</span>}^{\top})$ can be calculated analytically:</span>
<span id="cb4-1250"><a href="#cb4-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1251"><a href="#cb4-1251" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1252"><a href="#cb4-1252" aria-hidden="true" tabindex="-1"></a>\begin{equation}nm\,\text{RMS}(\boldsymbol{O}_t)^2 = \sum_{i=1}^n\sum_{j=1}^m \sum_{k=1}^r U_{i,k}^2V_{k,j}^2 = \sum_{k=1}^r\left(\sum_{i=1}^n U_{i,k}^2\right)\left(\sum_{j=1}^m V_{k,j}^2\right) = \sum_{k=1}^r 1 = r\end{equation}</span>
<span id="cb4-1253"><a href="#cb4-1253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1254"><a href="#cb4-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1255"><a href="#cb4-1255" aria-hidden="true" tabindex="-1"></a>That is, $\text{RMS}(\boldsymbol{O}_t) = \sqrt{r/nm}$. In practice, the probability of a matrix being strictly low-rank is quite small, so we can assume $r = \min(n,m)$, giving us $\text{RMS}(\boldsymbol{O}_t) = \sqrt{1/\max(n,m)}$. Therefore, we ultimately used the equivalent analytical version instead of direct RMS normalization:</span>
<span id="cb4-1256"><a href="#cb4-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1257"><a href="#cb4-1257" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1258"><a href="#cb4-1258" aria-hidden="true" tabindex="-1"></a>\begin{equation}\boldsymbol{W}_t = \boldsymbol{W}_{t-1} - \eta_t (0.2\, \boldsymbol{O}_t\,\sqrt{\max(n,m)} + \lambda \boldsymbol{W}_{t-1})\end{equation}</span>
<span id="cb4-1259"><a href="#cb4-1259" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1260"><a href="#cb4-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1261"><a href="#cb4-1261" aria-hidden="true" tabindex="-1"></a>This final formula indicates that it's not appropriate to use the same learning rate for all parameters in Muon. For example, Moonlight is an MoE model with many matrix parameters whose shapes deviate from square matrices, resulting in a wide range of $\max(n,m)$ values. Using a single learning rate would inevitably lead to asynchronous issues where some parameters learn too quickly or too slowly, affecting the final result.</span>
<span id="cb4-1262"><a href="#cb4-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1263"><a href="#cb4-1263" aria-hidden="true" tabindex="-1"></a><span class="fu">## Experiments</span></span>
<span id="cb4-1264"><a href="#cb4-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1265"><a href="#cb4-1265" aria-hidden="true" tabindex="-1"></a>We conducted a fairly comprehensive comparison between Adam and Muon on MoE models of sizes 2.4B/16B and found that Muon has significant advantages in both convergence speed and final performance. For detailed comparison results, we recommend reading the original paper; here we only share some excerpts.</span>
<span id="cb4-1266"><a href="#cb4-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1267"><a href="#cb4-1267" aria-hidden="true" tabindex="-1"></a>First, here's a relatively objective comparison table, including our own controlled variable training comparing Muon and Adam, as well as comparisons with models trained by others (DeepSeek) using Adam with the same architecture (for ease of comparison, Moonlight's architecture is identical to DSV3-Small), showing Muon's unique advantages. The following table from the paper compares between Muon (Moonlight) and Adam (Moonlight-A and DSV3-small):</span>
<span id="cb4-1268"><a href="#cb4-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1269"><a href="#cb4-1269" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb4-1270"><a href="#cb4-1270" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;style&gt;table { border-collapse: collapse; width: 100%; margin: 20px 0; font-family: Arial, sans-serif; } th, td { padding: 8px; text-align: center; } th.left-align, td.left-align { text-align: left; } .border-top { border-top: 2px solid black; } .border-bottom { border-bottom: 2px solid black; } .border-right { border-right: 2px solid black; } .border-left { border-left: 2px solid black; } .bold { font-weight: bold; } .category { text-align: center; }&lt;/style&gt;</span></span>
<span id="cb4-1271"><a href="#cb4-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1272"><a href="#cb4-1272" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;table class="table-hover caption-top table"&gt;</span></span>
<span id="cb4-1273"><a href="#cb4-1273" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;caption&gt;Table 4: Comparison of different models at around 1.2T tokens.&lt;/caption&gt;</span></span>
<span id="cb4-1274"><a href="#cb4-1274" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;thead&gt;</span></span>
<span id="cb4-1275"><a href="#cb4-1275" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1276"><a href="#cb4-1276" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;&lt;/th&gt;</span></span>
<span id="cb4-1277"><a href="#cb4-1277" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Benchmark (Metric)&lt;/th&gt;</span></span>
<span id="cb4-1278"><a href="#cb4-1278" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;DSV3-Small&lt;/th&gt;</span></span>
<span id="cb4-1279"><a href="#cb4-1279" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;Moonlight-A@1.2T&lt;/th&gt;</span></span>
<span id="cb4-1280"><a href="#cb4-1280" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;Moonlight@1.2T&lt;/th&gt;</span></span>
<span id="cb4-1281"><a href="#cb4-1281" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1282"><a href="#cb4-1282" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/thead&gt;</span></span>
<span id="cb4-1283"><a href="#cb4-1283" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;tbody&gt;</span></span>
<span id="cb4-1284"><a href="#cb4-1284" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1285"><a href="#cb4-1285" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;&lt;/th&gt;</span></span>
<span id="cb4-1286"><a href="#cb4-1286" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Activated Params&lt;sup&gt;†&lt;/sup&gt;&lt;/th&gt;</span></span>
<span id="cb4-1287"><a href="#cb4-1287" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;2.24B&lt;/td&gt;</span></span>
<span id="cb4-1288"><a href="#cb4-1288" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;2.24B&lt;/td&gt;</span></span>
<span id="cb4-1289"><a href="#cb4-1289" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;2.24B&lt;/td&gt;</span></span>
<span id="cb4-1290"><a href="#cb4-1290" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1291"><a href="#cb4-1291" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1292"><a href="#cb4-1292" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;&lt;/th&gt;</span></span>
<span id="cb4-1293"><a href="#cb4-1293" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Total Params&lt;sup&gt;†&lt;/sup&gt;&lt;/th&gt;</span></span>
<span id="cb4-1294"><a href="#cb4-1294" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;15.29B&lt;/td&gt;</span></span>
<span id="cb4-1295"><a href="#cb4-1295" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;15.29B&lt;/td&gt;</span></span>
<span id="cb4-1296"><a href="#cb4-1296" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;15.29B&lt;/td&gt;</span></span>
<span id="cb4-1297"><a href="#cb4-1297" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1298"><a href="#cb4-1298" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1299"><a href="#cb4-1299" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;&lt;/th&gt;</span></span>
<span id="cb4-1300"><a href="#cb4-1300" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Training Tokens&lt;/th&gt;</span></span>
<span id="cb4-1301"><a href="#cb4-1301" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;1.33T&lt;/td&gt;</span></span>
<span id="cb4-1302"><a href="#cb4-1302" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;1.2T&lt;/td&gt;</span></span>
<span id="cb4-1303"><a href="#cb4-1303" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;1.2T&lt;/td&gt;</span></span>
<span id="cb4-1304"><a href="#cb4-1304" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1305"><a href="#cb4-1305" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1306"><a href="#cb4-1306" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th&gt;&lt;/th&gt;</span></span>
<span id="cb4-1307"><a href="#cb4-1307" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Optimizer&lt;/th&gt;</span></span>
<span id="cb4-1308"><a href="#cb4-1308" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1309"><a href="#cb4-1309" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1310"><a href="#cb4-1310" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;Muon&lt;/td&gt;</span></span>
<span id="cb4-1311"><a href="#cb4-1311" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1312"><a href="#cb4-1312" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1313"><a href="#cb4-1313" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="category" rowspan="4"&gt;English&lt;/th&gt;</span></span>
<span id="cb4-1314"><a href="#cb4-1314" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MMLU&lt;/th&gt;</span></span>
<span id="cb4-1315"><a href="#cb4-1315" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;53.3&lt;/td&gt;</span></span>
<span id="cb4-1316"><a href="#cb4-1316" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;60.2&lt;/td&gt;</span></span>
<span id="cb4-1317"><a href="#cb4-1317" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;60.4&lt;/td&gt;</span></span>
<span id="cb4-1318"><a href="#cb4-1318" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1319"><a href="#cb4-1319" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1320"><a href="#cb4-1320" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MMLU-pro&lt;/th&gt;</span></span>
<span id="cb4-1321"><a href="#cb4-1321" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1322"><a href="#cb4-1322" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;26.8&lt;/td&gt;</span></span>
<span id="cb4-1323"><a href="#cb4-1323" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;28.1&lt;/td&gt;</span></span>
<span id="cb4-1324"><a href="#cb4-1324" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1325"><a href="#cb4-1325" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1326"><a href="#cb4-1326" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;BBH&lt;/th&gt;</span></span>
<span id="cb4-1327"><a href="#cb4-1327" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;41.4&lt;/td&gt;</span></span>
<span id="cb4-1328"><a href="#cb4-1328" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;45.3&lt;/td&gt;</span></span>
<span id="cb4-1329"><a href="#cb4-1329" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;43.2&lt;/td&gt;</span></span>
<span id="cb4-1330"><a href="#cb4-1330" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1331"><a href="#cb4-1331" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1332"><a href="#cb4-1332" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;TriviaQA&lt;/th&gt;</span></span>
<span id="cb4-1333"><a href="#cb4-1333" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1334"><a href="#cb4-1334" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;57.4&lt;/td&gt;</span></span>
<span id="cb4-1335"><a href="#cb4-1335" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;58.1&lt;/td&gt;</span></span>
<span id="cb4-1336"><a href="#cb4-1336" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1337"><a href="#cb4-1337" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1338"><a href="#cb4-1338" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="category" rowspan="2"&gt;Code&lt;/th&gt;</span></span>
<span id="cb4-1339"><a href="#cb4-1339" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;HumanEval&lt;/th&gt;</span></span>
<span id="cb4-1340"><a href="#cb4-1340" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;26.8&lt;/td&gt;</span></span>
<span id="cb4-1341"><a href="#cb4-1341" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;29.3&lt;/td&gt;</span></span>
<span id="cb4-1342"><a href="#cb4-1342" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;37.2&lt;/td&gt;</span></span>
<span id="cb4-1343"><a href="#cb4-1343" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1344"><a href="#cb4-1344" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1345"><a href="#cb4-1345" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MBPP&lt;/th&gt;</span></span>
<span id="cb4-1346"><a href="#cb4-1346" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;36.8&lt;/td&gt;</span></span>
<span id="cb4-1347"><a href="#cb4-1347" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;49.2&lt;/td&gt;</span></span>
<span id="cb4-1348"><a href="#cb4-1348" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;52.9&lt;/td&gt;</span></span>
<span id="cb4-1349"><a href="#cb4-1349" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1350"><a href="#cb4-1350" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1351"><a href="#cb4-1351" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="category" rowspan="3"&gt;Math&lt;/th&gt;</span></span>
<span id="cb4-1352"><a href="#cb4-1352" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;GSM8K&lt;/th&gt;</span></span>
<span id="cb4-1353"><a href="#cb4-1353" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;31.4&lt;/td&gt;</span></span>
<span id="cb4-1354"><a href="#cb4-1354" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;43.8&lt;/td&gt;</span></span>
<span id="cb4-1355"><a href="#cb4-1355" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;45.0&lt;/td&gt;</span></span>
<span id="cb4-1356"><a href="#cb4-1356" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1357"><a href="#cb4-1357" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1358"><a href="#cb4-1358" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MATH&lt;/th&gt;</span></span>
<span id="cb4-1359"><a href="#cb4-1359" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;10.7&lt;/td&gt;</span></span>
<span id="cb4-1360"><a href="#cb4-1360" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;16.1&lt;/td&gt;</span></span>
<span id="cb4-1361"><a href="#cb4-1361" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;19.8&lt;/td&gt;</span></span>
<span id="cb4-1362"><a href="#cb4-1362" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1363"><a href="#cb4-1363" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1364"><a href="#cb4-1364" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;CMath&lt;/th&gt;</span></span>
<span id="cb4-1365"><a href="#cb4-1365" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1366"><a href="#cb4-1366" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;57.8&lt;/td&gt;</span></span>
<span id="cb4-1367"><a href="#cb4-1367" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;60.2&lt;/td&gt;</span></span>
<span id="cb4-1368"><a href="#cb4-1368" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1369"><a href="#cb4-1369" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1370"><a href="#cb4-1370" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="category" rowspan="2"&gt;Chinese&lt;/th&gt;</span></span>
<span id="cb4-1371"><a href="#cb4-1371" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;C-Eval&lt;/th&gt;</span></span>
<span id="cb4-1372"><a href="#cb4-1372" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1373"><a href="#cb4-1373" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;57.2&lt;/td&gt;</span></span>
<span id="cb4-1374"><a href="#cb4-1374" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;59.9&lt;/td&gt;</span></span>
<span id="cb4-1375"><a href="#cb4-1375" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1376"><a href="#cb4-1376" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-bottom"&gt;</span></span>
<span id="cb4-1377"><a href="#cb4-1377" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;CMMLU&lt;/th&gt;</span></span>
<span id="cb4-1378"><a href="#cb4-1378" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1379"><a href="#cb4-1379" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;58.2&lt;/td&gt;</span></span>
<span id="cb4-1380"><a href="#cb4-1380" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="bold"&gt;58.8&lt;/td&gt;</span></span>
<span id="cb4-1381"><a href="#cb4-1381" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1382"><a href="#cb4-1382" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/tbody&gt;</span></span>
<span id="cb4-1383"><a href="#cb4-1383" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/table&gt;</span></span>
<span id="cb4-1384"><a href="#cb4-1384" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-1385"><a href="#cb4-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1386"><a href="#cb4-1386" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">small</span><span class="dt">&gt;&lt;</span><span class="kw">sup</span><span class="dt">&gt;</span>†<span class="dt">&lt;/</span><span class="kw">sup</span><span class="dt">&gt;</span>The reported parameter counts exclude the embedding parameters.<span class="dt">&lt;/</span><span class="kw">small</span><span class="dt">&gt;</span></span>
<span id="cb4-1387"><a href="#cb4-1387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1388"><a href="#cb4-1388" aria-hidden="true" tabindex="-1"></a>What's different about models trained with Muon? Since we said earlier that Muon is steepest descent under the spectral norm, and the spectral norm is the largest singular value, we thought of monitoring and analyzing singular values. Indeed, we found some interesting signals: parameters trained by Muon have a more uniform distribution of singular values. We use singular value entropy to quantitatively describe this phenomenon:</span>
<span id="cb4-1389"><a href="#cb4-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1390"><a href="#cb4-1390" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1391"><a href="#cb4-1391" aria-hidden="true" tabindex="-1"></a>\begin{equation}H(\boldsymbol{\sigma}) = -\frac{1}{\log n}\sum_{i=1}^n \frac{\sigma_i^2}{\sum_{j=1}^n\sigma_j^2}\log \frac{\sigma_i^2}{\sum_{j=1}^n\sigma_j^2}\end{equation}</span>
<span id="cb4-1392"><a href="#cb4-1392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-1393"><a href="#cb4-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1394"><a href="#cb4-1394" aria-hidden="true" tabindex="-1"></a>Here, $\boldsymbol{\sigma}=(\sigma_1,\sigma_2,\cdots,\sigma_n)$ represents all the singular values of a parameter. Parameters trained by Muon have higher entropy, meaning a more uniform distribution of singular values, which indicates that these parameters are less easily compressed. This suggests that Muon more fully utilizes the potential of the parameters:</span>
<span id="cb4-1395"><a href="#cb4-1395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1396"><a href="#cb4-1396" aria-hidden="true" tabindex="-1"></a><span class="al">![Weights trained by Muon have higher singular value entropy.](figure/3782823216.png)</span></span>
<span id="cb4-1397"><a href="#cb4-1397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1398"><a href="#cb4-1398" aria-hidden="true" tabindex="-1"></a>Another interesting finding is that when we use Muon for fine-tuning (SFT), we might get suboptimal solutions if the pre-training didn't use Muon. Specifically, if both pre-training and fine-tuning use Muon, the performance is the best. But for the other three combinations (Adam+Muon, Muon+Adam, Adam+Adam), the effectiveness doesn't show a clear pattern.</span>
<span id="cb4-1399"><a href="#cb4-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1400"><a href="#cb4-1400" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb4-1401"><a href="#cb4-1401" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;style&gt;</span></span>
<span id="cb4-1402"><a href="#cb4-1402" aria-hidden="true" tabindex="-1"></a><span class="in">  table {   border-collapse: collapse;   width: 100%;   margin: 20px 0;   font-family: Arial, sans-serif;  }  caption {   margin-bottom: 10px;   font-weight: bold;  }  th, td {   padding: 8px;   text-align: center;   border: 1px solid #ddd;  }  th.left-align, td.left-align {   text-align: left;  }  .border-top {   border-top: 2px solid black;  }  .border-bottom {   border-bottom: 2px solid black;  }  .border-right {   border-right: 2px solid black;  }  .border-left {   border-left: 2px solid black;  }  .bold {   font-weight: bold;  }</span></span>
<span id="cb4-1403"><a href="#cb4-1403" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/style&gt;</span></span>
<span id="cb4-1404"><a href="#cb4-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1405"><a href="#cb4-1405" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;table class="table-hover caption-top table"&gt;</span></span>
<span id="cb4-1406"><a href="#cb4-1406" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;caption&gt;Table 6: Examining the impact of optimizer interchangeability between pretraining and SFT phases.&lt;/caption&gt;</span></span>
<span id="cb4-1407"><a href="#cb4-1407" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;thead&gt;</span></span>
<span id="cb4-1408"><a href="#cb4-1408" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1409"><a href="#cb4-1409" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align border-top"&gt;Benchmark (Metric)&lt;/th&gt;</span></span>
<span id="cb4-1410"><a href="#cb4-1410" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-top border-right"&gt;# Shots&lt;/th&gt;</span></span>
<span id="cb4-1411"><a href="#cb4-1411" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-top border-left" colspan="4"&gt;Moonlight-1.2T&lt;/th&gt;</span></span>
<span id="cb4-1412"><a href="#cb4-1412" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1413"><a href="#cb4-1413" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/thead&gt;</span></span>
<span id="cb4-1414"><a href="#cb4-1414" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;tbody&gt;</span></span>
<span id="cb4-1415"><a href="#cb4-1415" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1416"><a href="#cb4-1416" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Pretraining Optimizer&lt;/th&gt;</span></span>
<span id="cb4-1417"><a href="#cb4-1417" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1418"><a href="#cb4-1418" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;Muon&lt;/td&gt;</span></span>
<span id="cb4-1419"><a href="#cb4-1419" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1420"><a href="#cb4-1420" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;Muon&lt;/td&gt;</span></span>
<span id="cb4-1421"><a href="#cb4-1421" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1422"><a href="#cb4-1422" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1423"><a href="#cb4-1423" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1424"><a href="#cb4-1424" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;SFT Optimzier&lt;/th&gt;</span></span>
<span id="cb4-1425"><a href="#cb4-1425" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;-&lt;/td&gt;</span></span>
<span id="cb4-1426"><a href="#cb4-1426" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;Muon&lt;/td&gt;</span></span>
<span id="cb4-1427"><a href="#cb4-1427" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;Muon&lt;/td&gt;</span></span>
<span id="cb4-1428"><a href="#cb4-1428" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1429"><a href="#cb4-1429" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;AdamW&lt;/td&gt;</span></span>
<span id="cb4-1430"><a href="#cb4-1430" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1431"><a href="#cb4-1431" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1432"><a href="#cb4-1432" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MMLU (EM)&lt;/th&gt;</span></span>
<span id="cb4-1433"><a href="#cb4-1433" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot (CoT)&lt;/td&gt;</span></span>
<span id="cb4-1434"><a href="#cb4-1434" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;55.7&lt;/td&gt;</span></span>
<span id="cb4-1435"><a href="#cb4-1435" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;55.3&lt;/td&gt;</span></span>
<span id="cb4-1436"><a href="#cb4-1436" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;50.2&lt;/td&gt;</span></span>
<span id="cb4-1437"><a href="#cb4-1437" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;52.0&lt;/td&gt;</span></span>
<span id="cb4-1438"><a href="#cb4-1438" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1439"><a href="#cb4-1439" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1440"><a href="#cb4-1440" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;HumanEval (Pass@1)&lt;/th&gt;</span></span>
<span id="cb4-1441"><a href="#cb4-1441" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot&lt;/td&gt;</span></span>
<span id="cb4-1442"><a href="#cb4-1442" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;57.3&lt;/td&gt;</span></span>
<span id="cb4-1443"><a href="#cb4-1443" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;53.7&lt;/td&gt;</span></span>
<span id="cb4-1444"><a href="#cb4-1444" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;52.4&lt;/td&gt;</span></span>
<span id="cb4-1445"><a href="#cb4-1445" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;53.1&lt;/td&gt;</span></span>
<span id="cb4-1446"><a href="#cb4-1446" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1447"><a href="#cb4-1447" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1448"><a href="#cb4-1448" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MBPP (Pass@1)&lt;/th&gt;</span></span>
<span id="cb4-1449"><a href="#cb4-1449" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot&lt;/td&gt;</span></span>
<span id="cb4-1450"><a href="#cb4-1450" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;55.6&lt;/td&gt;</span></span>
<span id="cb4-1451"><a href="#cb4-1451" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;55.5&lt;/td&gt;</span></span>
<span id="cb4-1452"><a href="#cb4-1452" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;55.2&lt;/td&gt;</span></span>
<span id="cb4-1453"><a href="#cb4-1453" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;55.2&lt;/td&gt;</span></span>
<span id="cb4-1454"><a href="#cb4-1454" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1455"><a href="#cb4-1455" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-bottom"&gt;</span></span>
<span id="cb4-1456"><a href="#cb4-1456" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align border-bottom"&gt;GSM8K (EM)&lt;/th&gt;</span></span>
<span id="cb4-1457"><a href="#cb4-1457" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom"&gt;5-shot&lt;/td&gt;</span></span>
<span id="cb4-1458"><a href="#cb4-1458" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom bold"&gt;68.0&lt;/td&gt;</span></span>
<span id="cb4-1459"><a href="#cb4-1459" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom"&gt;62.1&lt;/td&gt;</span></span>
<span id="cb4-1460"><a href="#cb4-1460" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom"&gt;64.9&lt;/td&gt;</span></span>
<span id="cb4-1461"><a href="#cb4-1461" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-bottom"&gt;64.6&lt;/td&gt;</span></span>
<span id="cb4-1462"><a href="#cb4-1462" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1463"><a href="#cb4-1463" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/tbody&gt;</span></span>
<span id="cb4-1464"><a href="#cb4-1464" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/table&gt;</span></span>
<span id="cb4-1465"><a href="#cb4-1465" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-1466"><a href="#cb4-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1467"><a href="#cb4-1467" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb4-1468"><a href="#cb4-1468" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;style&gt;</span></span>
<span id="cb4-1469"><a href="#cb4-1469" aria-hidden="true" tabindex="-1"></a><span class="in">  table {   border-collapse: collapse;   width: 100%;   margin: 20px 0;   font-family: Arial, sans-serif;  }  caption {   margin-bottom: 10px;   font-weight: bold;  }  th, td {   padding: 8px;   text-align: center;   border: 1px solid #ddd;  }  th.left-align, td.left-align {   text-align: left;  }  .border-top {   border-top: 2px solid black;  }  .border-bottom {   border-bottom: 2px solid black;  }  .border-right {   border-right: 2px solid black;  }  .border-left {   border-left: 2px solid black;  }  .bold {   font-weight: bold;  }</span></span>
<span id="cb4-1470"><a href="#cb4-1470" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/style&gt;</span></span>
<span id="cb4-1471"><a href="#cb4-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1472"><a href="#cb4-1472" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;table class="table-hover caption-top table"&gt;</span></span>
<span id="cb4-1473"><a href="#cb4-1473" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;caption&gt;Table 7: Comparison of Adam and Muon optimizers applied to the SFT of the Qwen2.5-7B pretrained model.&lt;/caption&gt;</span></span>
<span id="cb4-1474"><a href="#cb4-1474" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;thead&gt;</span></span>
<span id="cb4-1475"><a href="#cb4-1475" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1476"><a href="#cb4-1476" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align border-top"&gt;Benchmark (Metric)&lt;/th&gt;</span></span>
<span id="cb4-1477"><a href="#cb4-1477" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-top border-right"&gt;# Shots&lt;/th&gt;</span></span>
<span id="cb4-1478"><a href="#cb4-1478" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-top border-right"&gt;Adam-SFT&lt;/th&gt;</span></span>
<span id="cb4-1479"><a href="#cb4-1479" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-top"&gt;Muon-SFT&lt;/th&gt;</span></span>
<span id="cb4-1480"><a href="#cb4-1480" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1481"><a href="#cb4-1481" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1482"><a href="#cb4-1482" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;Pretrained Model&lt;/th&gt;</span></span>
<span id="cb4-1483"><a href="#cb4-1483" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-right"&gt;-&lt;/th&gt;</span></span>
<span id="cb4-1484"><a href="#cb4-1484" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="border-left" colspan="2"&gt;Qwen2.5-7B&lt;/th&gt;</span></span>
<span id="cb4-1485"><a href="#cb4-1485" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1486"><a href="#cb4-1486" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/thead&gt;</span></span>
<span id="cb4-1487"><a href="#cb4-1487" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;tbody&gt;</span></span>
<span id="cb4-1488"><a href="#cb4-1488" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-top"&gt;</span></span>
<span id="cb4-1489"><a href="#cb4-1489" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MMLU (EM)&lt;/th&gt;</span></span>
<span id="cb4-1490"><a href="#cb4-1490" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot (CoT)&lt;/td&gt;</span></span>
<span id="cb4-1491"><a href="#cb4-1491" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;71.4&lt;/td&gt;</span></span>
<span id="cb4-1492"><a href="#cb4-1492" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;70.8&lt;/td&gt;</span></span>
<span id="cb4-1493"><a href="#cb4-1493" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1494"><a href="#cb4-1494" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1495"><a href="#cb4-1495" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;HumanEval (Pass@1)&lt;/th&gt;</span></span>
<span id="cb4-1496"><a href="#cb4-1496" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot&lt;/td&gt;</span></span>
<span id="cb4-1497"><a href="#cb4-1497" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;79.3&lt;/td&gt;</span></span>
<span id="cb4-1498"><a href="#cb4-1498" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;77.4&lt;/td&gt;</span></span>
<span id="cb4-1499"><a href="#cb4-1499" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1500"><a href="#cb4-1500" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr&gt;</span></span>
<span id="cb4-1501"><a href="#cb4-1501" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align"&gt;MBPP (Pass@1)&lt;/th&gt;</span></span>
<span id="cb4-1502"><a href="#cb4-1502" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right"&gt;0-shot&lt;/td&gt;</span></span>
<span id="cb4-1503"><a href="#cb4-1503" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right bold"&gt;71.9&lt;/td&gt;</span></span>
<span id="cb4-1504"><a href="#cb4-1504" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td&gt;71.6&lt;/td&gt;</span></span>
<span id="cb4-1505"><a href="#cb4-1505" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1506"><a href="#cb4-1506" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;tr class="border-bottom"&gt;</span></span>
<span id="cb4-1507"><a href="#cb4-1507" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;th class="left-align border-bottom"&gt;GSM8K (EM)&lt;/th&gt;</span></span>
<span id="cb4-1508"><a href="#cb4-1508" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom"&gt;5-shot&lt;/td&gt;</span></span>
<span id="cb4-1509"><a href="#cb4-1509" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-right border-bottom bold"&gt;89.8&lt;/td&gt;</span></span>
<span id="cb4-1510"><a href="#cb4-1510" aria-hidden="true" tabindex="-1"></a><span class="in">      &lt;td class="border-bottom"&gt;85.8&lt;/td&gt;</span></span>
<span id="cb4-1511"><a href="#cb4-1511" aria-hidden="true" tabindex="-1"></a><span class="in">    &lt;/tr&gt;</span></span>
<span id="cb4-1512"><a href="#cb4-1512" aria-hidden="true" tabindex="-1"></a><span class="in">  &lt;/tbody&gt;</span></span>
<span id="cb4-1513"><a href="#cb4-1513" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/table&gt;</span></span>
<span id="cb4-1514"><a href="#cb4-1514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-1515"><a href="#cb4-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1516"><a href="#cb4-1516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1517"><a href="#cb4-1517" aria-hidden="true" tabindex="-1"></a>This phenomenon suggests that some special initializations are unfavorable for Muon, and conversely, there might be initializations that are more favorable for Muon. We are still exploring the underlying principles.</span>
<span id="cb4-1518"><a href="#cb4-1518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1519"><a href="#cb4-1519" aria-hidden="true" tabindex="-1"></a><span class="fu">## Some more thoughts</span></span>
<span id="cb4-1520"><a href="#cb4-1520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1521"><a href="#cb4-1521" aria-hidden="true" tabindex="-1"></a>Overall, in our experiments, Muon's performance compared to Adam is very competitive. As a new optimizer that differs significantly from Adam in form, Muon's performance is not just "noteworthy" but indicates that it might have captured some essential characteristics.</span>
<span id="cb4-1522"><a href="#cb4-1522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1523"><a href="#cb4-1523" aria-hidden="true" tabindex="-1"></a>Previously, there was a view in the community that Adam performs well because mainstream model architecture improvements are "overfitting" to Adam. This view likely originated from <span class="co">[</span><span class="ot">*Neural Networks (Maybe) Evolved to Make Adam The Best Optimizer*</span><span class="co">](https://parameterfree.com/2020/12/06/neural-network-maybe-evolved-to-make-adam-the-best-optimizer/)</span>. It seems absurd at first glance but is actually profound. Think about it: when we try to improve a model, we train it once with Adam to see the effect, keeping it if it's good and discarding it otherwise. But is the good effect due to its inherent superiority or because it matches Adam better?</span>
<span id="cb4-1524"><a href="#cb4-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1525"><a href="#cb4-1525" aria-hidden="true" tabindex="-1"></a>This is quite thought-provoking. Certainly not all, but at least some works perform better because they align better with Adam, so over time, model architectures evolve in a direction favorable to Adam. In this context, an optimizer significantly different from Adam that can "break out" is particularly worth attention and reflection. Note that neither I nor my company are the proposers of Muon, so these remarks are purely "heartfelt words" without any self-promotion.</span>
<span id="cb4-1526"><a href="#cb4-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1527"><a href="#cb4-1527" aria-hidden="true" tabindex="-1"></a>What work remains for Muon? Quite a bit remains. For instance, we need to analyze further the aforementioned issue that "Adam pre-training + Muon fine-tuning" does not work well, especially since most currently publicly available model weights are trained with Adam. If Muon fine-tuning doesn't work well on Adam-pretrained models, it will hurt its popularity. Of course, we can also take this opportunity to deepen our understanding of Muon (this is bug-oriented learning).</span>
<span id="cb4-1528"><a href="#cb4-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1529"><a href="#cb4-1529" aria-hidden="true" tabindex="-1"></a>Another thought I had is that Muon is based on the spectral norm, which is the maximum singular value. In fact, there are many norms based on singular values, such as the <span class="co">[</span><span class="ot">Schatten norms</span><span class="co">](https://en.wikipedia.org/wiki/Schatten_norm)</span> and the <span class="co">[</span><span class="ot">Ky Fan norms</span><span class="co">](https://en.wikipedia.org/wiki/Ky_Fan_norm)</span>. Generalizing to these more general norms and then tuning parameters could theoretically yield even better results. Additionally, after releasing Moonlight, some readers asked how to adapt <span class="co">[</span><span class="ot">µP (maximal update parametrization)</span><span class="co">](https://papers.cool/arxiv/2203.03466)</span> to Muon, another problem for furher research.</span>
<span id="cb4-1530"><a href="#cb4-1530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1531"><a href="#cb4-1531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1532"><a href="#cb4-1532" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metadata {.appendix}</span></span>
<span id="cb4-1533"><a href="#cb4-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-1534"><a href="#cb4-1534" aria-hidden="true" tabindex="-1"></a>These are several blogposts on the homepage of Jianlin Su (苏剑林) that I selected because they are relevant for understanding Muon. I organized them in a chronological sequence, and simplified certain derivations and made certain explanations easier to follow.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>