<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2024-04-11">
<meta name="description" content="I teach you how to do probability calculations and gigantic integrals in the ‘field-theoretic style’, done in exhaustive details. I aim for clarity, pointing out every pitfall that I have fallen into so that you don’t have to.">

<title>How to do field-theoretic calculations – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-493ec8732bc442be923a7677f0a4f8b4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="How to do field-theoretic calculations – Yuxi on the Wired">
<meta property="og:description" content="I teach you how to do probability calculations and gigantic integrals in the ‘field-theoretic style’, done in exhaustive details. I aim for clarity, pointing out every pitfall that I have fallen into so that you don’t have to.">
<meta property="og:image" content="https://yuxi.ml/sketches/posts/field-theory-how-to/img/blog icon.jpg">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta name="twitter:title" content="How to do field-theoretic calculations – Yuxi on the Wired">
<meta name="twitter:description" content="I teach you how to do probability calculations and gigantic integrals in the ‘field-theoretic style’, done in exhaustive details. I aim for clarity, pointing out every pitfall that I have fallen into so that you don’t have to.">
<meta name="twitter:image" content="https://yuxi.ml/sketches/posts/field-theory-how-to/img/blog icon.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../logs/index.html"> 
<span class="menu-text">Logs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi_liu@berkeley.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../feeds.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">How to do field-theoretic calculations</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          I teach you how to do probability calculations and gigantic integrals in the ‘field-theoretic style’, done in exhaustive details. I aim for clarity, pointing out every pitfall that I have fallen into so that you don’t have to.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">math</div>
                <div class="quarto-category">physics</div>
                <div class="quarto-category">scaling</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 11, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 16, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-recipe-of-field-theoretic-calculations." id="toc-the-recipe-of-field-theoretic-calculations." class="nav-link active" data-scroll-target="#the-recipe-of-field-theoretic-calculations.">The recipe of field-theoretic calculations.</a></li>
  <li><a href="#sanovs-theorem" id="toc-sanovs-theorem" class="nav-link" data-scroll-target="#sanovs-theorem">Sanov’s theorem</a>
  <ul class="collapse">
  <li><a href="#statement-of-sanovs-theorem" id="toc-statement-of-sanovs-theorem" class="nav-link" data-scroll-target="#statement-of-sanovs-theorem">Statement of Sanov’s theorem</a></li>
  <li><a href="#field-theoretic-interpretation" id="toc-field-theoretic-interpretation" class="nav-link" data-scroll-target="#field-theoretic-interpretation">Field-theoretic interpretation</a></li>
  <li><a href="#field-theoretic-calculation" id="toc-field-theoretic-calculation" class="nav-link" data-scroll-target="#field-theoretic-calculation">Field-theoretic calculation</a></li>
  </ul></li>
  <li><a href="#overlap-matrix" id="toc-overlap-matrix" class="nav-link" data-scroll-target="#overlap-matrix">Overlap matrix</a>
  <ul class="collapse">
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#field-theoretic-interpretation-1" id="toc-field-theoretic-interpretation-1" class="nav-link" data-scroll-target="#field-theoretic-interpretation-1">Field-theoretic interpretation</a></li>
  <li><a href="#field-theoretic-calculation-1" id="toc-field-theoretic-calculation-1" class="nav-link" data-scroll-target="#field-theoretic-calculation-1">Field-theoretic calculation</a></li>
  </ul></li>
  <li><a href="#easy-results" id="toc-easy-results" class="nav-link" data-scroll-target="#easy-results">Easy results</a>
  <ul class="collapse">
  <li><a href="#asymptotics-of-spherical-volumes" id="toc-asymptotics-of-spherical-volumes" class="nav-link" data-scroll-target="#asymptotics-of-spherical-volumes">Asymptotics of spherical volumes</a></li>
  <li><a href="#cramérs-theorem" id="toc-cramérs-theorem" class="nav-link" data-scroll-target="#cramérs-theorem">Cramér’s theorem</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<p>General references: <span class="citation" data-cites="mezardInformationPhysicsComputation2009 meiSTAT260MeanField2021">(<a href="#ref-mezardInformationPhysicsComputation2009" role="doc-biblioref">Mézard and Montanari 2009</a>; <a href="#ref-meiSTAT260MeanField2021" role="doc-biblioref">Mei 2021</a>)</span></p>
<p>When I was studying machine learning theory, I often encounter problems in high-dimensional probability and statistics, and here and there, I would meet with a confusing statement like “let’s do a field-theoretic calculation”. Field theory? I don’t see any gravitational wave or electromagnetic wave!</p>
<p>It turns out that “field-theoretic calculation” does mean something like a field, but in a highly abstracted form. It is not well-described in the literature, and it took me great effort to understand what is going on. The calculations are long, arduous, and filled with opportunities for mistakes.</p>
<p>Still, if you are going to do machine learning theory (as I am), then learning it is a must. This essay is a practical introduction to field-theoretic calculations through detailed examples, including Sanov’s theorem and the analysis of high-dimensional random vectors using overlap matrices. I aim for clarity, pointing out every pitfall that I have fallen into so that you don’t have to.</p>
<p>While the essay assumes familiarity with basic probability, calculus, and linear algebra, it aims to provide a self-contained and accessible introduction to the field. Readers are encouraged to actively engage with the examples, referring back to the provided recipe for field-theoretic calculations as needed.</p>
<section id="the-recipe-of-field-theoretic-calculations." class="level2">
<h2 class="anchored" data-anchor-id="the-recipe-of-field-theoretic-calculations.">The recipe of field-theoretic calculations.</h2>
<p>Here is the reference. You should not read this directly. Instead, you should go directly to the examples below and refer back to this as you go along.</p>
<ol type="1">
<li>To calculate: a massive integral of the form</li>
</ol>
<p><span class="math display">\[
\underbrace{\int\cdots\int}_{\text{$N \to \infty$, with constraint $C$}} (\text{something}) d^N x
\]</span></p>
<ol start="2" type="1">
<li>The constraint <span class="math inline">\(C\)</span> is handled by introducing a Dirac delta factor:</li>
</ol>
<p><span class="math display">\[
=_{\ln} \underbrace{\int\cdots\int}_{\text{$N \to \infty$}} (\text{something}) \times \delta^{(n)}(C' - C)
\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of conditions within <span class="math inline">\(C\)</span>. For example, if the constraint says <span class="math inline">\(\sum_i x_i^2 = 1\)</span>, then <span class="math inline">\(n=1\)</span>. If the constraint also says <span class="math inline">\(\sum_{ij} x_ix_j = 0\)</span>, then <span class="math inline">\(n=2\)</span>, and so on.</p>
<ol start="3" type="1">
<li>Express the Dirac delta function as a Fourier transform using <span class="math inline">\(\delta^{(n)}(x) = \frac{1}{(2\pi)^n}\int_{\mathbb{R}^n} e^{-i x \lambda} d\lambda\)</span>, then exchange the order of integral.</li>
<li>Put the inner integral into an exponent, and do some rewriting, resulting in something like</li>
</ol>
<p><span class="math display">\[
=_{\ln} \underbrace{\int\cdots\int}_{\text{$n$}} (\text{something unimportant}) e^{N \ln \int(\cdots)d^N x} d^n\lambda
\]</span></p>
<p>Define <span class="math inline">\(S[\lambda] := -\ln \int(\cdots)d^N x\)</span>, which is sometimes called the <strong>field free energy</strong>.</p>
<ol type="1">
<li>Argue, at large <span class="math inline">\(N\)</span>, the integral is dominated by the point where <span class="math inline">\(\nabla S[\lambda] = 0\)</span>. This has many names: method of steepest descent, saddle point method, stationary point method, stationary-phase method, etc.</li>
<li>Write down <span class="math inline">\(\nabla S = 0\)</span>, and give it the fancy name of <strong>mean field equation</strong>.</li>
<li>Solve the mean field equation to be some <span class="math inline">\(\lambda^*\)</span>.</li>
<li>Declare the result to be</li>
</ol>
<p><span class="math display">\[=_{\ln} e^{-N S[\lambda^*]}\]</span></p>
<p>Here, we use the notation <span class="math inline">\(=_{\ln}\)</span> to mean that they have the same exponential rate. That is, <span class="math inline">\(f(N) =_{\ln} g(N)\)</span> means that</p>
<p><span class="math display">\[
\lim_{N \to \infty} \frac 1N \ln f = \lim_{N \to \infty}  \frac 1N \ln g
\]</span></p>
</section>
<section id="sanovs-theorem" class="level2">
<h2 class="anchored" data-anchor-id="sanovs-theorem">Sanov’s theorem</h2>
<section id="statement-of-sanovs-theorem" class="level3">
<h3 class="anchored" data-anchor-id="statement-of-sanovs-theorem">Statement of Sanov’s theorem</h3>
<p><a href="https://en.wikipedia.org/wiki/Sanov%27s_theorem">Sanov’s theorem</a> concerns the large deviation principle for IID samples from a multinomial distribution.</p>
<p>To see how Sanov’s theorem works, let’s consider an example. Say you are working at a dice factory, and your job is to quality-assure dices. An ideal dice should have all <span class="math inline">\(p_i = 1/6\)</span>, and your job is to test that a given real dice has <span class="math inline">\(p_i \approx 1/6\)</span>. Since you are not able to observe <span class="math inline">\(p\)</span> directly, you can only throw the dice for <span class="math inline">\(N\)</span> rounds, and compute the empirical distribution <span class="math inline">\(\hat p\)</span> from the outcomes <span class="math inline">\(x_1, ..., x_N\)</span>.</p>
<p>For example, if you threw it 7 times and you got every number once except <span class="math inline">\(1\)</span> twice, then <span class="math inline">\(\hat p = (2/7, 1/7, ..., 1/7)\)</span>.</p>
<p>Because <span class="math inline">\(\hat p\)</span> depends on the throws, it is itself a random variable. Intuitively, we should expect that <span class="math inline">\(\hat p\)</span> converging to <span class="math inline">\(p\)</span> as <span class="math inline">\(N \to \infty\)</span>. Sanov’s theorem states that it is exponentially unlikely for us to be far from the right answer, with the rate of exponential convergence depending on how far we are mistaken. The further <span class="math inline">\(\hat p\)</span> is from <span class="math inline">\(p\)</span>, the faster we can eliminate that possibility.</p>
<p>Let’s state this more formally.</p>
<p>Define:</p>
<ul>
<li><span class="math inline">\(p_{1:n}\)</span> is a probability vector.</li>
<li><span class="math inline">\(x_{1:N}\)</span> are IID samples from a multinomial distribution with probability vector <span class="math inline">\(p_{1:n}\)</span>.</li>
<li><span class="math inline">\(\hat{p}\)</span> is the empirical distribution derived from these samples.</li>
<li><span class="math inline">\(\Delta_n\)</span> is the probability simplex.</li>
</ul>
<p>As the number of samples <span class="math inline">\(N\)</span> approaches infinity, the probability of observing a specific empirical distribution <span class="math inline">\(\hat{p}\)</span> within a closed subset <span class="math inline">\(A \subset \Delta_n\)</span> is characterized by the Kullback-Leibler (KL) divergence <span class="math inline">\(D_{KL}(\hat{p} \| p)\)</span> between the empirical distribution <span class="math inline">\(\hat{p}\)</span> and the true distribution <span class="math inline">\(p\)</span>.</p>
<p>Formally stated:</p>
<div id="thm-sanov" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Sanov)</strong></span> <span class="math display">\[\lim_{N \to \infty} \frac{1}{N} \ln Pr(\hat{p} \in A) = -\inf_{\hat{p} \in A} D_{KL}(\hat{p} \| p)\]</span></p>
</div>
<p>We can get an intuitive feel for Sanov’s theorem by the following video.</p>
<p>Let us fix <span class="math inline">\(n = 3\)</span> and <span class="math inline">\(p = (0.2, 0.3, 0.5)\)</span>. We set <span class="math inline">\(n = 3\)</span> because <span class="math inline">\(\Delta_3\)</span> has two dimensions, which allows us to actually plot it.</p>
<p>If we sample for <span class="math inline">\(N\)</span> times from the multinomial distribution defined by <span class="math inline">\(p\)</span>, and plot the heatmap of the samples within <span class="math inline">\(\Delta_2\)</span> (shown as a black triangle), we notice that as <span class="math inline">\(N \rightarrow \infty\)</span>, the distribution converges to a gaussian around the point <span class="math inline">\((0.2,0.3,0.5)\)</span>, with the contours converging in shape to ellipses, with radii converging as <span class="math inline">\(1 / \sqrt{N}\)</span>.</p>
<p>Meanwhile, the separation between the discrete points converge as <span class="math inline">\(1 / N\)</span>, and so the discrete multinomial distribution converges to a continuous gaussian distribution.</p>
<p>So, roughly speaking, we have approximately</p>
<p><span class="math display">\[
Pr(\hat p) \propto e^{- (\hat p - p)^T NV (\hat p - p)}
\]</span></p>
<p>for some covariance matrix <span class="math inline">\(V\)</span> that describes the shape of the ellipses.</p>
<video controls="" width="100%">
<source src="figure/Sanov_convergence.webm" type="video/webm">
</video>
<p>Now, if we boldly proceed, we would obtain</p>
<p><span class="math display">\[
\frac 1N \ln Pr(\hat p) \sim -(\hat p - p)^T A (\hat p - p)
\]</span></p>
<p>This is not quite right, because for any finite <span class="math inline">\(N\)</span>, there are only finitely many possible <span class="math inline">\(\hat p\)</span>. So generally <span class="math inline">\(Pr(\hat p) = 0\)</span>, and to fix this, instead of writing <span class="math inline">\(Pr(\hat p)\)</span>, we should write <span class="math inline">\(Pr(\hat p \in A)\)</span> for some closed subset <span class="math inline">\(A \subset \Delta_n\)</span>.</p>
<p>Next, since given any two exponentially decaying functions <span class="math inline">\(f(N) \propto e^{-kN}, g(N) \propto e^{-lN}\)</span>, we have <span class="math inline">\(f \gg g\)</span> iff <span class="math inline">\(k &lt; l\)</span>, we only need to account for the least unlikely case:</p>
<p><span class="math display">\[
\lim_N \frac 1N \ln Pr(\hat p \in A) \approx \max_{q\in A} (-(q-p)^T A (q-p)) \approx - \min_{q\in A} D_{KL}(q \| p)
\]</span></p>
<blockquote class="blockquote">
<p>Any large deviation is done in the least unlikely of all the unlikely ways!</p>
<p><span class="citation" data-cites="denhollanderLargeDeviations2008">(<a href="#ref-denhollanderLargeDeviations2008" role="doc-biblioref">Den Hollander 2008, 10</a>)</span></p>
</blockquote>
</section>
<section id="field-theoretic-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="field-theoretic-interpretation">Field-theoretic interpretation</h3>
<p>We can interpret this problem through the lens of statistical physics. Imagine a system of <span class="math inline">\(N\)</span> identical particles. Each particle has <span class="math inline">\(n\)</span> degrees of freedom. The state of a particle can be one of the unit vectors in <span class="math inline">\(\mathbb{R}^n\)</span>. The problem is to find the distribution of the average state of all the particles.</p>
<p>The particles are completely independent of each other – no interaction whatsoever. This is a “no interaction field”. The only thing saving the example from irrelevance is that the particles are still influenced by something – an externally-imposed potential field, biasing the distribution of each particle’s state independently and identically (IID).</p>
<p>As typical in statistical mechanics, we suppose each particle is distributed according to the Boltzmann distribution with temperature <span class="math inline">\(1\)</span>. This then tells us that the potential field <span class="math inline">\(V\)</span> satisfies</p>
<p><span class="math display">\[p_i = e^{-V_i}/Z\]</span></p>
<p>That is, we can write <span class="math inline">\(V_i = -\ln p_i - \ln Z\)</span> where <span class="math inline">\(Z\)</span> is a normalizing constant (<strong>partition function</strong> again).</p>
<p>The average energy per particle (<strong>order parameter</strong>) is then</p>
<p><span class="math display">\[\bar E \sum_i \bar p_i V_i = -\sum_i \bar p_i \ln p_i - \ln Z\]</span></p>
<p>The minimum is at <span class="math inline">\(\bar p_i = p_i\)</span>, and if you have seen some statistical mechanics before, you would notice a pattern: a fluctuation in the average energy per particle should be proportional to <span class="math inline">\(e^{-N(\bar E  - \bar E_{min})}\)</span>. This is not quite right, in the sense that <span class="math inline">\(\bar E - \bar E_{min}\)</span> is not the rate function, but it converges to the rate function in a neighborhood of <span class="math inline">\(p\)</span>.</p>
</section>
<section id="field-theoretic-calculation" class="level3">
<h3 class="anchored" data-anchor-id="field-theoretic-calculation">Field-theoretic calculation</h3>
<p>This section is based on <span class="citation" data-cites="mezardInformationPhysicsComputation2009">(<a href="#ref-mezardInformationPhysicsComputation2009" role="doc-biblioref">Mézard and Montanari 2009, sec. 4.7</a>)</span>.</p>
<p>We use field-theoretic techniques to compute the rate function, treating both the empirical distribution <span class="math inline">\(\hat{p}\)</span> and the true distribution <span class="math inline">\(p\)</span> as fields over a finite set of points:</p>
<p><span class="math display">\[p: \{1, 2, ..., n\} \to \mathbb{R}\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="formulate a constraint">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
formulate a constraint
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We really want to write <span class="math inline">\(Pr(\hat{p} = q)\)</span>, even though as we noted, this does not make sense. To fix this problem, we introduce an infinitesimal fudge factor of <span class="math inline">\(\epsilon\)</span>.</p>
<p>That is, we want to know the probability of observing an empirical distribution <span class="math inline">\(\hat{p}\)</span> within an infinitesimal neighborhood of a specific distribution <span class="math inline">\(q\)</span>:</p>
<p><span class="math display">\[Pr(\hat{p} =_{\epsilon} q)\]</span></p>
<p>where <span class="math inline">\(=\epsilon\)</span> means that <span class="math inline">\(\hat{p}_i \in q_i \pm \epsilon\)</span> for each <span class="math inline">\(i = 1, 2, \dots, n\)</span>, or more roughly, that they are within an <span class="math inline">\(O(\epsilon)\)</span> distance of each other.</p>
<p>Thus, we can write the desired problem in the form of a constrained integral:</p>
<p><span class="math display">\[
Pr(\hat p =_\epsilon q) = \int_{\mathbb{R}^N} \rho(x) d^N x \left( 1[\hat p(x) = q]\right)
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="introduce a Dirac delta">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
introduce a Dirac delta
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Next, we need to move the constraint from the integral domain to the integrand, in preparation for exchanging the order of integral. We do this by introducing a Dirac delta factor.</p>
<p>For any fixed tiny, but non-zero, <span class="math inline">\(\epsilon\)</span>, we have</p>
<p><span class="math display">\[
\int_{\mathbb{R}^N} \rho(x) d^N x \left( 1[\hat p(x) = q]\right) =_{\ln} \int_{\mathbb{R}^N} \rho(x) d^N x \left( \frac{1[\hat p(x) = q]}{\mathrm{Vol}(\text{ball with radius } \epsilon)}\right)
\]</span></p>
<p>because even though <span class="math inline">\(\frac{1[\hat p(x) = q]}{\mathrm{Vol}(\text{ball with radius } \epsilon)}\)</span> is huge, it is still <span class="math inline">\(O(1)\)</span>, and <span class="math inline">\(\lim_{N\to\infty} \frac{(\text{huge but fixed})}{N} = 0\)</span>.</p>
<p><span class="math display">\[
= \int_{\mathbb{R}^N} \rho(x) d^N x \delta^{(n)}(\hat p(x) - q)
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="do a Fourier transform">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
do a Fourier transform
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Next, we do the Fourier transform of the Dirac delta factor. This step is mostly mechanical.</p>
<p><span class="math display">\[
\begin{aligned}
\delta^{(n)} (\hat p(x) - q) &amp;= \delta^{(n)} (N\hat p(x) - N q) \\
&amp;= \prod_{k=1}^n \delta \left( \sum_{j=1}^N 1[x_j = k] - Nq_k \right) \\
&amp;= \prod_{k=1}^n \frac{1}{2\pi} \int d\lambda_k e^{i\lambda_k \left( \sum_{j=1}^N 1[x_j = k] - Nq_k \right)} \\
&amp;=_{\ln} \int d^n \lambda e^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1[x_j = k] - Nq_k \right)}
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="exchange the order of integration">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
exchange the order of integration
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Now we exchange the order of integration.</p>
<p><span class="math display">\[
\begin{aligned}
Pr(\hat p =_\epsilon q) &amp;= {\color{red}\int_{\mathbb{R}^N} \rho(x) d^N x} {\color{red}\int d^n \lambda} e^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1[x_j = k] - Nq_k \right)} \\
&amp;= \int d^n \lambda \int_{\mathbb{R}^N} \rho(x) d^N xe^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1[x_j = k] - Nq_k \right)} \\
&amp;= \int d^n \lambda e^{-iN \sum_{k=1}^n \lambda_k q_k}  \int_{\mathbb{R}^N} \rho(x) d^N x e^{i \sum_{j=1}^N \sum_{k=1}^n \lambda_k 1[x_j = k]} \\
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="inner integral">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
inner integral
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The inner integral splits because of the independence of <span class="math inline">\(x_1, ..., x_N\)</span>.</p>
<p><span class="math display">\[
\int_{\mathbb{R}^N} \rho(x) d^N x e^{i \sum_{j=1}^N \sum_{k=1}^n \lambda_k 1[x_j = k]} = \prod_{j=1}^N \langle e^{i \sum_{k=1}^n \lambda_k 1[x_j = k]}\rangle_{x_j}
\]</span></p>
<p>where the angled bracket denotes a probability expectation, and the subscript <span class="math inline">\(x_j\)</span> denotes what we are taking the expectation over. Because all <span class="math inline">\(x_j\)</span> have the same distribution, it is equal to</p>
<p><span class="math display">\[
\langle e^{i \sum_{k=1}^n \lambda_k 1[x_j = k]}\rangle_{x_1}^N = \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)^N = e^{N \ln \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)}
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="outer integral">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
outer integral
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
Pr(\hat p =_\epsilon q) &amp;= \int d^n \lambda e^{-iN \sum_{k=1}^n \lambda_k q_k + N \ln \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)} \\
&amp;= \int d^n \lambda e^{NS[\lambda]}
\end{aligned}
\]</span></p>
<p>where the field free energy is</p>
<p><span class="math display">\[S[\lambda] = \ln \left( \sum_{k\in 1:n}p_k e^{i \lambda_k}\right)-i\sum_{k\in 1:n} \lambda_k q_k\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="the mean field equation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
the mean field equation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The dominant contribution to the integral arises from the saddle point of the action, which corresponds to the solution of the mean field equation</p>
<p><span class="math display">\[\nabla_{\lambda} S = 0\]</span></p>
<p>The mean field equation is solved by some <span class="math inline">\(\lambda^*\)</span> satisfying:</p>
<p><span class="math display">\[\begin{cases}
i\lambda_k^* = \ln(C q_k/p_k) \\
C = \sum_k p_k e^{i\lambda_k^*}
\end{cases}
\]</span></p>
<p>Unfortunately, it is difficult to solve this in closed form, but we are on a lucky break: plugging them back to <span class="math inline">\(S[\lambda^*]\)</span> gives us a clean solution:</p>
<p>Plugging those back to <span class="math inline">\(S\)</span>, we find that <span class="math display">\[S[\lambda^*] = -\sum_{k=1}^n q_k \ln(q_k/p_k) = -D_{KL}(q\| p)\]</span></p>
</div>
</div>
</div>
<p>Conclusion</p>
<p><span class="math display">\[Pr(\hat p =_{\epsilon} q) =_{\ln} e^{NS[\lambda^*]} = e^{-ND_{KL}(q \| p)}\]</span></p>
<blockquote class="blockquote">
<p>The reader who has never encountered this type of reasoning before may wonder why use such an indirect approach. It turns out that it is a very common formalism in statistical physics, where similar methods are also applied, under the name ‘field theory’, to continuous spaces <span class="math inline">\(\mathcal X\)</span> (some implicit discretization is then usually assumed at intermediate steps, and the correct definition of a continuum limit is often not obvious). In particular, the reader interested in the statistical-physics approach to optimization problems or information theory will often find this type of calculation in research papers. One of the advantages of this approach is that it provides a formal solution to a large variety of problems. The quantity to be computed is expressed in an integral form. In problems that have a ‘mean-field’ structure, the dimension of the space over which the integration is performed does not depend upon N. Therefore its leading exponential behaviour at large N can be obtained by saddle point methods. The reader who wants to get some practice with this approach is invited to ‘derive’ the various theorems and corollaries of this chapter in this way.</p>
<p><span class="citation" data-cites="mezardInformationPhysicsComputation2009">(<a href="#ref-mezardInformationPhysicsComputation2009" role="doc-biblioref">Mézard and Montanari 2009, sec. 4.7</a>)</span></p>
</blockquote>
</section>
</section>
<section id="overlap-matrix" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="overlap-matrix">Overlap matrix</h2>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>We investigate the properties of a set of <span class="math inline">\(k\)</span> random vectors sampled uniformly from a high-dimensional sphere as the dimension <span class="math inline">\(N\)</span> approaches infinity. Let <span class="math inline">\(\sigma_1, ..., \sigma_k\)</span> be these vectors, each belonging to <span class="math inline">\(\mathbb{R}^N\)</span> with a norm of <span class="math inline">\(\sqrt{N}\)</span>, and let <span class="math inline">\(\sigma\)</span> be the matrix formed by concatenating these vectors: <span class="math inline">\(\sigma = [\sigma_1, ..., \sigma_k]\)</span>.</p>
<p>Since <span class="math inline">\(E[\sigma] = 0\)</span>, we focus on analyzing the variance of <span class="math inline">\(\sigma\)</span>, divided by <span class="math inline">\(N\)</span>. Define the matrix <span class="math inline">\(\bar{Q}\)</span> as the normalized outer product of <span class="math inline">\(\sigma\)</span>:</p>
<p><span class="math display">\[\bar Q := \sigma^T \sigma/N = \frac 1N
\begin{bmatrix}
\sigma_1^T\sigma_1 &amp; \sigma_1^T\sigma_2 &amp; \cdots &amp;\sigma_1^T\sigma_k\\
\sigma_2^T\sigma_1 &amp; \sigma_2^T\sigma_2 &amp; \cdots &amp;\sigma_2^T\sigma_k \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\sigma_k^T\sigma_1 &amp; \sigma_k^T\sigma_2 &amp; \cdots &amp; \sigma_k^T\sigma_k
\end{bmatrix}\]</span></p>
<p>We know that <span class="math inline">\(\bar{Q}\)</span> is symmetric, has all entries within the range <span class="math inline">\([-1, +1]\)</span>, and has diagonal entries equal to <span class="math inline">\(+1\)</span>. Our goal is to uncover further properties of this matrix as <span class="math inline">\(N\)</span> becomes very large.</p>
<p>Let <span class="math inline">\(Q\)</span> be an arbitrary symmetric matrix with entries in the range <span class="math inline">\([-1, +1]\)</span> and with diagonal entries equal to <span class="math inline">\(+1\)</span>. We aim to calculate the rate function <span class="math inline">\(S\)</span> that quantifies the probability of observing an empirical distribution <span class="math inline">\(\bar{Q}\)</span> that is close to <span class="math inline">\(Q\)</span> as <span class="math inline">\(N\to\infty\)</span>:</p>
<p><span class="math display">\[Pr(\bar Q =_\epsilon Q) =_{\ln} e^{-NS[Q]}\]</span></p>
<p>More rigorously, we seek to determine:</p>
<p><span class="math display">\[\lim _{\epsilon \rightarrow 0} \lim _{N \rightarrow \infty} \frac{1}{N} \log Pr \left(\bar{Q}(\sigma)_{i j} \in\left[Q_{i j}-\epsilon, Q_{i j}+\epsilon\right], \forall i, j\right)\]</span></p>
</section>
<section id="field-theoretic-interpretation-1" class="level3">
<h3 class="anchored" data-anchor-id="field-theoretic-interpretation-1">Field-theoretic interpretation</h3>
<p>We can interpret this problem through the lens of statistical physics. Imagine a system of <span class="math inline">\(N\)</span> identical particles, each possessing <span class="math inline">\(k\)</span> degrees of freedom. For instance, the <span class="math inline">\(i\)</span>-th particle has degrees of freedom represented by <span class="math inline">\((\sigma_{1, i}, \dots, \sigma_{k, i})\)</span>.</p>
<p>These particles interact with each other equally, regardless of their spatial separation. This “infinite-range interaction” imposes a global constraint on the system, ensuring a form of “average kinetic energy conservation”. We express this constraint as:</p>
<p><span class="math display">\[\forall j\in 1:k, \quad \sum_{i \in 1:N}\sigma_{j, i}^2 = N\]</span></p>
<p>To illustrate, if we consider <span class="math inline">\(\sigma_{j, i}\)</span> as the type-<span class="math inline">\(j\)</span> velocity of the <span class="math inline">\(i\)</span>-th particle, then the constraint implies that the average type-<span class="math inline">\(j\)</span> kinetic energy per particle remains constant at <span class="math inline">\(1/2\)</span>, even as the number of particles increases.</p>
<p>Since <span class="math inline">\(\bar{Q}_{j, j'} = \frac{1}{N} \sum_{i\in 1:N}\sigma_{j, i} \sigma_{j', i}\)</span>, the matrix <span class="math inline">\(\bar{Q}\)</span> represents the average covariance between different types of velocities in this system.</p>
</section>
<section id="field-theoretic-calculation-1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="field-theoretic-calculation-1">Field-theoretic calculation</h3>
<p>This section is based on <span class="citation" data-cites="meiSTAT260MeanField2021">(<a href="#ref-meiSTAT260MeanField2021" role="doc-biblioref">Mei 2021</a>, lecture 8)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="formulate a constraint">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
formulate a constraint
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To prepare for the introduction of the Dirac delta factor, we need to move the constraint from the integral domain to the integrand.</p>
<p><span class="math display">\[
\begin{aligned}
Pr(\bar Q =_\epsilon Q) &amp;= \mathbb{E}_\sigma [1[\bar Q(\sigma) - Q =_\epsilon 0]]\\
&amp;= \mathbb{E}_\sigma \left[\prod_{1 \leq i &lt; j \leq k} 1[\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0]\right]\\
\end{aligned}
\]</span></p>
<p>Notice well the interplay of two dimensions: The integral <span class="math inline">\(\mathbb{E}_\sigma\)</span> is over a very large space, over <em>all</em> particles’ states, of dimension, so it has dimension <span class="math inline">\(\sim k^2 N\)</span>. The constraint <span class="math inline">\(1[\bar Q(\sigma) - Q =_\epsilon 0]\)</span> is on the <em>average</em> states of all particles, so it is over a small space of fixed dimensions <span class="math inline">\(\sim k^2\)</span>.</p>
<p>Again, we do that <span class="math inline">\(1[x=_\epsilon 0] \approx \delta(x)/\epsilon\)</span> trick again, and we get</p>
<p><span class="math display">\[
Pr(\bar Q =_\epsilon Q) =_{\ln} \mathbb{E}_\sigma \left[\prod_{1 \leq i &lt; j \leq k} \delta(\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0)\right]
\]</span></p>
<p>Notice how we have the product <span class="math inline">\(\prod\)</span> over <span class="math inline">\(1 \leq i &lt; j \leq k\)</span>, because <span class="math inline">\(\bar Q, Q\)</span> are both symmetric, with diagonal entries equal to <span class="math inline">\(+1\)</span>. If we were to write something like <span class="math inline">\(\prod_{1 \leq i {\color{red} \leq} j \leq k}\)</span>, we would cause <span class="math inline">\(\delta(\bar Q_{i, i}(\sigma) - Q_{i, i} =_\epsilon 0)\)</span> to always be infinite, which does not work.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="formulate a constraint, take 2">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
formulate a constraint, take 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It turns out we have not finished with the constraint yet. Back when we did Sanov’s theorem, because the particles are not interacting, we had to only formulate one constraint, a global one where <span class="math inline">\(\hat p =_\epsilon q\)</span>. In this case, the particles <em>are</em> interacting by the conservation of kinetic energy:</p>
<p><span class="math display">\[\forall j\in 1:k, \quad \frac 1N \sum_{i \in 1:N}\|\sigma_{j}\|_2^2 = 1\]</span></p>
<p>Let us go back to the start again:</p>
<p><span class="math display">\[
\begin{aligned}
Pr(\bar Q =_\epsilon Q) &amp;= \mathbb{E}_\sigma [1[\bar Q(\sigma) - Q =_\epsilon 0]] \\
&amp;= \int_{(\sqrt N S^N)^k}\frac{d\sigma}{\mathrm{Vol}(\sqrt N S^N)^k} \; 1[\bar Q(\sigma) - Q =_\epsilon 0]
\end{aligned}
\]</span></p>
<p>The integral over <span class="math inline">\((\sqrt N S^N)^k\)</span> is uncomfortable. What to do? … That’s right, when the domain of integral is uncomfortable, we use a Dirac delta factor to move it into the integrand:</p>
<p><span class="math display">\[
= \frac{\int_{\mathbb{R}^{N \times k}} \delta(\cdots) d\sigma \; 1[\bar Q(\sigma) - Q =_\epsilon 0]}{\int_{\mathbb{R}^{N \times k}} \delta(\cdots) d\sigma}
\]</span></p>
<p>where we must fill in the constraint of <span class="math inline">\(\sigma \in (\sqrt N S^N)^k\)</span> into the <span class="math inline">\(\delta(\cdots)\)</span>. Now, <span class="math inline">\(\sigma \in (\sqrt N S^N)^k\)</span> is equivalent to <span class="math inline">\(\frac 1N \|\sigma_{j}\|^2 - 1 = 0\)</span> for all <span class="math inline">\(j\in 1:k\)</span>, so naturally, we should try <span class="math inline">\(\prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right)\)</span>, giving us</p>
<p><span class="math display">\[
= \frac{\int_{\mathbb{R}^{N \times k}} {\color{red} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right)} d\sigma \; 1[\bar Q(\sigma) - Q =_\epsilon 0]}{\int_{\mathbb{R}^{N \times k}} {\color{red} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right)} d\sigma}
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="the off-shell trick">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
the off-shell trick
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Let’s take a moment to see what the trick is. The trick is this: We need to integrate something over the uniform distribution on <span class="math inline">\((\sqrt N S^N)^k\)</span>, but integrating over it is difficult, because we don’t have a convenient coordinate system over the sphere <span class="math inline">\(\sqrt N S^N\)</span>. So instead, we slightly thicken each sphere,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and suddenly we can integrate over the real space <span class="math inline">\(\mathbb{R}^{N \times k}\)</span>, for which we <em>do</em> have a good coordinate system:</p>
<p><span class="math display">\[
\mathbb{E}_{\sigma \sim \mathrm{Uniform}((\sqrt N S^N)^k)} [\text{something}] = \lim_{\epsilon \downarrow 0} \mathbb{E}_{\sigma \sim \mathrm{Uniform}((\sqrt N S^N \text{thickened by }\sqrt N \epsilon )^k)} [\text{something}]
\]</span></p>
<p>Now, since</p>
<p><span class="math display">\[
\sigma_j \in \sqrt N S^N \text{thickened by }\sqrt N \epsilon \iff \|\sigma_j\|^2 - N \in \pm N\epsilon \iff \frac 1N \|\sigma_j\|^2 - 1 =_\epsilon 0
\]</span></p>
<p>we can write the constraint as <span class="math inline">\(1 \left( \frac 1N \|\sigma_j\|^2 - 1 =_\epsilon 0 \right) = \delta \left( \frac 1N \|\sigma_j\|^2 - 1 \right)/\epsilon\)</span>.</p>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;If we return to our field-theoretic interpretation, then allowing <span class="math inline">\(\sigma_j\)</span> to have norm <span class="math inline">\(\sqrt N \pm \sqrt N \epsilon\)</span> means that we are allowing the average type-<span class="math inline">\(j\)</span> kinetic energy to fluctuate a bit, even though it is exactly <span class="math inline">\(1\)</span>. Quantum field theorists call this <strong>off the (kinetic) energy shell</strong>, and if you ask, they might wave mysteriously in the air and speak of “virtual particles” and “Faddeev-Popov ghosts”.</p></div></div><div class="callout callout-style-default callout-note callout-titled" title="formulate a constraint, take 3">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
formulate a constraint, take 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Again we must handle the constraint of <span class="math inline">\(1[\bar Q(\sigma) - Q =_\epsilon 0]\)</span>, but this time it’s different. Whereas before, we had to use <span class="math inline">\(\left[\prod_{1 \leq i {\color{red} &lt;} j \leq k} 1[\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0]\right]\)</span>, this time we have to use <span class="math inline">\(\prod_{1 \leq i {\color{red} \leq} j \leq k}\)</span>. Why? Because this time, we have set <span class="math inline">\(\sigma\)</span> free from the cage of <span class="math inline">\((\sqrt N S^N)^k\)</span>, so the diagonal entries of <span class="math inline">\(\bar Q(\sigma)\)</span> are no longer forced to stay exactly <span class="math inline">\(+1\)</span>. Thus, we have to do this instead:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;= \frac{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma \; 1[\bar Q(\sigma) - Q =_\epsilon 0]}{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma} \\
&amp;=_{\ln} \frac{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma \; \prod_{1 \leq s {\color{red} \leq} t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma} \\
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="introduce a Dirac delta">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
introduce a Dirac delta
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We have already done the Dirac deltas. To remind you,</p>
<p><span class="math display">\[
Pr(\bar Q =_\epsilon Q) =_{\ln}\frac{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma \; \prod_{1 \leq s \leq t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma}
\]</span></p>
<p>Actually, it is more convenient to scale the <span class="math inline">\(\delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right)\)</span> both above and below the fraction to <span class="math inline">\(\delta\left( \|\sigma_{j}\|^2 - N \right)\)</span>, and similarly scale the <span class="math inline">\(\delta(\bar Q_{s, t}(\sigma) - Q_{s, t})\)</span> to <span class="math inline">\(\delta(N\bar Q_{s, t} - NQ_{s, t}) N\)</span>, giving us</p>
<p><span class="math display">\[
Pr(\bar Q =_\epsilon Q) =_{\ln}\frac{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \|\sigma_{j}\|^2 - N \right) d\sigma \; \prod_{1 \leq s \leq t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\mathbb{R}^{N \times k}} \prod_{j\in 1:k} \delta\left( \|\sigma_{j}\|^2 - N \right) d\sigma}
\]</span></p>
<p>where we have discarded the factor of <span class="math inline">\(N^{\frac 12 k(k+1)}\)</span>, because it does not matter after taking <span class="math inline">\(\frac 1N \ln(\cdots)\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="evaluate the numerator by field equation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
evaluate the numerator by field equation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Since this time we can’t do the inner integral easily, we will rush directly to the field equation. Don’t worry, as it will all come out correct in the end.</p>
<p>Do the Fourier transform of the Dirac delta factor, and exchange the order of integration. We first do the numerator.</p>
<p><span class="math display">\[
\begin{aligned}
&amp;= \int_{\mathbb{R}^{N \times k}} d\sigma \int_{1 \leq l \leq k, \; 1 \leq i \leq j \leq k} d\lambda_l dq_{ij} e^{i \left(
\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})
\right)} \\
&amp;= \int_{1 \leq l \leq k, \; 1 \leq i \leq j \leq k} d\lambda_l dq_{ij} \int_{\mathbb{R}^{N \times k}} d\sigma e^{i \left(
\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})
\right)} \\
\end{aligned}
\]</span></p>
<p>As before, we only need to find the “least unlikely of all unlikely ways”. That is, we only need to pick the least tiny of all tiny inner integrals. In other words, we need to find a stationary point where it has finally ceased being so tiny:</p>
<p><span class="math display">\[0 = \nabla_{q, \lambda}\int_{\mathbb{R}^{N \times k}} d\sigma e^{i \left(
\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})
\right)}\]</span></p>
<p>Because we are seeking a stationary point, and we are already doing it physicists, it is no big problem if we seek stationary points over all of the complex plane. That is, we allow <span class="math inline">\(q, \lambda\)</span> to take not just real, but also complex values.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Then we can scale both by <span class="math inline">\(-i\)</span> and get</p>
<p><span class="math display">\[
\nabla_{q, \lambda}\int_{\mathbb{R}^{N \times k}} d\sigma e^{- \left(
\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})
\right)}
\]</span></p>
<p>For cleaner notation, we define <span class="math inline">\(q_{ji} = q_{ij}\)</span>, and <span class="math inline">\(\Lambda = \mathrm{diag}(\lambda_1, \dots, \lambda_k)\)</span>. Noting that <span class="math inline">\(Q_{ii} = 1\)</span> for all <span class="math inline">\(i\)</span>, we get</p>
<p><span class="math display">\[
\nabla_{q, \lambda}\int_{\mathbb{R}^{N \times k}} d\sigma e^{- \left(\sum_{ij} (\Lambda_{ij} + \frac 12 q_{ij}) (\sigma_i^T \sigma_j - NQ_{ij})
\right)}
\]</span></p>
<p>Since the stationary point of this with respect to <span class="math inline">\(q, \lambda\)</span> is the same as the stationary point of this with respect to <span class="math inline">\(\Lambda + \frac 12 q\)</span>, we need only</p>
<p><span class="math display">\[
\nabla_{q}\int_{\mathbb{R}^{N \times k}} d\sigma e^{- \left(\sum_{ij} \frac 12 q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})
\right)}
\]</span></p>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;If you want justification, look up “the method of steepest descent” <span class="citation" data-cites="erdelyiAsymptoticExpansions1956">(<a href="#ref-erdelyiAsymptoticExpansions1956" role="doc-biblioref">Erdélyi 1956, sec. 2.5</a>)</span>. Intuitively speaking, it is because when we are doing an integral like <span class="math inline">\(\int_\mathbb{R}dq (\cdots)\)</span>, we are doing a path integral in the complex plane, and so we can deform the path integral in the complex plane and still get the same result. Thus, we can deform it so hard that it walks across a “mountain pass” in the complex plane, where the saddle-point of the mountain pass is where <span class="math inline">\(\nabla_q (\cdots) = 0\)</span> – i.e., a stationary point.</p></div></div><div class="callout callout-style-default callout-note callout-titled" title="evaluate the denominator by field equation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
evaluate the denominator by field equation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>At this point, it’s easier to evaluate the denominator first.</p>
<p>The same argument given above applies to the denominator. If you are pressed for time, you can just take the previous derivation for the saddle point equation, and set <span class="math inline">\(q = 0, Q = 0\)</span>. This gives the field equation</p>
<p><span class="math display">\[
0 = \nabla_{\lambda}\int_{\mathbb{R}^{N \times k}} d\sigma e^{-\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N)}
\]</span></p>
<p>Now, the integral is just a gaussian integral, and it factors, too!</p>
<p><span class="math display">\[
\int_{\mathbb{R}^{N \times k}} d\sigma e^{-\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N)} = \prod_l e^{N \lambda_l} \left(\int_\mathbb{R}d\sigma e^{-\lambda_l \sigma^2} \right)^N = e^{N\sum_l (\lambda_l - \frac 12 \ln\lambda_l + \frac 12 \ln \pi)}
\]</span></p>
<p>Its stationary point is <span class="math inline">\(e^{N \frac k2 ( 1 + \ln 2\pi)}\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="evaluate the numerator, continued">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
evaluate the numerator, continued
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Where we left off, we had to solve the field equation</p>
<p><span class="math display">\[
0 = \nabla_{q}e^{\frac 12 N \sum_{ij}q_{ij}Q_{ij}} \int_{\mathbb{R}^{N \times k}} d\sigma e^{-\sum_{ij} \frac 12 q_{ij} \sigma_i^T \sigma_j}
\]</span></p>
<p>The integral is just a gaussian integral, and it factors, too:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;= \int_{\mathbb{R}^{N \times k}} d\sigma e^{-\frac 12 \sum_{ij}q_{ij}\sigma_i^T \sigma_j} \\
&amp;= \left(\int_{\mathbb{R}^{ k}} d\sigma e^{-\frac 12 \sum_{ij}q_{ij}\sigma_i \sigma_j}\right)^N \\
&amp;= (2\pi)^{Nk/2}\det(q)^{-N/2}
\end{aligned}
\]</span></p>
<p>Taking the derivative, we observe that <span class="math inline">\(\nabla_q \ln \det q = (q^{-1})^T\)</span> for an arbitrary matrix <span class="math inline">\(q\)</span>. However, as <span class="math inline">\(q\)</span> is constrained to be a symmetric matrix, we obtain</p>
<p><span class="math display">\[\partial_{q_{ij}}(\braket{Q,q} - \ln\det (q)) = \begin{cases}
Q_{ij}+ Q_{ji} - (q^{-1})_{ij} - (q^{-1})_{ji} &amp; i\neq j \\
Q_{ii}- (q^{-1})_{ii} &amp; i=j
\end{cases}\]</span></p>
<p>Setting all derivatives to zero yields the solution <span class="math inline">\(q = (Q^{-1})^T = Q^{-1}\)</span>. Notably, there exists only one stationary point within the entire multidimensional complex space.</p>
<p>We proceed to compute the numerator, resulting in</p>
<p><span class="math display">\[
=\exp\left(\frac N2(\braket{Q^{-1}, Q} + k \ln(2\pi) - \ln \det Q^{-1})\right) = \exp\left(\frac N2(k+ k \ln(2\pi) + \ln \det Q)\right)
\]</span></p>
</div>
</div>
</div>
<p>In summary, we have</p>
<p><span class="math display">\[
Pr(\bar Q =_\epsilon Q) =_{\ln} \frac{\exp\left(\frac N2(k+ k \ln(2\pi) + \ln \det Q)\right)}{\exp\left({N \frac k2 ( 1 + \ln 2\pi)}\right)} = e^{N S[Q]}
\]</span></p>
<p>where the rate function is</p>
<p><span class="math display">\[S[Q] = \frac 12 \ln \det Q\]</span></p>
</section>
</section>
<section id="easy-results" class="level2">
<h2 class="anchored" data-anchor-id="easy-results">Easy results</h2>
<p>Now that you have gone through that effort learning field-theoretic calculations, enjoy some quick and simple results.</p>
<section id="asymptotics-of-spherical-volumes" class="level3">
<h3 class="anchored" data-anchor-id="asymptotics-of-spherical-volumes">Asymptotics of spherical volumes</h3>
<p>Let <span class="math inline">\(S^{N-1}(r)\)</span> be the sphere of radius <span class="math inline">\(r\)</span> in <span class="math inline">\(\mathbb{R}^N\)</span>, then</p>
<p><span class="math display">\[|S^{N-1}(\sqrt N)| \sim (2\pi e)^{N/2}\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{aligned}
      |S^{N-1}(\sqrt N)| &amp;= \int_{\mathbb{R}^N} \delta(x^T x- N )dx \\
      &amp;=_{\ln} \int_{\mathbb{R}^N} \int_\mathbb{R}e^{iq(x^T x- N )} dqdx \\
      &amp;= \int_{\mathbb{R}} dq \; e^{-iqN} \left[\int_{\mathbb{R}^N} e^{iqx^T x} dx\right] \\
      &amp;= \int_{\mathbb{R}} dq \; e^{-iqN} \left[\int_{\mathbb{R}} e^{iqx^2} dx\right]^N \\
      &amp;= \int_{\mathbb{R}} dq \; e^{-iqN} (e^{i\pi/4}\sqrt{\pi/q})^N \\
      \end{aligned}\]</span> - Thus, <span class="math inline">\(\frac 1N \ln |S^{N-1}(\sqrt N)|\)</span> converges to the stationary point of <span class="math display">\[-iq + \frac{i\pi}{4} + \frac 12 \ln \pi - \frac 12 \ln q\]</span></p>
<p>which occurs at <span class="math inline">\(q^* = i/2\)</span>. Plugging it in, we obtain</p>
<p><span class="math display">\[\frac 1N \ln |S^{N-1}(\sqrt N)| \to \ln\sqrt{2\pi e}\]</span></p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Probabilistic interpretation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Probabilistic interpretation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>As is well-known, in high-dimensions, everything looks like a gaussian. Specifically, the standard gaussian distribution <span class="math inline">\(\mathcal N(0, I_N)\)</span> in <span class="math inline">\(\mathbb{R}^N\)</span> space is strongly concentrated around the spherical shell of radius <span class="math inline">\(\sqrt N\)</span>, by the law of large numbers. Therefore, the log-surface area of <span class="math inline">\(S^{N-1}(\sqrt N)\)</span> converges to the entropy of the <span class="math inline">\(\mathcal N(0, I_N)\)</span>, which is just <span class="math inline">\(N\)</span> times the entropy of <span class="math inline">\(\mathcal N(0, 1)\)</span>.</p>
<p>In more detail, we can sample from <span class="math inline">\(\mathcal N(0, I_N)\)</span> in two ways: Either directly sample <span class="math inline">\(N\)</span> standard normal variables independently, or sample a point on <span class="math inline">\(S^{N-1}(\sqrt N)\)</span>, before shifting it along the radius by an independently sampled displacement. Both ways give us exactly the same entropy. Now, because the radius of <span class="math inline">\(x \sim \mathcal N(0, I_N)\)</span> is distributed as the square-root of the <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">chi-squared distribution</a> <span class="math inline">\(\chi^2_N\)</span>, we have</p>
<p><span class="math display">\[r^2 = \|x\|^2 \sim \chi^2_N \approx \mathcal N(N, 2N)\]</span></p>
<p>When <span class="math inline">\(N\)</span> is large, we can write <span class="math inline">\(r^2 \approx N + \sqrt{2N} z\)</span> where <span class="math inline">\(z \sim \mathcal(0, 1)\)</span>, so <span class="math inline">\(r \approx \sqrt N + 2^{-1/2}z\)</span>. Therefore, the amount of radial displacement is roughly constant, and we have</p>
<p><span class="math display">\[
\mathrm{Ent}[\mathcal N(0, I_N)] \approx \ln |S^{N-1}(\sqrt N)| + \mathrm{Ent}[\mathcal N(0, 1/2)]
\]</span></p>
<p>giving us the second term in the Stirling approximation:</p>
<p><span class="math display">\[
\frac 1N \ln |S^{N-1}(\sqrt N)| = \ln\sqrt{2\pi e} + \frac{\ln\sqrt{\pi e}}{N} + O(N^{-2})
\]</span></p>
</div>
</div>
</div>
</section>
<section id="cramérs-theorem" class="level3">
<h3 class="anchored" data-anchor-id="cramérs-theorem">Cramér’s theorem</h3>
<p>The most commonly used result from large deviation theory is Cramér’s theorem <span class="citation" data-cites="demboLargeDeviationsTechniques2009">(<a href="#ref-demboLargeDeviationsTechniques2009" role="doc-biblioref">Dembo and Zeitouni 2009</a>, theorem 2.2.30)</span>.</p>
<div id="thm-cramer" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (Cramér)</strong></span> Given a vector function <span class="math inline">\(M: X \to \mathbb{R}^m\)</span> and a distribution on <span class="math inline">\(X\)</span>, its rate function is the convex transform of its cumulant generating function:</p>
<p><span class="math display">\[I_X(x) := \sup_{k \in \mathbb{R}^m}(\braket{k,x} - \ln \mathbb{E}_x[e^{\braket{k, M(x)}}])\]</span></p>
<p>That is, for any compact subset <span class="math inline">\(A \subset \mathbb{R}^m\)</span>, the rate function over the whole subset is just the highest possible rate:</p>
<p><span class="math display">\[\lim_N\frac 1N \ln Pr\left(\frac 1N \sum_{i=1}^N M(x_i) \in A\right) = \sup_{x\in A} -I_X(x)\]</span></p>
<p>where <span class="math inline">\(x_1, ..., x_N\)</span> are IID samples from the same distribution.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It suffices to prove it for <span class="math inline">\(A\)</span> being really small, essentially just a single point, because we can then cut up the whole of <span class="math inline">\(A\)</span> into many pieces like that, and then run the result on each piece. The rate difference is such that only the highest rate can survive, as it races pass every other piece exponentially fast: <span class="math inline">\(N^{-1} \ln (e^{-Na} + e^{-Nb}) \to \max(-a, -b)\)</span>, and even if two pieces have the exact same rate, then their combined rate gains a negligible factor of <span class="math inline">\(N^{-1}\ln 2 \to 0\)</span>.</p>
<p>So, we once again repeat the same calculation:</p>
<p><span class="math display">\[
\begin{aligned}
Pr\left(\frac 1N \sum_{i=1}^N M(x_i) =_\epsilon m\right) &amp;=_{\ln}  \mathbb{E}_x \left[\delta^{(m)}\left(\sum_i M(x_i) - Nm\right)\right] &amp; \text{ only $m$ terms in the Dirac delta}\\
&amp;=   \mathbb{E}_x \left[\int_{\mathbb{R}^m} dq e^{i\braket{iq, \sum_i M(x_i) - Nm}}\right]  &amp; \text{Dirac delta Fourier transform} \\
&amp;= \int_{\mathbb{R}^m} dq e^{-N \braket{iq, m}}\mathbb{E}_x[e^{\braket{iq, M}}]^N&amp; \text{IID assumption} \\
&amp;= \int_{\mathbb{R}^m}dq e^{N(-\braket{iq, m} + \ln \mathbb{E}_x[e^{\braket{iq, M}}])}
\end{aligned}
\]</span></p>
<p>The last equation is again dominated by the stationary point. This would give us</p>
<p><span class="math display">\[=_{\ln}\mathrm{stat}_{q\in \mathbb C^m} e^{N(-\braket{q, m} + \ln \mathbb{E}_x[e^{\braket{q, M}}])}\]</span></p>
<p>We still don’t know <em>which</em> stationary point we should pick. However, in large deviation theory, we usually pick the global minimum, and most often, the global minimum is the unique stationary point in the real space. Assuming that, we have</p>
<p><span class="math display">\[\frac 1N \ln Pr\left(\frac 1N \sum_{i=1}^N M(x_i)\right) \to -\sup_{q\in \mathbb R^m} (\braket{q, m} - \ln \mathbb{E}_x[e^{\braket{q, M}}])\]</span></p>
</div>
</div>
</div>


<!-- -->


</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-demboLargeDeviationsTechniques2009" class="csl-entry" role="listitem">
Dembo, Amir, and Ofer Zeitouni. 2009. <em>Large <span>Deviations Techniques</span> and <span>Applications</span></em>. 2nd ed. 1998. 2nd printing 2009 edition. Berlin Heidelberg: Springer.
</div>
<div id="ref-denhollanderLargeDeviations2008" class="csl-entry" role="listitem">
Den Hollander, Frank. 2008. <em>Large Deviations</em>. American Mathematical Society.
</div>
<div id="ref-erdelyiAsymptoticExpansions1956" class="csl-entry" role="listitem">
Erdélyi, Arthur. 1956. <em>Asymptotic Expansions</em>. 3. Courier Corporation.
</div>
<div id="ref-meiSTAT260MeanField2021" class="csl-entry" role="listitem">
Mei, Song. 2021. <span>“<span>STAT260</span>: <span>Mean Field Asymptotics</span> in <span>Statistical Learning</span>.”</span> <a href="https://www.stat.berkeley.edu/~songmei/Teaching/STAT260_Spring2021/index.html">https://www.stat.berkeley.edu/~songmei/Teaching/STAT260_Spring2021/index.html</a>.
</div>
<div id="ref-mezardInformationPhysicsComputation2009" class="csl-entry" role="listitem">
Mézard, Marc, and Andrea Montanari. 2009. <em>Information, Physics, and Computation</em>. Oxford Graduate Texts. Oxford: Oxford university press.
</div>
</div></section></div></main> <!-- /main -->
<!-- file: html/copy‑anchors-js.html -->

<script type="module">

document.addEventListener("DOMContentLoaded", () => {

  // 1. All little ¶ icons Quarto/AnchorJS adds

  document.querySelectorAll("a.anchorjs-link").forEach(anchor => {

    anchor.addEventListener("click", async (evt) => {

      // Keep normal scroll behaviour but stop full page reload

      evt.preventDefault();



      // Build absolute URL: origin + path + #hash

      const url = `${location.origin}${location.pathname}${anchor.getAttribute("href")}`;



      // 2. Try modern Clipboard API first

      try {

        await navigator.clipboard.writeText(url);

      } catch {

        // 3. Fallback for legacy browsers

        const helper = Object.assign(document.createElement("input"), { value: url });

        document.body.appendChild(helper);

        helper.select();

        document.execCommand("copy");

        helper.remove();

      }

      // TODO: The following two doesn't work yet

      // 4. Brief visual confirmation (optional)

      anchor.dataset.tooltip = "Copied!";

      setTimeout(() => delete anchor.dataset.tooltip, 1500);



      // 5. Still jump to the heading

      history.pushState(null, "", anchor.getAttribute("href"));

    }, false);

  });

});

</script>

<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yuxi\.ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "How to do field-theoretic calculations"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yuxi Liu"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-04-11"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2025-02-16"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [math, physics, scaling]</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    resources:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        - "figure/**"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "I teach you how to do probability calculations and gigantic integrals in the 'field-theoretic style', done in exhaustive details. I aim for clarity, pointing out every pitfall that I have fallen into so that you don't have to."</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># image: "figure/banner.png"</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "draft"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "certain"</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 3</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../static/_macros.tex &gt;}}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>General references: <span class="co">[</span><span class="ot">@mezardInformationPhysicsComputation2009; @meiSTAT260MeanField2021</span><span class="co">]</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>When I was studying machine learning theory, I often encounter problems in high-dimensional probability and statistics, and here and there, I would meet with a confusing statement like "let's do a field-theoretic calculation". Field theory? I don't see any gravitational wave or electromagnetic wave!</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>It turns out that "field-theoretic calculation" does mean something like a field, but in a highly abstracted form. It is not well-described in the literature, and it took me great effort to understand what is going on. The calculations are long, arduous, and filled with opportunities for mistakes.</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>Still, if you are going to do machine learning theory (as I am), then learning it is a must. This essay is a practical introduction to field-theoretic calculations through detailed examples, including Sanov's theorem and the analysis of high-dimensional random vectors using overlap matrices. I aim for clarity, pointing out every pitfall that I have fallen into so that you don't have to.</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>While the essay assumes familiarity with basic probability, calculus, and linear algebra, it aims to provide a self-contained and accessible introduction to the field. Readers are encouraged to actively engage with the examples, referring back to the provided recipe for field-theoretic calculations as needed.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">## The recipe of field-theoretic calculations.</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>Here is the reference. You should not read this directly. Instead, you should go directly to the examples below and refer back to this as you go along.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>To calculate: a massive integral of the form</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>\ub{\int\cdots\int}{$N \to \infty$, with constraint $C$} (\text{something}) d^N x</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The constraint $C$ is handled by introducing a Dirac delta factor:</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>=_{\ln} \ub{\int\cdots\int}{$N \to \infty$} (\text{something}) \times \delta^{(n)}(C' - C)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>where $n$ is the number of conditions within $C$. For example, if the constraint says $\sum_i x_i^2 = 1$, then $n=1$. If the constraint also says $\sum_{ij} x_ix_j = 0$, then $n=2$, and so on.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Express the Dirac delta function as a Fourier transform using $\delta^{(n)}(x) = \frac{1}{(2\pi)^n}\int_{\R^n} e^{-i x \lambda} d\lambda$, then exchange the order of integral.</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Put the inner integral into an exponent, and do some rewriting, resulting in something like</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>=_{\ln} \ub{\int\cdots\int}{$n$} (\text{something unimportant}) e^{N \ln \int(\cdots)d^N x} d^n\lambda</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>Define $S<span class="co">[</span><span class="ot">\lambda</span><span class="co">]</span> := -\ln \int(\cdots)d^N x$, which is sometimes called the **field free energy**.</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Argue, at large $N$, the integral is dominated by the point where $\nabla S<span class="co">[</span><span class="ot">\lambda</span><span class="co">]</span> = 0$. This has many names: method of steepest descent, saddle point method, stationary point method, stationary-phase method, etc.</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Write down $\nabla S = 0$, and give it the fancy name of **mean field equation**.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Solve the mean field equation to be some $\lambda^*$.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Declare the result to be </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>$$=_{\ln} e^{-N S<span class="co">[</span><span class="ot">\lambda^*</span><span class="co">]</span>}$$</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>Here, we use the notation $=_{\ln}$ to mean that they have the same exponential rate. That is, $f(N) =_{\ln} g(N)$ means that</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>\lim_{N \to \infty} \frac 1N \ln f = \lim_{N \to \infty}  \frac 1N \ln g</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sanov's theorem</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="fu">### Statement of Sanov's theorem</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Sanov's theorem</span><span class="co">](https://en.wikipedia.org/wiki/Sanov%27s_theorem)</span> concerns the large deviation principle for IID samples from a multinomial distribution.</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>To see how Sanov's theorem works, let's consider an example. Say you are working at a dice factory, and your job is to quality-assure dices. An ideal dice should have all $p_i = 1/6$, and your job is to test that a given real dice has $p_i \approx 1/6$. Since you are not able to observe $p$ directly, you can only throw the dice for $N$ rounds, and compute the empirical distribution $\hat p$ from the outcomes $x_1, ..., x_N$.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>For example, if you threw it 7 times and you got every number once except $1$ twice, then $\hat p = (2/7, 1/7, ..., 1/7)$.</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>Because $\hat p$ depends on the throws, it is itself a random variable. Intuitively, we should expect that $\hat p$ converging to $p$ as $N \to \infty$. Sanov's theorem states that it is exponentially unlikely for us to be far from the right answer, with the rate of exponential convergence depending on how far we are mistaken. The further $\hat p$ is from $p$, the faster we can eliminate that possibility.</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>Let's state this more formally.</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>Define:</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$p_{1:n}$ is a probability vector.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$x_{1:N}$ are IID samples from a multinomial distribution with probability vector $p_{1:n}$.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\hat{p}$ is the empirical distribution derived from these samples.</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\Delta_n$ is the probability simplex.</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>As the number of samples $N$ approaches infinity, the probability of observing a specific empirical distribution $\hat{p}$ within a closed subset $A \subset \Delta_n$ is characterized by the Kullback-Leibler (KL) divergence $D_{KL}(\hat{p} <span class="sc">\|</span> p)$ between the empirical distribution $\hat{p}$ and the true distribution $p$.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>Formally stated:</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>::: {#thm-sanov}</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu"># Sanov</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>$$\lim_{N \to \infty} \frac{1}{N} \ln Pr(\hat{p} \in A) = -\inf_{\hat{p} \in A} D_{KL}(\hat{p} <span class="sc">\|</span> p)$$</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>We can get an intuitive feel for Sanov's theorem by the following video.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>Let us fix $n = 3$ and $p = (0.2, 0.3, 0.5)$. We set $n = 3$ because $\Delta_3$ has two dimensions, which allows us to actually plot it.</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>If we sample for $N$ times from the multinomial distribution defined by $p$, and plot the heatmap of the samples within $\Delta_2$ (shown as a black triangle), we notice that as $N \rightarrow \infty$, the distribution converges to a gaussian around the point $(0.2,0.3,0.5)$, with the contours converging in shape to ellipses, with radii converging as $1 / \sqrt{N}$.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>Meanwhile, the separation between the discrete points converge as $1 / N$, and so the discrete multinomial distribution converges to a continuous gaussian distribution.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>So, roughly speaking, we have approximately</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>Pr(\hat p) \propto e^{- (\hat p - p)^T NV (\hat p - p)}</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>for some covariance matrix $V$ that describes the shape of the ellipses.</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">video</span><span class="ot"> controls width</span><span class="op">=</span><span class="st">100%</span><span class="dt">&gt;</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">source</span><span class="ot"> src</span><span class="op">=</span><span class="st">"figure/Sanov_convergence.webm"</span><span class="ot"> type</span><span class="op">=</span><span class="st">"video/webm"</span><span class="ot"> </span><span class="dt">/&gt;</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">video</span><span class="dt">&gt;</span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>Now, if we boldly proceed, we would obtain</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>\frac 1N \ln Pr(\hat p) \sim -(\hat p - p)^T A (\hat p - p)</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>This is not quite right, because for any finite $N$, there are only finitely many possible $\hat p$. So generally $Pr(\hat p) = 0$, and to fix this, instead of writing $Pr(\hat p)$, we should write $Pr(\hat p \in A)$ for some closed subset $A \subset \Delta_n$.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>Next, since given any two exponentially decaying functions $f(N) \propto e^{-kN}, g(N) \propto e^{-lN}$, we have $f \gg g$ iff $k &lt; l$, we only need to account for the least unlikely case:</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>\lim_N \frac 1N \ln Pr(\hat p \in A) \approx \max_{q\in A} (-(q-p)^T A (q-p)) \approx - \min_{q\in A} D_{KL}(q <span class="sc">\|</span> p)</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Any large deviation is done in the least unlikely of all the unlikely ways!</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@denhollanderLargeDeviations2008, page 10</span><span class="co">]</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="fu">### Field-theoretic interpretation</span></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>We can interpret this problem through the lens of statistical physics. Imagine a system of $N$ identical particles. Each particle has $n$ degrees of freedom. The state of a particle can be one of the unit vectors in $\R^n$. The problem is to find the distribution of the average state of all the particles.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>The particles are completely independent of each other -- no interaction whatsoever. This is a "no interaction field". The only thing saving the example from irrelevance is that the particles are still influenced by something -- an externally-imposed potential field, biasing the distribution of each particle's state independently and identically (IID).</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>As typical in statistical mechanics, we suppose each particle is distributed according to the Boltzmann distribution with temperature $1$. This then tells us that the potential field $V$ satisfies</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>$$p_i = e^{-V_i}/Z$$</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>That is, we can write $V_i = -\ln p_i - \ln Z$ where $Z$ is a normalizing constant (**partition function** again).</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>The average energy per particle (**order parameter**) is then </span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>$$\bar E \sum_i \bar p_i V_i = -\sum_i \bar p_i \ln p_i - \ln Z$$</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>The minimum is at $\bar p_i = p_i$, and if you have seen some statistical mechanics before, you would notice a pattern: a fluctuation in the average energy per particle should be proportional to $e^{-N(\bar E  - \bar E_{min})}$. This is not quite right, in the sense that $\bar E - \bar E_{min}$ is not the rate function, but it converges to the rate function in a neighborhood of $p$.</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="fu">### Field-theoretic calculation</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>This section is based on <span class="co">[</span><span class="ot">@mezardInformationPhysicsComputation2009, section 4.7</span><span class="co">]</span>.</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>We use field-theoretic techniques to compute the rate function, treating both the empirical distribution $\hat{p}$ and the true distribution $p$ as fields over a finite set of points:</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>$$p: <span class="sc">\{</span>1, 2, ..., n<span class="sc">\}</span> \to \R$$</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="formulate a constraint" collapse="true" }</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>We really want to write $Pr(\hat{p} = q)$, even though as we noted, this does not make sense. To fix this problem, we introduce an infinitesimal fudge factor of $\epsilon$.</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>That is, we want to know the probability of observing an empirical distribution $\hat{p}$ within an infinitesimal neighborhood of a specific distribution $q$:</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>$$Pr(\hat{p} =_{\epsilon} q)$$</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>where $=\epsilon$ means that $\hat{p}_i \in q_i \pm \epsilon$ for each $i = 1, 2, \dots, n$, or more roughly, that they are within an $O(\epsilon)$ distance of each other.</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>Thus, we can write the desired problem in the form of a constrained integral:</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>Pr(\hat p =_\epsilon q) = \int_{\R^N} \rho(x) d^N x \left( 1<span class="co">[</span><span class="ot">\hat p(x) = q</span><span class="co">]</span>\right)</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="introduce a Dirac delta" collapse="true" }</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>Next, we need to move the constraint from the integral domain to the integrand, in preparation for exchanging the order of integral. We do this by introducing a Dirac delta factor.</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>For any fixed tiny, but non-zero, $\epsilon$, we have</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>\int_{\R^N} \rho(x) d^N x \left( 1<span class="co">[</span><span class="ot">\hat p(x) = q</span><span class="co">]</span>\right) =_{\ln} \int_{\R^N} \rho(x) d^N x \left( \frac{1<span class="co">[</span><span class="ot">\hat p(x) = q</span><span class="co">]</span>}{\mathrm{Vol}(\text{ball with radius } \epsilon)}\right)</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>because even though $\frac{1<span class="co">[</span><span class="ot">\hat p(x) = q</span><span class="co">]</span>}{\mathrm{Vol}(\text{ball with radius } \epsilon)}$ is huge, it is still $O(1)$, and $\lim_{N\to\infty} \frac{(\text{huge but fixed})}{N} = 0$.</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>= \int_{\R^N} \rho(x) d^N x \delta^{(n)}(\hat p(x) - q)</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="do a Fourier transform" collapse="true" }</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>Next, we do the Fourier transform of the Dirac delta factor. This step is mostly mechanical.</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>\delta^{(n)} (\hat p(x) - q) &amp;= \delta^{(n)} (N\hat p(x) - N q) <span class="sc">\\</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>&amp;= \prod_{k=1}^n \delta \left( \sum_{j=1}^N 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span> - Nq_k \right) <span class="sc">\\</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>&amp;= \prod_{k=1}^n \frac{1}{2\pi} \int d\lambda_k e^{i\lambda_k \left( \sum_{j=1}^N 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span> - Nq_k \right)} <span class="sc">\\</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>&amp;=_{\ln} \int d^n \lambda e^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span> - Nq_k \right)}</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="exchange the order of integration" collapse="true" }</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>Now we exchange the order of integration.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>Pr(\hat p =_\epsilon q) &amp;= {\color{red}\int_{\R^N} \rho(x) d^N x} {\color{red}\int d^n \lambda} e^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span> - Nq_k \right)} <span class="sc">\\</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>&amp;= \int d^n \lambda \int_{\R^N} \rho(x) d^N xe^{i \sum_{k=1}^n \lambda_k \left( \sum_{j=1}^N 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span> - Nq_k \right)} <span class="sc">\\</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>&amp;= \int d^n \lambda e^{-iN \sum_{k=1}^n \lambda_k q_k}  \int_{\R^N} \rho(x) d^N x e^{i \sum_{j=1}^N \sum_{k=1}^n \lambda_k 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span>} <span class="sc">\\</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="inner integral" collapse="true" }</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>The inner integral splits because of the independence of $x_1, ..., x_N$.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>\int_{\R^N} \rho(x) d^N x e^{i \sum_{j=1}^N \sum_{k=1}^n \lambda_k 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span>} = \prod_{j=1}^N \langle e^{i \sum_{k=1}^n \lambda_k 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span>}\rangle_{x_j}</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>where the angled bracket denotes a probability expectation, and the subscript $x_j$ denotes what we are taking the expectation over. Because all $x_j$ have the same distribution, it is equal to</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>\langle e^{i \sum_{k=1}^n \lambda_k 1<span class="co">[</span><span class="ot">x_j = k</span><span class="co">]</span>}\rangle_{x_1}^N = \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)^N = e^{N \ln \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)}</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="outer integral" collapse="true" }</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>Pr(\hat p =_\epsilon q) &amp;= \int d^n \lambda e^{-iN \sum_{k=1}^n \lambda_k q_k + N \ln \left(\sum_{k=1}^n p_k e^{i\lambda_k} \right)} <span class="sc">\\</span></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>&amp;= \int d^n \lambda e^{NS<span class="co">[</span><span class="ot">\lambda</span><span class="co">]</span>}</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>where the field free energy is</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>$$S<span class="co">[</span><span class="ot">\lambda</span><span class="co">]</span> = \ln \left( \sum_{k\in 1:n}p_k e^{i \lambda_k}\right)-i\sum_{k\in 1:n} \lambda_k q_k$$</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="the mean field equation" collapse="true" }</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>The dominant contribution to the integral arises from the saddle point of the action, which corresponds to the solution of the mean field equation</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>$$\nabla_{\lambda} S = 0$$</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>The mean field equation is solved by some $\lambda^*$ satisfying:</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>$$\begin{cases}</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>i\lambda_k^* = \ln(C q_k/p_k) <span class="sc">\\</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>C = \sum_k p_k e^{i\lambda_k^*}</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>Unfortunately, it is difficult to solve this in closed form, but we are on a lucky break: plugging them back to $S<span class="co">[</span><span class="ot">\lambda^*</span><span class="co">]</span>$ gives us a clean solution:</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>Plugging those back to $S$, we find that </span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>$$S<span class="co">[</span><span class="ot">\lambda^*</span><span class="co">]</span> = -\sum_{k=1}^n q_k \ln(q_k/p_k) = -D_{KL}(q<span class="sc">\|</span> p)$$</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>Conclusion</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a>$$Pr(\hat p =_{\epsilon} q) =_{\ln} e^{NS[\lambda^*]} = e^{-ND_{KL}(q <span class="sc">\|</span> p)}$$ </span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The reader who has never encountered this type of reasoning before may wonder why use such an indirect approach. It turns out that it is a very common formalism in statistical physics, where similar methods are also applied, under the name 'field theory', to continuous spaces $\mathcal X$ (some implicit discretization is then usually assumed at intermediate steps, and the correct definition of a continuum limit is often not obvious). In particular, the reader interested in the statistical-physics approach to optimization problems or information theory will often find this type of calculation in research papers. One of the advantages of this approach is that it provides a formal solution to a large variety of problems. The quantity to be computed is expressed in an integral form. In problems that have a ‘mean-field’ structure, the dimension of the space over which the integration is performed does not depend upon N. Therefore its leading exponential behaviour at large N can be obtained by saddle point methods. The reader who wants to get some practice with this approach is invited to ‘derive’ the various theorems and corollaries of this chapter in this way.</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@mezardInformationPhysicsComputation2009, section 4.7</span><span class="co">]</span></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overlap matrix</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setup</span></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a>We investigate the properties of a set of $k$ random vectors sampled uniformly from a high-dimensional sphere as the dimension $N$ approaches infinity. Let $\sigma_1, ..., \sigma_k$ be these vectors, each belonging to $\mathbb{R}^N$ with a norm of $\sqrt{N}$, and let $\sigma$ be the matrix formed by concatenating these vectors: $\sigma = <span class="co">[</span><span class="ot">\sigma_1, ..., \sigma_k</span><span class="co">]</span>$.</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a>Since $E<span class="co">[</span><span class="ot">\sigma</span><span class="co">]</span> = 0$, we focus on analyzing the variance of $\sigma$, divided by $N$. Define the matrix $\bar{Q}$ as the normalized outer product of $\sigma$:</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>$$\bar Q := \sigma^T \sigma/N = \frac 1N</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>\sigma_1^T\sigma_1 &amp; \sigma_1^T\sigma_2 &amp; \cdots &amp;\sigma_1^T\sigma_k<span class="sc">\\</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>\sigma_2^T\sigma_1 &amp; \sigma_2^T\sigma_2 &amp; \cdots &amp;\sigma_2^T\sigma_k <span class="sc">\\</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>\vdots &amp; \vdots &amp; \ddots &amp; \vdots <span class="sc">\\</span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>\sigma_k^T\sigma_1 &amp; \sigma_k^T\sigma_2 &amp; \cdots &amp; \sigma_k^T\sigma_k</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}$$</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>We know that $\bar{Q}$ is symmetric, has all entries within the range $<span class="co">[</span><span class="ot">-1, +1</span><span class="co">]</span>$, and has diagonal entries equal to $+1$. Our goal is to uncover further properties of this matrix as $N$ becomes very large.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>Let $Q$ be an arbitrary symmetric matrix with entries in the range $<span class="co">[</span><span class="ot">-1, +1</span><span class="co">]</span>$ and with diagonal entries equal to $+1$. We aim to calculate the rate function $S$ that quantifies the probability of observing an empirical distribution $\bar{Q}$ that is close to $Q$ as $N\to\infty$:</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>$$Pr(\bar Q =_\epsilon Q) =_{\ln} e^{-NS<span class="co">[</span><span class="ot">Q</span><span class="co">]</span>}$$</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>More rigorously, we seek to determine:</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>$$\lim _{\epsilon \rightarrow 0} \lim _{N \rightarrow \infty} \frac{1}{N} \log Pr \left(\bar{Q}(\sigma)_{i j} \in\left[Q_{i j}-\epsilon, Q_{i j}+\epsilon\right], \forall i, j\right)$$</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a><span class="fu">### Field-theoretic interpretation</span></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>We can interpret this problem through the lens of statistical physics. Imagine a system of $N$ identical particles, each possessing $k$ degrees of freedom. For instance, the $i$-th particle has degrees of freedom represented by $(\sigma_{1, i}, \dots, \sigma_{k, i})$.</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>These particles interact with each other equally, regardless of their spatial separation. This "infinite-range interaction" imposes a global constraint on the system, ensuring a form of "average kinetic energy conservation". We express this constraint as:</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>$$\forall j\in 1:k, \quad \sum_{i \in 1:N}\sigma_{j, i}^2 = N$$</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>To illustrate, if we consider $\sigma_{j, i}$ as the type-$j$ velocity of the $i$-th particle, then the constraint implies that the average type-$j$ kinetic energy per particle remains constant at $1/2$, even as the number of particles increases.</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>Since $\bar{Q}_{j, j'} = \frac{1}{N} \sum_{i\in 1:N}\sigma_{j, i} \sigma_{j', i}$, the matrix $\bar{Q}$ represents the average covariance between different types of velocities in this system.</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="fu">### Field-theoretic calculation</span></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a>This section is based on <span class="co">[</span><span class="ot">@meiSTAT260MeanField2021, lecture 8</span><span class="co">]</span>.</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="formulate a constraint" collapse="true" }</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>To prepare for the introduction of the Dirac delta factor, we need to move the constraint from the integral domain to the integrand.</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) &amp;= \E_\sigma [1[\bar Q(\sigma) - Q =_\epsilon 0]]<span class="sc">\\</span></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>&amp;= \E_\sigma \left<span class="co">[</span><span class="ot">\prod_{1 \leq i &lt; j \leq k} 1[\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0]\right</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>Notice well the interplay of two dimensions: The integral $\E_\sigma$ is over a very large space, over *all* particles' states, of dimension, so it has dimension $\sim k^2 N$. The constraint $1[\bar Q(\sigma) - Q =_\epsilon 0]$ is on the *average* states of all particles, so it is over a small space of fixed dimensions $\sim k^2$.</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>Again, we do that $1<span class="co">[</span><span class="ot">x=_\epsilon 0</span><span class="co">]</span> \approx \delta(x)/\epsilon$ trick again, and we get</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) =_{\ln} \E_\sigma \left[\prod_{1 \leq i &lt; j \leq k} \delta(\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0)\right]</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>Notice how we have the product $\prod$ over $1 \leq i &lt; j \leq k$, because $\bar Q, Q$ are both symmetric, with diagonal entries equal to $+1$. If we were to write something like $\prod_{1 \leq i \red{\leq} j \leq k}$, we would cause $\delta(\bar Q_{i, i}(\sigma) - Q_{i, i} =_\epsilon 0)$ to always be infinite, which does not work.</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="formulate a constraint, take 2" collapse="true" }</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>It turns out we have not finished with the constraint yet. Back when we did Sanov's theorem, because the particles are not interacting, we had to only formulate one constraint, a global one where $\hat p =_\epsilon q$. In this case, the particles *are* interacting by the conservation of kinetic energy:</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>$$\forall j\in 1:k, \quad \frac 1N \sum_{i \in 1:N}<span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>_2^2 = 1$$</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>Let us go back to the start again:</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) &amp;= \E_\sigma [1[\bar Q(\sigma) - Q =_\epsilon 0]] <span class="sc">\\</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{(\sqrt N S^N)^k}\frac{d\sigma}{\mathrm{Vol}(\sqrt N S^N)^k} \; 1<span class="co">[</span><span class="ot">\bar Q(\sigma) - Q =_\epsilon 0</span><span class="co">]</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>The integral over $(\sqrt N S^N)^k$ is uncomfortable. What to do? ... That's right, when the domain of integral is uncomfortable, we use a Dirac delta factor to move it into the integrand:</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>= \frac{\int_{\R^{N \times k}} \delta(\cdots) d\sigma \; 1<span class="co">[</span><span class="ot">\bar Q(\sigma) - Q =_\epsilon 0</span><span class="co">]</span>}{\int_{\R^{N \times k}} \delta(\cdots) d\sigma}</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>where we must fill in the constraint of $\sigma \in (\sqrt N S^N)^k$ into the $\delta(\cdots)$. Now, $\sigma \in (\sqrt N S^N)^k$ is equivalent to $\frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 = 0$ for all $j\in 1:k$, so naturally, we should try $\prod_{j\in 1:k} \delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right)$, giving us</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>= \frac{\int_{\R^{N \times k}} {\color{red} \prod_{j\in 1:k} \delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right)} d\sigma \; 1<span class="co">[</span><span class="ot">\bar Q(\sigma) - Q =_\epsilon 0</span><span class="co">]</span>}{\int_{\R^{N \times k}} {\color{red} \prod_{j\in 1:k} \delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right)} d\sigma}</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="the off-shell trick" collapse="true" }</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>Let's take a moment to see what the trick is. The trick is this: We need to integrate something over the uniform distribution on $(\sqrt N S^N)^k$, but integrating over it is difficult, because we don't have a convenient coordinate system over the sphere $\sqrt N S^N$. So instead, we slightly thicken each sphere,<span class="ot">[^qft-off-shell]</span> and suddenly we can integrate over the real space $\R^{N \times k}$, for which we *do* have a good coordinate system:</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="ot">[^qft-off-shell]: </span>If we return to our field-theoretic interpretation, then allowing $\sigma_j$ to have norm $\sqrt N \pm \sqrt N \epsilon$ means that we are allowing the average type-$j$ kinetic energy to fluctuate a bit, even though it is exactly $1$. Quantum field theorists call this **off the (kinetic) energy shell**, and if you ask, they might wave mysteriously in the air and speak of "virtual particles" and "Faddeev-Popov ghosts".</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>\E_{\sigma \sim \mathrm{Uniform}((\sqrt N S^N)^k)} <span class="co">[</span><span class="ot">\text{something}</span><span class="co">]</span> = \lim_{\epsilon \downarrow 0} \E_{\sigma \sim \mathrm{Uniform}((\sqrt N S^N \text{thickened by }\sqrt N \epsilon )^k)} <span class="co">[</span><span class="ot">\text{something}</span><span class="co">]</span></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a>Now, since</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>\sigma_j \in \sqrt N S^N \text{thickened by }\sqrt N \epsilon \iff <span class="sc">\|</span>\sigma_j<span class="sc">\|</span>^2 - N \in \pm N\epsilon \iff \frac 1N <span class="sc">\|</span>\sigma_j<span class="sc">\|</span>^2 - 1 =_\epsilon 0</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>we can write the constraint as $1 \left( \frac 1N <span class="sc">\|</span>\sigma_j<span class="sc">\|</span>^2 - 1 =_\epsilon 0 \right) = \delta \left( \frac 1N <span class="sc">\|</span>\sigma_j<span class="sc">\|</span>^2 - 1 \right)/\epsilon$.</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="formulate a constraint, take 3" collapse="true" }</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a>Again we must handle the constraint of $1<span class="co">[</span><span class="ot">\bar Q(\sigma) - Q =_\epsilon 0</span><span class="co">]</span>$, but this time it's different. Whereas before, we had to use $\left<span class="co">[</span><span class="ot">\prod_{1 \leq i \red{&lt;} j \leq k} 1[\bar Q_{i, j}(\sigma) - Q_{i, j} =_\epsilon 0]\right</span><span class="co">]</span>$, this time we have to use $\prod_{1 \leq i \red{\leq} j \leq k}$. Why? Because this time, we have set $\sigma$ free from the cage of $(\sqrt N S^N)^k$, so the diagonal entries of $\bar Q(\sigma)$ are no longer forced to stay exactly $+1$. Thus, we have to do this instead:</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right) d\sigma \; 1<span class="co">[</span><span class="ot">\bar Q(\sigma) - Q =_\epsilon 0</span><span class="co">]</span>}{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right) d\sigma} <span class="sc">\\</span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a>&amp;=_{\ln} \frac{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma \; \prod_{1 \leq s \red{\leq} t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}<span class="sc">\|</span>^2 - 1 \right) d\sigma} <span class="sc">\\</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="introduce a Dirac delta" collapse="true" }</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>We have already done the Dirac deltas. To remind you,</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) =_{\ln}\frac{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}\|^2 - 1 \right) d\sigma \; \prod_{1 \leq s \leq t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \frac 1N \|\sigma_{j}<span class="sc">\|</span>^2 - 1 \right) d\sigma}</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>Actually, it is more convenient to scale the $\delta\left( \frac 1N <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - 1 \right)$ both above and below the fraction to $\delta\left( <span class="sc">\|</span>\sigma_{j}<span class="sc">\|</span>^2 - N \right)$, and similarly scale the $\delta(\bar Q_{s, t}(\sigma) - Q_{s, t})$ to $\delta(N\bar Q_{s, t} - NQ_{s, t}) N$, giving us</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) =_{\ln}\frac{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \|\sigma_{j}\|^2 - N \right) d\sigma \; \prod_{1 \leq s \leq t \leq k} \delta(\bar Q_{s, t}(\sigma) - Q_{s, t})}{\int_{\R^{N \times k}} \prod_{j\in 1:k} \delta\left( \|\sigma_{j}<span class="sc">\|</span>^2 - N \right) d\sigma}</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>where we have discarded the factor of $N^{\frac 12 k(k+1)}$, because it does not matter after taking $\frac 1N \ln(\cdots)$.</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="evaluate the numerator by field equation" collapse="true" }</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>Since this time we can't do the inner integral easily, we will rush directly to the field equation. Don't worry, as it will all come out correct in the end.</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>Do the Fourier transform of the Dirac delta factor, and exchange the order of integration. We first do the numerator.</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{\R^{N \times k}} d\sigma \int_{1 \leq l \leq k, \; 1 \leq i \leq j \leq k} d\lambda_l dq_{ij} e^{i \left(</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a>\right)} <span class="sc">\\</span></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{1 \leq l \leq k, \; 1 \leq i \leq j \leq k} d\lambda_l dq_{ij} \int_{\R^{N \times k}} d\sigma e^{i \left(</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>\right)} <span class="sc">\\</span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>As before, we only need to find the "least unlikely of all unlikely ways". That is, we only need to pick the least tiny of all tiny inner integrals. In other words, we need to find a stationary point where it has finally ceased being so tiny:</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>$$0 = \nabla_{q, \lambda}\int_{\R^{N \times k}} d\sigma e^{i \left(</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>\right)}$$</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>Because we are seeking a stationary point, and we are already doing it physicists, it is no big problem if we seek stationary points over all of the complex plane. That is, we allow $q, \lambda$ to take not just real, but also complex values.<span class="ot">[^steepest-descent]</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a><span class="ot">[^steepest-descent]: </span>If you want justification, look up "the method of steepest descent" <span class="co">[</span><span class="ot">@erdelyiAsymptoticExpansions1956, section 2.5</span><span class="co">]</span>. Intuitively speaking, it is because when we are doing an integral like $\int_\R dq (\cdots)$, we are doing a path integral in the complex plane, and so we can deform the path integral in the complex plane and still get the same result. Thus, we can deform it so hard that it walks across a "mountain pass" in the complex plane, where the saddle-point of the mountain pass is where $\nabla_q (\cdots) = 0$ -- i.e., a stationary point.</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>Then we can scale both by $-i$ and get</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>\nabla_{q, \lambda}\int_{\R^{N \times k}} d\sigma e^{- \left(</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N) + \sum_{1 \leq i \leq j \leq k} q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>\right)}</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>For cleaner notation, we define $q_{ji} = q_{ij}$, and $\Lambda = \mathrm{diag}(\lambda_1, \dots, \lambda_k)$. Noting that $Q_{ii} = 1$ for all $i$, we get</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a>\nabla_{q, \lambda}\int_{\R^{N \times k}} d\sigma e^{- \left(\sum_{ij} (\Lambda_{ij} + \frac 12 q_{ij}) (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>\right)}</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>Since the stationary point of this with respect to $q, \lambda$ is the same as the stationary point of this with respect to $\Lambda + \frac 12 q$, we need only</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a>\nabla_{q}\int_{\R^{N \times k}} d\sigma e^{- \left(\sum_{ij} \frac 12 q_{ij} (\sigma_i^T \sigma_j - NQ_{ij})</span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a>\right)}</span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="evaluate the denominator by field equation" collapse="true" }</span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>At this point, it's easier to evaluate the denominator first.</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>The same argument given above applies to the denominator. If you are pressed for time, you can just take the previous derivation for the saddle point equation, and set $q = 0, Q = 0$. This gives the field equation</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>0 = \nabla_{\lambda}\int_{\R^{N \times k}} d\sigma e^{-\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N)}</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>Now, the integral is just a gaussian integral, and it factors, too!</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>\int_{\R^{N \times k}} d\sigma e^{-\sum_{1 \leq l \leq k} \lambda_l (\sigma_l^T \sigma_l - N)} = \prod_l e^{N \lambda_l} \left(\int_\R d\sigma e^{-\lambda_l \sigma^2} \right)^N = e^{N\sum_l (\lambda_l - \frac 12 \ln\lambda_l + \frac 12 \ln \pi)}</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>Its stationary point is $e^{N \frac k2 ( 1 + \ln 2\pi)}$.</span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="evaluate the numerator, continued" collapse="true" }</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>Where we left off, we had to solve the field equation</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>0 = \nabla_{q}e^{\frac 12 N \sum_{ij}q_{ij}Q_{ij}} \int_{\R^{N \times k}} d\sigma e^{-\sum_{ij} \frac 12 q_{ij} \sigma_i^T \sigma_j}</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>The integral is just a gaussian integral, and it factors, too:</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{\R^{N \times k}} d\sigma e^{-\frac 12 \sum_{ij}q_{ij}\sigma_i^T \sigma_j} <span class="sc">\\</span></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>&amp;= \left(\int_{\R^{ k}} d\sigma e^{-\frac 12 \sum_{ij}q_{ij}\sigma_i \sigma_j}\right)^N <span class="sc">\\</span></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>&amp;= (2\pi)^{Nk/2}\det(q)^{-N/2}</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>Taking the derivative, we observe that $\nabla_q \ln \det q = (q^{-1})^T$ for an arbitrary matrix $q$. However, as $q$ is constrained to be a symmetric matrix, we obtain</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>$$\partial_{q_{ij}}(\braket{Q,q} - \ln\det (q)) = \begin{cases}</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a>Q_{ij}+ Q_{ji} - (q^{-1})_{ij} - (q^{-1})_{ji} &amp; i\neq j <span class="sc">\\</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>Q_{ii}- (q^{-1})_{ii} &amp; i=j</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a>\end{cases}$$</span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a>Setting all derivatives to zero yields the solution $q = (Q^{-1})^T = Q^{-1}$. Notably, there exists only one stationary point within the entire multidimensional complex space.</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>We proceed to compute the numerator, resulting in</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>=\exp\left(\frac N2(\braket{Q^{-1}, Q} + k \ln(2\pi) - \ln \det Q^{-1})\right) = \exp\left(\frac N2(k+ k \ln(2\pi) + \ln \det Q)\right)</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a>In summary, we have</span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>Pr(\bar Q =_\epsilon Q) =_{\ln} \frac{\exp\left(\frac N2(k+ k \ln(2\pi) + \ln \det Q)\right)}{\exp\left({N \frac k2 ( 1 + \ln 2\pi)}\right)} = e^{N S<span class="co">[</span><span class="ot">Q</span><span class="co">]</span>}</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a>where the rate function is</span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a>$$S<span class="co">[</span><span class="ot">Q</span><span class="co">]</span> = \frac 12 \ln \det Q$$</span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a><span class="fu">## Easy results</span></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>Now that you have gone through that effort learning field-theoretic calculations, enjoy some quick and simple results.</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a><span class="fu">### Asymptotics of spherical volumes</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a>Let $S^{N-1}(r)$ be the sphere of radius $r$ in $\R^N$, then </span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>$$|S^{N-1}(\sqrt N)| \sim (2\pi e)^{N/2}$$</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="true"}</span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a>$$\begin{aligned}</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>      <span class="pp">|</span>S^{N-1}(\sqrt N)<span class="pp">|</span> &amp;= \int_{\R^N} \delta(x^T x- N )dx <span class="sc">\\</span></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a>      &amp;=_{\ln} \int_{\R^N} \int_\R e^{iq(x^T x- N )} dqdx <span class="sc">\\</span></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>      &amp;= \int_{\R} dq \; e^{-iqN} \left<span class="co">[</span><span class="ot">\int_{\R^N} e^{iqx^T x} dx\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a>      &amp;= \int_{\R} dq \; e^{-iqN} \left<span class="co">[</span><span class="ot">\int_{\R} e^{iqx^2} dx\right</span><span class="co">]</span>^N <span class="sc">\\</span></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>      &amp;= \int_{\R} dq \; e^{-iqN} (e^{i\pi/4}\sqrt{\pi/q})^N <span class="sc">\\</span></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a>      \end{aligned}$$   - Thus, $\frac 1N \ln |S^{N-1}(\sqrt N)|$ converges to the stationary point of</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a>$$-iq + \frac{i\pi}{4} + \frac 12 \ln \pi - \frac 12 \ln q$$</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a>which occurs at $q^* = i/2$. Plugging it in, we obtain  </span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a>$$\frac 1N \ln |S^{N-1}(\sqrt N)| \to \ln\sqrt{2\pi e}$$ </span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Probabilistic interpretation" collapse="true"}</span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>As is well-known, in high-dimensions, everything looks like a gaussian. Specifically, the standard gaussian distribution $\mathcal N(0, I_N)$ in $\R^N$ space is strongly concentrated around the spherical shell of radius $\sqrt N$, by the law of large numbers. Therefore, the log-surface area of $S^{N-1}(\sqrt N)$ converges to the entropy of the $\mathcal N(0, I_N)$, which is just $N$ times the entropy of $\mathcal N(0, 1)$.</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>In more detail, we can sample from $\mathcal N(0, I_N)$ in two ways: Either directly sample $N$ standard normal variables independently, or sample a point on $S^{N-1}(\sqrt N)$, before shifting it along the radius by an independently sampled displacement. Both ways give us exactly the same entropy. Now, because the radius of $x \sim \mathcal N(0, I_N)$ is distributed as the square-root of the <span class="co">[</span><span class="ot">chi-squared distribution</span><span class="co">](https://en.wikipedia.org/wiki/Chi-squared_distribution)</span> $\chi^2_N$, we have </span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>$$r^2 = <span class="sc">\|</span>x<span class="sc">\|</span>^2 \sim \chi^2_N \approx \mathcal N(N, 2N)$$</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>When $N$ is large, we can write $r^2 \approx N + \sqrt{2N} z$ where $z \sim \mathcal(0, 1)$, so $r \approx \sqrt N + 2^{-1/2}z$. Therefore, the amount of radial displacement is roughly constant, and we have</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>\mathrm{Ent}<span class="co">[</span><span class="ot">\mathcal N(0, I_N)</span><span class="co">]</span> \approx \ln |S^{N-1}(\sqrt N)| + \mathrm{Ent}<span class="co">[</span><span class="ot">\mathcal N(0, 1/2)</span><span class="co">]</span></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>giving us the second term in the Stirling approximation:</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a>\frac 1N \ln |S^{N-1}(\sqrt N)| = \ln\sqrt{2\pi e} + \frac{\ln\sqrt{\pi e}}{N} + O(N^{-2})</span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cramér's theorem</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a>The most commonly used result from large deviation theory is Cramér's theorem <span class="co">[</span><span class="ot">@demboLargeDeviationsTechniques2009, theorem 2.2.30</span><span class="co">]</span>.</span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>::: {#thm-cramer}</span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a><span class="fu"># Cramér</span></span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a>Given a vector function $M: X \to \R^m$ and a distribution on $X$, its rate function is the convex transform of its cumulant generating function:</span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a>$$I_X(x) := \sup_{k \in \R^m}(\braket{k,x} - \ln \E_x<span class="co">[</span><span class="ot">e^{\braket{k, M(x)}}</span><span class="co">]</span>)$$</span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a>That is, for any compact subset $A \subset \R^m$, the rate function over the whole subset is just the highest possible rate:</span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a>$$\lim_N\frac 1N \ln Pr\left(\frac 1N \sum_{i=1}^N M(x_i) \in A\right) = \sup_{x\in A} -I_X(x)$$</span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a>where $x_1, ..., x_N$ are IID samples from the same distribution.</span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="true"}</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>It suffices to prove it for $A$ being really small, essentially just a single point, because we can then cut up the whole of $A$ into many pieces like that, and then run the result on each piece. The rate difference is such that only the highest rate can survive, as it races pass every other piece exponentially fast: $N^{-1} \ln (e^{-Na} + e^{-Nb}) \to \max(-a, -b)$, and even if two pieces have the exact same rate, then their combined rate gains a negligible factor of $N^{-1}\ln 2 \to 0$.</span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a>So, we once again repeat the same calculation:</span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a>Pr\left(\frac 1N \sum_{i=1}^N M(x_i) =_\epsilon m\right) &amp;=_{\ln}  \E_x \left<span class="co">[</span><span class="ot">\delta^{(m)}\left(\sum_i M(x_i) - Nm\right)\right</span><span class="co">]</span> &amp; \text{ only $m$ terms in the Dirac delta}<span class="sc">\\</span></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a>&amp;=   \E_x \left<span class="co">[</span><span class="ot">\int_{\R^m} dq e^{i\braket{iq, \sum_i M(x_i) - Nm}}\right</span><span class="co">]</span>  &amp; \text{Dirac delta Fourier transform} <span class="sc">\\</span></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{\R^m} dq e^{-N \braket{iq, m}}\E_x<span class="co">[</span><span class="ot">e^{\braket{iq, M}}</span><span class="co">]</span>^N&amp; \text{IID assumption} <span class="sc">\\</span></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a>&amp;= \int_{\R^m}dq e^{N(-\braket{iq, m} + \ln \E_x<span class="co">[</span><span class="ot">e^{\braket{iq, M}}</span><span class="co">]</span>)}</span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>The last equation is again dominated by the stationary point. This would give us</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a>$$=_{\ln}\mathrm{stat}_{q\in \mathbb C^m} e^{N(-\braket{q, m} + \ln \E_x<span class="co">[</span><span class="ot">e^{\braket{q, M}}</span><span class="co">]</span>)}$$</span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a>We still don't know *which* stationary point we should pick. However, in large deviation theory, we usually pick the global minimum, and most often, the global minimum is the unique stationary point in the real space. Assuming that, we have</span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a>$$\frac 1N \ln Pr\left(\frac 1N \sum_{i=1}^N M(x_i)\right) \to -\sup_{q\in \mathbb R^m} (\braket{q, m} - \ln \E_x<span class="co">[</span><span class="ot">e^{\braket{q, M}}</span><span class="co">]</span>)$$ </span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a>:::</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>