<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2024-01-20">
<meta name="description" content="Minimizing log-perplexity loss is equivalent to maximizing survival length in a Turing test. Assuming compute-loss scaling law, a scaled-up GPT that produces human-like science papers would cost ~200 years of global GDP.">

<title>Predicting AGI by the Turing Test – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-493ec8732bc442be923a7677f0a4f8b4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Predicting AGI by the Turing Test – Yuxi on the Wired">
<meta property="og:description" content="Minimizing log-perplexity loss is equivalent to maximizing survival length in a Turing test. Assuming compute-loss scaling law, a scaled-up GPT that produces human-like science papers would cost ~200 years of global GDP.">
<meta property="og:image" content="https://yuxi.ml/essays/posts/perplexity-turing-test/figure/banner_4_edit.png">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta property="og:image:height" content="1024">
<meta property="og:image:width" content="1792">
<meta property="og:image:alt" content="An abstract representation of the Turing test. On the left is a dark city of obelisks over a bright background, and on the right is the same thing, mirrored and inverted, but with subtle differences due to the randomness of the art generator. It represents the abstract idea of the Turing test: duality, subtle differences, same contours, and complex object made of simple parts. High contrast, monochromatic, minimalistic, in the style of vector svg art.">
<meta name="twitter:title" content="Predicting AGI by the Turing Test – Yuxi on the Wired">
<meta name="twitter:description" content="Minimizing log-perplexity loss is equivalent to maximizing survival length in a Turing test. Assuming compute-loss scaling law, a scaled-up GPT that produces human-like science papers would cost ~200 years of global GDP.">
<meta name="twitter:image" content="https://yuxi.ml/essays/posts/perplexity-turing-test/figure/banner_4_edit.png">
<meta name="twitter:image-height" content="1024">
<meta name="twitter:image-width" content="1792">
<meta name="twitter:image:alt" content="An abstract representation of the Turing test. On the left is a dark city of obelisks over a bright background, and on the right is the same thing, mirrored and inverted, but with subtle differences due to the randomness of the art generator. It represents the abstract idea of the Turing test: duality, subtle differences, same contours, and complex object made of simple parts. High contrast, monochromatic, minimalistic, in the style of vector svg art.">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../logs/index.html"> 
<span class="menu-text">Logs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi_liu@berkeley.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../feeds.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Predicting AGI by the Turing Test</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Minimizing log-perplexity loss is equivalent to maximizing survival length in a Turing test. Assuming compute-loss scaling law, a scaled-up GPT that produces human-like science papers would cost ~200 years of global GDP.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">scaling</div>
                <div class="quarto-category">math</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 20, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 25, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#turing-test-as-statistical-hypothesis-test" id="toc-turing-test-as-statistical-hypothesis-test" class="nav-link" data-scroll-target="#turing-test-as-statistical-hypothesis-test">Turing test as statistical hypothesis test</a>
  <ul class="collapse">
  <li><a href="#turing-test" id="toc-turing-test" class="nav-link" data-scroll-target="#turing-test">Turing test</a></li>
  <li><a href="#sequential-hypothesis-testing" id="toc-sequential-hypothesis-testing" class="nav-link" data-scroll-target="#sequential-hypothesis-testing">Sequential hypothesis testing</a></li>
  <li><a href="#slowdown-factor" id="toc-slowdown-factor" class="nav-link" data-scroll-target="#slowdown-factor">Slowdown factor</a></li>
  <li><a href="#measuring-the-slowdown-factor" id="toc-measuring-the-slowdown-factor" class="nav-link" data-scroll-target="#measuring-the-slowdown-factor">Measuring the slowdown factor</a></li>
  </ul></li>
  <li><a href="#entropy-of-natural-languages" id="toc-entropy-of-natural-languages" class="nav-link" data-scroll-target="#entropy-of-natural-languages">Entropy of natural languages</a>
  <ul class="collapse">
  <li><a href="#sec-chinchilla-scaling" id="toc-sec-chinchilla-scaling" class="nav-link" data-scroll-target="#sec-chinchilla-scaling">Chinchilla scaling</a></li>
  <li><a href="#turing-completeness" id="toc-turing-completeness" class="nav-link" data-scroll-target="#turing-completeness">Turing-completeness</a></li>
  <li><a href="#guessing-game" id="toc-guessing-game" class="nav-link" data-scroll-target="#guessing-game">Guessing game</a></li>
  <li><a href="#lossless-compression" id="toc-lossless-compression" class="nav-link" data-scroll-target="#lossless-compression">Lossless compression</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#sec-forecasting-agi" id="toc-sec-forecasting-agi" class="nav-link" data-scroll-target="#sec-forecasting-agi">Forecasting AGI</a></li>
  <li><a href="#sec-ergodic-theory" id="toc-sec-ergodic-theory" class="nav-link" data-scroll-target="#sec-ergodic-theory">Appendix: Ergodic theory</a>
  <ul class="collapse">
  <li><a href="#measure-theoretic-pov" id="toc-measure-theoretic-pov" class="nav-link" data-scroll-target="#measure-theoretic-pov">Measure-theoretic POV</a></li>
  <li><a href="#sequence-pov" id="toc-sequence-pov" class="nav-link" data-scroll-target="#sequence-pov">Sequence POV</a></li>
  <li><a href="#sec-smb-theorem" id="toc-sec-smb-theorem" class="nav-link" data-scroll-target="#sec-smb-theorem">Shannon–McMillan–Breiman</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="abstract" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This essay explains <em>the Direct Approach</em> proposed by <span class="citation" data-cites="barnettScalingTransformativeAutoregressive2023">(<a href="#ref-barnettScalingTransformativeAutoregressive2023" role="doc-biblioref">Barnett and Besiroglu 2023a</a>)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> I encourage you to play with the <a href="https://epochai.org/blog/direct-approach-interactive-model"><em>Direct Approach Interactive Model</em></a> to explore an interactive simulation using the approach.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;The thing is released in a scattered way, typical for an internet-native publication. There is the report <span class="citation" data-cites="barnettScalingTransformativeAutoregressive2023">(<a href="#ref-barnettScalingTransformativeAutoregressive2023" role="doc-biblioref">Barnett and Besiroglu 2023a</a>)</span>, in the form of a paper – clearly meant to be cited, despite being hard to read. There is the website <span class="citation" data-cites="barnettDirectApproach2023">(<a href="#ref-barnettDirectApproach2023" role="doc-biblioref">Barnett and Besiroglu 2023b</a>)</span>, in the form of a blog post – clearly meant to be read, despite not being upper-class enough to be cited in journal papers. Finally there is the <a href="https://epochai.org/blog/direct-approach-interactive-model">interactive model</a> which looks like an optional add-on to the blog post.</p></div></div><blockquote class="blockquote">
<p>The Direct Approach framework bounds the compute requirements for transformative AI by extrapolating neural scaling laws. We combine those estimates with simple models of future progress in algorithms, investment, and compute costs to produce a user-adjustable forecast over the date at which TAI will be achieved. <span class="citation" data-cites="barnettDirectApproach2023">(<a href="#ref-barnettDirectApproach2023" role="doc-biblioref">Barnett and Besiroglu 2023b</a>)</span></p>
</blockquote>
<p>From the POV of the judge, a Turing test is a sequential test for two statistical hypotheses – “is human” and “is machine”. Under reasonable assumptions, halving the (reducible part of) log-perplexity loss of the language model would double the time it can survive in a Turing test.</p>
<p>We can think of the peer-review of scientific papers as a Turing test, and say that AGI has arrived when we have AI scientists that can pass the papers peer-review. This allows us to calculate the log-perplexity loss of the first AGI. If we assume it is just a scaled-up GPT, then assuming the Chinchilla scaling law, <a href="#sec-forecasting-agi">it would cost about 200 years of global GDP</a>. This makes it virtually certain that the first AGI will not be a scaled-up GPT.</p>
</section>
<section id="turing-test-as-statistical-hypothesis-test" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="turing-test-as-statistical-hypothesis-test">Turing test as statistical hypothesis test</h2>
<section id="turing-test" class="level3">
<h3 class="anchored" data-anchor-id="turing-test">Turing test</h3>
<p>In the <a href="https://en.wikipedia.org/wiki/Turing_test">Turing test</a>, there are three players: one judge and two players. The first player is a human, and the second is a machine. The judge asks each player text questions and receives text answers. The judge must decide who is the human.</p>
<p>We consider a simplified Turing test. In this test, the judge does not ask, and simply receives <em>one</em> stream of text <span class="math inline">\(X_{1:\infty}\)</span>. The judge must decide whether the stream is produced by the human or the machine, and do so quickly.</p>
<p>Cast in the language of statistical hypothesis testing, we have two hypotheses:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: “the stream is produced by the human”;</li>
<li><span class="math inline">\(H_1\)</span>: “the stream is produced by the machine”.</li>
</ul>
<p>The judge would read from the stream <span class="math inline">\(X_{1:\infty}\)</span>, <code>o-n-e- -t-o-k-e-n</code> at a time, and at each token, decide whether to take another one, or announce its judgment: <span class="math inline">\(H_0\)</span> or <span class="math inline">\(H_1\)</span>.</p>
<p>As the organizers of the Turing test, we would start the test by flipping a fair coin to decide whether to use the human or the machine. Therefore, <span class="math inline">\(Pr(H_0) = Pr(H_1)\)</span>, and by Bayes, the posterior log-probability ratio is</p>
<p><span class="math display">\[
\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} = \ln\frac{Pr(H_0|X_{1:n})}{Pr(H_1|X_{1:n})}
\]</span></p>
<p>This allows us to use the <a href="https://en.wikipedia.org/wiki/Sequential_probability_ratio_test">sequential probability ratio test</a> (SPRT). The judge would decide on two decision boundaries, and calculate <span class="math inline">\(\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\)</span> at each token. It would stop and announce the decision as soon as the quantity exceeds one of the boundaries.</p>
<p>For example, suppose the judge wants to decide when the odds ratio is 10 to 1, then it would set the decision boundaries to be <span class="math inline">\([-\ln 10, + \ln 10]\)</span>. If <span class="math inline">\(\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\)</span> goes above <span class="math inline">\(+\ln 10\)</span> when <span class="math inline">\(n = 60\)</span>, then the judge would announce “<span class="math inline">\(H_0\)</span>” at that point.</p>
<p>The <span class="math inline">\(\ln 10\)</span> is a good rule of thumb, which we will use for the remainder of the essay.</p>
</section>
<section id="sequential-hypothesis-testing" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sequential-hypothesis-testing">Sequential hypothesis testing</h3>
<p>Consider the following simple equation:</p>
<p><span id="eq-sprt"><span class="math display">\[
\underbrace{\frac 1n \mathbb{E}_{X \sim Pr(\cdot | H_0)}\left[ \ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\right]}_{\text{$\frac 1n D_{KL}(Pr(\cdot | H_0)\| Pr(\cdot | H_1))$}} = \underbrace{\frac 1n
\mathbb{E}_{X \sim Pr(\cdot | H_0)}\left[\ln\frac{1}{Pr(X_{1:n}|H_1)}\right]}_{\text{negative log-likelihood loss per token}} - \underbrace{\frac 1n  \mathbb{E}_{X \sim Pr(\cdot | H_0)}\left[\frac{1}{\ln Pr(X_{1:n}|H_0)}\right]}_{\text{entropy rate of the human itself}}
\tag{1}\]</span></span></p>
<p>The first term is the KL-divergence per token between the machine and the human. Roughly speaking, it is how different they are, per token emitted. It is an information-theoretic quantity.</p>
<p>The second term is negative log-likelihood loss per token. This is what language models are trained to minimize. We write it as <span class="math inline">\(L\)</span>.</p>
<p>The third term is the entropy rate of the human. It is how random the human is. We write it as <span class="math inline">\(L_\infty\)</span>, because it is the theoretical minimal loss that the language model can reach.</p>
<p>If the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.</p>
<p>Assuming that the human is an ergodic speakers of English,<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> we can sample an infinite stream <span class="math inline">\(X_{1:\infty}\)</span> from the human, then call up the <a href="#sec-smb-theorem">Shannon–McMillan–Breiman theorem</a> and find that</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;In short, an ergodic speaker is someone who has only one speech. If you hear it speak once for a very long time, then hear it speak again for a very long time, then you can take the first and shift it around, so that it looks like the second over a very long sub-segment. Ergodic speakers allow you to take the average over a single very long speech, and be assured that it is close to the average over all possible speeches.</p>
<p>In long, see <a href="#sec-ergodic-theory">the appendix on ergodic theory</a>.</p></div></div><p><span class="math display">\[
\frac 1n \ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} \to L - L_\infty
\]</span></p>
<p>On the other hand, if the machine is also an ergodic speaker of English, then we can sample an infinite stream <span class="math inline">\(X_{1:\infty}\)</span> from the machine, then call up the SMB theorem and find that</p>
<p><span class="math display">\[
\frac 1n \ln\frac{Pr(X_{1:n}|H_1)}{Pr(X_{1:n}|H_0)} \to L' - L_\infty'
\]</span></p>
<p>where unfortunately, we have the odd <span class="math inline">\(L'\)</span> and <span class="math inline">\(L_\infty'\)</span>, defined by</p>
<p><span class="math display">\[
L' := \lim_n \frac 1n
\mathbb{E}_{X \sim Pr(\cdot | H_1)}\left[\ln\frac{1}{Pr(X_{1:n}|H_0)}\right], \quad L_\infty' := \lim_n \frac 1n
\mathbb{E}_{X \sim Pr(\cdot | H_1)}\left[\ln\frac{1}{Pr(X_{1:n}|H_1)}\right]
\]</span></p>
<p>We can interpret them as the loss of the human at imitating the machine, and the entropy rate of the machine itself. When the machine is close enough to the human, we can take the approximation <span class="math inline">\(L' \approx L,  L_\infty' \approx L_\infty\)</span>.</p>
<p>Now, define the log-ratio at step <span class="math inline">\(n\)</span> to be <span class="math inline">\(r_n := \frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\)</span>. During a Turing test, the judge calculates</p>
<p><span class="math display">\[
\begin{aligned}
r_0 &amp;= 1 \\
r_1 &amp;= r_0 + \frac{Pr(X_{1:1}|H_0)}{Pr(X_{1:1}|H_1)} \\
r_2 &amp;= r_1 + \frac{Pr(X_{1:2}|X_{1:1}, H_0)}{Pr(X_{1:2}|X_{1:1}, H_1)} \\
&amp;\cdots
\end{aligned}
\]</span></p>
<p>So, imagine that such a perfect judge is going through a Turing test, upon receiving “my cat is technically”, and we are listening on its thoughts:</p>
<ul>
<li>“If it were a human, then it would start with ‘my’ with probability <span class="math inline">\(0.01\)</span>. If it were a machine, then <span class="math inline">\(0.05\)</span>. Therefore, the odds ratio is 2 to 1.”</li>
<li>“If it were a human, then it would follow ‘my’ with ‘cat’ with probability <span class="math inline">\(0.01\)</span>. If it were a machine, then <span class="math inline">\(0.033\)</span>. Therefore, the odds ratio is 3 to 1.”</li>
<li>“If it were a human, then it would follow ‘is’ with ‘my cat’ with probability… I do not know. However, I do know that the odds <em>ratio</em> is 2 to 1. Now that the total odds ratio is 12 to 1, I can decide: <span class="math inline">\(H_0\)</span>.”</li>
</ul>
<p>We see that the judge does not have to know the probabilities <span class="math inline">\(Pr(X_{1:n}|H_0)\)</span> and <span class="math inline">\(Pr(X_{1:n}|H_1)\)</span>, only their <em>ratio</em>. This might be a minor point, but this idea of likelihood ratio is quite important. It is like “I don’t know how often you say ‘cat’ but I know that you say it twice as often than I do!”.</p>
<p>Let <span class="math inline">\(T^*\)</span> be the time it takes for the judge to decide.</p>
<p><span class="math display">\[T^* \approx \frac{\ln 10}{L - L_\infty}\]</span></p>
<p>Intuitively, each token <em>on average</em> moves the log-probability-ratio away from 0 by another <span class="math inline">\((L-L_\infty)\)</span>. Decision is triggered when it finally moves out of the interval <span class="math inline">\([-\ln 10, +\ln 10]\)</span>.</p>
<p>We are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you’d see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.</p>
</section>
<section id="slowdown-factor" class="level3">
<h3 class="anchored" data-anchor-id="slowdown-factor">Slowdown factor</h3>
<p>To perform the SPRT as described, the judge must know intimately the difference between a human and a machine. Can the judge do that? Can anyone know, with certainty, that I would start my speech with “Forty cats …” with a probability that is <em>exactly</em> 32.42 times that of GPT-3?</p>
<p>As a crude approximation, we can model real-world judges as slowed-down version of the perfect judge. We can imagine that at each step, instead of updating the log-ratio by</p>
<p><span class="math display">\[
\ln r_{n+1} \leftarrow \ln r_n + \ln \frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}
\]</span></p>
<p>we update it by</p>
<p><span class="math display">\[
\ln r_{n+1} \leftarrow \ln r_n + \frac 1s \ln \frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}
\]</span></p>
<p>where <span class="math inline">\(s &gt; 1\)</span> is the <strong>slowdown factor</strong>. This implies that if it takes <span class="math inline">\(\sim T\)</span> tokens for the perfect judge to reach a likelihood ratio of <span class="math inline">\(r\)</span>, it would take <span class="math inline">\(\sim sT\)</span> tokens for a human judge.</p>
</section>
<section id="measuring-the-slowdown-factor" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="measuring-the-slowdown-factor">Measuring the slowdown factor</h3>
<p>The slowdown factor <span class="math inline">\(s\)</span> is unknown.</p>
<blockquote class="blockquote">
<p>Informed by an internal poll, we enforce a lognormal distribution with a median of 53.1, a 15th percentile estimate of 9.84, and an 85th percentile of 290. <span class="citation" data-cites="atkinsonDirectApproachInteractive2023">(<a href="#ref-atkinsonDirectApproachInteractive2023" role="doc-biblioref">Atkinson 2023</a>)</span></p>
</blockquote>
<p>The original paper <span class="citation" data-cites="barnettScalingTransformativeAutoregressive2023">(<a href="#ref-barnettScalingTransformativeAutoregressive2023" role="doc-biblioref">Barnett and Besiroglu 2023a</a>)</span> contains no estimate of <span class="math inline">\(s\)</span>. They did propose to measure it experimentally by running the Turing test with a human judge and two language models. One model <span class="math inline">\(H_0\)</span> “perfectly imitates humans” by simply sampling a random text segment from a corpus, and the other model <span class="math inline">\(H_1\)</span> is a trained language model, finetuned to imitate the same corpus. They claimed that for any piece of text <span class="math inline">\(X_{1:n}\)</span>, they can calculate the log-ratio <span class="math inline">\(\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\)</span>, but I found it difficult: Suppose <span class="math inline">\(X_{1:n} = \text{ technically fork}\)</span>, which is unlikely but possible, yet the phrase never appears in the corpus, what should be <span class="math inline">\(Pr(X_{1:n}|H_0)\)</span>? We can use one of the many smoothing tricks <span class="citation" data-cites="jurafskySpeechLanguageProcessing2023">(<a href="#ref-jurafskySpeechLanguageProcessing2023" role="doc-biblioref">Jurafsky and Martin 2023, chap. 3</a>)</span>, but this gets complicated.</p>
<section id="my-ideas" class="level4">
<h4 class="anchored" data-anchor-id="my-ideas">My ideas</h4>
<p>What I think would work well is if both <span class="math inline">\(H_0\)</span>and <span class="math inline">\(H_1\)</span> are language models, perhaps even the same model with different sampling temperatures, then the human judge only has to distinguish the two models.</p>
<p>Perhaps we can make this into a gambling game. The human subject would be presented with two long outputs from two hidden Markov models. Then the subject becomes the judge of a Turing test: “Are you seeing the output from machine 0 or machine 1?”. At each step, the subject can either pay a few cents of fake money to see another character, or stop and make a bet with the entire bankroll: “I bet 70% of my bankroll on machine 0 and the rest on machine 1!”. Both bets have payoff odds of <span class="math inline">\(2:1\)</span>. I believe that if the cost of seeing another character is <em>just right</em>, the subject would be nudged to make a decision at exactly <span class="math inline">\(10:1\)</span> posterior odds ratio on the two hypotheses “machine 0” and “machine 1”.</p>
<p>A diffusion guessing game: The user uploads a lot of MIDI musics. The program plays back note by note, but adds increasingly severe distortions (add a gaussian or Poisson noise to each note). The user guesses which music it is. The more noise there is, the longer it should take the user to guess. Compare the length with the Bayesian optimal predictor.</p>
</section>
<section id="human-or-not" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="human-or-not">Human-or-not</h4>
<p>There was one large-scale attempt at the Turing test in early 2023, in a game called “Human or Not?” <span class="citation" data-cites="jannaiHumanNotGamified2023">(<a href="#ref-jannaiHumanNotGamified2023" role="doc-biblioref">Jannai et al. 2023</a>)</span>. Human participants took 2-minute conversations, and at the end, had to decide whether they were talking to a human or a bot.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;There was no mention of whether the bots had to decide the same question.</p></div></div><blockquote class="blockquote">
<p>The conversations have a “ping-pong” structure that prevents players from sending two consecutive messages without a response, in order to ensure a balanced and dynamic exchange. Each message, limited to a maximum of 100 characters, has to be composed and sent within a 20-second window, and the chat ends after 2 minutes, usually consisting of 4-5 messages from each side. This ensures that players don’t have to wait for too long, so they can remain engaged with the game and a constant suspense is kept. Once the conversation is over, players are prompted to guess whether their conversational partner was a fellow human or an AI bot. <span class="citation" data-cites="jannaiHumanNotGamified2023">(<a href="#ref-jannaiHumanNotGamified2023" role="doc-biblioref">Jannai et al. 2023</a>)</span></p>
</blockquote>
<p>I counted that during a typical message, each side sends <span class="math inline">\([20, 40]\)</span> English words in total, or <span class="math inline">\([30, 50]\)</span> tokens. In <span class="math inline">\([60\%, 70\%]\)</span> of trials, the human participant judged correctly. This suggests that the log-ratio achieved after <span class="math inline">\([30, 50]\)</span> tokens is around the range of <span class="math inline">\([\pm \ln 6/4, \pm \ln 7/3]\)</span>. In other words, the average log-ratio per token is</p>
<p><span class="math display">\[
\frac{[\ln 6/4, \ln 7/3]}{[30, 50]} \in [0.01, 0.03] \;\rm{ nat/token}
\]</span></p>
<p>They used several different AI, ranging between Jurassic-2, GPT-4, and Cohere. None of them have published their training compute or loss curves. The only good estimate is for GPT-4, which has training cost <span class="math inline">\(C = 2\times 10^{25}\rm{FLOP}\)</span>.</p>
<p>Assuming that <a href="#eq-chinchilla-scaling">Chinchilla scaling</a> holds, average log-ratio per token that an ideal judge should achieve is <span class="math inline">\(L - L_\infty = \frac{1070}{C^{0.154}} = 0.14 \;\rm{ nat/token}\)</span>. Therefore,</p>
<p><span class="math display">\[s \in [5, 14]\]</span></p>
<p>I did not expect the estimate to be nearly symmetric around <span class="math inline">\(10\)</span>.</p>
</section>
</section>
</section>
<section id="entropy-of-natural-languages" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="entropy-of-natural-languages">Entropy of natural languages</h2>
<p>In <a href="#eq-sprt" class="quarto-xref">Equation&nbsp;1</a>, we argued that <span class="math inline">\(L_\infty\)</span> <em>should</em> be interpreted as the entropy rate of the source, usually human-generated English. Unfortunately, unlike that of coin flips or Markov chains, the entropy rate of English cannot be calculated, only estimated. Fortunately, it can be estimated in several ways, and we can check their agreement.</p>
<p>Since tokenizers are temporary, but English is permanent, we convert all units to <span class="math inline">\(\;\rm{bit/character}\)</span> for easy comparison.</p>
<section id="sec-chinchilla-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-chinchilla-scaling">Chinchilla scaling</h3>
<p>In the Chinchilla scaling law paper, the authors trained many language models with various sizes from a single architecture family, and fitted a statistical law to the data, giving <span class="math inline">\(L_\infty = 1.69 \;\rm{ nat/token}\)</span> (without error bars, unfortunately) <span class="citation" data-cites="hoffmannTrainingComputeOptimalLarge2022">(<a href="#ref-hoffmannTrainingComputeOptimalLarge2022" role="doc-biblioref">Hoffmann et al. 2022, 25</a>)</span>.</p>
<p>To find the effective <span class="math inline">\(\;\rm{bit/character}\)</span> for the Chinchilla scaling law, we need to convert <span class="math inline">\(\rm{nat}\)</span> to <span class="math inline">\(\rm{bit}\)</span>, and <span class="math inline">\(\rm{token}\)</span> to <span class="math inline">\(\rm{character}\)</span>. The first is easy: <span class="math inline">\(1 \;\mathrm{bit} = \ln(2)\;\mathrm{nat}\)</span>. The second can be estimated by running a tokenizer over a large natural English corpus. I have estimated this by running the GPT-2 tokenizer on the <a href="https://paperswithcode.com/dataset/wikitext-2"><code>WikiText-2</code></a> corpus, and found that on average,</p>
<p><span class="math display">\[
1 \;\rm{token} = 4.5 \;\rm{character} = 0.85 \;\rm{word}
\]</span></p>
<p>Thus, <span class="math inline">\(L_\infty \approx \frac{1.69}{4.5\times \ln 2} = 0.54 \;\rm{bit/character}\)</span>.</p>
</section>
<section id="turing-completeness" class="level3">
<h3 class="anchored" data-anchor-id="turing-completeness">Turing-completeness</h3>
<p>Unfortunately, to lower-bound entropy rates, we typically have to make strong assumptions, because in general, lower-bounding entropy is not computable. For example, the entropy of <span class="math inline">\(982148086513282306647093844\dots\)</span> appears to be <span class="math inline">\(\ln 10\)</span>, but it is in fact zero, because those are the digits of <span class="math inline">\(10^{100} \pi\)</span> starting at the radix point. In general, this means we have all the hairy problems of measuring the Kolmogorov complexity.</p>
<p>There is also another problem: Probabilistically speaking, there is no such thing as the entropy rate of a single sequence. We can convert a single sequence into a stochastic process, by, for example, sampling a random positive integer <span class="math inline">\(n\)</span>, then start the sequence at the <span class="math inline">\(n\)</span>-th place. The problem is that we really have two versions of the same word “entropy”, one is by minimal description length, and another is by probability. The two versions are connected by Shannon coding theorem, but they are not the same.</p>
<p>This is similar to the Halting problem. It’s possible in general to prove that a machine halts: just run it. It’s not possible in general to prove that it does not halt. Similarly, there is a program <span class="math inline">\(P\)</span>, such that given any input <span class="math inline">\(x\)</span>, it will output a sequence of numbers <span class="math inline">\(P(x)_1, P(x)_2, \dots\)</span> that can converge to the Kolmogorov complexity <em>from above</em>: <span class="math inline">\(P(x)_1 &gt; P(x)_2 &gt; \cdots, \lim_n P(x)_n = K(x)\)</span>. The program just runs every possible Turing machine in parallel.</p>
<p>There are two catches.</p>
<p>One, it is impossible to know in general whether <span class="math inline">\(P(x)_n\)</span> is the last time it will output, or whether if we wait a few more eternities, we will see another output <span class="math inline">\(P(x)_{n+1}\)</span>.</p>
<p>Two, it is also impossible to have a program <span class="math inline">\(P'\)</span> that approaches it from below: <span class="math inline">\(P(x)_1 &lt; P(x)_2 &lt; \cdots, \lim_n P(x)_n = K(x)\)</span>. Otherwise, we would have a machine that can calculate the Busy Beaver function.</p>
<p><span class="citation" data-cites="feutrillReviewShannonDifferential2021">(<a href="#ref-feutrillReviewShannonDifferential2021" role="doc-biblioref">Feutrill and Roughan 2021</a>)</span> reviews the entropy rate formulas for several commonly used models. An ergodic Markov chain with stationary distribution <span class="math inline">\(\pi_i\)</span> and transition probabilities <span class="math inline">\(p_{ij}\)</span> has entropy rate <span class="math inline">\(-\sum_{ij}\pi_i p_{ij}\ln p_{ij}\)</span>. For the hidden Markov model, there is no known closed-form formula in the transition probabilities, though there are upper and lower bounds <span class="citation" data-cites="coverElementsInformationTheory2006">(<a href="#ref-coverElementsInformationTheory2006" role="doc-biblioref">T. M. Cover and Thomas 2006</a>, Theorem 4.5.1)</span>.</p>
</section>
<section id="guessing-game" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="guessing-game">Guessing game</h3>
<p>The earliest attempt to measure the entropy rate of English is by Shannon himself <span class="citation" data-cites="shannonPredictionEntropyPrinted1951">(<a href="#ref-shannonPredictionEntropyPrinted1951" role="doc-biblioref">Shannon 1951</a>)</span>: <span class="math inline">\([0.6, 1.3] \;\rm{bit/character}\)</span>. He obtained the estimate by presenting human subjects <span class="math inline">\(n-1\)</span> characters from a text, and ask them to guess the next character repeatedly, until they got it right. In this case, the optimal strategy is to construct the <span class="math inline">\(n\)</span>-gram table, and pick the argmax character for the given <span class="math inline">\((n-1)\)</span>-gram, then the arg-next-max, and so on.</p>
<p>Let <span class="math inline">\(N\)</span> be the total number of characters allowed – Shannon’s experiment used <span class="math inline">\(N = 27\)</span>, with 26 lowercase letters and one white space. Let <span class="math inline">\(p_k\)</span> be the frequency that the subject makes exactly <span class="math inline">\(k\)</span> guesses – including the correct guess, so that <span class="math inline">\(\sum_{k=1}^N p_k = 1\)</span>. By convention, <span class="math inline">\(p_{N+1} := 0\)</span>. Shannon derived both an upper and a lower bound for the entropy per character:</p>
<p><span class="math display">\[
\sum_{k=1}^N k(p_k - p_{k+1}) \ln k \leq H \leq - \sum_{k=1}^N p_k \ln p_k
\]</span></p>
<p>The upper bound is proved by <a href="https://en.wikipedia.org/wiki/Shannon's_source_coding_theorem">Shannon’s source coding theorem</a>. Taking a human subject, copy it, then they can be used as an encoder-decoder pair.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> The lower bound is not only tricky to prove, but also <strong>wrong</strong> in general. It is only correct when the human subject is <em>the optimal</em> <span class="math inline">\(N\)</span>-gram predictor, <em>and</em> when the language <em>is</em> exactly generated by an <span class="math inline">\(N\)</span>-gram model.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;It still works even if the humans are pseudorandom. We just have to whisper the same <abbr title="Random Number Generator">RNG</abbr> seed into both humans’ ears, and then they would behave in the same pseudorandom way.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;The simplest counterexample: Suppose the source is binary, and satisfies <span class="math inline">\(X_{n+1} = X_{n} + 1 \mod 2\)</span>, so it has zero entropy. Nevertheless, the human intentionally guesses wrong the first time. Therefore, we have <span class="math inline">\(p_2 = 1\)</span>, and we have violated the lower bound by <span class="math inline">\(2\ln 2 &gt; 0\)</span>.</p>
<p>This source can be made ergodic by adding an <span class="math inline">\(\epsilon\)</span> amount of coin-flip noise: <span class="math inline">\(X_{n+1} = X_{n} + 1 \mod 2\)</span> with probability <span class="math inline">\(1-\epsilon\)</span>. This would still give us <span class="math inline">\(2\ln 2 + O(\epsilon) &gt; O(\epsilon \ln \epsilon)\)</span>.</p></div></div><p><span class="citation" data-cites="burtonLongrangeConstraintsStatistical1955">(<a href="#ref-burtonLongrangeConstraintsStatistical1955" role="doc-biblioref">Burton and Licklider 1955</a>)</span> uses the same method as Shannon, but with longer contexts and texts from more books (Shannon sampled all passages from just one book). They found that English has “redundancy” in <span class="math inline">\([0.6, 0.8]\)</span>, meaning that English has entropy rate <span class="math inline">\(\ln 27 \times (1- [0.6, 0.8]) = [0.7, 1.3] \;\rm{bit/character}\)</span>.</p>
<p>Over the years, others devised other methods to estimate this entropy. For example, <span class="citation" data-cites="coverConvergentGamblingEstimate1978">(<a href="#ref-coverConvergentGamblingEstimate1978" role="doc-biblioref">T. Cover and King 1978</a>)</span> used a gambling game estimation, in the style of the <a href="https://en.wikipedia.org/wiki/Kelly_criterion">Kelly criterion</a>. Subjects were required to divide their entire bankroll into 27 differently-sized bets over 27 possibilities (26 letters and 1 whitespace). The right bet pays back 27-fold, and the other bets are lost. Let <span class="math inline">\(S_n\)</span> be the size of bankroll after <span class="math inline">\(n\)</span> rounds of betting, then</p>
<p><span class="math display">\[
H \leq \ln 27 - \limsup_n \frac 1n \ln S_n
\]</span></p>
<p>They found that <span class="math inline">\(H \leq 1.3 \;\rm{bit/character}\)</span>.</p>
<p>The guesser does not have to be a human. It can very well be a language model. <span class="citation" data-cites="brownEstimateUpperBound1992">(<a href="#ref-brownEstimateUpperBound1992" role="doc-biblioref">Brown et al. 1992</a>)</span> made a simple trigram model over the Brown corpus (600 million words), and found that it gives <span class="math inline">\(H \leq 1.75 \;\rm{bit/character}\)</span>. <span class="citation" data-cites="behrjrEstimatingComparingEntropy2002">(<a href="#ref-behrjrEstimatingComparingEntropy2002" role="doc-biblioref">Behr Jr et al. 2002</a>)</span> used a model that combines multiple n-gram models, giving <span class="math inline">\(H \leq 1.46 \;\rm{bit/character}\)</span>.</p>
<p>A <a href="https://www.lesswrong.com/posts/htrZrxduciZ5QaCjw/language-models-seem-to-be-much-better-than-humans-at-next">more recent attempt in 2022</a> is crucial, as it seems to show humans are already surpassed by the best language models like GPT-3 in terms of reaching low perplexity, but I haven’t yet studied it in detail.</p>
</section>
<section id="lossless-compression" class="level3">
<h3 class="anchored" data-anchor-id="lossless-compression">Lossless compression</h3>
<p>Another way to estimate is by lossless compression of a large corpus, since the entropy rate is the lower bound on compression rate. In more detail, if you have a source of information emitting symbols, and its symbol stream has an entropy rate of <span class="math inline">\(x \;\mathrm{bit/symbol}\)</span>, then it takes at least <span class="math inline">\(\sim xl\)</span> bits to encode a long segment with <span class="math inline">\(l\)</span> symbols. Furthermore, this lower bound is approachable using the <a href="https://en.wikipedia.org/wiki/Entropy_coding">entropy encoding</a>.</p>
<p>The <a href="http://prize.hutter1.net/">Hutter prize</a> is a competition for compressing a <span class="math inline">\(10^9\)</span>-byte corpus from the English Wikipedia (<code>enwik9</code>). For the size of the finished product, both the algorithm and the compressed data must be counted. In particular, if a neural network is used, then the size of the neural network weights must be counted as well.</p>
<p>The <code>enwik9</code> dataset is in <code>XML</code> format, and thus contains a lot of non-English content like <code>&lt;timestamp&gt;2005-12-27T18:46:47Z&lt;/timestamp&gt;</code>. It has <span class="math inline">\(10^9\)</span> bytes. It is tricky to decide how to clean it up to remove all the <code>XML</code> formatting. As a simple estimate, we simply counted its characters:</p>
<p><span class="math display">\[
997,520,891 \text{ characters} = 1,000,000,000 \text{ bytes}
\]</span></p>
<p>Therefore, the entropy rate is</p>
<p><span id="eq-hutter-prize-entropy-rate"><span class="math display">\[
\frac{8\times 10^8 / 997,520,891}{\text{compression ratio}} = \frac{8.02}{\text{compression ratio}}\;\rm{bit/character}
\tag{2}\]</span></span></p>
<p>The standard zip algorithm can compress it down to about 300 Mb in size, a compression ratio of <span class="math inline">\(\sim 3\times\)</span>. Over the years, the progress has been slow but somewhat steady. The current winning entry (Kaido Orav, 2024) has a compression ratio of <span class="math inline">\(8.88\times\)</span>. If we extrapolate the prize-winning entries over the years, it seems that the best possible compression ratio is <span class="math inline">\(\sim 10\times\)</span>.</p>
<p>Similar to the Hutter prize, the <a href="https://mattmahoney.net/dc/text.html">Large Text Compression Benchmark</a> also asks for compressing the <code>enwik9</code> dataset. However, there is no limit to the algorithm runtime or size, so the compression ratio for this benchmark is always higher. Currently (2024-01-19), the maximal compression rate reached is <span class="math inline">\(9.35\times\)</span> with <a href="https://bellard.org/nncp/"><code>nncp v3.2</code></a>, which uses a small Transformer model.</p>
<p><span class="citation" data-cites="grassbergerDataCompressionEntropy2002">(<a href="#ref-grassbergerDataCompressionEntropy2002" role="doc-biblioref">Grassberger 2002</a>)</span> used a substitutional compression algorithm with increasingly large codebooks. When the codebook had 6000 codes, the algorithm gave <span class="math inline">\(h \leq 1.82 \;\rm{bit/character}\)</span>. By extrapolating the {codebook size}-{entropy rate} curve to an infinitely large codebook, they estimated that English has entropy rate <span class="math inline">\(0.7 \pm 0.2 \;\rm{bit/character}\)</span>.</p>
</section>
<section id="summary" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>estimate</th>
<th>method</th>
<th>raw number</th>
<th>effective entropy rate (bit/char)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="citation" data-cites="grassbergerDataCompressionEntropy2002">(<a href="#ref-grassbergerDataCompressionEntropy2002" role="doc-biblioref">Grassberger 2002</a>)</span></td>
<td>compression, extrapolation</td>
<td><span class="math inline">\(0.7 \pm 0.2 \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\sim[0.5, 0.9]\)</span></td>
</tr>
<tr class="even">
<td><a href="http://prize.hutter1.net/">Hutter prize</a> (Kaido Orav, 2024)</td>
<td>compression</td>
<td>compression ratio <span class="math inline">\(\geq 8.88\)</span></td>
<td><span class="math inline">\(\leq 0.90\)</span></td>
</tr>
<tr class="odd">
<td>Hutter prize extrapolated</td>
<td>compression, extrapolation</td>
<td>compression ratio <span class="math inline">\(\sim 10\)</span></td>
<td><span class="math inline">\(\sim 0.80\)</span></td>
</tr>
<tr class="even">
<td><a href="https://mattmahoney.net/dc/text.html">Large Text Compression Benchmark</a> (<code>nncp v3.2</code>, 2023)</td>
<td>compression</td>
<td>compression ratio <span class="math inline">\(\geq 9.35\)</span></td>
<td><span class="math inline">\(\leq 0.86\)</span></td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="shannonPredictionEntropyPrinted1951">(<a href="#ref-shannonPredictionEntropyPrinted1951" role="doc-biblioref">Shannon 1951</a>)</span></td>
<td>guessing game</td>
<td><span class="math inline">\(\in [0.6, 1.3] \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\in [0.6, 1.3]\)</span></td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="burtonLongrangeConstraintsStatistical1955">(<a href="#ref-burtonLongrangeConstraintsStatistical1955" role="doc-biblioref">Burton and Licklider 1955</a>)</span></td>
<td>guessing game</td>
<td><span class="math inline">\(\in [0.6, 1.3] \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\in [0.7, 1.3]\)</span></td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="coverConvergentGamblingEstimate1978">(<a href="#ref-coverConvergentGamblingEstimate1978" role="doc-biblioref">T. Cover and King 1978</a>)</span></td>
<td>guessing game</td>
<td><span class="math inline">\(\leq 1.3 \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\leq 1.3\)</span></td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="brownEstimateUpperBound1992">(<a href="#ref-brownEstimateUpperBound1992" role="doc-biblioref">Brown et al. 1992</a>)</span></td>
<td>3-gram language model</td>
<td><span class="math inline">\(\leq 1.75 \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\leq 1.75\)</span></td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="behrjrEstimatingComparingEntropy2002">(<a href="#ref-behrjrEstimatingComparingEntropy2002" role="doc-biblioref">Behr Jr et al. 2002</a>)</span></td>
<td>n-gram language model</td>
<td><span class="math inline">\(\leq 1.46 \;\rm{bit/character}\)</span></td>
<td><span class="math inline">\(\leq 1.46\)</span></td>
</tr>
<tr class="even">
<td><span class="citation" data-cites="kaplanScalingLawsNeural2020">(<a href="#ref-kaplanScalingLawsNeural2020" role="doc-biblioref">Kaplan et al. 2020</a>)</span></td>
<td>Transformer language model, extrapolation</td>
<td><span class="math inline">\(\sim 1.7 \;\rm{nat/token}\)</span></td>
<td><span class="math inline">\(\sim 0.57\)</span></td>
</tr>
<tr class="odd">
<td><span class="citation" data-cites="hoffmannTrainingComputeOptimalLarge2022">(<a href="#ref-hoffmannTrainingComputeOptimalLarge2022" role="doc-biblioref">Hoffmann et al. 2022</a>)</span></td>
<td>Transformer language model, extrapolation</td>
<td><span class="math inline">\(L_\infty = 1.69 \;\rm{nat/token}\)</span></td>
<td><span class="math inline">\(\sim 0.54\)</span><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></td>
</tr>
</tbody>
</table>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Because the tokenizers differ, the same <code>nat/token</code> translates to different <code>bit/char</code>.</p></div></div><p>Notably, the above table has mostly upper bounds, and only one dubious lower bound (by Shannon) from 1951. Perhaps lower bounds can be established by using <a href="https://en.wikipedia.org/wiki/Randomness_extractor">randomness extractors</a> on a large corpus, and checking that the output from the extractor passes pseudorandomness tests.</p>
<p>Most of the data seems to be centered around 0.8 bpc. The one outlier is the Chinchilla scaling law estimate: 0.54 bpc. I have found that a lot hinges on the exact tokenizer-dataset fit, which is why tokenization is so annoying and I wish people would try to do away with it, or at least report bit-per-character in addition to nat-per-token.</p>
</section>
</section>
<section id="sec-forecasting-agi" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-forecasting-agi">Forecasting AGI</h2>
<p>According to the <a href="https://en.wikipedia.org/wiki/Neural_scaling_law#Chinchilla_scaling_(Hoffmann,_et_al,_2022)">Chinchilla scaling law</a> <span class="citation" data-cites="hoffmannTrainingComputeOptimalLarge2022">(<a href="#ref-hoffmannTrainingComputeOptimalLarge2022" role="doc-biblioref">Hoffmann et al. 2022</a>)</span>, if we have a fixed amount of computing budget <span class="math inline">\(C\)</span>, by choosing the model and dataset size correctly, the minimal reducible loss achievable is</p>
<p><span id="eq-chinchilla-scaling"><span class="math display">\[
L - L_\infty = \frac{1070}{(C/\;\rm{FLOP})^{0.154}} \;\rm{nat/token}
\tag{3}\]</span></span></p>
<p>Assuming a slowdown factor <span class="math inline">\(s\)</span>, that the judge decides when the odds ratio is <span class="math inline">\(r:1\)</span>, and the Chinchilla scaling law, we have a direct method to predict how long a language model can survive in a Turing test, according to the cost of training compute <span class="math inline">\(C\)</span>:</p>
<p><span class="math display">\[T^* \sim \frac{s\ln r}{1070}(C/\;\rm{FLOP})^{0.154} \;\rm{token}\]</span></p>
<p>This gives, as a rule of thumb, <span class="math inline">\(100\times\)</span> compute means <span class="math inline">\(2 \times\)</span> length of survival in a Turing test.</p>
<p>For example, assuming a slowdown factor of <span class="math inline">\(s=10\)</span>, and that the judge decides when the odds ratio is <span class="math inline">\(10:1\)</span>, for a language model to survive for 1000 tokens, it needs</p>
<p><span class="math display">\[L - L_\infty \leq 10 \times \ln 10 / 1000 = 0.023 \;\rm{nat/token}\]</span></p>
<p>If GPT-4 costs <span class="math inline">\(2\times 10^{25} \;\rm{FLOP}\)</span> in compute, and <span class="math inline">\(1 \;\rm{word} \approx 1.2 \;\rm{token}\)</span>, then</p>
<p><span class="math display">\[T^* \approx 170 \text{ tokens} \approx 150 \text{ words}\]</span></p>
<p>meaning it has a good chance of passing the Turing test if limited to only 150 words. For context, the <em>Attention is All You Need</em> paper has an abstract that’s 200 tokens long.</p>
<p>A typical scientific paper is about 4000 words long, which is <span class="math inline">\(27\times\)</span> that of 150 words, so it would need <span class="math inline">\(27^{1/0.153} = (2\times 10^9)\times\)</span> that of compute. Assuming that GPT-4 cost 10 million USD to train, this hypothetical AI would cost <span class="math inline">\(2\times 10^{16}\)</span> USD, or 200 years of global GDP<sub>2023</sub>.</p>
<p>This implies that the first AGI will not be a scaled-up GPT – autoregressive transformer generatively pretrained on a lightly filtered text dataset. It has to include something else, perhaps multimodal data, high-quality data, better architecture, etc. Even if we were to attempt to merely scale it up, turning earth into a GPT-factory,<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> with even 50% of global GDP devoted,<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> and with 2% growth rate forever, it would still take 110 years,<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> arriving at year 2133. Whole brain emulation would likely take less time.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;Consider this anecdote from <a href="https://en.wikipedia.org/wiki/Edward_Teller">Edward Teller</a>:</p>
<blockquote class="blockquote">
<p>The possibilities of developing an atomic weapon and the desirability of doing it secretly were discussed at a Princeton University conference in which I participated in March 1939… Bohr said this rare variety could not be separated from common uranium except by turning the country into a gigantic factory. Bohr was worried that this could be done and that an atomic bomb could be developed–but he hoped that neither could be accomplished. Years later, when Bohr came to Los Alamos, I was prepared to say, “You see…” But before I could open my mouth, he said: “You see, I told you it couldn’t be done without turning the whole country into a factory. You have done just that.” <span class="citation" data-cites="tellerLegacyHiroshima1975">(<a href="#ref-tellerLegacyHiroshima1975" role="doc-biblioref">Teller and Brown 1975</a>)</span></p>
</blockquote>
</div><div id="fn8"><p><sup>8</sup>&nbsp;Only in a life-or-death situation does 50% of GDP get devoted to one purpose. For example, that is about the level of GDP devoted to war production during WWII in the major combatant countries. The USA spent 4 trillion USD<sub>2011</sub> over 6 years out of an annual GDP of 1.3 trillion USD<sub>2011</sub>.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;Solve for <span class="math inline">\(x\)</span> in <span class="math inline">\(200 = \sum_{k=0}^x 0.5 \times 1.02^k\)</span>.</p></div><div id="fn10"><p><sup>10</sup>&nbsp;<iframe src="https://www.metaculus.com/questions/question_embed/2813/?theme=dark" style="height:430px; width:100%; max-width:550px"></iframe></p></div></div></section>
<section id="sec-ergodic-theory" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-ergodic-theory">Appendix: Ergodic theory</h2>
<p>Since we used ergodic theory during the essay, we should quickly explain what it is about. This section is foundational, but the full complexity is not necessary.</p>
<section id="measure-theoretic-pov" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="measure-theoretic-pov">Measure-theoretic POV</h3>
<p>I know, you know too, nobody really likes measure theory any more than pianists like practicing scales hundreds of times. Still, it is at the right level of abstraction for many theories, including probability.</p>
<p>We omit all mentions of “almost-everywhere”, “except on a set of measure zero”, and similar annoying phrases. As long as you never make a union of uncountable many subsets, you will not be hurt by this omission.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Probability_space">probability space</a> is a measurable space with a measure of <span class="math inline">\(1\)</span>. We write it as <span class="math inline">\((\Omega, \mathcal B, Pr)\)</span>, where <span class="math inline">\(\mathcal B\)</span> is the sigma-algebra of measurable sets, and <span class="math inline">\(Pr\)</span> is the probability measure. We also write <span class="math inline">\(\mu\)</span> for the measure.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;Pronounced “mu” – it is a pun because both “mu” and “measure” starts with “m”.</p></div></div><p>We consider a single measurable function <span class="math inline">\(T : \Omega \to \Omega\)</span>, and call it the <strong>shift map</strong>.</p>
<p>We demand that <span class="math inline">\(T\)</span> <em>must</em> <strong>preserve measure</strong>. That is, <span class="math inline">\(\forall S \in \mathcal B\)</span>, we have <span class="math inline">\(Pr(T^{-1}(S)) = Pr(S)\)</span>.</p>
<p>A subset is <strong>measurable</strong> iff it is an element of <span class="math inline">\(\mathcal B\)</span>. A measurable set is also called an <strong>event</strong>.</p>
<p>A subset <span class="math inline">\(S \in \mathcal B\)</span> is <span class="math inline">\(T\)</span>-invariant iff <span class="math inline">\(T^{-1}(S) = S\)</span> almost everywhere.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> Let <span class="math inline">\(\mathcal I\)</span> be the set of all <span class="math inline">\(T\)</span>-invariant subsets:</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;That is, except on a subset of measure zero: <span class="math inline">\(Pr(T^{-1}(S) - S) = 0\)</span> and <span class="math inline">\(Pr(S - T^{-1}(S)) = 0\)</span>. This is the last time we will measure this.</p></div></div><p><span class="math display">\[
\mathcal I := \{S \in \mathcal B : T^{-1}(S) = S\}
\]</span></p>
<p>Now, obviously any set of measure zero or one are <span class="math inline">\(T\)</span>-invariant. We say that those are <em>trivially</em> <span class="math inline">\(T\)</span>-invariant. We say that <span class="math inline">\(T\)</span> is <strong>ergodic</strong> iff <span class="math inline">\(\mathcal I\)</span> has only such trivial subsets. In other words, <span class="math inline">\(T\)</span> is ergodic iff it cannot be factored into two nontrivial chunks:</p>
<p><span class="math display">\[
S, S' \text{ partitions } \Omega,\quad \text{such that } T^{-1}(S) = S ,\; T^{-1}(S') = S',\; Pr(S) &gt; 0 ,\; Pr(S') &gt; 0
\]</span></p>
<p>We <em>usually</em> ask <span class="math inline">\(T\)</span> to also be ergodic, though sometimes we don’t need that.</p>
<p>Ergodic maps have many very good properties. We will use the following one. For the theorem, you can picture it as the real space <span class="math inline">\(\mathbb{R}^n\)</span> with the gaussian probability distribution, but in fact, it applies for just about everything we would care about, such as the space of English texts, <a href="https://en.wikipedia.org/wiki/Queueing_theory">queuing jobs</a>, <a href="https://en.wikipedia.org/wiki/Wiener_process">random walks</a>, etc.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;Except pathological examples constructed by logicians who have nothing better to do than to care about the continuum hypothesis, large cardinals, and the arithmetic hierarchy. Those who desire the rigor-mortis of logic, let them have it.</p></div></div><div id="thm-ergodic-dense-orbit" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Dense orbits)</strong></span> If the state space is a <a href="https://en.wikipedia.org/wiki/Second-countable_space">topological space with a countable basis</a>, and any nonempty open set has positive measure, then almost any <span class="math inline">\(X\in\Omega\)</span> has a dense orbit.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(U\)</span> be a nonempty open set.</p>
<p><span class="math inline">\(\Omega - \cup_{i \geq 0} T^{-i}U\)</span> is <span class="math inline">\(T\)</span>-invariant, and since it excludes <span class="math inline">\(U\)</span>, it does not have the full measure. Since <span class="math inline">\(T\)</span> is ergodic, the set actually has zero measure.</p>
<p>Now, <span class="math inline">\(\cup(\Omega - \cup T^{-i}U)\)</span> is a union of countably many zero-measure sets, so it still has zero measure. By expanding the definition, this is the set of all points with non-dense orbit.</p>
</div>
<p>Finally, there is a common theme in ergodic theory. There are rigorous versions of it, but instead of going for rigor, the spirit is more important:</p>
<div id="thm-ergodic-decomposition" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (ergodic decomposition)</strong></span> Any interesting map is a partition/sum/integral of ergodic maps.</p>
</div>
<p>For example, the shear map on the unit square <span class="math inline">\([0, 1]^2\)</span> defined by</p>
<p><span class="math display">\[
(x, y) \mapsto (x, x+y \mod 1)
\]</span></p>
<p>can be thought of as an integral over rotations: For each <span class="math inline">\(x \in [0, 1]\)</span>, we have <span class="math inline">\(T_x : y \mapsto x+y\mod 1\)</span>. For almost all <span class="math inline">\(x\in [0, 1]\)</span>, we have <span class="math inline">\(T_x\)</span> an <a href="https://en.wikipedia.org/wiki/Irrational_rotation">irrational rotation</a>, thus ergodic.</p>
</section>
<section id="sequence-pov" class="level3">
<h3 class="anchored" data-anchor-id="sequence-pov">Sequence POV</h3>
<p>We must interpret the language of measure theory, which is dead like chalk dust, back into the language of sequence predictions, which is alive like reinforced concrete.</p>
<p>Each point in the state space <span class="math inline">\(X\in \Omega\)</span> is a text: a stream of tokens infinite both forwards and backwards. The state space <span class="math inline">\(\Omega\)</span> is the all possible texts <span class="math inline">\((X_n)_n\)</span>. We assume that all tokens come from the same finite-size alphabet, for example, the 128 ASCII symbols.</p>
<p>The shift map on the state space <span class="math inline">\(T : \Omega \to \Omega\)</span> is defined by moving the origin to the right by one:</p>
<p><span class="math display">\[
T(\dots, X_{-1}, X_0, X_1, \dots) := (\dots, X_0, X_1, X_2, \dots)
\]</span></p>
<p>The shift map is measure-preserving, meaning that the process is <strong>stationary</strong>: We could have started reading at any point, and we would still expect to see the same kind of probability distribution. It would not be like “Sorry, the word ‘cat’ appears with zero probability when <span class="math inline">\(n \geq 1000\)</span>.”. It would be like “No matter where we start reading, we should expect to the first three tokens to be ‘cat’ with probability <span class="math inline">\(10^{-4}\)</span>.”.</p>
<p>Repeatedly applying the shift map <span class="math inline">\(T\)</span> is just reading through the stream, one token at a time:</p>
<p><span class="math display">\[
\text{...Lorem ipsum ...} \mapsto \text{...orem ipsum d...} \mapsto \text{...rem ipsum do...} \mapsto \cdots
\]</span></p>
<p>A periodic point of <span class="math inline">\(T\)</span> is a text that repeats itself like a broken record. For example, <span class="math inline">\(X := \text{... and and and ...}\)</span> satisfies <span class="math inline">\(T^4X = X\)</span>.</p>
<p>A <span class="math inline">\(T\)</span>-invariant set <span class="math inline">\(S\subset \Omega\)</span> is a set of texts, such that if we take any text <span class="math inline">\(X\)</span> from <span class="math inline">\(S\)</span>, and jump either forwards or backwards for an arbitrary amount, we get another set in <span class="math inline">\(S\)</span>. In other words, <span class="math inline">\(S\)</span> is a set of token streams where there is no origin: you can start reading from any token.</p>
<p>A probability distribution over <span class="math inline">\(\Omega\)</span> describes the probability of observing various kinds of text streams.</p>
<p>If we can partition <span class="math inline">\(\Omega\)</span> into two subsets <span class="math inline">\(P, Q\)</span>, with probabilities <span class="math inline">\(\epsilon &gt; 0, 1-\epsilon &gt; 0\)</span>, then it means that any text from <span class="math inline">\(P\)</span> is different from any text from <span class="math inline">\(Q\)</span>, after any shift. It is as if there are two languages, and each text can be exclusively written in one language only.</p>
<p>We wish to consider only texts created by some imaginary “universal English speaker”. In particular, we do not want it to get stuck in one sub-language of English, then never escape from it. That is, we assume the universal speaker is <strong>ergodic</strong>.</p>
<p>Now imagine that we randomly sample two pieces of text generated by the universal speaker, and we shift the first text around to match it against the second. By <a href="#thm-ergodic-dense-orbit" class="quarto-xref">Theorem&nbsp;1</a>, the orbit of the first text is dense in the space of all possible English texts spoken by the universal speaker. We can gamify this situation thus:</p>
<ul>
<li>Prover: “I take one piece of text <span class="math inline">\(x\)</span>, then another piece <span class="math inline">\(x'\)</span>.”.</li>
<li>Challenger: “I challenge you to find a stretch of text from <span class="math inline">\(x\)</span> that matches the <span class="math inline">\(-1000:1000\)</span> stretch in <span class="math inline">\(x'\)</span>.”.</li>
<li>Prover asks <a href="https://en.wikipedia.org/wiki/Infinite_monkey_theorem">a team of immortal monkeys</a> to do the task. A million years later: “At <span class="math inline">\(49134819\)</span>.”.</li>
<li>Challenger verifies that <span class="math inline">\(T^{49134819}(x)_{-1000:1000} = (x')_{-1000:1000}\)</span>.</li>
</ul>
</section>
<section id="sec-smb-theorem" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-smb-theorem">Shannon–McMillan–Breiman</h3>
<p>If someone has created an infinite sequence of coin flips <span class="math inline">\(X_{-\infty:+\infty}\)</span>, then revealed it to us one by one, then each reveal would give us <span class="math inline">\(1 \;\rm{bit} = \ln 2 \;\rm{nat}\)</span>. The long-term average obtained per reveal is still <span class="math inline">\(\ln 2 \;\rm{nat}\)</span>, a rather boring situation.</p>
<p>How do we measure the entropy of an English speaker? It speaks token by token, and we have to measure the average information we obtain per token. The problem is that there are two senses of “average”. It could be the time-average: we listen to the speaker speak for a very long time, and calculate the entropy in the speech. It could be the ensemble-average: we listen to the speaker speak for a very long time, then do it again, then again, etc, then average together the time-averages.</p>
<p>If the speaker is ergodic, then the speaker essentially has just one speech, and any two samples of its speech are just translations of each other.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> Consequently, it is intuitively clear that with probability 1, the time-average of the entropy of one speech equals the ensemble-average of the entropy of all speeches. Intuitively, with probability 1,</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;Statistical mechanists might recognize this as saying that the language is <a href="https://en.wikipedia.org/wiki/Self-averaging">self-averaging</a>. That is, sampling many speeches from the language is essentially the same as sampling one very long speech that we then cut into many sub-speeches.</p></div></div><p><span class="math display">\[
\frac{1}{n} \ln Pr(X_{1:n}) \to \mathbb{E}\left[\frac{1}{n} \ln Pr(X_{1:n})\right]
\]</span></p>
<p>For non-ergodic speakers. We simply <a href="@thm-ergodic-decomposition">decompose the speaker into an ensemble of ergodic speakers</a>, then apply the SMB theorem to each one. It is like the strong law of large numbers. Intuitively, with probability 1,</p>
<p><span class="math display">\[
\frac{1}{n} \ln Pr(X_{1:n}| X \text{ is type }i)\to \mathbb{E}\left[\frac{1}{n} \ln Pr(X_{1:n}) | X \text{ is type }i\right]
\]</span></p>
<p>This is the <a href="https://en.wikipedia.org/wiki/Shannon-McMillan-Breiman_theorem">Shannon–McMillan–Breiman theorem</a>.</p>
<p>In textbooks and Wikipedia, the SMB theorem is stated rigorously, but you have already understood the idea of SMB, and the rigorous versions are simply paraphrases of the idea.</p>


<!-- -->


</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-atkinsonDirectApproachInteractive2023" class="csl-entry" role="listitem">
Atkinson, David. 2023. <span>“Direct <span>Approach Interactive Model</span>.”</span> <em>Epoch</em>. <a href="https://epochai.org/blog/direct-approach-interactive-model">https://epochai.org/blog/direct-approach-interactive-model</a>.
</div>
<div id="ref-barnettScalingTransformativeAutoregressive2023" class="csl-entry" role="listitem">
Barnett, Matthew, and Tamay Besiroglu. 2023a. <span>“Scaling Transformative Autoregressive Models.”</span> <a href="https://epochai.org/files/direct-approach.pdf">https://epochai.org/files/direct-approach.pdf</a>.
</div>
<div id="ref-barnettDirectApproach2023" class="csl-entry" role="listitem">
———. 2023b. <span>“The <span>Direct Approach</span>.”</span> <em>Epoch</em>. <a href="https://epochai.org/blog/the-direct-approach">https://epochai.org/blog/the-direct-approach</a>.
</div>
<div id="ref-behrjrEstimatingComparingEntropy2002" class="csl-entry" role="listitem">
Behr Jr, Frederic H., Victoria Fossum, Michael D. Mitzenmacher, and David Xiao. 2002. <span>“Estimating and Comparing Entropy Across Written Natural Languages Using <span>PPM</span> Compression.”</span> <a href="https://dash.harvard.edu/handle/1/25104999">https://dash.harvard.edu/handle/1/25104999</a>.
</div>
<div id="ref-brownEstimateUpperBound1992" class="csl-entry" role="listitem">
Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, Jennifer C. Lai, and Robert L. Mercer. 1992. <span>“An Estimate of an Upper Bound for the Entropy of <span>English</span>.”</span> <em>Computational Linguistics</em> 18 (1): 31–40. <a href="https://aclanthology.org/J92-1002.pdf">https://aclanthology.org/J92-1002.pdf</a>.
</div>
<div id="ref-burtonLongrangeConstraintsStatistical1955" class="csl-entry" role="listitem">
Burton, N. G., and J. C. R. Licklider. 1955. <span>“Long-Range Constraints in the Statistical Structure of Printed <span>English</span>.”</span> <em>The American Journal of Psychology</em> 68 (4): 650–53. <a href="https://doi.org/10.2307/1418794">https://doi.org/10.2307/1418794</a>.
</div>
<div id="ref-coverElementsInformationTheory2006" class="csl-entry" role="listitem">
Cover, T. M., and Joy A. Thomas. 2006. <em>Elements of Information Theory</em>. 2nd ed. Hoboken, N.J: Wiley-Interscience.
</div>
<div id="ref-coverConvergentGamblingEstimate1978" class="csl-entry" role="listitem">
Cover, Thomas, and Roger King. 1978. <span>“A Convergent Gambling Estimate of the Entropy of <span>English</span>.”</span> <em>IEEE Transactions on Information Theory</em> 24 (4): 413–21. <a href="https://doi.org/10.1109/TIT.1978.1055912">https://doi.org/10.1109/TIT.1978.1055912</a>.
</div>
<div id="ref-feutrillReviewShannonDifferential2021" class="csl-entry" role="listitem">
Feutrill, Andrew, and Matthew Roughan. 2021. <span>“A <span>Review</span> of <span>Shannon</span> and <span>Differential Entropy Rate Estimation</span>.”</span> <em>Entropy</em> 23 (8): 1046. <a href="https://doi.org/10.3390/e23081046">https://doi.org/10.3390/e23081046</a>.
</div>
<div id="ref-grassbergerDataCompressionEntropy2002" class="csl-entry" role="listitem">
Grassberger, Peter. 2002. <span>“Data <span>Compression</span> and <span>Entropy Estimates</span> by <span class="nocase">Non-sequential Recursive Pair Substitution</span>.”</span> arXiv. <a href="http://arxiv.org/abs/physics/0207023">http://arxiv.org/abs/physics/0207023</a>.
</div>
<div id="ref-hoffmannTrainingComputeOptimalLarge2022" class="csl-entry" role="listitem">
Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <span>“Training <span>Compute-Optimal Large Language Models</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2203.15556">https://doi.org/10.48550/arXiv.2203.15556</a>.
</div>
<div id="ref-jannaiHumanNotGamified2023" class="csl-entry" role="listitem">
Jannai, Daniel, Amos Meron, Barak Lenz, Yoav Levine, and Yoav Shoham. 2023. <span>“Human or <span>Not</span>? <span>A Gamified Approach</span> to the <span>Turing Test</span>.”</span> <em>arXiv.org</em>, May. <a href="https://arxiv.org/abs/2305.20010v1">https://arxiv.org/abs/2305.20010v1</a>.
</div>
<div id="ref-jurafskySpeechLanguageProcessing2023" class="csl-entry" role="listitem">
Jurafsky, Dan, and James H. Martin. 2023. <em>Speech and <span>Language Processing</span>: <span>An Introduction</span> to <span>Natural Language Processing</span>, <span>Computational Linguistics</span> and <span>Speech Recognition</span></em>. 3rd ed.
</div>
<div id="ref-kaplanScalingLawsNeural2020" class="csl-entry" role="listitem">
Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. <span>“Scaling <span>Laws</span> for <span>Neural Language Models</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2001.08361">http://arxiv.org/abs/2001.08361</a>.
</div>
<div id="ref-shannonPredictionEntropyPrinted1951" class="csl-entry" role="listitem">
Shannon, Claude E. 1951. <span>“Prediction and Entropy of Printed <span>English</span>.”</span> <em>Bell System Technical Journal</em> 30 (1): 50–64. <a href="https://doi.org/10.1002/j.1538-7305.1951.tb01366.x">https://doi.org/10.1002/j.1538-7305.1951.tb01366.x</a>.
</div>
<div id="ref-tellerLegacyHiroshima1975" class="csl-entry" role="listitem">
Teller, Edward, and Allen Brown. 1975. <em>The Legacy of <span>Hiroshima</span></em>. Westport, Conn: Greenwood Press.
</div>
</div></section></div></main> <!-- /main -->
<!-- file: html/copy‑anchors-js.html -->

<script type="module">

document.addEventListener("DOMContentLoaded", () => {

  // 1. All little ¶ icons Quarto/AnchorJS adds

  document.querySelectorAll("a.anchorjs-link").forEach(anchor => {

    anchor.addEventListener("click", async (evt) => {

      // Keep normal scroll behaviour but stop full page reload

      evt.preventDefault();



      // Build absolute URL: origin + path + #hash

      const url = `${location.origin}${location.pathname}${anchor.getAttribute("href")}`;



      // 2. Try modern Clipboard API first

      try {

        await navigator.clipboard.writeText(url);

      } catch {

        // 3. Fallback for legacy browsers

        const helper = Object.assign(document.createElement("input"), { value: url });

        document.body.appendChild(helper);

        helper.select();

        document.execCommand("copy");

        helper.remove();

      }

      // TODO: The following two doesn't work yet

      // 4. Brief visual confirmation (optional)

      anchor.dataset.tooltip = "Copied!";

      setTimeout(() => delete anchor.dataset.tooltip, 1500);



      // 5. Still jump to the heading

      history.pushState(null, "", anchor.getAttribute("href"));

    }, false);

  });

});

</script>

<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yuxi\.ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Predicting AGI by the Turing Test"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yuxi Liu"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-01-20"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2025-02-25"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [AI, scaling, math]</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Minimizing log-perplexity loss is equivalent to maximizing survival length in a Turing test. Assuming compute-loss scaling law, a scaled-up GPT that produces human-like science papers would cost ~200 years of global GDP."</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "figure/banner_4_edit.png"</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="an">image-alt:</span><span class="co"> "An abstract representation of the Turing test. On the left is a dark city of obelisks over a bright background, and on the right is the same thing, mirrored and inverted, but with subtle differences due to the randomness of the art generator. It represents the abstract idea of the Turing test: duality, subtle differences, same contours, and complex object made of simple parts. High contrast, monochromatic, minimalistic, in the style of vector svg art."</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "finished"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "possible"</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 10</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../static/_macros.tex &gt;}}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## Abstract</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>This essay explains *the Direct Approach* proposed by [@barnettScalingTransformativeAutoregressive2023].[^direct-approach-report] I encourage you to play with the [*Direct Approach Interactive Model*](https://epochai.org/blog/direct-approach-interactive-model) to explore an interactive simulation using the approach.</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The Direct Approach framework bounds the compute requirements for transformative AI by extrapolating neural scaling laws. We combine those estimates with simple models of future progress in algorithms, investment, and compute costs to produce a user-adjustable forecast over the date at which TAI will be achieved. </span><span class="co">[</span><span class="ot">@barnettDirectApproach2023</span><span class="co">]</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ot">[^direct-approach-report]: </span>The thing is released in a scattered way, typical for an internet-native publication. There is the report <span class="co">[</span><span class="ot">@barnettScalingTransformativeAutoregressive2023</span><span class="co">]</span>, in the form of a paper -- clearly meant to be cited, despite being hard to read. There is the website <span class="co">[</span><span class="ot">@barnettDirectApproach2023</span><span class="co">]</span>, in the form of a blog post -- clearly meant to be read, despite not being upper-class enough to be cited in journal papers. Finally there is the <span class="co">[</span><span class="ot">interactive model</span><span class="co">](https://epochai.org/blog/direct-approach-interactive-model)</span> which looks like an optional add-on to the blog post.</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>From the POV of the judge, a Turing test is a sequential test for two statistical hypotheses -- "is human" and "is machine". Under reasonable assumptions, halving the (reducible part of) log-perplexity loss of the language model would double the time it can survive in a Turing test. </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>We can think of the peer-review of scientific papers as a Turing test, and say that AGI has arrived when we have AI scientists that can pass the papers peer-review. This allows us to calculate the log-perplexity loss of the first AGI. If we assume it is just a scaled-up GPT, then assuming the Chinchilla scaling law, <span class="co">[</span><span class="ot">it would cost about 200 years of global GDP</span><span class="co">](#sec-forecasting-agi)</span>. This makes it virtually certain that the first AGI will not be a scaled-up GPT.</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="fu">## Turing test as statistical hypothesis test</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### Turing test</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>In the <span class="co">[</span><span class="ot">Turing test</span><span class="co">](https://en.wikipedia.org/wiki/Turing_test)</span>, there are three players: one judge and two players. The first player is a human, and the second is a machine. The judge asks each player text questions and receives text answers. The judge must decide who is the human.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>We consider a simplified Turing test. In this test, the judge does not ask, and simply receives *one* stream of text $X_{1:\infty}$. The judge must decide whether the stream is produced by the human or the machine, and do so quickly.</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Cast in the language of statistical hypothesis testing, we have two hypotheses:</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$H_0$: "the stream is produced by the human";</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$H_1$: "the stream is produced by the machine".</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>The judge would read from the stream $X_{1:\infty}$, <span class="in">`o-n-e- -t-o-k-e-n`</span> at a time, and at each token, decide whether to take another one, or announce its judgment: $H_0$ or $H_1$.</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>As the organizers of the Turing test, we would start the test by flipping a fair coin to decide whether to use the human or the machine. Therefore, $Pr(H_0) = Pr(H_1)$, and by Bayes, the posterior log-probability ratio is </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} = \ln\frac{Pr(H_0|X_{1:n})}{Pr(H_1|X_{1:n})}</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>This allows us to use the <span class="co">[</span><span class="ot">sequential probability ratio test</span><span class="co">](https://en.wikipedia.org/wiki/Sequential_probability_ratio_test)</span> (SPRT). The judge would decide on two decision boundaries, and calculate $\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}$ at each token. It would stop and announce the decision as soon as the quantity exceeds one of the boundaries. </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>For example, suppose the judge wants to decide when the odds ratio is 10 to 1, then it would set the decision boundaries to be $<span class="co">[</span><span class="ot">-\ln 10, + \ln 10</span><span class="co">]</span>$. If $\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}$ goes above $+\ln 10$ when $n = 60$, then the judge would announce "$H_0$" at that point.</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>The $\ln 10$ is a good rule of thumb, which we will use for the remainder of the essay.</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sequential hypothesis testing</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>Consider the following simple equation:</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>\ub{\frac 1n \E_{X \sim Pr(\cdot | H_0)}\left<span class="co">[</span><span class="ot"> \ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}\right</span><span class="co">]</span>}{$\frac 1n D_{KL}(Pr(\cdot | H_0)<span class="sc">\|</span> Pr(\cdot | H_1))$} = \ub{\frac 1n </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>\E_{X \sim Pr(\cdot | H_0)}\lrs{\ln\frac{1}{Pr(X_{1:n}|H_1)}}}{negative log-likelihood loss per token} - \ub{\frac 1n  \E_{X \sim Pr(\cdot | H_0)}\lrs{\frac{1}{\ln Pr(X_{1:n}|H_0)}}}{entropy rate of the human itself}</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>$${#eq-sprt}</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>The first term is the KL-divergence per token between the machine and the human. Roughly speaking, it is how different they are, per token emitted. It is an information-theoretic quantity.</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>The second term is negative log-likelihood loss per token. This is what language models are trained to minimize. We write it as $L$.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>The third term is the entropy rate of the human. It is how random the human is. We write it as $L_\infty$, because it is the theoretical minimal loss that the language model can reach.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>If the machine is a perfect replica of the human, then the second term is zero, and the first term equals the third term.</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>Assuming that the human is an ergodic speakers of English,<span class="ot">[^ergodic-speaker]</span> we can sample an infinite stream $X_{1:\infty}$ from the human, then call up the <span class="co">[</span><span class="ot">Shannon--McMillan--Breiman theorem</span><span class="co">](#sec-smb-theorem)</span> and find that</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="ot">[^ergodic-speaker]</span>:</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>    In short, an ergodic speaker is someone who has only one speech. If you hear it speak once for a very long time, then hear it speak again for a very long time, then you can take the first and shift it around, so that it looks like the second over a very long sub-segment. Ergodic speakers allow you to take the average over a single very long speech, and be assured that it is close to the average over all possible speeches.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="in">    In long, see [the appendix on ergodic theory](#sec-ergodic-theory).</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>\frac 1n \ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)} \to L - L_\infty</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>On the other hand, if the machine is also an ergodic speaker of English, then we can sample an infinite stream $X_{1:\infty}$ from the machine, then call up the SMB theorem and find that</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>\frac 1n \ln\frac{Pr(X_{1:n}|H_1)}{Pr(X_{1:n}|H_0)} \to L' - L_\infty'</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>where unfortunately, we have the odd $L'$ and $L_\infty'$, defined by</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>L' := \lim_n \frac 1n </span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>\E_{X \sim Pr(\cdot | H_1)}\lrs{\ln\frac{1}{Pr(X_{1:n}|H_0)}}, \quad L_\infty' := \lim_n \frac 1n </span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>\E_{X \sim Pr(\cdot | H_1)}\lrs{\ln\frac{1}{Pr(X_{1:n}|H_1)}}</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>We can interpret them as the loss of the human at imitating the machine, and the entropy rate of the machine itself. When the machine is close enough to the human, we can take the approximation $L' \approx L,  L_\infty' \approx L_\infty$.</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>Now, define the log-ratio at step $n$ to be $r_n := \frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}$. During a Turing test, the judge calculates</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>r_0 &amp;= 1 <span class="sc">\\</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>r_1 &amp;= r_0 + \frac{Pr(X_{1:1}|H_0)}{Pr(X_{1:1}|H_1)} <span class="sc">\\</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>r_2 &amp;= r_1 + \frac{Pr(X_{1:2}|X_{1:1}, H_0)}{Pr(X_{1:2}|X_{1:1}, H_1)} <span class="sc">\\</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>&amp;\cdots</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>So, imagine that such a perfect judge is going through a Turing test, upon receiving "my cat is technically", and we are listening on its thoughts:</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"If it were a human, then it would start with 'my' with probability $0.01$. If it were a machine, then $0.05$. Therefore, the odds ratio is 2 to 1."</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"If it were a human, then it would follow 'my' with 'cat' with probability $0.01$. If it were a machine, then $0.033$. Therefore, the odds ratio is 3 to 1."</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"If it were a human, then it would follow 'is' with 'my cat' with probability... I do not know. However, I do know that the odds *ratio* is 2 to 1. Now that the total odds ratio is 12 to 1, I can decide: $H_0$."</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>We see that the judge does not have to know the probabilities $Pr(X_{1:n}|H_0)$ and $Pr(X_{1:n}|H_1)$, only their *ratio*. This might be a minor point, but this idea of likelihood ratio is quite important. It is like "I don't know how often you say 'cat' but I know that you say it twice as often than I do!".</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>Let $T^*$ be the time it takes for the judge to decide.</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>$$T^* \approx \frac{\ln 10}{L - L_\infty}$$</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>Intuitively, each token *on average* moves the log-probability-ratio away from 0 by another $(L-L_\infty)$. Decision is triggered when it finally moves out of the interval $<span class="co">[</span><span class="ot">-\ln 10, +\ln 10</span><span class="co">]</span>$.</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>We are not able to simply look at a few tokens, draw a straight line, and call it a day, because the trajectory of log-probability-ratio is much closer to a random walk with drift. Subjectively, if you were a judge and watching the log-probability-ratio moving, you'd see ups and downs, keeping you in suspense, until it finally crosses the decision boundaries.</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="fu">### Slowdown factor</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>To perform the SPRT as described, the judge must know intimately the difference between a human and a machine. Can the judge do that? Can anyone know, with certainty, that I would start my speech with "Forty cats ..." with a probability that is *exactly* 32.42 times that of GPT-3?</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>As a crude approximation, we can model real-world judges as slowed-down version of the perfect judge. We can imagine that at each step, instead of updating the log-ratio by </span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>\ln r_{n+1} \leftarrow \ln r_n + \ln \frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>we update it by </span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>\ln r_{n+1} \leftarrow \ln r_n + \frac 1s \ln \frac{Pr(X_{n+1}|H_0, X_{1:n})}{Pr(X_{n+1}|H_1, X_{1:n})}</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>where $s &gt; 1$ is the **slowdown factor**. This implies that if it takes $\sim T$ tokens for the perfect judge to reach a likelihood ratio of $r$, it would take $\sim sT$ tokens for a human judge. </span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="fu">### Measuring the slowdown factor</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>The slowdown factor $s$ is unknown.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Informed by an internal poll, we enforce a lognormal distribution with a median of 53.1, a 15th percentile estimate of 9.84, and an 85th percentile of 290. </span><span class="co">[</span><span class="ot">@atkinsonDirectApproachInteractive2023</span><span class="co">]</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>The original paper <span class="co">[</span><span class="ot">@barnettScalingTransformativeAutoregressive2023</span><span class="co">]</span> contains no estimate of $s$. They did propose to measure it experimentally by running the Turing test with a human judge and two language models. One model $H_0$ "perfectly imitates humans" by simply sampling a random text segment from a corpus, and the other model $H_1$ is a trained language model, finetuned to imitate the same corpus. They claimed that for any piece of text $X_{1:n}$, they can calculate the log-ratio $\ln\frac{Pr(X_{1:n}|H_0)}{Pr(X_{1:n}|H_1)}$, but I found it difficult: Suppose $X_{1:n} = \text{ technically fork}$, which is unlikely but possible, yet the phrase never appears in the corpus, what should be $Pr(X_{1:n}|H_0)$? We can use one of the many smoothing tricks <span class="co">[</span><span class="ot">@jurafskySpeechLanguageProcessing2023, chapter 3</span><span class="co">]</span>, but this gets complicated.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="fu">#### My ideas</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>What I think would work well is if both $H_0$and $H_1$ are language models, perhaps even the same model with different sampling temperatures, then the human judge only has to distinguish the two models.</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>Perhaps we can make this into a gambling game. The human subject would be presented with two long outputs from two hidden Markov models. Then the subject becomes the judge of a Turing test: "Are you seeing the output from machine 0 or machine 1?". At each step, the subject can either pay a few cents of fake money to see another character, or stop and make a bet with the entire bankroll: "I bet 70\% of my bankroll on machine 0 and the rest on machine 1!". Both bets have payoff odds of $2:1$. I believe that if the cost of seeing another character is *just right*, the subject would be nudged to make a decision at exactly $10:1$ posterior odds ratio on the two hypotheses "machine 0" and "machine 1".</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>A diffusion guessing game: The user uploads a lot of MIDI musics. The program plays back note by note, but adds increasingly severe distortions (add a gaussian or Poisson noise to each note). The user guesses which music it is. The more noise there is, the longer it should take the user to guess. Compare the length with the Bayesian optimal predictor.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Human-or-not</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>There was one large-scale attempt at the Turing test in early 2023, in a game called "Human or Not?" <span class="co">[</span><span class="ot">@jannaiHumanNotGamified2023</span><span class="co">]</span>. Human participants took 2-minute conversations, and at the end, had to decide whether they were talking to a human or a bot.<span class="ot">[^human-participant]</span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="ot">[^human-participant]: </span>There was no mention of whether the bots had to decide the same question.</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; The conversations have a “ping-pong” structure that prevents players from sending two consecutive messages without a response, in order to ensure a balanced and dynamic exchange. Each message, limited to a maximum of 100 characters, has to be composed and sent within a 20-second window, and the chat ends after 2 minutes, usually consisting of 4-5 messages from each side. This ensures that players don’t have to wait for too long, so they can remain engaged with the game and a constant suspense is kept. Once the conversation is over, players are prompted to guess whether their conversational partner was a fellow human or an AI bot. </span><span class="co">[</span><span class="ot">@jannaiHumanNotGamified2023</span><span class="co">]</span></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>I counted that during a typical message, each side sends $<span class="co">[</span><span class="ot">20, 40</span><span class="co">]</span>$ English words in total, or $<span class="co">[</span><span class="ot">30, 50</span><span class="co">]</span>$ tokens. In $<span class="co">[</span><span class="ot">60\%, 70\%</span><span class="co">]</span>$ of trials, the human participant judged correctly. This suggests that the log-ratio achieved after $<span class="co">[</span><span class="ot">30, 50</span><span class="co">]</span>$ tokens is around the range of $<span class="co">[</span><span class="ot">\pm \ln 6/4, \pm \ln 7/3</span><span class="co">]</span>$. In other words, the average log-ratio per token is</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>\frac{<span class="co">[</span><span class="ot">\ln 6/4, \ln 7/3</span><span class="co">]</span>}{<span class="co">[</span><span class="ot">30, 50</span><span class="co">]</span>} \in <span class="co">[</span><span class="ot">0.01, 0.03</span><span class="co">]</span> \;\rm{ nat/token}</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>They used several different AI, ranging between Jurassic-2, GPT-4, and Cohere. None of them have published their training compute or loss curves. The only good estimate is for GPT-4, which has training cost $C = 2\times 10^{25}\rm{FLOP}$.</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>Assuming that <span class="co">[</span><span class="ot">Chinchilla scaling</span><span class="co">](#eq-chinchilla-scaling)</span> holds, average log-ratio per token that an ideal judge should achieve is $L - L_\infty = \frac{1070}{C^{0.154}} = 0.14 \;\rm{ nat/token}$. Therefore, </span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>$$s \in <span class="co">[</span><span class="ot">5, 14</span><span class="co">]</span>$$</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>I did not expect the estimate to be nearly symmetric around $10$.</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="fu">## Entropy of natural languages</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>In @eq-sprt, we argued that $L_\infty$ *should* be interpreted as the entropy rate of the source, usually human-generated English. Unfortunately, unlike that of coin flips or Markov chains, the entropy rate of English cannot be calculated, only estimated. Fortunately, it can be estimated in several ways, and we can check their agreement.</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>Since tokenizers are temporary, but English is permanent, we convert all units to $\;\rm{bit/character}$ for easy comparison.</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="fu">### Chinchilla scaling {#sec-chinchilla-scaling}</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>In the Chinchilla scaling law paper, the authors trained many language models with various sizes from a single architecture family, and fitted a statistical law to the data, giving $L_\infty = 1.69 \;\rm{ nat/token}$ (without error bars, unfortunately) <span class="co">[</span><span class="ot">@hoffmannTrainingComputeOptimalLarge2022, page 25</span><span class="co">]</span>.</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>To find the effective $\;\rm{bit/character}$ for the Chinchilla scaling law, we need to convert $\rm{nat}$ to $\rm{bit}$, and $\rm{token}$ to $\rm{character}$. The first is easy: $1 \;\mathrm{bit} = \ln(2)\;\mathrm{nat}$. The second can be estimated by running a tokenizer over a large natural English corpus. I have estimated this by running the GPT-2 tokenizer on the <span class="co">[</span><span class="ot">`WikiText-2`</span><span class="co">](https://paperswithcode.com/dataset/wikitext-2)</span> corpus, and found that on average,</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>1 \;\rm{token} = 4.5 \;\rm{character} = 0.85 \;\rm{word}</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>Thus, $L_\infty \approx \frac{1.69}{4.5\times \ln 2} = 0.54 \;\rm{bit/character}$.</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="fu">### Turing-completeness</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>Unfortunately, to lower-bound entropy rates, we typically have to make strong assumptions, because in general, lower-bounding entropy is not computable. For example, the entropy of $982148086513282306647093844\dots$ appears to be $\ln 10$, but it is in fact zero, because those are the digits of $10^{100} \pi$ starting at the radix point. In general, this means we have all the hairy problems of measuring the Kolmogorov complexity.</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>There is also another problem: Probabilistically speaking, there is no such thing as the entropy rate of a single sequence. We can convert a single sequence into a stochastic process, by, for example, sampling a random positive integer $n$, then start the sequence at the $n$-th place. The problem is that we really have two versions of the same word "entropy", one is by minimal description length, and another is by probability. The two versions are connected by Shannon coding theorem, but they are not the same.</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>This is similar to the Halting problem. It's possible in general to prove that a machine halts: just run it. It's not possible in general to prove that it does not halt. Similarly, there is a program $P$, such that given any input $x$, it will output a sequence of numbers $P(x)_1, P(x)_2, \dots$ that can converge to the Kolmogorov complexity *from above*: $P(x)_1 &gt; P(x)_2 &gt; \cdots, \lim_n P(x)_n = K(x)$. The program just runs every possible Turing machine in parallel.</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>There are two catches.</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>One, it is impossible to know in general whether $P(x)_n$ is the last time it will output, or whether if we wait a few more eternities, we will see another output $P(x)_{n+1}$.</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>Two, it is also impossible to have a program $P'$ that approaches it from below: $P(x)_1 &lt; P(x)_2 &lt; \cdots, \lim_n P(x)_n = K(x)$. Otherwise, we would have a machine that can calculate the Busy Beaver function.</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@feutrillReviewShannonDifferential2021</span><span class="co">]</span> reviews the entropy rate formulas for several commonly used models. An ergodic Markov chain with stationary distribution $\pi_i$ and transition probabilities $p_{ij}$ has entropy rate $-\sum_{ij}\pi_i p_{ij}\ln p_{ij}$. For the hidden Markov model, there is no known closed-form formula in the transition probabilities, though there are upper and lower bounds <span class="co">[</span><span class="ot">@coverElementsInformationTheory2006, Theorem 4.5.1</span><span class="co">]</span>.</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="fu">### Guessing game</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>The earliest attempt to measure the entropy rate of English is by Shannon himself <span class="co">[</span><span class="ot">@shannonPredictionEntropyPrinted1951</span><span class="co">]</span>: $<span class="co">[</span><span class="ot">0.6, 1.3</span><span class="co">]</span> \;\rm{bit/character}$. He obtained the estimate by presenting human subjects $n-1$ characters from a text, and ask them to guess the next character repeatedly, until they got it right. In this case, the optimal strategy is to construct the $n$-gram table, and pick the argmax character for the given $(n-1)$-gram, then the arg-next-max, and so on.</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>Let $N$ be the total number of characters allowed -- Shannon's experiment used $N = 27$, with 26 lowercase letters and one white space. Let $p_k$ be the frequency that the subject makes exactly $k$ guesses -- including the correct guess, so that $\sum_{k=1}^N p_k = 1$. By convention, $p_{N+1} := 0$. Shannon derived both an upper and a lower bound for the entropy per character:</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>\sum_{k=1}^N k(p_k - p_{k+1}) \ln k \leq H \leq - \sum_{k=1}^N p_k \ln p_k</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>The upper bound is proved by <span class="co">[</span><span class="ot">Shannon's source coding theorem</span><span class="co">](https://en.wikipedia.org/wiki/Shannon's_source_coding_theorem)</span>. Taking a human subject, copy it, then they can be used as an encoder-decoder pair.<span class="ot">[^rng-human]</span> The lower bound is not only tricky to prove, but also **wrong** in general. It is only correct when the human subject is *the optimal* $N$-gram predictor, *and* when the language *is* exactly generated by an $N$-gram model.<span class="ot">[^wrong-shannon]</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@burtonLongrangeConstraintsStatistical1955</span><span class="co">]</span> uses the same method as Shannon, but with longer contexts and texts from more books (Shannon sampled all passages from just one book). They found that English has "redundancy" in $<span class="co">[</span><span class="ot">0.6, 0.8</span><span class="co">]</span>$, meaning that English has entropy rate $\ln 27 \times (1- <span class="co">[</span><span class="ot">0.6, 0.8</span><span class="co">]</span>) = <span class="co">[</span><span class="ot">0.7, 1.3</span><span class="co">]</span> \;\rm{bit/character}$.</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a><span class="ot">[^rng-human]: </span>It still works even if the humans are pseudorandom. We just have to whisper the same <span class="dt">&lt;</span><span class="kw">abbr</span><span class="ot"> title</span><span class="op">=</span><span class="st">"Random Number Generator"</span><span class="dt">&gt;</span>RNG<span class="dt">&lt;/</span><span class="kw">abbr</span><span class="dt">&gt;</span> seed into both humans' ears, and then they would behave in the same pseudorandom way.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="ot">[^wrong-shannon]</span>:</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>    The simplest counterexample: Suppose the source is binary, and satisfies $X_{n+1} = X_{n} + 1 \mod 2$, so it has zero entropy. Nevertheless, the human intentionally guesses wrong the first time. Therefore, we have $p_2 = 1$, and we have violated the lower bound by $2\ln 2 &gt; 0$.</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="in">    This source can be made ergodic by adding an $\epsilon$ amount of coin-flip noise: $X_{n+1} = X_{n} + 1 \mod 2$ with probability $1-\epsilon$. This would still give us $2\ln 2 + O(\epsilon) &gt; O(\epsilon \ln \epsilon)$.</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>Over the years, others devised other methods to estimate this entropy. For example, <span class="co">[</span><span class="ot">@coverConvergentGamblingEstimate1978</span><span class="co">]</span> used a gambling game estimation, in the style of the <span class="co">[</span><span class="ot">Kelly criterion</span><span class="co">](https://en.wikipedia.org/wiki/Kelly_criterion)</span>. Subjects were required to divide their entire bankroll into 27 differently-sized bets over 27 possibilities (26 letters and 1 whitespace). The right bet pays back 27-fold, and the other bets are lost. Let $S_n$ be the size of bankroll after $n$ rounds of betting, then</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>H \leq \ln 27 - \limsup_n \frac 1n \ln S_n</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>They found that $H \leq 1.3 \;\rm{bit/character}$.</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>The guesser does not have to be a human. It can very well be a language model. <span class="co">[</span><span class="ot">@brownEstimateUpperBound1992</span><span class="co">]</span> made a simple trigram model over the Brown corpus (600 million words), and found that it gives $H \leq 1.75 \;\rm{bit/character}$. <span class="co">[</span><span class="ot">@behrjrEstimatingComparingEntropy2002</span><span class="co">]</span> used a model that combines multiple n-gram models, giving $H \leq 1.46 \;\rm{bit/character}$.</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>A <span class="co">[</span><span class="ot">more recent attempt in 2022</span><span class="co">](https://www.lesswrong.com/posts/htrZrxduciZ5QaCjw/language-models-seem-to-be-much-better-than-humans-at-next)</span> is crucial, as it seems to show humans are already surpassed by the best language models like GPT-3 in terms of reaching low perplexity, but I haven't yet studied it in detail.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lossless compression</span></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>Another way to estimate is by lossless compression of a large corpus, since the entropy rate is the lower bound on compression rate. In more detail, if you have a source of information emitting symbols, and its symbol stream has an entropy rate of $x \;\mathrm{bit/symbol}$, then it takes at least $\sim xl$ bits to encode a long segment with $l$ symbols. Furthermore, this lower bound is approachable using the <span class="co">[</span><span class="ot">entropy encoding</span><span class="co">](https://en.wikipedia.org/wiki/Entropy_coding)</span>.</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>The <span class="co">[</span><span class="ot">Hutter prize</span><span class="co">](http://prize.hutter1.net/)</span> is a competition for compressing a $10^9$-byte corpus from the English Wikipedia (<span class="in">`enwik9`</span>). For the size of the finished product, both the algorithm and the compressed data must be counted. In particular, if a neural network is used, then the size of the neural network weights must be counted as well.</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>The <span class="in">`enwik9`</span> dataset is in <span class="in">`XML`</span> format, and thus contains a lot of non-English content like <span class="in">`&lt;timestamp&gt;2005-12-27T18:46:47Z&lt;/timestamp&gt;`</span>. It has $10^9$ bytes. It is tricky to decide how to clean it up to remove all the <span class="in">`XML`</span> formatting. As a simple estimate, we simply counted its characters:</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>997,520,891 \text{ characters} = 1,000,000,000 \text{ bytes}</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>Therefore, the entropy rate is</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>\frac{8\times 10^8 / 997,520,891}{\text{compression ratio}} = \frac{8.02}{\text{compression ratio}}\;\rm{bit/character}</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>$${#eq-hutter-prize-entropy-rate}</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>The standard zip algorithm can compress it down to about 300 Mb in size, a compression ratio of $\sim 3\times$. Over the years, the progress has been slow but somewhat steady. The current winning entry (Kaido Orav, 2024) has a compression ratio of $8.88\times$. If we extrapolate the prize-winning entries over the years, it seems that the best possible compression ratio is $\sim 10\times$. </span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>Similar to the Hutter prize, the <span class="co">[</span><span class="ot">Large Text Compression Benchmark</span><span class="co">](https://mattmahoney.net/dc/text.html)</span> also asks for compressing the <span class="in">`enwik9`</span> dataset. However, there is no limit to the algorithm runtime or size, so the compression ratio for this benchmark is always higher. Currently (2024-01-19), the maximal compression rate reached is $9.35\times$ with <span class="co">[</span><span class="ot">`nncp v3.2`</span><span class="co">](https://bellard.org/nncp/)</span>, which uses a small Transformer model.</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@grassbergerDataCompressionEntropy2002</span><span class="co">]</span> used a substitutional compression algorithm with increasingly large codebooks. When the codebook had 6000 codes, the algorithm gave $h \leq 1.82 \;\rm{bit/character}$. By extrapolating the {codebook size}-{entropy rate} curve to an infinitely large codebook, they estimated that English has entropy rate $0.7 \pm 0.2 \;\rm{bit/character}$.</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> estimate <span class="pp">|</span> method <span class="pp">|</span> raw number<span class="pp">|</span> effective entropy rate (bit/char) <span class="pp">|</span></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="pp">| ----</span> <span class="pp">| ----</span> <span class="pp">| ----</span> <span class="pp">| ----</span> <span class="pp">|</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@grassbergerDataCompressionEntropy2002</span><span class="co">]</span> <span class="pp">|</span> compression, extrapolation <span class="pp">|</span> $0.7 \pm 0.2 \;\rm{bit/character}$ <span class="pp">|</span> $\sim<span class="co">[</span><span class="ot">0.5, 0.9</span><span class="co">]</span>$ <span class="pp">|</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">Hutter prize</span><span class="co">](http://prize.hutter1.net/)</span> (Kaido Orav, 2024) <span class="pp">|</span> compression <span class="pp">|</span> compression ratio $\geq 8.88$ <span class="pp">|</span> $\leq 0.90$ <span class="pp">|</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Hutter prize extrapolated <span class="pp">|</span> compression, extrapolation <span class="pp">|</span> compression ratio $\sim 10$ <span class="pp">|</span> $\sim 0.80$ <span class="pp">|</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">Large Text Compression Benchmark</span><span class="co">](https://mattmahoney.net/dc/text.html)</span> (<span class="in">`nncp v3.2`</span>, 2023) <span class="pp">|</span> compression <span class="pp">|</span> compression ratio $\geq 9.35$ <span class="pp">|</span> $\leq 0.86$ <span class="pp">|</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@shannonPredictionEntropyPrinted1951</span><span class="co">]</span> <span class="pp">|</span> guessing game <span class="pp">|</span> $\in <span class="co">[</span><span class="ot">0.6, 1.3</span><span class="co">]</span> \;\rm{bit/character}$ <span class="pp">|</span> $\in <span class="co">[</span><span class="ot">0.6, 1.3</span><span class="co">]</span>$ <span class="pp">|</span></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@burtonLongrangeConstraintsStatistical1955</span><span class="co">]</span> <span class="pp">|</span> guessing game <span class="pp">|</span> $\in <span class="co">[</span><span class="ot">0.6, 1.3</span><span class="co">]</span> \;\rm{bit/character}$ <span class="pp">|</span> $\in <span class="co">[</span><span class="ot">0.7, 1.3</span><span class="co">]</span>$ <span class="pp">|</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@coverConvergentGamblingEstimate1978</span><span class="co">]</span> <span class="pp">|</span> guessing game <span class="pp">|</span> $\leq 1.3 \;\rm{bit/character}$ <span class="pp">|</span> $\leq 1.3$ <span class="pp">|</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@brownEstimateUpperBound1992</span><span class="co">]</span> <span class="pp">|</span> 3-gram language model <span class="pp">|</span> $\leq 1.75 \;\rm{bit/character}$ <span class="pp">|</span> $\leq 1.75$ <span class="pp">|</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@behrjrEstimatingComparingEntropy2002</span><span class="co">]</span> <span class="pp">|</span> n-gram language model <span class="pp">|</span> $\leq 1.46 \;\rm{bit/character}$ <span class="pp">|</span> $\leq 1.46$ <span class="pp">|</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@kaplanScalingLawsNeural2020</span><span class="co">]</span> <span class="pp">|</span> Transformer language model, extrapolation <span class="pp">|</span> $\sim 1.7 \;\rm{nat/token}$ <span class="pp">|</span> $\sim 0.57$ <span class="pp">|</span></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="co">[</span><span class="ot">@hoffmannTrainingComputeOptimalLarge2022</span><span class="co">]</span> <span class="pp">|</span> Transformer language model, extrapolation <span class="pp">|</span> $L_\infty = 1.69 \;\rm{nat/token}$ <span class="pp">|</span> $\sim 0.54$<span class="ot">[^tokenizer-difference]</span> <span class="pp">|</span></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="ot">[^tokenizer-difference]: </span>Because the tokenizers differ, the same <span class="in">`nat/token`</span> translates to different <span class="in">`bit/char`</span>.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>Notably, the above table has mostly upper bounds, and only one dubious lower bound (by Shannon) from 1951. Perhaps lower bounds can be established by using <span class="co">[</span><span class="ot">randomness extractors</span><span class="co">](https://en.wikipedia.org/wiki/Randomness_extractor)</span> on a large corpus, and checking that the output from the extractor passes pseudorandomness tests.</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>Most of the data seems to be centered around 0.8 bpc. The one outlier is the Chinchilla scaling law estimate: 0.54 bpc. I have found that a lot hinges on the exact tokenizer-dataset fit, which is why tokenization is so annoying and I wish people would try to do away with it, or at least report bit-per-character in addition to nat-per-token.</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## Forecasting AGI {#sec-forecasting-agi}</span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>According to the <span class="co">[</span><span class="ot">Chinchilla scaling law</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Neural_scaling_law#Chinchilla_scaling_(Hoffmann,_et_al,_2022)) <span class="co">[</span><span class="ot">@hoffmannTrainingComputeOptimalLarge2022</span><span class="co">]</span>, if we have a fixed amount of computing budget $C$, by choosing the model and dataset size correctly, the minimal reducible loss achievable is</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>L - L_\infty = \frac{1070}{(C/\;\rm{FLOP})^{0.154}} \;\rm{nat/token}</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>$${#eq-chinchilla-scaling}</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a>Assuming a slowdown factor $s$, that the judge decides when the odds ratio is $r:1$, and the Chinchilla scaling law, we have a direct method to predict how long a language model can survive in a Turing test, according to the cost of training compute $C$:</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>$$T^* \sim \frac{s\ln r}{1070}(C/\;\rm{FLOP})^{0.154} \;\rm{token}$$</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>This gives, as a rule of thumb, $100\times$ compute means $2 \times$ length of survival in a Turing test.</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>For example, assuming a slowdown factor of $s=10$, and that the judge decides when the odds ratio is $10:1$, for a language model to survive for 1000 tokens, it needs</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>$$L - L_\infty \leq 10 \times \ln 10 / 1000 = 0.023 \;\rm{nat/token}$$</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>If GPT-4 costs $2\times 10^{25} \;\rm{FLOP}$ in compute, and $1 \;\rm{word} \approx 1.2 \;\rm{token}$, then</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>$$T^* \approx 170 \text{ tokens} \approx 150 \text{ words}$$</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>meaning it has a good chance of passing the Turing test if limited to only 150 words. For context, the *Attention is All You Need* paper has an abstract that's 200 tokens long. </span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>A typical scientific paper is about 4000 words long, which is $27\times$ that of 150 words, so it would need $27^{1/0.153} = (2\times 10^9)\times$ that of compute. Assuming that GPT-4 cost 10 million USD to train, this hypothetical AI would cost $2\times 10^{16}$ USD, or 200 years of global GDP<span class="dt">&lt;</span><span class="kw">sub</span><span class="dt">&gt;</span>2023<span class="dt">&lt;/</span><span class="kw">sub</span><span class="dt">&gt;</span>.</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>This implies that the first AGI will not be a scaled-up GPT -- autoregressive transformer generatively pretrained on a lightly filtered text dataset. It has to include something else, perhaps multimodal data, high-quality data, better architecture, etc. Even if we were to attempt to merely scale it up, turning earth into a GPT-factory,<span class="ot">[^gpt-factory]</span> with even 50\% of global GDP devoted,<span class="ot">[^50-percent-gdp]</span> and with 2\% growth rate forever, it would still take 110 years,<span class="ot">[^110-years]</span> arriving at year 2133. Whole brain emulation would likely take less time.<span class="ot">[^wbe-timeline]</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="ot">[^110-years]: </span>Solve for $x$ in $200 = \sum_{k=0}^x 0.5 \times 1.02^k$.</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a><span class="ot">[^50-percent-gdp]: </span>Only in a life-or-death situation does 50\% of GDP get devoted to one purpose. For example, that is about the level of GDP devoted to war production during WWII in the major combatant countries. The USA spent 4 trillion USD<span class="dt">&lt;</span><span class="kw">sub</span><span class="dt">&gt;</span>2011<span class="dt">&lt;/</span><span class="kw">sub</span><span class="dt">&gt;</span> over 6 years out of an annual GDP of 1.3 trillion USD<span class="dt">&lt;</span><span class="kw">sub</span><span class="dt">&gt;</span>2011<span class="dt">&lt;/</span><span class="kw">sub</span><span class="dt">&gt;</span>.</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a><span class="ot">[^wbe-timeline]: </span><span class="dt">&lt;</span><span class="kw">iframe</span><span class="ot"> src</span><span class="op">=</span><span class="st">"https://www.metaculus.com/questions/question_embed/2813/?theme=dark"</span><span class="ot"> style</span><span class="op">=</span><span class="st">"height:430px; width:100%; max-width:550px"</span><span class="dt">&gt;&lt;/</span><span class="kw">iframe</span><span class="dt">&gt;</span></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a><span class="ot">[^gpt-factory]</span>:</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>    Consider this anecdote from <span class="co">[</span><span class="ot">Edward Teller</span><span class="co">](https://en.wikipedia.org/wiki/Edward_Teller)</span>:</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; The possibilities of developing an atomic weapon and the desirability of doing it secretly were discussed at a Princeton University conference in which I participated in March 1939... Bohr said this rare variety could not be separated from common uranium except by turning the country into a gigantic factory. Bohr was worried that this could be done and that an atomic bomb could be developed--but he hoped that neither could be accomplished. Years later, when Bohr came to Los Alamos, I was prepared to say, "You see..." But before I could open my mouth, he said: "You see, I told you it couldn't be done without turning the whole country into a factory. You have done just that." [@tellerLegacyHiroshima1975]</span></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix: Ergodic theory {#sec-ergodic-theory}</span></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>Since we used ergodic theory during the essay, we should quickly explain what it is about. This section is foundational, but the full complexity is not necessary. </span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="fu">### Measure-theoretic POV</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>I know, you know too, nobody really likes measure theory any more than pianists like practicing scales hundreds of times. Still, it is at the right level of abstraction for many theories, including probability.</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>We omit all mentions of "almost-everywhere", "except on a set of measure zero", and similar annoying phrases. As long as you never make a union of uncountable many subsets, you will not be hurt by this omission.</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>A <span class="co">[</span><span class="ot">probability space</span><span class="co">](https://en.wikipedia.org/wiki/Probability_space)</span> is a measurable space with a measure of $1$. We write it as $(\Omega, \mathcal B, Pr)$, where $\mathcal B$ is the sigma-algebra of measurable sets, and $Pr$ is the probability measure. We also write $\mu$ for the measure.<span class="ot">[^pronounced-mu]</span></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="ot">[^pronounced-mu]: </span>Pronounced "mu" -- it is a pun because both "mu" and "measure" starts with "m".</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>We consider a single measurable function $T : \Omega \to \Omega$, and call it the **shift map**.</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>We demand that $T$ *must* **preserve measure**. That is, $\forall S \in \mathcal B$, we have $Pr(T^{-1}(S)) = Pr(S)$.</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>A subset is **measurable** iff it is an element of $\mathcal B$. A measurable set is also called an **event**.</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>A subset $S \in \mathcal B$ is $T$-invariant iff $T^{-1}(S) = S$ almost everywhere.<span class="ot">[^ae-warning]</span> Let $\mathcal I$ be the set of all $T$-invariant subsets:</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>\mathcal I := <span class="sc">\{</span>S \in \mathcal B : T^{-1}(S) = S<span class="sc">\}</span></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a><span class="ot">[^ae-warning]: </span>That is, except on a subset of measure zero: $Pr(T^{-1}(S) - S) = 0$ and $Pr(S - T^{-1}(S)) = 0$. This is the last time we will measure this.</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>Now, obviously any set of measure zero or one are $T$-invariant. We say that those are *trivially* $T$-invariant. We say that $T$ is **ergodic** iff $\mathcal I$ has only such trivial subsets. In other words, $T$ is ergodic iff it cannot be factored into two nontrivial chunks:</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>S, S' \text{ partitions } \Omega,\quad \text{such that } T^{-1}(S) = S ,\; T^{-1}(S') = S',\; Pr(S) &gt; 0 ,\; Pr(S') &gt; 0</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>We *usually* ask $T$ to also be ergodic, though sometimes we don't need that.</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>Ergodic maps have many very good properties. We will use the following one. For the theorem, you can picture it as the real space $\R^n$ with the gaussian probability distribution, but in fact, it applies for just about everything we would care about, such as the space of English texts, <span class="co">[</span><span class="ot">queuing jobs</span><span class="co">](https://en.wikipedia.org/wiki/Queueing_theory)</span>, <span class="co">[</span><span class="ot">random walks</span><span class="co">](https://en.wikipedia.org/wiki/Wiener_process)</span>, etc.<span class="ot">[^rigor-mortis]</span></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a><span class="ot">[^rigor-mortis]: </span>Except pathological examples constructed by logicians who have nothing better to do than to care about the continuum hypothesis, large cardinals, and the arithmetic hierarchy. Those who desire the rigor-mortis of logic, let them have it.</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a>::: {#thm-ergodic-dense-orbit}</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dense orbits</span></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>If the state space is a <span class="co">[</span><span class="ot">topological space with a countable basis</span><span class="co">](https://en.wikipedia.org/wiki/Second-countable_space)</span>, and any nonempty open set has positive measure, then almost any $X\in\Omega$ has a dense orbit.</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>Let $U$ be a nonempty open set. </span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>$\Omega - \cup_{i \geq 0} T^{-i}U$ is $T$-invariant, and since it excludes $U$, it does not have the full measure. Since $T$ is ergodic, the set actually has zero measure.</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>Now, $\cup(\Omega - \cup T^{-i}U)$ is a union of countably many zero-measure sets, so it still has zero measure. By expanding the definition, this is the set of all points with non-dense orbit.</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>Finally, there is a common theme in ergodic theory. There are rigorous versions of it, but instead of going for rigor, the spirit is more important:</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>::: {#thm-ergodic-decomposition}</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="fu">## ergodic decomposition</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>Any interesting map is a partition/sum/integral of ergodic maps.</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>For example, the shear map on the unit square $<span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>^2$ defined by</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a>(x, y) \mapsto (x, x+y \mod 1)</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>can be thought of as an integral over rotations: For each $x \in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$, we have $T_x : y \mapsto x+y\mod 1$. For almost all $x\in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$, we have $T_x$ an <span class="co">[</span><span class="ot">irrational rotation</span><span class="co">](https://en.wikipedia.org/wiki/Irrational_rotation)</span>, thus ergodic.</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sequence POV</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>We must interpret the language of measure theory, which is dead like chalk dust, back into the language of sequence predictions, which is alive like reinforced concrete.</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>Each point in the state space $X\in \Omega$ is a text: a stream of tokens infinite both forwards and backwards. The state space $\Omega$ is the all possible texts $(X_n)_n$. We assume that all tokens come from the same finite-size alphabet, for example, the 128 ASCII symbols. </span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>The shift map on the state space $T : \Omega \to \Omega$ is defined by moving the origin to the right by one:</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a>T(\dots, X_{-1}, X_0, X_1, \dots) := (\dots, X_0, X_1, X_2, \dots)</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>The shift map is measure-preserving, meaning that the process is **stationary**: We could have started reading at any point, and we would still expect to see the same kind of probability distribution. It would not be like "Sorry, the word 'cat' appears with zero probability when $n \geq 1000$.". It would be like "No matter where we start reading, we should expect to the first three tokens to be 'cat' with probability $10^{-4}$.".</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>Repeatedly applying the shift map $T$ is just reading through the stream, one token at a time:</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>\text{...Lorem ipsum ...} \mapsto \text{...orem ipsum d...} \mapsto \text{...rem ipsum do...} \mapsto \cdots</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>A periodic point of $T$ is a text that repeats itself like a broken record. For example, $X := \text{... and and and ...}$ satisfies $T^4X = X$.</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>A $T$-invariant set $S\subset \Omega$ is a set of texts, such that if we take any text $X$ from $S$, and jump either forwards or backwards for an arbitrary amount, we get another set in $S$. In other words, $S$ is a set of token streams where there is no origin: you can start reading from any token.</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>A probability distribution over $\Omega$ describes the probability of observing various kinds of text streams.</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>If we can partition $\Omega$ into two subsets $P, Q$, with probabilities $\epsilon &gt; 0, 1-\epsilon &gt; 0$, then it means that any text from $P$ is different from any text from $Q$, after any shift. It is as if there are two languages, and each text can be exclusively written in one language only.</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>We wish to consider only texts created by some imaginary "universal English speaker". In particular, we do not want it to get stuck in one sub-language of English, then never escape from it. That is, we assume the universal speaker is **ergodic**.</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>Now imagine that we randomly sample two pieces of text generated by the universal speaker, and we shift the first text around to match it against the second. By @thm-ergodic-dense-orbit, the orbit of the first text is dense in the space of all possible English texts spoken by the universal speaker. We can gamify this situation thus:</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Prover: "I take one piece of text $x$, then another piece $x'$.".</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Challenger: "I challenge you to find a stretch of text from $x$ that matches the $-1000:1000$ stretch in $x'$.".</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Prover asks <span class="co">[</span><span class="ot">a team of immortal monkeys</span><span class="co">](https://en.wikipedia.org/wiki/Infinite_monkey_theorem)</span> to do the task. A million years later: "At $49134819$.".</span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Challenger verifies that $T^{49134819}(x)_{-1000:1000} = (x')_{-1000:1000}$.</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a><span class="fu">### Shannon--McMillan--Breiman {#sec-smb-theorem}</span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>If someone has created an infinite sequence of coin flips $X_{-\infty:+\infty}$, then revealed it to us one by one, then each reveal would give us $1 \;\rm{bit} = \ln 2 \;\rm{nat}$. The long-term average obtained per reveal is still $\ln 2 \;\rm{nat}$, a rather boring situation.</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>How do we measure the entropy of an English speaker? It speaks token by token, and we have to measure the average information we obtain per token. The problem is that there are two senses of "average". It could be the time-average: we listen to the speaker speak for a very long time, and calculate the entropy in the speech. It could be the ensemble-average: we listen to the speaker speak for a very long time, then do it again, then again, etc, then average together the time-averages.</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>If the speaker is ergodic, then the speaker essentially has just one speech, and any two samples of its speech are just translations of each other.<span class="ot">[^ergodicity-and-self-averaging]</span> Consequently, it is intuitively clear that with probability 1, the time-average of the entropy of one speech equals the ensemble-average of the entropy of all speeches. Intuitively, with probability 1,</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="ot">[^ergodicity-and-self-averaging]: </span>Statistical mechanists might recognize this as saying that the language is <span class="co">[</span><span class="ot">self-averaging</span><span class="co">](https://en.wikipedia.org/wiki/Self-averaging)</span>. That is, sampling many speeches from the language is essentially the same as sampling one very long speech that we then cut into many sub-speeches.</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a>\frac{1}{n} \ln Pr(X_{1:n}) \to \E\lrs{\frac{1}{n} \ln Pr(X_{1:n})}</span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>For non-ergodic speakers. We simply <span class="co">[</span><span class="ot">decompose the speaker into an ensemble of ergodic speakers</span><span class="co">](@thm-ergodic-decomposition)</span>, then apply the SMB theorem to each one. It is like the strong law of large numbers. Intuitively, with probability 1,</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>\frac{1}{n} \ln Pr(X_{1:n}| X \text{ is type }i)\to \E\lrs{\frac{1}{n} \ln Pr(X_{1:n}) | X \text{ is type }i}</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>This is the <span class="co">[</span><span class="ot">Shannon--McMillan--Breiman theorem</span><span class="co">](https://en.wikipedia.org/wiki/Shannon-McMillan-Breiman_theorem)</span>.</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>In textbooks and Wikipedia, the SMB theorem is stated rigorously, but you have already understood the idea of SMB, and the rigorous versions are simply paraphrases of the idea.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>