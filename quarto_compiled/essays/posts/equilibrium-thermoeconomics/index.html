<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuxi Liu">
<meta name="dcterms.date" content="2024-05-09">
<meta name="description" content="How to think like a classical thermodynamic-economist, delivered with many illustrations and some sci-fi metaphors. Particular emphasis on what traditional pedagogy gets wrong. Prerequisites: multivariate calculus and mathematical maturity.">

<title>Classical Thermodynamics and Economics – Yuxi on the Wired</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../img/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark-493ec8732bc442be923a7677f0a4f8b4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../../site_libs/bootstrap/bootstrap-c590cb3103796f9f406a17afdd3881b8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Classical Thermodynamics and Economics – Yuxi on the Wired">
<meta property="og:description" content="How to think like a classical thermodynamic-economist, delivered with many illustrations and some sci-fi metaphors. Particular emphasis on what traditional pedagogy gets wrong. Prerequisites: multivariate calculus and mathematical maturity.">
<meta property="og:image" content="https://yuxi.ml/essays/posts/equilibrium-thermoeconomics/figure/banner/banner_1.png">
<meta property="og:site_name" content="Yuxi on the Wired">
<meta property="og:image:height" content="768">
<meta property="og:image:width" content="1232">
<meta property="og:image:alt" content="A brutalist sculpture representing classical thermodynamics/neoclassical economics: nonlinear (curved surface) constraint (steel cables tying it down) optimization (the surface struggling to fly towards the sun, touching the solar rays at the closest points). Made in Ideogram V1, with prompt 'A stunning conceptual artwork featuring a white sun casting intense white rays of sunlight, piercing through a curved hyperboloid structure made of concrete. The structure is adorned with straight lines of tight steel cables, creating a strong geometric pattern. The white background and high contrast accentuate the minimalistic vector art style. The piece is reminiscent of Chiaroscuro painting in the style of Piranesi, with a monochrome palette that enhances the drama and depth of the scene., illustration'.">
<meta name="twitter:title" content="Classical Thermodynamics and Economics – Yuxi on the Wired">
<meta name="twitter:description" content="How to think like a classical thermodynamic-economist, delivered with many illustrations and some sci-fi metaphors. Particular emphasis on what traditional pedagogy gets wrong. Prerequisites: multivariate calculus and mathematical maturity.">
<meta name="twitter:image" content="https://yuxi.ml/essays/posts/equilibrium-thermoeconomics/figure/banner/banner_1.png">
<meta name="twitter:image-height" content="768">
<meta name="twitter:image-width" content="1232">
<meta name="twitter:image:alt" content="A brutalist sculpture representing classical thermodynamics/neoclassical economics: nonlinear (curved surface) constraint (steel cables tying it down) optimization (the surface struggling to fly towards the sun, touching the solar rays at the closest points). Made in Ideogram V1, with prompt 'A stunning conceptual artwork featuring a white sun casting intense white rays of sunlight, piercing through a curved hyperboloid structure made of concrete. The structure is adorned with straight lines of tight steel cables, creating a strong geometric pattern. The white background and high contrast accentuate the minimalistic vector art style. The piece is reminiscent of Chiaroscuro painting in the style of Piranesi, with a monochrome palette that enhances the drama and depth of the scene., illustration'.">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../img/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Yuxi on the Wired</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../essays/index.html"> 
<span class="menu-text">Essays</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../sketches/index.html"> 
<span class="menu-text">Sketches</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../logs/index.html"> 
<span class="menu-text">Logs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/index.html"> 
<span class="menu-text">Docs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:yuxi_liu@berkeley.com"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../feeds.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Classical Thermodynamics and Economics</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          How to think like a classical thermodynamic-economist, delivered with many illustrations and some sci-fi metaphors. Particular emphasis on what traditional pedagogy gets wrong. Prerequisites: multivariate calculus and mathematical maturity.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">math</div>
                <div class="quarto-category">physics</div>
                <div class="quarto-category">philosophy</div>
                <div class="quarto-category">economics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Yuxi Liu </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 9, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 13, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#what-this-essay-contains" id="toc-what-this-essay-contains" class="nav-link" data-scroll-target="#what-this-essay-contains">What this essay contains</a></li>
  <li><a href="#quick-reference" id="toc-quick-reference" class="nav-link" data-scroll-target="#quick-reference">Quick reference</a></li>
  <li><a href="#further-readings" id="toc-further-readings" class="nav-link" data-scroll-target="#further-readings">Further readings</a></li>
  </ul></li>
  <li><a href="#what-is-thermodynamics" id="toc-what-is-thermodynamics" class="nav-link" data-scroll-target="#what-is-thermodynamics">What is thermodynamics?</a>
  <ul class="collapse">
  <li><a href="#systems" id="toc-systems" class="nav-link" data-scroll-target="#systems">Systems</a></li>
  <li><a href="#state-space" id="toc-state-space" class="nav-link" data-scroll-target="#state-space">State space</a></li>
  <li><a href="#constraint" id="toc-constraint" class="nav-link" data-scroll-target="#constraint">Constraint</a></li>
  <li><a href="#contacts" id="toc-contacts" class="nav-link" data-scroll-target="#contacts">Contacts</a></li>
  <li><a href="#compound-systems" id="toc-compound-systems" class="nav-link" data-scroll-target="#compound-systems">Compound systems</a></li>
  <li><a href="#equilibrium-virtual-vs-actual-states" id="toc-equilibrium-virtual-vs-actual-states" class="nav-link" data-scroll-target="#equilibrium-virtual-vs-actual-states">Equilibrium, virtual vs actual states</a></li>
  <li><a href="#some-common-misconceptions" id="toc-some-common-misconceptions" class="nav-link" data-scroll-target="#some-common-misconceptions">Some common misconceptions</a></li>
  </ul></li>
  <li><a href="#the-three-laws" id="toc-the-three-laws" class="nav-link" data-scroll-target="#the-three-laws">The three laws</a>
  <ul class="collapse">
  <li><a href="#second-law" id="toc-second-law" class="nav-link" data-scroll-target="#second-law">Second law</a></li>
  <li><a href="#first-law" id="toc-first-law" class="nav-link" data-scroll-target="#first-law">First law</a></li>
  <li><a href="#zeroth-law" id="toc-zeroth-law" class="nav-link" data-scroll-target="#zeroth-law">Zeroth law</a></li>
  <li><a href="#third-law" id="toc-third-law" class="nav-link" data-scroll-target="#third-law">Third law</a></li>
  <li><a href="#an-economic-interpretation" id="toc-an-economic-interpretation" class="nav-link" data-scroll-target="#an-economic-interpretation">An economic interpretation</a></li>
  </ul></li>
  <li><a href="#basic-consequences" id="toc-basic-consequences" class="nav-link" data-scroll-target="#basic-consequences">Basic consequences</a>
  <ul class="collapse">
  <li><a href="#thermodynamic-forcesuction" id="toc-thermodynamic-forcesuction" class="nav-link" data-scroll-target="#thermodynamic-forcesuction">Thermodynamic force/suction</a></li>
  <li><a href="#helmholtz-free-entropy" id="toc-helmholtz-free-entropy" class="nav-link" data-scroll-target="#helmholtz-free-entropy">Helmholtz free entropy</a></li>
  <li><a href="#first-order-phase-transition" id="toc-first-order-phase-transition" class="nav-link" data-scroll-target="#first-order-phase-transition">First-order phase transition</a></li>
  <li><a href="#other-free-entropies-and-energies" id="toc-other-free-entropies-and-energies" class="nav-link" data-scroll-target="#other-free-entropies-and-energies">Other free entropies and energies</a></li>
  <li><a href="#maxwell-relations" id="toc-maxwell-relations" class="nav-link" data-scroll-target="#maxwell-relations">Maxwell relations</a></li>
  </ul></li>
  <li><a href="#caratheodorys-thermodynamics" id="toc-caratheodorys-thermodynamics" class="nav-link" data-scroll-target="#caratheodorys-thermodynamics">Caratheodory’s thermodynamics</a>
  <ul class="collapse">
  <li><a href="#entropy-and-temperature" id="toc-entropy-and-temperature" class="nav-link" data-scroll-target="#entropy-and-temperature">Entropy and temperature</a></li>
  <li><a href="#cardinal-and-ordinal-utilities" id="toc-cardinal-and-ordinal-utilities" class="nav-link" data-scroll-target="#cardinal-and-ordinal-utilities">Cardinal and ordinal utilities</a></li>
  <li><a href="#extensive-entropy" id="toc-extensive-entropy" class="nav-link" data-scroll-target="#extensive-entropy">Extensive entropy</a></li>
  </ul></li>
  <li><a href="#bonus-geometric-thermodynamics" id="toc-bonus-geometric-thermodynamics" class="nav-link" data-scroll-target="#bonus-geometric-thermodynamics">Bonus: Geometric thermodynamics</a>
  <ul class="collapse">
  <li><a href="#contact-geometry" id="toc-contact-geometry" class="nav-link" data-scroll-target="#contact-geometry">Contact geometry</a></li>
  <li><a href="#samuelsons-area-ratio-thermodynamics" id="toc-samuelsons-area-ratio-thermodynamics" class="nav-link" data-scroll-target="#samuelsons-area-ratio-thermodynamics">Samuelson’s area-ratio thermodynamics</a></li>
  <li><a href="#bonus-riemannian-geometry" id="toc-bonus-riemannian-geometry" class="nav-link" data-scroll-target="#bonus-riemannian-geometry">Bonus: Riemannian geometry</a></li>
  </ul></li>
  <li><a href="#chemical-equilibrium-done-right" id="toc-chemical-equilibrium-done-right" class="nav-link" data-scroll-target="#chemical-equilibrium-done-right">Chemical equilibrium done right</a>
  <ul class="collapse">
  <li><a href="#fixed-volume-and-temperature" id="toc-fixed-volume-and-temperature" class="nav-link" data-scroll-target="#fixed-volume-and-temperature">Fixed volume and temperature</a></li>
  <li><a href="#multireaction-equilibrium" id="toc-multireaction-equilibrium" class="nav-link" data-scroll-target="#multireaction-equilibrium">Multireaction equilibrium</a></li>
  <li><a href="#fixed-pressure-and-temperature" id="toc-fixed-pressure-and-temperature" class="nav-link" data-scroll-target="#fixed-pressure-and-temperature">Fixed pressure and temperature</a></li>
  <li><a href="#the-meaning-of-delta-g" id="toc-the-meaning-of-delta-g" class="nav-link" data-scroll-target="#the-meaning-of-delta-g">The meaning of <span class="math inline">\(\Delta G\)</span></a></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations">Practical considerations</a></li>
  </ul></li>
  <li><a href="#sec-phase-equilibrium" id="toc-sec-phase-equilibrium" class="nav-link" data-scroll-target="#sec-phase-equilibrium">Phase equilibrium</a>
  <ul class="collapse">
  <li><a href="#two-phases-of-a-gas-in-equilibrium" id="toc-two-phases-of-a-gas-in-equilibrium" class="nav-link" data-scroll-target="#two-phases-of-a-gas-in-equilibrium">Two phases of a gas in equilibrium</a></li>
  <li><a href="#gibbs-phase-rule" id="toc-gibbs-phase-rule" class="nav-link" data-scroll-target="#gibbs-phase-rule">Gibbs phase rule</a></li>
  <li><a href="#boiling-water" id="toc-boiling-water" class="nav-link" data-scroll-target="#boiling-water">Boiling water</a></li>
  <li><a href="#nonextensivity-breaks-the-gibbs-phase-rule" id="toc-nonextensivity-breaks-the-gibbs-phase-rule" class="nav-link" data-scroll-target="#nonextensivity-breaks-the-gibbs-phase-rule">Nonextensivity breaks the Gibbs phase rule</a></li>
  </ul></li>
  <li><a href="#sec-stereodynamics" id="toc-sec-stereodynamics" class="nav-link" data-scroll-target="#sec-stereodynamics">Bonus: Stereodynamics</a>
  <ul class="collapse">
  <li><a href="#solid-universe-theory" id="toc-solid-universe-theory" class="nav-link" data-scroll-target="#solid-universe-theory">Solid Universe Theory</a></li>
  <li><a href="#from-the-closed-world-to-the-infinite-universe" id="toc-from-the-closed-world-to-the-infinite-universe" class="nav-link" data-scroll-target="#from-the-closed-world-to-the-infinite-universe">From the Closed World to the Infinite Universe</a></li>
  <li><a href="#war-of-the-strata" id="toc-war-of-the-strata" class="nav-link" data-scroll-target="#war-of-the-strata">War of the Strata</a></li>
  <li><a href="#the-starry-sky" id="toc-the-starry-sky" class="nav-link" data-scroll-target="#the-starry-sky">The Starry Sky</a></li>
  <li><a href="#classical-stereodynamics" id="toc-classical-stereodynamics" class="nav-link" data-scroll-target="#classical-stereodynamics">Classical stereodynamics</a></li>
  <li><a href="#karnot-space-engine" id="toc-karnot-space-engine" class="nav-link" data-scroll-target="#karnot-space-engine">Karnot space engine</a></li>
  <li><a href="#space-death-of-the-universe" id="toc-space-death-of-the-universe" class="nav-link" data-scroll-target="#space-death-of-the-universe">Space Death of the Universe</a></li>
  </ul></li>
  
  
  
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<blockquote class="blockquote">
<p>It is to the economist, the statistician, the philosopher, and to the general reader that I commend the analysis contained herein… mathematics as applied to classical thermodynamics is beautiful: if you can’t see that, you were born color-blind and are to be pitied.</p>
<p><a href="https://en.wikipedia.org/wiki/Paul_Samuelson">Paul Samuelson</a>, forewords to <span class="citation" data-cites="bicklerInvestmentPortfolioDecisionmaking1974">(<a href="#ref-bicklerInvestmentPortfolioDecisionmaking1974" role="doc-biblioref">Bickler and Samuelson 1974</a>)</span></p>
</blockquote>
<section id="what-this-essay-contains" class="level3">
<h3 class="anchored" data-anchor-id="what-this-essay-contains">What this essay contains</h3>
<p>Unlike my <a href="https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/"><em>Analytical Mechanics</em> essay</a>, this essay does not cover much of the width covered in a university course on classical thermodynamics <em>or</em> neoclassical economics. Instead, it’s best described as “the conceptual foundations that a typical course does not work well on”, a deep but narrow essay to supplement a shallow but wide typical textbook.</p>
<p>Unlike analytical mechanics, which is typically taught to students intent on reaching the abstract plane of modern theoretical physics, and is thus deep but narrow, a typical course on classical thermodynamics is shallow, but very wide, and taught to a wide student base – theoretical physicists, thermal engineers, electric engineers, chemists, biologists… When something must be taught to a wide audience, and is both deep and wide, depth is sacrificed. This is perfectly practicable, but it leaves a small minority confused with a sinister feeling that the teachers have abused their trust in them. I am in that minority.</p>
<p>The essay contains: three laws of thermodynamics, entropy, Helmholtz and Gibbs free energy, nonextensive entropy, Caratheodory’s axiomatic thermodynamics, Vladimir Arnold’s contact-geometric thermodynamics, Paul Samuelson’s area-ratio thermodynamics, Le Chatelier’s principle, chemical equilibrium, Gibbs phase rule and its extensions, analogies with neoclassical economics, speculative sci-fi.</p>
<p>It does not contain: statistical mechanics, most of the “width” part of thermodynamics and economics.</p>
<p>The prerequisites are multivariate calculus and mathematical maturity. It’s good to be familiar with basic economics as well.</p>
</section>
<section id="quick-reference" class="level3">
<h3 class="anchored" data-anchor-id="quick-reference">Quick reference</h3>
<ul>
<li><span class="math inline">\(S\)</span>: entropy</li>
<li><span class="math inline">\(U\)</span>: internal energy</li>
<li><span class="math inline">\(V\)</span>: volume</li>
<li><span class="math inline">\(T\)</span>: temperature</li>
<li><span class="math inline">\(\beta = 1/T\)</span>: inverse temperature</li>
<li><span class="math inline">\(N\)</span>: number of particles of a chemical species</li>
<li><span class="math inline">\(n\)</span>: number of moles of a chemical species</li>
<li><span class="math inline">\(\xi\)</span>: extent of reaction</li>
<li><span class="math inline">\(X\)</span>: “other properties that we are not concerned with”
<ul>
<li>For example, with an ideal gas trapped in a copper box, its macroscopic state is determined by <span class="math inline">\(U, N, V\)</span>. If we want to focus on <span class="math inline">\(U\)</span>, then we can let <span class="math inline">\(X = (N, V)\)</span>, and write <span class="math inline">\(S = S(U, X)\)</span>.</li>
<li>Similarly, for a photon gas in a blackbody chamber, its macroscopic state is determined by <span class="math inline">\(U, V\)</span>, since photons can be created and destroyed on the inner surface of the blackbody chamber. We can then write <span class="math inline">\(S = S(U, X)\)</span> if we are concerned only about how entropy changes with <span class="math inline">\(U\)</span>, holding the other state constant. We can also write <span class="math inline">\(S = S(V, X)\)</span> vice versa.</li>
</ul></li>
</ul>
<p>Thermodynamics is notorious for having too many partial differentials and coordinate changes. <span class="math inline">\((\partial_{x_1} f)_{x_1, x_2, \dots, x_n}\)</span> means that we lay down a coordinate system defined by <span class="math inline">\(x_1, \dots, x_n\)</span>, then calculate <span class="math inline">\(\partial_{x_1}f\)</span>, fixing the other coordinates constant. In particular, <span class="math inline">\((\partial_{x_1} f)_{x_1, x_2, \dots, x_n}\)</span> is likely different from <span class="math inline">\((\partial_{x_1} f)_{x_1, y_2, \dots, y_n}\)</span>.</p>
<p>If in doubt, write down</p>
<p><span class="math display">\[df = \sum_{i=1}^n (\partial_{x_i} f)_{x_1, \dots, x_n} dx_i\]</span></p>
<p>and reason thenceforth.</p>
<p>Sometimes people write <span class="math inline">\((\partial_{x_i} f)_{x_2, \dots, x_n}\)</span> instead of <span class="math inline">\((\partial_{x_i} f)_{x_1, x_2, \dots, x_n}\)</span> to save them one stroke of the pen. I try to avoid that, but be aware and beware.</p>
</section>
<section id="further-readings" class="level3">
<h3 class="anchored" data-anchor-id="further-readings">Further readings</h3>
<ul>
<li><span class="citation" data-cites="pippardElementsClassicalThermodynamics1964">(<a href="#ref-pippardElementsClassicalThermodynamics1964" role="doc-biblioref">Pippard 1964</a>)</span>. Slim, elegant, both mathematical and applied. In the best British tradition of mathematics – think James Maxwell and G. H. Hardy.</li>
<li><span class="citation" data-cites="fermiThermodynamics1956">(<a href="#ref-fermiThermodynamics1956" role="doc-biblioref">Fermi 1956</a>)</span>. The same as above. However, it also covers chemical thermodynamics.</li>
<li><span class="citation" data-cites="lemonsThermodynamicWeirdnessFahrenheit2019">(<a href="#ref-lemonsThermodynamicWeirdnessFahrenheit2019" role="doc-biblioref">Lemons 2019</a>)</span>. A very readable introduction to classical thermodynamics, slim but deep. I finally understood the meaning of the three laws of thermodynamics after reading it. Contains copious historical quotations.</li>
<li><span class="citation" data-cites="lemonsMereThermodynamics2008">(<a href="#ref-lemonsMereThermodynamics2008" role="doc-biblioref">Lemons 2008</a>)</span>. A textbook version of the author’s <span class="citation" data-cites="lemonsThermodynamicWeirdnessFahrenheit2019">(<a href="#ref-lemonsThermodynamicWeirdnessFahrenheit2019" role="doc-biblioref">Lemons 2019</a>)</span>, weaving in history and philosophical contemplation at every turn.</li>
<li><span class="citation" data-cites="carnotReflectionsMotivePower1988">(<a href="#ref-carnotReflectionsMotivePower1988" role="doc-biblioref">Carnot, Clapeyron, and Clausius 1988</a>)</span>. A reprint of the most important papers in thermodynamics published before 1900. Useful to have on hand if you are reading <span class="citation" data-cites="lemonsThermodynamicWeirdnessFahrenheit2019">(<a href="#ref-lemonsThermodynamicWeirdnessFahrenheit2019" role="doc-biblioref">Lemons 2019</a>)</span>.</li>
<li><span class="citation" data-cites="buchdahlConceptsClassicalThermodynamics1966">(<a href="#ref-buchdahlConceptsClassicalThermodynamics1966" role="doc-biblioref">Buchdahl 1966</a>)</span>. A textbook based on Carathéodory’s axiomatic thermodynamics. The notation is ponderous, and the payoff is unclear. I don’t know what is its intended audience – perhaps professional pedants and differential geometers? Nevertheless, if you need to do research in Carathéodory’s axiomatic thermodynamics, I think this is your best bet.</li>
<li>Ted Chiang’s <em>Exhalation</em> (2008), printed in <span class="citation" data-cites="chiangExhalation2019">(<a href="#ref-chiangExhalation2019" role="doc-biblioref">Chiang 2019</a>)</span>. A sci-fi story about an alien race where pneumatic engines, not heat engines, are all-important. A better take on stereodynamics than <a href="#sec-stereodynamics">my attempt</a>.</li>
</ul>
</section>
</section>
<section id="what-is-thermodynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-is-thermodynamics">What is thermodynamics?</h2>
<p>Both neoclassical economics and classical thermodynamics are about the equilibria of large systems. While a large system is generally hopelessly complicated, almost all the complexity falls away when the system is maximizing a single quantity. Ceaselessly striving to maximize entropy, a complex system sheds its complexity and reaches the pure simplicity of maximal entropy. Ceaselessly striving to maximize profit, a complex company sheds its complexity and reaches the pure simplicity of perfect product.</p>
<p>In both fields, everything we can say about the world are nothing more than systems, constraints, contacts, and equilibria. Time and change do not exist. All we can explain is which states <em>are</em> in constrained equilibrium, not how a system can <em>get there</em>. Atoms do not exist. All we can explain is what happens to homogeneous substances in constrained equilibrium. People do not exist. All we can explain is what happens to constrained economic systems in equilibrium.</p>
<p>Different things can be maximized: the total entropy, or the negative Gibbs free energy, or the profit, or the sum-total of utility, or something else. Through different lenses, different things are maximized, but they predict the same phenomena. Using this mathematical freedom, experts brachiate around the coordinate axes like gibbons brachiating around vines, looking for the perfect angle to solve each particular problem.</p>
<table class="caption-top table">
<caption>Constrained maximization problems in economics and thermodynamics.</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>interpretation</th>
<th>maximized quantity</th>
<th>constraint</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>conglomerate accounting</td>
<td>book value</td>
<td>Assets is conserved, but can be moved between child companies.</td>
</tr>
<tr class="even">
<td>social welfare</td>
<td>social utility</td>
<td>Wealth is conserved, but can be redistributed.</td>
</tr>
<tr class="odd">
<td>closed system</td>
<td>entropy</td>
<td>Quantities are conserved, but can be moved between sub-systems.</td>
</tr>
<tr class="even">
<td>factory production</td>
<td>profit</td>
<td>Some raw materials are on sale at a market, but others are not.</td>
</tr>
<tr class="odd">
<td>consumer choice</td>
<td>utility</td>
<td>Some finished goods are on sale at a market, but others are not. The market uses a commodity money.</td>
</tr>
<tr class="even">
<td>partially open system</td>
<td>negative free energy</td>
<td>Some quantities can be exchanged with a bath, but others are conserved.</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>Even if the capitalist system is to give way to one in which service and not profit shall be the object, there will still be an integral of anticipated utilities to be made a maximum. Since we must find a function which maximizes an integral we must in many cases use the Calculus of Variations. But the problem here transcends the questions of depreciation and useful life, and belongs to the dawning economic theory based on considerations of maximum and minimum which bears to the older theories the relations which the Hamiltonian dynamics and the thermodynamics of entropy bear to their predecessors.</p>
<p><span class="citation" data-cites="hotellingGeneralMathematicalTheory1925">(<a href="#ref-hotellingGeneralMathematicalTheory1925" role="doc-biblioref">Hotelling 1925</a>)</span></p>
</blockquote>
<section id="systems" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="systems">Systems</h3>
<p>Systems are the main characters of the drama of thermodynamics. A thermodynamic system is fully determined by a few macroscopic properties, related by equations of state. Once we know enough of its properties, we know all there is to know about such a system. There is nothing left to say about it.</p>
<p><strong>Everything is a thermodynamic system</strong>. However, there are two special types: bath systems, and mechanical systems.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Any number of thermodynamic systems can be connected into a larger system – a <strong>compound system</strong>.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Some children are confused when they heard that squares are rectangles too. I hope you won’t be equally confused when you hear that mechanical systems are also thermodynamic systems.</p></div></div><p>The prototypical thermodynamic system is a tank of ideal gas whose number of particles is fixed. It has 2 degrees of freedom, so if we write down <span class="math inline">\(n\)</span> different macroscopic properties, they would (generically) be related by <span class="math inline">\(n-2\)</span> equations of state. So for example, if we write down the properties internal energy <span class="math inline">\(U\)</span>, temperature <span class="math inline">\(T\)</span>, volume <span class="math inline">\(V\)</span>, pressure <span class="math inline">\(P\)</span>, they would be related by the 2 equations of state</p>
<p><span class="math display">\[PV = k_BNT, \quad U = \frac 32 k_B NT\]</span></p>
<p>If we know two out of the four of internal energy <span class="math inline">\(U\)</span>, temperature <span class="math inline">\(T\)</span>, volume <span class="math inline">\(V\)</span>, pressure <span class="math inline">\(P\)</span>, then we can solve for all the others by equations of state. The macroscopic properties fully describe the system, and nothing more can be said about it. We cannot ask additional questions such as “Are there more particles on the left than on the right?” or “How long did it take for the system to reach equilibrium?”, because such questions are literally <em>undefined</em> in classical thermodynamics.</p>
<p>Because the properties are related by equations of state, we need only know a few of the properties in order to infer all the rest. For example, knowing the volume <span class="math inline">\(V\)</span>, internal energy <span class="math inline">\(U\)</span>, and particle number <span class="math inline">\(N\)</span>, of a tank of ideal gas, we can infer that its pressure is <span class="math inline">\(P = \frac{2U}{3V}\)</span>, and its temperature is <span class="math inline">\(T = PV/k_BN\)</span>. Succinctly,</p>
<p><span class="math display">\[P = P(U, V, N), \quad T = T(U, V, N)\]</span></p>
<p>meaning “If we know <span class="math inline">\(U, V, N\)</span>, then we can calculate <span class="math inline">\(P\)</span> and <span class="math inline">\(T\)</span>”.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>It’s too easy to misread it as saying that <span class="math inline">\(P\)</span> <em>is</em> a mathematical function of <span class="math inline">\(U, V, N\)</span>. It is not. It really is saying that, there exists a mathematical function <span class="math inline">\(f_P\)</span>, such that for any state <span class="math inline">\(\omega\)</span> of the system, we have</p>
<p><span class="math display">\[P(\omega) = f_P(U(\omega), V(\omega), N(\omega))\]</span></p>
</div>
</div>
<p>Everything about a thermodynamic system is known once we specify how its entropy is a function of its macroscopic properties. For example, the ideal gas is fully specified by</p>
<p><span class="math display">\[S(U, V, N) = k_B N \ln\left[\frac{V}{N}\,\left(\frac{U}{\hat{c}_V k_B N}\right)^{\hat{c}_V}\,\frac{1}{\Phi}\right]\]</span></p>
<p>where <span class="math inline">\(\hat c_V\)</span> and <span class="math inline">\(\Phi\)</span> are constants that differ for each gas.</p>
<p>As another example, the photon gas is defined by</p>
<p><span class="math display">\[S(U, V) = C V^{1/4}U^{3/4}, \quad C=\left(\frac{256\pi^2 k_B^4}{1215 c^3 \hbar^3}\right)^{1/4}\]</span></p>
<p>The fact that <span class="math inline">\(S(U, V) \propto V^{1/4}U^{3/4}\)</span> can be derived from 19th-century physics (indeed, it was known to Boltzmann), but the constant <span class="math inline">\(C\)</span> has to wait for proper quantum mechanics.</p>
<section id="baths" class="level4">
<h4 class="anchored" data-anchor-id="baths">Baths</h4>
<p>A <strong>bath system</strong> is an infinite source of a conserved quantity at constant marginal entropy. A bath system is intended to be used as a “free market” where non-bath systems can trade some conserved quantities with.</p>
<p>For example, if we take a copper piston and fill it with ideal gas, then immerse the piston in the bottom of an ocean, then it is playing the role of a <em>volume-and-energy bath</em> with constant pressure-and-temperature. If we cover up the piston with some insulating material, then the ocean suddenly plays the role of merely a volume bath with constant pressure. If we use screws to fix the piston head, then the ocean suddenly becomes merely an energy bath with constant temperature. From this, we see that a bath <em>in itself</em> is a rather vacant concept. A bath should always be in contact with some non-bath system.</p>
<p>Because they are infinitely large, if you connect two baths together, something bad will happen. For example, if you connect two energy baths together, but with different temperature, what would happen? The simple answer is: “A torrent of heat will flow from the hotter to the colder bath.”. The more correct answer is: “Classical thermodynamics does not allow such a question to be asked. It would be like asking what happens when ‘an unstoppable force meets an immovable object’. If we literally have two baths, then we cannot connect them. If we only have two giant oceans that seem like baths when compared to this little tank of gas, then if the two oceans are connected to each other, they will no longer appear as baths to each other.”.</p>
<p>You can take this in two ways. Either will work. You can say that both systems and baths are first-class concepts in thermodynamics, and enforce the rule that you can never connect two baths together. You can also say that systems are first-class concepts in thermodynamics, but baths are second-class concepts, a convenient way to think about a system that is much larger <em>relative</em> to some other systems. Since a bath is a <em>relative</em> concept, it simply is a bad question to ask “What happens if we connect two baths together?” – The correct reply is “You mean, two systems that appear as baths… relative to <em>what</em>?”.</p>
<p>Some important (and unimportant) examples of baths:</p>
<ul>
<li>A heat bath, or more accurately an energy bath, is a system that you can take or dump as much energy as you want, always at constant marginal price of energy.</li>
<li>An atmosphere, or more accurately an energy-and-volume bath, is a system that you can take or dump as much energy or volume as you want, always at constant temperature and pressure.</li>
<li>The surface of a lake could serve as an energy-and-area bath.</li>
<li>A large block of salt can serve as a salt-chemical bath.</li>
</ul>
</section>
<section id="mechanical-systems" class="level4">
<h4 class="anchored" data-anchor-id="mechanical-systems">Mechanical systems</h4>
<p>A <strong>mechanical system</strong> is a thermodynamic system whose entropy is always zero. Essentially all systems studied in classical mechanics are such systems. In classical thermodynamics, they are not put center-stage, but if you know where to look, you will see them everywhere.</p>
<p>An ideal linear-spring has two macroscopic properties: length <span class="math inline">\(x\)</span> and internal energy <span class="math inline">\(U\)</span>, with equation of state <span class="math inline">\(U = \frac 12kx^2\)</span>. For example, a helix spring is close to an ideal linear-spring.</p>
<p>An ideal surface-spring is the same as an ideal linear-spring, but with area <span class="math inline">\(A\)</span> instead of length <span class="math inline">\(x\)</span>. Its equation of state is <span class="math inline">\(U = \sigma A\)</span>, where <span class="math inline">\(\sigma\)</span> is surface tension constant. For example, a balloon skin is close to an ideal surface-spring.</p>
<p>An ideal volume-spring is similar. It would resemble a lump of jelly. An ideal gas, though it looks like a volume-spring, is not an example, because its entropy is not zero. In particular, this means an ideal gas has temperature and can be “heated up”, but a lump of ideal jelly cannot.</p>
<p>In general, we can construct an arbitrary energy storage system, such that it has two macroscopic properties <span class="math inline">\(x, U\)</span>, satisfying <span class="math inline">\(U = f(x)\)</span>, where <span class="math inline">\(f\)</span> is any differentiable function. To show this, we can imagine taking a mystery box with a chain we can pull on, and by some internal construction with gears, pulleys, weights, and springs, the force on the chain is <span class="math inline">\(f'(x)\)</span>, where <span class="math inline">\(x\)</span> is the length by which we have pulled. That is the desired system.</p>
</section>
</section>
<section id="state-space" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="state-space">State space</h3>
<p>A tank of gas has on the order of <span class="math inline">\(10^{26}\)</span> particles, but in classical thermodynamics, its state is entirely determined if we know its <span class="math inline">\(U, V, N\)</span>. In this sense, we can say that its macroscopic state space has just 3 dimensions. In many situations, such as in the Carnot heat engine, we also fix its <span class="math inline">\(N\)</span>, in which case its state space has just 2 dimensions.</p>
<p>This is typically plotted in either the <span class="math inline">\((P, V)\)</span> space, or the <span class="math inline">\((T, S)\)</span> space, or some other spaces, but in every case, there are just two dimensions. We can unify all these diagrams as merely different viewpoints upon the same curvy surface – the state space <span class="math inline">\(\mathcal X\)</span> itself. Each point <span class="math inline">\(\omega \in \mathcal X\)</span> in the state space is a state, and each macroscopic property <span class="math inline">\(X\)</span> is a scalar function of type <span class="math inline">\(X : \mathcal X \to \mathbb{R}\)</span>.</p>
<p>If the state space has just <span class="math inline">\(d\)</span> dimensions, then we need only <span class="math inline">\(d\)</span> macroscopic properties <span class="math inline">\(X_1, \dots, X_d\)</span> in order to lay down a coordinate system for the state space. If we have another macroscopic property <span class="math inline">\(Y\)</span>, then there in general exists a function <span class="math inline">\(f_Y: \mathbb{R}^d \to \mathbb{R}\)</span>, such that <span class="math inline">\(Y(\omega) = f_Y(X_1(\omega), \dots, X_d(\omega))\)</span> for any state <span class="math inline">\(\omega\)</span>. In other words, we have an <strong>equation of state</strong>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/thermodynamic_state_manifold.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The state space for a thermodynamic system with 2 degrees of freedom. If we lay down three macroscopic properties, then they satisfy one equation of state.</figcaption>
</figure>
</div>
<section id="calculus-on-state-space" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="calculus-on-state-space">Calculus on state space</h4>
<p>In thermodynamics, we typically have many more macroscopic properties than dimensions. For example, the state space of an ideal gas has only 3 dimensions, but has many macroscopic properties: <span class="math inline">\(S, U, V, N, T, P, \mu, \dots\)</span>. In this case, every time we take a derivative on the state space, we need to pick exactly 3 properties, since picking different coordinates leads to different partial differentials.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Example with $x, y, z$">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example with <span class="math inline">\(x, y, z\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>As an illustrative example, let <span class="math inline">\(x, y, z\)</span> be smooth scalar functions on a smooth 2D surface, such that their contour lines are linearly independent at every point on the surface. Then, picking any 2 out of <span class="math inline">\(x, y, z\)</span> would give us a coordinate system. Any other smooth function <span class="math inline">\(f\)</span> on the surface can be expressed in 3 different ways, as</p>
<p><span class="math display">\[f = f_{x, y}(x, y) = f_{y, z}(y, z) = f_{z, x}(z, x)\]</span></p>
<p>This gives us two different ways to “differentiate <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(x\)</span>”:</p>
<p><span class="math display">\[
\left(\pp{f}{x}\right)_y := \partial_1 f_{x, y}, \quad
\left(\pp{f}{x}\right)_z := \partial_2 f_{z, x}
\]</span></p>
<p>where <span class="math inline">\(\partial_1\)</span> means “partial differentiation with respect to the first input”, etc.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Example with $\mathbb{R}^2$">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example with <span class="math inline">\(\mathbb{R}^2\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(x, y\)</span> be the usual coordinates on the 2D plane <span class="math inline">\(\mathbb{R}^2\)</span>, and let <span class="math inline">\(z = x + y, w = x - y\)</span>. We can pick any 2 of <span class="math inline">\(x, y, z, w\)</span> to construct a coordinate system. Then,</p>
<p><span class="math display">\[
\left(\pp{y}{x}\right)_y = 0 \quad \left(\pp{y}{x}\right)_z = -1 \quad \left(\pp{y}{x}\right)_w = 1
\]</span></p>
</div>
</div>
</div>
<p>In general, if we pick <span class="math inline">\(x_1, \dots, x_d, y\)</span> from a list of many smooth scalar functions on a surface, such that <span class="math inline">\(x_1, \dots, x_d\)</span> form a smooth and linearly independent coordinate system on the surface, then we can express <span class="math inline">\(y = f(x_1, \dots, x_d)\)</span> for some function <span class="math inline">\(f : \mathbb{R}^d \to \mathbb{R}\)</span>, and define</p>
<p><span class="math display">\[
\left(\pp{y}{x_1}\right)_{x_2, \dots, x_d} = \partial_1 f, \quad
\left(\frac{\partial y}{\partial x_1\partial x_2}\right)_{x_3, \dots, x_d} = \partial_1\partial_2 f, \quad \dots
\]</span></p>
<p>In particular, we have</p>
<p><span class="math display">\[dy = \sum_{i=1}^d (\partial_{x_i} y)_{x_1, \dots, x_d} dx_i\]</span></p>
<div id="exr-0" class="theorem exercise page-columns page-full">
<p><span class="theorem-title"><strong>Exercise 1</strong></span> Based on the following diagram, prove that if we have three smooth scalar functions <span class="math inline">\(x, y, z\)</span> on a smooth<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> 2D surface, such that their contour surfaces are linearly independent, then <span class="math inline">\(\left(\frac{\partial x}{\partial z}\right)_y\left(\frac{\partial y}{\partial x}\right)_z\left(\frac{\partial z}{\partial y}\right)_x = -1\)</span>. Generalize this to higher dimensions.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;It is sufficient to assume the surface and the scalar functions are <span class="math inline">\(C^2\)</span>, but we need not worry about it, because everything is smooth in classical thermodynamics, except at phase transitions.</p></div></div><p><img src="figure/constraint_partial_derivatives.jpg" class="img-fluid"></p>
</div>
</section>
</section>
<section id="constraint" class="level3">
<h3 class="anchored" data-anchor-id="constraint">Constraint</h3>
<p>A <strong>constraint</strong> is an equation of form <span class="math inline">\(f(A, B, C, \dots) = f_0\)</span>, where <span class="math inline">\(f\)</span> is a mathematical function, <span class="math inline">\(A, B, C, \dots\)</span> are macroscopic properties, and <span class="math inline">\(f_0\)</span> is a constant.</p>
<p>For example, if we have two tanks of gas in thermal contact, then the constraint is as follows:</p>
<p><span class="math display">\[
\begin{cases}
V_1 &amp;= V_{1,0} \\
V_2 &amp;= V_{2,0} \\
U_1 + U_2 &amp;= U_{1,0} + U_{2,0} \\
\end{cases}
\]</span></p>
<p>meaning that the volume of each tank of gas is conserved, and the sum of their energy is also conserved.</p>
<p>The constraints on a compound system are determined by the contacts between its subsystems.</p>
</section>
<section id="contacts" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="contacts">Contacts</h3>
<p>If we only have systems isolated in a perfect vacuum, then nothing interesting will happen. If two systems are perfectly connected, then they will never be brought apart. A contact allows two systems to interact, without destroying their individuality. It allows two systems to communicate, without becoming literally one system. Economically, contacts are trade contracts.</p>
<p>In general, the effect of a contact is to reduce the number of constraints by one. For example, a metal rod between two pistons reduces the two constraints</p>
<p><span class="math display">\[V_1 = V_{1,0}, \quad V_2 = V_{2, 0}\]</span></p>
<p>into one constraint: <span class="math display">\[V_1 + V_2 = V_{1,0} + V_{2,0}\]</span></p>
<p>As another example, in a tank of three kinds of gas <span class="math inline">\(N_2, H_2, NH_3\)</span>, allowing a single chemical reaction <span class="math inline">\(N_2 + 3H_2 \rightleftharpoons 2NH_3\)</span> reduces three constraints</p>
<p><span class="math display">\[
N_{N_2} = N_{N_2, 0}, \quad N_{H_2} = N_{H_2, 0}, \quad N_{NH_3}= N_{NH_3, 0}
\]</span></p>
<p>into two:</p>
<p><span class="math display">\[
N_{N_2} - N_{N_2, 0} = (N_{H_2} - N_{H_2, 0})/3, \quad N_{N_2} - N_{N_2, 0} = (N_{NH_3} - N_{NH_3, 0})/2
\]</span></p>
<p>A contact can be nonlinear. For example, if we have two pistons of the same area, connected by a lever, such that pushing on one piston by <span class="math inline">\(\Delta x\)</span> would be pulling on the other piston by <span class="math inline">\(2 \Delta x\)</span>, then the constraint becomes <span class="math inline">\(2(V_1 - V_{1,0}) + (V_2 - V_{2,0}) = 0\)</span>. And by designing a series of levers, gears, and chains, we can realize any constraint function <span class="math inline">\(f(V_1, V_2) = f(V_{1,0}, V_{2,0})\)</span> for any smooth function <span class="math inline">\(f\)</span>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/arbitrary_mechanical_system.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A thermodynamical system (a piston of gas) is connected to a mechanical system (a mass in gravity) via an arbitrary constraint (variable gears).</figcaption>
</figure>
</div>
</section>
<section id="compound-systems" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="compound-systems">Compound systems</h3>
<p>A compound system is nothing more than several systems connected. If we know the connections, and the entropy function of each subsystem, then we know everything about the compound system. The number of DOF for the compound system is the sum of the DOF of the subsystems, minus the degree of constraints.</p>
<p>For example, in the adiabatic expansion of a tank of ideal gas, we are really studying one compound system made of 3 subsystems:</p>
<ul>
<li>a tank of ideal gas (thermodynamic system),</li>
<li>a lump of mass in gravity (mechanical system),</li>
<li>with a gear system between them (contact).</li>
</ul>
<p>The gear system is designed with gear-ratio that varies as the system turns, in just the right way such that the system is always in equilibrium no matter the position of the piston, so that it really has no preference of going forwards or backwards.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/arbitrary_mechanical_system.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The compound system. Inside it, there is a subsystem of a tank of ideal gas that undergoes adiabatic expansion.</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Only one system">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Only one system
</div>
</div>
<div class="callout-body-container callout-body">
<p>We typically think of the tank of ideal gas itself as part of the thermodynamics, and the other parts as “the environment”, but we should consider one single compound system, properly speaking, of which the tank of ideal gas is merely a sub-system. This way, we can state directly that the entropy of the entire compound system is maximized.</p>
</div>
</div>
<div id="exm-0" class="theorem example">
<p><span class="theorem-title"><strong>Example 1 (heat-engine-and-environment compound system)</strong></span> A heat engine is a thermodynamic system that is used as a component of a larger compound system. The large system contains 4 parts: two energy baths, one heat engine, and one carefully designed mechanical system acting as energy storage.</p>
<p>If you only want a heat engine that works, then the energy storage does not need to be carefully designed. However, if you want a Carnot heat engine, i.e.&nbsp;at maximal efficiency, then the energy storage must be designed to be exactly right. It must be designed to follow the exact parameters of the heat engine, as well as the temperatures of the two energy baths. If any of those is ignored, the energy storage would fail to “mesh” with the rest of the compound system, and cause waste.</p>
<p>This is why a heat engine must be a component of a larger <em>compound system</em>. Every part depends on every other part. The energy storage unit is just as important and precisely designed as the heat engine is.</p>
</div>
</section>
<section id="equilibrium-virtual-vs-actual-states" class="level3">
<h3 class="anchored" data-anchor-id="equilibrium-virtual-vs-actual-states">Equilibrium, virtual vs actual states</h3>
<blockquote class="blockquote">
<p>Freedom is an iron cage.</p>
<p>Constraints set it free again.</p>
</blockquote>
<p>On the African savannah, there lived a bunch of meerkats. Meerkats love to stand on the tallest place.</p>
<p>At first, they could stand wherever they wanted, so they all stood on one single hill. It was crowded. A blind lion who had memorized the landscape came and ate all of them.</p>
<p>Then humans came and added long walls that divided the savannah into thin stripes. Now each meerkat’s location is determined by the stripe in which it happened to fall. The blind lion could find the meerkat if he knew the location of the stripe. In other words, optimizing for height, when there is one constraint, leads to one dimension of uncertainty.</p>
<p>This is a subtle point, so I will say it again. If you want to optimize for a quantity, and you don’t have a constraint, then you would always go to the globally best solution. The whole space of possibilities is open to you, but you don’t need them. Those states are “virtual”, because they are never observed, even though they are out there.</p>
<p>But if you have one constraint, then you have one unique solution for each possible setting of constraint. Suddenly a lot of those virtual states become real. You are still not free, but at least now you have a puppet master.</p>
<p>In classical thermodynamics, only equilibrium states are “real”. Nonequilibrium states are “virtual”. In Lagrangian mechanics, only stationary-action paths are real, and the other paths are virtual. You can imagine that if you throw a rock upwards, it might execute a complex figure-8 motion before returning to the ground again, but that’s a virtual path. The only real path is the unique virtual path that stationarizes the action integral.</p>
<p>Similarly, in classical thermodynamics, you could imagine that a tank of gas contains all its gas on the left side. Its entropy is just <span class="math inline">\(S(U, V/2, N)\)</span>, but that’s a virtual state that does not maximize entropy under constraint. The unique entropy-maximizing virtual state is the real state.</p>
<p>For every constraint, there are many nonequilibrium states that satisfy the constraint, but only one equilibrium entropy, and so equilibrium entropy is a function of constraints, even though the entropy function itself is not. It optimizes all its complexities away, allowing us to know it through just its external constraints.</p>
</section>
<section id="some-common-misconceptions" class="level3">
<h3 class="anchored" data-anchor-id="some-common-misconceptions">Some common misconceptions</h3>
<p>Thermodynamics is not statistical mechanics. Forget about molecules and atoms. Forget about statistics and statistical mechanics. Forget about <span class="math inline">\(S = k_B\ln \Omega\)</span> or <span class="math inline">\(S = -\sum_i p_i \ln p_i\)</span>. <strong>Randomness does not exist</strong> in classical thermodynamics.</p>
<p>Forget about the first law of thermodynamics. <strong>Energy is nothing special.</strong> The conservation of energy is no more important than the conservation of volume, or the conservation of electric charge.</p>
<p>Forget about heat. <strong>Heat does not exist</strong> – it is not a noun, not even an adjective, but an adverb at most. The theory of caloric has already been disproven in 1798 by the cannon-boring experiment.</p>
<p>Heat energy and work energy are both misnomers. Neither are types of energy. Instead, they are types of energy-flow. We should speak of only the heatly flow of energy and the workly flow of energy. In this way, both “heat” and “work” are revealed to be actually adverbs. This is a bit awkward, so we will continue to speak of “heat” and “work”, but you should understand that it’s a shorthand, and that there is neither “heat energy” nor “work energy”.</p>
<p>To perform work, one must perform work <em>upon</em> something. In other words, there is no such thing as “system A performed work”. There is really “some energy and length is between A and B, in compliance with an equation constraint, such that the total entropy of the compound system has remained constant”.</p>
<p>Forget about time. <strong>Time does not exist</strong> in classical thermodynamics. We can say nothing at all about what happens between equilibria. We can only say, “This is an equilibrium, but that is not an equilibrium.”. That is all we can say. See this, and you will see thermodynamics aright. As to what happened “between them”, that we must pass over in silence.</p>
<p>The name “thermodynamics” is a complete misnomer, because heat does not exist (thus no “thermo-”) and time does not exist (thus no “-dynamics”). If I am allowed a bit of name-rectification, I will call it “entropo-statics”.</p>
<p>If time does not exist, you ask, what do we mean when we study Joule expansion? That is, when we take half a tank of gas, and suddenly open the middle wall and wait until the gas equilibrates in the entire tank?</p>
<p>Quiet. We did not open the middle wall. We did not wait. Gas did not expand. The past did not cause the future. Time is a stubbornly persistent illusion, and causality too.</p>
<p>In fact, we are considering two different problems in thermodynamics.</p>
<p>First problem: Given a tank of gas with internal energy <span class="math inline">\(U = U_0\)</span>, molar-amount <span class="math inline">\(n = n_0\)</span>, and constraint <span class="math inline">\(V \leq \frac 12 V_0\)</span>. What is its equilibrium state? Answer: The state that maximizes entropy under the constraints: <span class="math display">\[
\begin{cases}
\max S(U, n, V) \\
V \leq \frac 12 V_0 \\
U = U_0 \\
n = n_0
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(S(U, n, V)\)</span> is the entropy of the gas when its states properties are <span class="math inline">\(U, n, V\)</span>.</p>
<p>Similarly, the second problem is another constraint-optimization problem: <span class="math display">\[
\begin{cases}
\max S(U, n, V) \\
V \leq V_0 \\
U = U_0 \\
n = n_0
\end{cases}
\]</span></p>
<p>That the two different problems seem to “follow one from another” is an illusion. In reality, they only appear to follow one another because this is what we observe in the real world: one equilibrium follows another. In equilibrium thermodynamics, equilibria do not follow one another – each stands alone.</p>
<p>Time only appears in the following sense: we observe a real-world system, like a car engine, and notice that its motion seems to consist of a sequence of equilibria. Not quite true equilibria, since true equilibria do not change. Maybe “pseudo-equilibria”? Too dismissive. Let’s call them “<a href="https://en.wikipedia.org/wiki/Quasistatic_process">quasi-equilibria</a>” instead.</p>
<p>Now, keeping those “quasi-equilibria” in mind, we muddle around the ocean of classical thermodynamics, until we have found some equilibria that resemble the quasi-equilibria we have in mind. And so, from the bottom of the ocean, we pick up one equilibrium, then another, then another. Then we string together these little equilibria along a number line like a pearl necklace. We run our fingers over these pearls and delight in their “motion”, like flipping the pages of a stop-motion book and shouting, “Look, it is moving!”.</p>
<p><img src="figure/banner/2.png" class="img-fluid"></p>
</section>
</section>
<section id="the-three-laws" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-three-laws">The three laws</h2>
<p>More accurately: one law and two non-laws.</p>
<section id="second-law" class="level3">
<h3 class="anchored" data-anchor-id="second-law">Second law</h3>
<blockquote class="blockquote">
<p>For the equilibrium of any isolated system it is necessary and sufficient that in all possible variations of the state of the systems which do not alter its energy, the variation of its entropy shall either vanish or be negative.</p>
<p><span class="citation" data-cites="gibbsEquilibriumHeterogeneousSubstances1878">(<a href="#ref-gibbsEquilibriumHeterogeneousSubstances1878" role="doc-biblioref">Gibbs 1878</a>)</span></p>
</blockquote>
<p>The second law of thermodynamics is all-important: maximizing entropy is all of classical thermodynamics. All other parts are just tricks for maximizing entropy.</p>
<p>Although, there are actually two aspects of the second law, subtly different. One of them is static, while the other is dynamic:</p>
<ul>
<li>Static: A thermodynamic system is described by a function on the state space, called the <em>entropy</em> function. Each system can be placed under many different forms of constraints. Under each possible constraint, the only physically observable state is the state that maximizes entropy under constraint.</li>
<li>Dynamic: The entropy of a thermodynamic system does not decrease over time.</li>
</ul>
<p>There is no difficulty with the static statement, but many difficulties with the dynamic statement, since it involves time, which really does not exist in classical thermodynamics. Nevertheless, since time is so important to the rest of physics, physicists, especially physics teachers, have repeatedly tried to hack it back into the theory, resulting in predictable and endless confusions. Since we do not compromise with intuition, in the rest of this essay, we will use the static formulation as much as possible.</p>
</section>
<section id="first-law" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="first-law">First law</h3>
<blockquote class="blockquote">
<p>As a student, I read with advantage a small book by F. Wald entitled “The Mistress of the World and her Shadow”. These meant energy and entropy. In the course of advancing knowledge the two seem to me to have exchanged places. In the huge manufactory of natural processes, the principle of entropy occupies the position of manager, for it dictates the manner and method of the whole business, whilst the principle of energy merely does the book- keeping, balancing credits and debits.</p>
<p><span class="citation" data-cites="emdenWhyWeHave1938">(<a href="#ref-emdenWhyWeHave1938" role="doc-biblioref">Emden 1938</a>)</span></p>
</blockquote>
<p>The first law of thermodynamics is entirely trivial. Energy is <em>nothing special</em>! Energy is <em>just</em> a conserved quantity, one among equals, much like volume, mass, and many other things… Every conserved quantity is equally conserved,<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> so it does not deserve a special thermodynamic law. You might as well say “conservation of mass” is “the second-first law of thermodynamics” and “conservation of volume” is “the third-first law of thermodynamics”, and “conservation of electrons” and “conservation of protons” and “conservation of length” (if you are studying a thermodynamic system restricted to move on a line) and “conservation of area” (if you are studying a thermodynamic system restricted on the surface of a lake), and so on…</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;The first law of thermodynamics had always struck me as oddly out of place, almost like a joke I could not catch, like</p>
<blockquote class="blockquote">
<p>All animals are equal, but some animals are more equal than others</p>
</blockquote>
<p>but with</p>
<blockquote class="blockquote">
<p>All conserved quantities are conserved, but some quantities are more conserved than others.</p>
</blockquote>
<p>I kept waiting for the textbooks, or the teachers, or someone to drop the act and confess, “Actually, we were joking – conservation of energy really is not that special, and we were just bored with standard physics and wanted to confuse you with a cute magic trick before showing you what standard physics really is saying.”. Slowly, I realized that there is no joke – conservation of energy is unironically treated as special not just by the students but even by the teachers. I had to figure out for myself how the joke really works, and it required me to rebuild thermodynamics according to my preferences.</p></div></div><p>This sounds extraordinary, but that is merely how classical thermodynamics works. The first law of thermodynamics does not deserve its title. It should be demoted to an experimental fact and not a law. Just to drive the point home, I wrote an entire <a href="#sec-stereodynamics">sci-fi worldbuilding sketch</a> about an alien species for which the conservation of volume that is fundamental, not energy, and which discovered stereodynamics. If you can laugh at their mistaken importance of the conservation of volume, maybe you can laugh at the mistaken importance of the conservation of energy too.</p>
<p>The proper place for the law of conservation of energy is not classical thermodynamics, but general physics, because energy is nothing special inside classical thermodynamics, but it is extremely special if we zoom out to consider the whole of physics. Whereas in classical thermodynamics, systems conserve energy, and volume, and mass, and electron-number, and proton-number, and… when you move outside of thermodynamics, such as when you add in electrodynamics, special relativity, and quantum mechanics, all kinds of conservations breakdown. You don’t have conservation of mass, or number of electrons, or even volume, but energy is always conserved.</p>
<p>This explains the long confusion around the conservation of energy. Within equilibrium thermodynamics, every conserved quantity is conserved, yes, but physicists are less interested in theoretical purity than mathematicians. They know that <em>outside</em>, energy is a more special conserved quantity than others, and so they can’t help but feel like energy should be treated as special <em>inside</em> thermodynamics too.</p>
</section>
<section id="zeroth-law" class="level3">
<h3 class="anchored" data-anchor-id="zeroth-law">Zeroth law</h3>
<p>Now that the first law has been dispelled, we can dispel the zeroth law of thermodynamics too. If energy falls from grace, so must its shadow, temperature.</p>
<div id="thm-zeroth-law" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (general zeroth law)</strong></span> If <span class="math inline">\(S_1(X_1, Y) + S_2(X_2, Y)\)</span> is maximized under the constraint <span class="math inline">\(X_1 + X_2 = X\)</span>, then <span class="math inline">\((\partial_X S_1)_Y = (\partial_X S_2)_Y\)</span>.</p>
</div>
<table class="caption-top table">
<caption>The zeroth law of thermodynamics in various guises.</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>maximized quantity <span class="math inline">\(S\)</span></th>
<th>conserved quantity <span class="math inline">\(X\)</span></th>
<th>derivative <span class="math inline">\((\partial_X S)_Y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>entropy</td>
<td>energy</td>
<td>inverse temperature <span class="math inline">\(\beta\)</span></td>
</tr>
<tr class="even">
<td>entropy</td>
<td>volume</td>
<td><span class="math inline">\(\beta P\)</span></td>
</tr>
<tr class="odd">
<td>entropy</td>
<td>particles</td>
<td><span class="math inline">\(-\beta \mu\)</span>, where <span class="math inline">\(\mu\)</span> is chemical potential</td>
</tr>
<tr class="even">
<td>entropy</td>
<td>surface area</td>
<td><span class="math inline">\(-\beta\sigma\)</span>, where <span class="math inline">\(\sigma\)</span> is surface tension</td>
</tr>
<tr class="odd">
<td>production value</td>
<td>raw material</td>
<td>marginal value</td>
</tr>
</tbody>
</table>
</section>
<section id="third-law" class="level3">
<h3 class="anchored" data-anchor-id="third-law">Third law</h3>
<p>The third law is rarely, if ever, used in classical thermodynamics, and its precise meaning is still unclear. It seems to me that its proper place is not thermodynamics, but quantum statistical mechanics, where it states that a substance, when at the lowest possible energy (ground state), has finite entropy – Einstein’s formulation of the third law. <span class="citation" data-cites="klimenkoTeachingThirdLaw2012">(<a href="#ref-klimenkoTeachingThirdLaw2012" role="doc-biblioref">Klimenko 2012</a>)</span></p>
</section>
<section id="an-economic-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="an-economic-interpretation">An economic interpretation</h3>
<p>Here is an economic interpretation of classical thermodynamics. There are other possible interpretations, and we will use the others in this essay.</p>
<p>In this interpretation, the laws of nature become the CEO of a company. Every conserved quantity is a commodity. The company has some commodity. Commodities themselves have no intrinsic value. Instead, the company is valued by a certain accounting agency. The CEO’s job is to move around the commodities so that the accounting agency gives it the highest book-value.</p>
<p>A compound system is a <em>conglomerate company</em>: a giant company made of little companies. If entropy is extensive, then it means the total book-value for the conglomerate is the sum of the book-value of each subsidiary company. Otherwise, entropy is nonextensive, and the accounting agency believes that the conglomerate has <a href="https://en.wikipedia.org/wiki/Corporate_synergy"><em>corporate synergy</em></a>.</p>
<p>The inverse temperature <span class="math inline">\(\beta\)</span> is the marginal value of energy:</p>
<p><span class="math display">\[\beta = \frac{d(\text{value of a sub-company})}{d(\text{energy owned by the sub-company})}\]</span></p>
<p>The pressure <span class="math inline">\(P\)</span>, multiplied by <span class="math inline">\(\beta\)</span>, is the marginal value of space:</p>
<p><span class="math display">\[\beta P = \frac{d(\text{value of a sub-company})}{d(\text{volume owned by the sub-company})}\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It might appear odd to write <span class="math inline">\(\beta P\)</span>, but in the entropy-centric view of thermodynamics, it is the quantity <span class="math inline">\(\beta P\)</span> that is fundamental, and in comparison, the pressure <span class="math inline">\(P\)</span> is less fundamental, as a ratio <span class="math inline">\(P := \frac{\beta P}{\beta}\)</span>. Why, then, do we speak of pressure <span class="math inline">\(P\)</span> and temperature <span class="math inline">\(T\)</span>, instead of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\beta P\)</span>? It is because classical thermodynamics is traditionally understood as energy-centric.</p>
</div>
</div>
</section>
</section>
<section id="basic-consequences" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="basic-consequences">Basic consequences</h2>
<section id="thermodynamic-forcesuction" class="level3">
<h3 class="anchored" data-anchor-id="thermodynamic-forcesuction">Thermodynamic force/suction</h3>
<p>Since nature is entropy-maximizing, if entropy can be increased by moving some energy from one system to another, it will happen. Similarly for space. It would seem as if there is a <strong>thermodynamic suction</strong> that is sucking on on energy, and the side with the higher thermodynamic suction tends to absorb it.</p>
<p><span class="math display">\[
\text{thermodynamic suction of $X$} = \left(\frac{\partial S}{\partial X}\right)_{\text{non-}X}
\]</span></p>
<p>In energy-centric thermodynamics, we use <strong>thermodynamic force</strong>, or <strong>thermodynamic potential</strong>, defined by</p>
<p><span class="math display">\[
\text{thermodynamic force of $X$} = -\frac{\left(\frac{\partial S}{\partial X}\right)_{\text{non-}X}}{\left(\frac{\partial S}{\partial U}\right)_{\text{non-}U}}
\]</span></p>
<p>For example, for a tank of gas, the macroscopic properties are <span class="math inline">\(U, V, N\)</span>, and so it has three thermodynamic suctions:</p>
<p><span class="math display">\[
\begin{aligned}
  \beta &amp;= (\partial_U S)_{V, N}\\
  \beta P &amp;= (\partial_V S)_{U, N}\\
  -\beta \mu &amp;= (\partial_N S)_{U, V}
\end{aligned}
\]</span></p>
<p>and the thermodynamic forces associated with <span class="math inline">\(V, N\)</span> are <span class="math inline">\(P\)</span> and <span class="math inline">\(-\mu\)</span>.</p>
<p>Unfortunately, the notations for thermodynamic suctions are far from elegant. The first one, <span class="math inline">\(\beta\)</span>, is the inverse of temperature.. The second one, <span class="math inline">\(\beta P\)</span>, is <span class="math inline">\(\beta\)</span> multiplied by pressure. The third one is truly the most annoying, as it not only involves <span class="math inline">\(\beta\)</span>, but also a negative sign. To see how the notation came about, we can write it out in differential form:</p>
<p><span class="math display">\[dS = \beta dU + \beta P dV - \beta \mu dN\]</span></p>
<p>Conventional notations are energy-centric, so we rewrite it to single out <span class="math inline">\(dU\)</span>:</p>
<p><span class="math display">\[
dU = TdS + (- PdV) + \mu dN
\]</span></p>
<p>Now we see how the notation came about: <span class="math inline">\(TdS\)</span> is the heat energy-flow into the system, <span class="math inline">\(-PdV\)</span> is the mechanical work energy-flow into the system, and <span class="math inline">\(\mu dN\)</span> is the chemical energy-flow into the system.</p>
<p>If I could truly reform notation, I would redefine <span class="math inline">\(\beta P\)</span> as <span class="math inline">\(p_V\)</span>, meaning “the price of volume”, meaning “the price of particle”, and so on. In this notation, we have:</p>
<p><span class="math display">\[
\begin{aligned}
dS &amp;= p_U dU + p_V dV + p_N dN \\
dU &amp;= p_U^{-1}dS - \frac{p_V}{p_U}dV - \frac{p_N}{p_U}dN
\end{aligned}
\]</span></p>
<div id="exm-0" class="theorem example">
<p><span class="theorem-title"><strong>Example 2 (photon gas with <span class="math inline">\(\mu = 0\)</span>)</strong></span> Suppose we have a piston chamber, with its inner surface covered with silver, and there is a tiny speck of blackbody inside it, then the chamber would be filled with bouncing photons, in the form of a “photon gas”. The photons would reflect off the surface of the chamber, some absorbed and some emitted in turn, by the blackbody.</p>
<p>As usual for gas, the state of the system is determined by its internal energy, volume, and particle number: <span class="math inline">\(U, V, N\)</span>, with</p>
<p><span class="math display">\[dS = \beta dU + \beta PdV - \beta \mu dN\]</span></p>
<p>However, the photon gas is quite special, in that photons can be created and destroyed by the speck of blackbody, so at equilibrium, we must have <span class="math inline">\(\beta\mu = 0\)</span>, for otherwise, the system would be able to increase in entropy simply by creating/destroying more photons, and thus it is not in equilibrium.</p>
<p>This contrasts with the typical case with chemical gases like oxygen, where the particle number in a reaction chamber is constant, allowing <span class="math inline">\(\mu \neq 0\)</span> even at equilibrium.</p>
</div>
</section>
<section id="helmholtz-free-entropy" class="level3">
<h3 class="anchored" data-anchor-id="helmholtz-free-entropy">Helmholtz free entropy</h3>
<p>When we have a small system connected to a large system, while we can solve its equilibria by maximizing the plain old entropy for the full compound system, it is often easier conceptually to define a “free entropy” for the small system, and treat the large system as a bath. This is similar to how one can solve for the motion of a cannonball on earth by describing a constant gravitational acceleration, even though we can could have solved for the full cannonball-earth two-body system.</p>
<div id="def-helmholtz" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Helmholtz free entropy)</strong></span> The <strong>Helmholtz free entropy</strong> is the convex dual of entropy with respect to energy:</p>
<p><span id="eq-Helmholtz-S"><span class="math display">\[
f(\beta, X) = \max_U [S(U, X) - \beta U]
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(U\)</span> is its internal energy, and <span class="math inline">\(X\)</span> are some other macroscopic properties.</p>
<p>Of historical importance is the <strong>Helmholtz free energy</strong> <span class="math inline">\(F := - T f\)</span>, or equivalently,</p>
<p><span id="eq-Helmholtz-U"><span class="math display">\[
F = \min_U [U - TS(U, X)]
\tag{2}\]</span></span></p>
</div>
<div id="thm-helmholtz-free-entropy" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (maximize Helmholtz free entropy)</strong></span> If a thermodynamic system is in energy-contact with an energy bath with price <span class="math inline">\(\beta\)</span>, and is held under constraint on the state by <span class="math inline">\(C(X) = 0\)</span>, then the system equilibrates at</p>
<p><span class="math display">\[
\begin{cases}
\max_{U, X} [S(U, X) - \beta U] = \max_{X} f(\beta, X)\\
C(X) = 0
\end{cases}
\]</span></p>
<p>That is, the system always equilibrates at the maximal Helmholtz free entropy state that satisfies the constraint.</p>
<p>Equivalently, the system minimizes its Helmholtz free energy under constraint.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>If we prove the case for Helmholtz free entropy, then by multiplying it by <span class="math inline">\(-T\)</span>, we find that the system minimizes its Helmholtz free energy under constraint. So it remains to prove the case for Helmholtz free entropy.</p>
<p>We prove the case where there is no constraint on the state of the system. The proof for the case with constraint is similar.</p>
<p>Suppose the system starts out at <span class="math inline">\(\beta, U_0, X\)</span>. Then the equilibrium condition is</p>
<p><span class="math display">\[
\begin{cases}
\max (S_{bath} + S) \\
U_{bath} + U = U_{bath, 0} + U_{0}
\end{cases}
\]</span></p>
<p>The entropy of the bath is</p>
<p><span class="math display">\[S_{bath} = S_{bath, 0} + \beta Q\]</span></p>
<p>where <span class="math inline">\(Q = U_{bath} - U_{bath, 0}\)</span> is the amount of energy received by the bath as heat.</p>
<p>Plugging this back in, the equilibrium condition simplifies to</p>
<p><span class="math display">\[
\max_U [\beta (U_0 - U) + S(U, X)]
\]</span></p>
<p>which is the desired result.</p>
</div>
</div>
</div>
<div id="thm-helmholtz-free-work" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 (Helmholtz free energy difference is available for work)</strong></span> Consider the following method of extracting mechanical energy. Connect the system to an energy bath at the energy price <span class="math inline">\(\beta\)</span>, and to a mechanical system of arbitrary design. The system starts at <span class="math inline">\(\beta, U_0, X_0\)</span> and ends at <span class="math inline">\(\beta, U_1, X_1\)</span>. No matter how the mechanical system is designed, and no matter whether the process is reversible or not, we have</p>
<p><span class="math display">\[
W\leq F(\beta, U_0, X_0) - F(\beta, U_1, X_1)
\]</span></p>
<p>where <span class="math inline">\(W\)</span> is “mechanical work done by the system”, that is, the increase in internal energy of the mechanical system. This is an equality when the process is reversible.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>By conservation of energy and the second law,</p>
<p><span class="math display">\[
\begin{cases}
U_1 = U_0 - (W + Q) \\
\beta Q + S(U_1, X_1) \geq S(U_0, X_0)
\end{cases}
\]</span></p>
<p>which simplifies to the result.</p>
<p>If the process is reversible, then the entropy before and after must be equal, which gives us</p>
<p><span class="math display">\[
\begin{cases}
U_1 = U_0 - (W + Q) \\
\beta Q + S(U_1, X_1) = S(U_0, X_0)
\end{cases}
\]</span></p>
<p>which simplifies to the result.</p>
</div>
</div>
</div>
<p>This result is typically interpreted as saying that <span class="math inline">\(\Delta F = W\)</span>, that is, in a system in constant thermal equilibrium with an energy bath of constant temperature, the decrease in Helmholtz energy of the system is the maximal mechanical work extractable from the system. Incidentally, this explains the odd name of “free energy” – “free” as in “free to do work” to contrast with the other parts of internal energy, which are chained up and not free to do work. Energy is born free, and eventually everywhere it is in chains.</p>
<div id="thm-envelope-helmholtz" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4 (envelope theorem for Helmholtz)</strong></span> For any inverse temperature <span class="math inline">\(\beta &gt; 0\)</span> and thermodynamic properties <span class="math inline">\(X\)</span>, let <span class="math inline">\(U^*\)</span> be the optimal internal energy that maximizes Helmholtz free entropy. We have</p>
<p><span class="math display">\[
\begin{aligned}
\beta &amp;= (\partial_U S)_X|_{U=U^*(\beta, X), X = X} \\
df    &amp;= (\partial_X S)_U|_{U=U^*(\beta, X), X = X} dX - U^*(\beta, X) d\beta
\end{aligned}
\]</span></p>
<p>if <span class="math inline">\(S\)</span> is differentiable and strictly concave at that point.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
</div>
<div class="callout-body-container callout-body">
<p>For the first equation, differentiate <span class="math inline">\(f\)</span>. For the second equation, apply the same no-arbitrage proof as in the proof of <a href="https://en.wikipedia.org/wiki/Hotelling%27s_lemma">Hotelling’s lemma</a> (see the essay on <a href="https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/"><em>Analytical Mechanics</em></a>).</p>
</div>
</div>
<p>Economically speaking, the second equation is a special case of the <a href="https://en.wikipedia.org/wiki/Envelope_theorem">envelope theorem</a>, just like Hotelling’s lemma.</p>
</section>
<section id="first-order-phase-transition" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="first-order-phase-transition">First-order phase transition</h3>
<p>What happens if <span class="math inline">\(S\)</span> is not differentiable and strictly concave? In this case, we do not have <span class="math inline">\(\beta = (\partial_U S)_X\)</span>. We have two possibilities.</p>
<p>The first possibility is pictured as follows. There is a kink in the curve of <span class="math inline">\(S(U, X)\)</span>. At that point of critical internal energy <span class="math inline">\(U_c\)</span>, there is an entire interval of possible <span class="math inline">\(\beta\)</span>. What we would notice is that at that critical internal energy and critical entropy, the system can be in equilibrium with <em>any</em> heat bath with <em>any</em> temperature between <span class="math inline">\([T_{c, min}, T_{c, max}]\)</span>. As far as I know, such systems do not exist, as all physically real systems have a unique temperature at all possible states.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/indeterminate_temperature_SU_curve.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">When there is a kink in the curve of <span class="math inline">\(S(U, X)\)</span>, the system has an indeterminate temperature.</figcaption>
</figure>
</div>
<p>The second possibility is pictured as follows. There is a bump in the curve, such that we can draw a double tangent over the bump, with slope <span class="math inline">\(\beta_c\)</span>. At that critical inverse temperature, the system can be either at the lower tangent point, or the upper tangent point. It cannot be anywhere in-between, because as we saw, such points do not minimize <span class="math inline">\(f(\beta, X)\)</span>, and thus are unstable.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/first_order_phase_transition_SU_curve.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">When there is a double tangent in the curve of <span class="math inline">\(S(U, X)\)</span>, the system undergoes a first-order phase transition with latent entropy and energy.</figcaption>
</figure>
</div>
<p>For example, if we confine some liquid water in a vacuum chamber, and bathe it in a cold bath, then at its critical <span class="math inline">\(\beta_c\)</span>, it would split into two parts, one part is all ice, and the other part is all water, mixed in just the right proportion to give it the correct amount of total internal energy. As it loses internal energy, the ice part grows larger, until it is all ice, at which point the system has finally gotten over the bump, and could cool down further.</p>
<p>At the critical point, <span class="math inline">\((\partial_{\beta}f)_X\)</span> changes abruptly. So if we plot <span class="math inline">\(\beta \mapsto f(\beta, X)\)</span>, the curve will kink there.</p>
<div id="thm-0" class="theorem page-columns page-full">
<p><span class="theorem-title"><strong>Theorem 5 (Maxwell equal area rule)</strong></span> In a first-order phase transition at a fixed temperature and varying pressure/volume, the <span class="math inline">\(P, V\)</span> diagram has a horizontal line going from <span class="math inline">\((P_c, V_1)\)</span> to <span class="math inline">\((P_c, V_2)\)</span>, such that</p>
<p><span class="math display">\[\int PdV = P_c(V_2-V_1)\]</span></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/maxwell_equal_area_rule.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Maxwell’s equal area rule states that the areas of the regions labelled I and II are equal.</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Fix the system’s internal energy <span class="math inline">\(U\)</span>, and its temperature <span class="math inline">\(T\)</span>, and plot the <span class="math inline">\(V, S\)</span> curve.</p>
<p>When pressure is at a critical value <span class="math inline">\(P_c\)</span>, the line of slope <span class="math inline">\(\beta P_c\)</span> is tangent to the <span class="math inline">\(V \mapsto S(U, V)\)</span> curve at two different points, with volumes <span class="math inline">\(V_1, V_2\)</span>. This is that first-order phase transition.</p>
<p>Now, move the system state from the first point to the second. During the process, <span class="math display">\[\int PdV = \int (TdS -dU) = \int TdS = T \Delta S = T \beta P_c(V_2 - V_1) = P_c(V_2-V_1)\]</span></p>
</div>
</div>
</div>
</section>
<section id="other-free-entropies-and-energies" class="level3">
<h3 class="anchored" data-anchor-id="other-free-entropies-and-energies">Other free entropies and energies</h3>
<p>Consider a thermodynamic system whose entropy function is <span class="math inline">\(S(U, V, X)\)</span>, where <span class="math inline">\(U\)</span> is the internal energy and <span class="math inline">\(V\)</span> is the volume. Its <strong>Gibbs free entropy</strong> is</p>
<p><span class="math display">\[
g(\beta, \beta P, X) = \max_{U, V} (S(U, V, X) - \beta U - (\beta P)V)
\]</span></p>
<p>In other words, it’s the convex dual of entropy with respect to energy and volume. Similarly, its <strong>Gibbs free energy</strong> is <span class="math inline">\(G = -g/\beta\)</span>.</p>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6 (Gibbs free entropy is maximized)</strong></span> Let a thermodynamic system be in equilibrium with an energy-and-volume bath of prices <span class="math inline">\(\beta, \beta P\)</span>. If the system has constraint on the state by <span class="math inline">\(C(X) = 0\)</span>, then the system equilibrates at</p>
<p><span class="math display">\[
\begin{cases}
\max_{X} g(\beta, \beta P, X)\\
C(X) = 0
\end{cases}
\]</span></p>
<p>And if <span class="math inline">\(S\)</span> is strictly concave and differentiable at that point, then <span class="math inline">\(dg = (\partial_X S)_{U, V} dX - Ud\beta - V d(\beta P)\)</span>.</p>
</div>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 7 (Gibbs free energy difference is available for work)</strong></span> Connect a system to an energy-and-volume bath at marginal entropies <span class="math inline">\(\beta, \beta P\)</span>, and a mechanical system of arbitrary design. The system starts at <span class="math inline">\(\beta, \beta P, X_0\)</span> and ends at <span class="math inline">\(\beta, \beta P, X_1\)</span>. Then,</p>
<p><span class="math display">\[
W\leq G(\beta, \beta P, X_0) - G(\beta, \beta P, X_1)
\]</span></p>
<p>where <span class="math inline">\(W\)</span> is “work”, that is, the increase in internal energy of the mechanical system. If the process is reversible, then equality holds.</p>
</div>
<div id="thm-envelope-gibbs" class="theorem">
<p><span class="theorem-title"><strong>Theorem 8 (envelope theorem for Gibbs)</strong></span> For any inverse temperature <span class="math inline">\(\beta &gt; 0\)</span>, any pressure <span class="math inline">\(P\)</span>, and other thermodynamic properties <span class="math inline">\(X\)</span>, let <span class="math inline">\(U^*, V^*\)</span> be the optimal internal energy and volume that maximizes Gibbs free entropy, then</p>
<p><span class="math display">\[
\begin{aligned}
\beta   &amp;= (\partial_U S)_{V, X} \\
\beta P &amp;= (\partial_V S)_{U, X}\\
dg      &amp;= (\partial_X S)_{U, V} dX - U^* d\beta - V^* d(\beta P)
\end{aligned}
\]</span></p>
<p>if <span class="math inline">\(S\)</span> is differentiable and strictly concave at that point. Here, the left sides of all equations are evaluated at <span class="math inline">\(U=U^*(\beta, \beta P, X), V=V^*(\beta, \beta P, X), X = X\)</span>.</p>
</div>
<div id="exr-0" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2</strong></span> Prove the above theorems for Gibbs free entropy.</p>
</div>
<p>Similarly, if a system is in energy-volume-chemical contact with an energy-volume-chemical bath, then the following <strong>Landau free entropy</strong> is useful:</p>
<p><span class="math display">\[
\omega(\beta, \beta P, -\beta\mu_1, \dots, -\beta\mu_n) = \max_{U, V, N_1, \dots, N_n} \left(S(U, V, N_1, \dots, N_n, X) - \beta U - (\beta P)V - \sum_{i=1}^n (-\beta \mu_i) N_i \right)
\]</span></p>
<p>In other words, it’s the convex dual of entropy with respect to energy, volume, and particle numbers.</p>
<div id="exr-0" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 3</strong></span> Formulate and prove the analogous theorems for Landau free entropy.</p>
</div>
<div id="exr-0" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 4</strong></span> If we consider a system, surrounded by gas, inside an adiathermal piston under an atmosphere, then we can consider the following form of free energy: <span class="math inline">\(\tilde s(U, \beta P, X) := \max_{V} (S(U, V, X) - \beta U - (\beta P)V)\)</span>. Formulate and prove the analogous theorems for this free entropy.</p>
</div>
<p>Take-home lessons:</p>
<ul>
<li>When a system is in contact with a <span class="math inline">\(Y\)</span>-bath, then it is useful to consider the convex dual of the entropy with respect to <span class="math inline">\(Y\)</span>, that is, <span class="math inline">\(\max_Y (S(Y, X) - p_Y Y)\)</span>, where <span class="math inline">\(p_Y\)</span> is the marginal entropy of <span class="math inline">\(Y\)</span> of the bath. That is, the price of entropy on the bath-market.</li>
<li>Free entropy is maximized when the system equilibrates with a bath. Free energy is minimized.</li>
<li>Change in free energy is the maximal amount of work extractable when the system equilibrates with both a bath and a mechanical system. This maximal amount of work is extracted precisely when the process is reversible. The process is irreversible precisely when less than maximal amount of work is extracted.</li>
</ul>
</section>
<section id="maxwell-relations" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="maxwell-relations">Maxwell relations</h3>
<p>Since <span class="math inline">\(dS = \beta dU + \beta P dV\)</span>, we have the first Maxwell relation</p>
<p><span id="eq-maxwell-1"><span class="math display">\[
\partial_U \partial_V S = (\partial_V \beta)_U = (\partial_U(\beta P) )_V
\tag{3}\]</span></span></p>
<p>In economic language, it states</p>
<p><span id="eq-maxwell-1-econ"><span class="math display">\[
\partial_{q_i}\partial_{q_j} S = (\partial_{q_i} p_j)_{q_j} = (\partial_{q_j} p_i)_{q_i}
\tag{4}\]</span></span></p>
<p>where <span class="math inline">\(q_i\)</span> is the quantity of commodity <span class="math inline">\(i\)</span>, and <span class="math inline">\(p_i\)</span> is its marginal utility. In economics, we usually prefer writing demanded quantity as a function of marginal price as</p>
<p><span class="math display">\[(\partial_{p_j}q_i)_{q_j} = (\partial_{p_i}q_j)_{q_i}\]</span></p>
<p>This is a symmetry of the <a href="https://en.wikipedia.org/wiki/Cross_elasticity_of_demand">cross-price elasticity of demand</a>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Samuelson used the Maxwell relations, and other relations, to justify neoclassical economics. His idea is that, while utility functions are unobservable, and we do not have a scientific instrument to measure “economic equilibrium”, we can make falsifiable predictions from assuming that the economy is in equilibrium – such as the symmetry of the cross-price elasticity of demand.</p></div></div><p>For example, if <span class="math inline">\(i, j\)</span> are noodles and bread, then <span class="math inline">\((\partial_{q_i} p_j)_{q_j}\)</span> is how much the marginal price of bread would rise if I have a little more noodle. As noodles and bread are substitutional goods, we expect the number to be negative, meaning that having more noodles, I would price bread less. The Maxwell relation then tells us that it is exactly the same in the other direction: If I am given a little more bread, I would price noodles less. Not only that, I would want less by <em>exactly the same amount</em>.</p>
<p>The second relation is a bit hard to explain, since enthalpy really does not have a good representation in entropy-centric thermodynamics. However, it turns out to be just the third relation with <span class="math inline">\(i, j\)</span> switched.</p>
<p>Since <span class="math inline">\(df = \beta P dV - Ud\beta\)</span>, we have the third Maxwell relation</p>
<p><span id="eq-maxwell-3"><span class="math display">\[
\partial_\beta\partial_V f = -(\partial_V U)_\beta = +(\partial_\beta(\beta P))_V
\tag{5}\]</span></span></p>
<p>In economic language, we have</p>
<p><span id="eq-maxwell-3-econ"><span class="math display">\[
\partial_{p_i}\partial_{q_j} \left[\max_{q_i}(S(q) - p_i q_i )\right]= -(\partial_{q_j} q_i)_{p_i} = (\partial_{p_i}p_j)_{q_j}
\tag{6}\]</span></span></p>
<p>Continuing from the previous example, if <span class="math inline">\(i, j\)</span> are noodles and bread, and we open a shop with an infinite amount of noodles always at the exact price, then I would buy and sell from the noodle shop until my marginal price of noodles is equal to the shop’s price. Now, <span class="math inline">\((\partial_{q_j} q_i)_{p_i}\)</span> is how much noodles I would buy if I am given a marginal unit of bread. As noodles and bread are substitutional goods, this number is negative. This then means <span class="math inline">\((\partial_{p_i}p_j)_{q_j} &gt; 0\)</span>, meaning that if the noodle price suddenly increases a bit, then I would sell a bit of noodles until I have reached equilibrium again. At that equilibrium, since I have less noodles, I would price higher its substitutional good, bread, by an equal amount as the previous scenario.</p>
<p>Since <span class="math inline">\(dg = -Ud\beta - Vd(\beta P)\)</span>, we have the fourth Maxwell relation</p>
<p><span id="eq-maxwell-4"><span class="math display">\[
-\partial_{\beta}\partial_{\beta P}g = (\partial_{\beta P}U)_\beta = (\partial_\beta V)_{\beta P}
\tag{7}\]</span></span></p>
<p>In economic language, we have</p>
<p><span id="eq-maxwell-4-econ"><span class="math display">\[
\partial_{p_i}\partial_{p_j} \left[\max_{q_i, q_j}(S(q) - p_i q_i - p_j q_j)\right]= -(\partial_{p_j} q_i)_{p_i}= -(\partial_{p_i} q_j)_{p_j}
\tag{8}\]</span></span></p>
<p>This is another symmetry of cross-price elasticity of demand.</p>
<p>Continuing from the previous example, if <span class="math inline">\(i, j\)</span> are noodles and bread, and we open a shop with an infinite amount of noodles and bread, then I would of course buy and sell from the shop until my marginal prices of noodles and bread are equal to the shop’s prices. Now, if the shop suddenly raises the price of bread by a small amount, I would sell off some bread until my marginal price for bread increases to the shop’s new price. Now my marginal price for noodles increases too by substitutional effect, so I buy some noodles. Thus <span class="math inline">\((\partial_{p_j} q_i)_{p_i} &gt; 0\)</span>. Switching the scenario, we find that raising the price of noodles would make me buy bread by an amount equal to that in the previous scenario.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Alternate proof of the Maxwell relations">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Alternate proof of the Maxwell relations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>We use the notation of economics here.</p>
<p>Suppose we have commodities <span class="math inline">\(1, 2, \dots, n\)</span>. We pick two commodities <span class="math inline">\(i, j\)</span>, and fix all other commodity quantities. Thus, we can write <span class="math inline">\(dS = p_i dq_i + p_j d q_j\)</span>.</p>
<p>Since knowing <span class="math inline">\(n\)</span> properties of the thermodynamic system allows us to know its exact state, and we have already fixed <span class="math inline">\(n-2\)</span> properties of it, there only remain two more degrees of freedom. We can parameterize this by <span class="math inline">\((q_i, q_j)\)</span>, or <span class="math inline">\((p_i, q_j)\)</span>, or <span class="math inline">\((p_i, p_j)\)</span>, or any other reasonable coordinate system.</p>
<p>If the thermodynamic system undergoes a cycle, then</p>
<p><span class="math display">\[0 = \oint dS = \oint p_i dq_i + \oint p_j dq_j\]</span></p>
<p>and thus, if we take the cycle infinitesimally small, we find that <span class="math inline">\(dp_i\wedge dq_i = -dp_j \wedge dq_j\)</span>. That is, the map <span class="math inline">\((p_i, q_i) \mapsto (p_j, q_j)\)</span> preserves areas, but reverses orientation. In particular, we have a Jacobian <span class="math display">\[
\frac{\partial(p_i, q_i)}{\partial(p_j, q_j)} = -1
\]</span></p>
<p>Now, let <span class="math inline">\((x, y)\)</span> be an arbitrary coordinate transform. By the chain rule for Jacobians, <span class="math display">\[
\frac{\partial(p_i, q_i)}{\partial(x, y)} = \frac{\partial(p_i, q_i)}{\partial(p_j, q_j)} \frac{\partial(p_j, q_j)}{\partial(x,y)} = -\frac{\partial(p_j, q_j)}{\partial(x,y)}
\]</span></p>
<p>This allows us to derive all the Maxwell relations. For example, setting <span class="math inline">\((x, y) = (p_i, q_j)\)</span> gives us the third relation</p>
<p><span class="math display">\[(\partial_{q_j} q_i)_{p_i} = -(\partial_{p_i}p_j)_{q_j}\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure" aria-labelledby="-caption">
<p><img src="figure/maxwell_relations_commutative_diagram.png" class="img-fluid figure-img"></p>

</figure>
</div>
</div>
</div>
</div>
<div id="-caption" class="margin-figure-caption column-margin callout-10-contents callout-collapse collapse show callout-margin-content">Deriving the four Maxwell relations by picking the right variables for (x, y).</div><p><img src="figure/banner/3.png" class="img-fluid"></p>
</section>
</section>
<section id="caratheodorys-thermodynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="caratheodorys-thermodynamics">Caratheodory’s thermodynamics</h2>
<p>In the early 1900s, Constantin Caratheodory discovered a new way to “geometrize” thermodynamics, with the austere beauty of Euclidean geometry. Though his formulation fell into obscurity, it was reborn in neoclassical economics as utility theory.</p>
<section id="entropy-and-temperature" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="entropy-and-temperature">Entropy and temperature</h3>
<p>Consider a thermodynamic system with <span class="math inline">\(n+1\)</span> dimensions of state space. Give the state space coordinates <span class="math inline">\(q_0, q_1, \dots, q_n\)</span>. For example, for a tank of ideal gas where the particle number is fixed, we have <span class="math inline">\(q_0 = U, q_1 = V\)</span>.</p>
<p>Let the system be at a certain state <span class="math inline">\(\vec q\)</span>, and wrap the system in a perfectly insulating (adiathermal) blanket. The system can undergo many different kinds of adiathermal motion, but there are certain motions that it cannot undergo.</p>
<p>For example, for a piston of ideal gas, the possible motions are adiabatic expansion, adiabatic compression, Joule expansion, and any combination of them. However, “Joule compression” is impossible – the gas will not spontaneously contract to the left half of the system, pulling in the piston head, anymore than a messy room will spontaneously tidy itself.</p>
<p>We say that <span class="math inline">\(\vec q'\)</span> is adiathermally accessible from <span class="math inline">\(\vec q\)</span> if there exists a path from <span class="math inline">\(\vec q\)</span> to <span class="math inline">\(\vec q'\)</span>, such that the path is infinitesimally adiathermal<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> at every point.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;The word “adiathermal” means “heat does not pass through”, while “adiabatic” has an entire history of meaning that makes it hard to say what exactly it is (see <a href="https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/">my essay on Analytical Mechanics</a>). Personally, I think “adiabatic” means “zero entropy change”, and all its other meanings derive from it.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/adiabatic_accessibility.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Adiabatic accessibility in the <span class="math inline">\(U, V\)</span> diagram.</figcaption>
</figure>
</div>
<p>Here is <strong>Caratheodory’s version of the second law of thermodynamics</strong>:</p>
<ul>
<li>In any neighborhood of any point <span class="math inline">\(\vec q\)</span>, there are points adiabatically inaccessible from it.</li>
<li>Furthermore, for any two points, <span class="math inline">\(\vec q, \vec q'\)</span>, at least one of them is adiabatically accessible from the other.</li>
</ul>
<p>The effect of these two axioms is that we can define a total ordering <span class="math inline">\(\preceq\)</span> on state space, where we write <span class="math inline">\(\vec q \preceq \vec q'\)</span> to mean that <span class="math inline">\(\vec q\)</span> can adiabatically access <span class="math inline">\(\vec q'\)</span>, and write <span class="math inline">\(\vec q \sim \vec q'\)</span> to mean that they are mutually adiabatically accessible.</p>
<p>Interpreted economically, we say that the system is an economic agent, that each <span class="math inline">\(\vec q\)</span> is a bundle of goods, that <span class="math inline">\(\vec q \preceq \vec q'\)</span> means that <span class="math inline">\(\vec q'\)</span> is preferable to the agent, and that <span class="math inline">\(\vec q \sim \vec q'\)</span> means they are equally preferred.</p>
<p>The total ordering partitions the state space into contour surfaces of equal accessibility, or <a href="https://en.wikipedia.org/wiki/Indifference_curve">indifference surfaces</a>. Assuming the state space is not designed to be <a href="https://en.wikipedia.org/wiki/Pathological_(mathematics)">pathological</a>, these indifference surfaces will be differentiable.</p>
<p>Let us consider the indifference surface passing state <span class="math inline">\(\vec q\)</span>. The indifference surface is locally a plane, so it has equations</p>
<p><span class="math display">\[
dq_0 - \sum_i \tilde p_i dq_i = 0
\]</span></p>
<p>where <span class="math inline">\(\tilde p_i = (\partial_{q_i}q_0)_{q_1, \dots, q_n}\)</span>. For example, a tank of (non-ideal) gas satisfies <span class="math inline">\(dU + PdV = 0\)</span> over its indifference curves.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/contact_geometry_one-form.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The field of planes defined by <span class="math inline">\(dq_0 - \sum_i \tilde p_i dq_i = 0\)</span>.</figcaption>
</figure>
</div>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9 (existence and uniqueness of temperature and entropy)</strong></span> Let <span class="math inline">\(\omega = dq_0 - \sum_i \tilde p_i dq_i\)</span>. If <span class="math inline">\(\omega\)</span> is nonzero everywhere, then there exists functions <span class="math inline">\(\beta, S\)</span> on the state space, such that <span class="math inline">\(dS = \beta \omega\)</span>.</p>
<p>Furthermore, they are unique up to a monotonic transform. That is, if we have another solution <span class="math inline">\(\beta', S'\)</span>, then there exists a strictly monotonic function <span class="math inline">\(f\)</span> such that <span class="math inline">\(S' = f \circ S\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
</div>
<div class="callout-body-container callout-body">
<p>At each point <span class="math inline">\(P\)</span> the one-form <span class="math inline">\(\omega(p)\)</span> is visualized as a stack of parallel planes. The planes are quilted together, but with “uneven thickness”. By scaling the one-forms just right at every point, the thickness becomes equalized, and so <span class="math inline">\(\beta \omega = dg\)</span> for two real-valued functions <span class="math inline">\(\beta, S\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure" aria-labelledby="-caption">
<p><img src="figure/Caratheodory_s_theorem_illustration.jpg" class="img-fluid figure-img" style="width:100.0%"></p>

</figure>
</div>
<p>Given any other solution <span class="math inline">\(\beta', S'\)</span>, both <span class="math inline">\(S\)</span> and <span class="math inline">\(S'\)</span> must have the same contour lines, so there exists some function that maps the <span class="math inline">\(S\)</span>-height of a contour line to its <span class="math inline">\(S'\)</span>-height.</p>
</div>
</div>
<div id="-caption" class="margin-figure-caption column-margin callout-margin-content">Proving Caratheodory’s theorem. Figure from .</div></section>
<section id="cardinal-and-ordinal-utilities" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="cardinal-and-ordinal-utilities">Cardinal and ordinal utilities</h3>
<p>Economically speaking, <span class="math inline">\(\tilde p_i\)</span> is the marginal worth of <span class="math inline">\(q_i\)</span> denoted in units of <span class="math inline">\(q_0\)</span>. For example, we can say that <span class="math inline">\(q_0\)</span> are cowry shells, which themselves are pretty and give us some utility. However, it can also be used as a monetary unit. Then, if <span class="math inline">\(i\)</span> is bread, then <span class="math inline">\(\tilde p_i\)</span> is the marginal amount of cowry shells that we would pay for a marginal amount of bread.</p>
<p>If we were to visit a free market where we can buy and sell items denoted in cowry shells, then we would buy bread if <span class="math inline">\(\tilde p_i &gt; \tilde p_{i, market}\)</span>, and sell bread if <span class="math inline">\(\tilde p_i &lt; \tilde p_{i, market}\)</span>. Right at the border of <span class="math inline">\(\tilde p_i = \tilde p_{i, market}\)</span>, we would be indifferent about buying or selling bread. When <span class="math inline">\(\tilde p_i = \tilde p_{i, market}\)</span> for all <span class="math inline">\(i\)</span>, we would be completely indifferent about the market.</p>
<p><span class="math inline">\(S\)</span> is the utility, and <span class="math inline">\(\beta\)</span> is the marginal utility of cowry shells. The theorem tells us that just by knowing how we <em>order</em> the goods (” <span class="math inline">\(S(\vec q) &gt; S(\vec q')\)</span> “), we can extract a <em>numerical value</em> for the goods (” <span class="math inline">\(S(\vec q) - S(\vec q') = 1.34(S(\vec q'') - S(\vec q'''))\)</span> “). Out of <em>ordinal utility</em>, we have achieved <em>cardinal utility</em>.</p>
<p>There used to be a debate between “ordinalists” and “cardinalists” of utility theory. The “cardinalists” were the more venerable of the two camps, tracing back to Bentham’s felicific calculus and the marginalist revolution. They argued that utility is real-valued, like entropy and temperature. The “ordinalists” countered that a nobody has ever measured a utility in anyone’s brain. The only thing we can observe is preferences: I prefer this over that – I can <em>order</em> everything that can ever happen to me on a <em>numberless</em> line of preferences. Similarly, nobody can ever actually measure temperature or entropy, only that energy flows from this gas to that gas, which presumably has lower temperature, and that one chunk of gas in one state ends up in another state, which presumably has higher entropy.</p>
<p>The debate has been mostly resolved by the work of <a href="https://en.wikipedia.org/wiki/G%C3%A9rard_Debreu">Gérard Debreu</a>, who showed that under fairly reasonable assumptions, cardinal utility is possible <span class="citation" data-cites="debreuTheoryValueAxiomatic1971">(<a href="#ref-debreuTheoryValueAxiomatic1971" role="doc-biblioref">Debreu 1971</a>)</span>.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Out of all those famous economists I have seen, Gérard Debreu is perhaps the most mathematically austere. Reading his works, I felt like he was another G. H. Hardy, a Bourbaki of economics. He did economics not to improve the world, not to help people, and not to advance a political agenda, but to simply uncover an ꙮmmatidium of eternity.</p></div></div><p>This theorem, or rather, this <em>family</em> of theorems, have several names, as befitting for such a versatile and productive family. In calculus, it’s called the <a href="https://en.wikipedia.org/wiki/Integrability_conditions_for_differential_systems">integrability of Pfaffian forms</a>. In differential geometry, it’s called <a href="https://en.wikipedia.org/wiki/Darboux%27s_theorem">Darboux’s theorem</a>, or <a href="https://en.wikipedia.org/wiki/Frobenius_theorem_(differential_topology)">Frobenius theorem</a>. In economics, it’s called the integrability of demand, or the cardinal-ordinal <a href="https://en.wikipedia.org/wiki/Utility_representation_theorem">utility representation theorem</a>.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="What's so special about energy, or cowry shells?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What’s so special about energy, or cowry shells?
</div>
</div>
<div class="callout-body-container callout-body">
<p>When cast in the language of economics, cowry shells are not special. We could denote prices in cowry shells, or cans of sardine, or grams of gold. That is, we are free to pick any numéraire we want, as long as we are consistent about it.</p>
<p>Similarly, energy is not special. For example, with ideal gas, we could write the first law of thermodynamics as the conservation of energy, like</p>
<p><span class="math display">\[dU - (-P)dV = \beta^{-1}dS\]</span></p>
<p>or as the conservation of volume, like</p>
<p><span class="math display">\[dV - (-P^{-1})dU= (\beta P)^{-1}dS\]</span></p>
<p>and from the perspective of classical thermodynamics, there is <em>no</em> possibility of saying that energy is <em>more special</em> than volume. Energy is exactly as special as volume, and no more special than that.</p>
<p>When I realized this difference, I was so incensed at this mistake that I wrote an entire <a href="#sec-stereodynamics">sci-fi worldbuilding sketch</a> about an alien species, for which it is the conservation of volume that is fundamental, not energy, and which discovered stereodynamics, not thermodynamics.</p>
</div>
</div>
</section>
<section id="extensive-entropy" class="level3">
<h3 class="anchored" data-anchor-id="extensive-entropy">Extensive entropy</h3>
<p>While we have constructed the temperature <span class="math inline">\(T\)</span> and the entropy <span class="math inline">\(S\)</span> of an isolated system, it is not unique: we can stretch and compress the entropy function <span class="math inline">\(S\)</span> arbitrarily by a monotonic function, and as long as we modify the temperature function <span class="math inline">\(T\)</span> just right, the two modifications cancel out, and we have <span class="math inline">\(TdS = T' dS'\)</span>.</p>
<p>In order to uniquely fix an entropy function, we need further assumptions. The most commonly used method is by considering what happens to the entropy of a compound system. In general, there is no reason to expect entropy to be extensive – if we take compound two systems together, the entropy of the compound system should be the sum of the two subsystems. However, if we make some assumptions on “rationality”, then the entropy would be uniquely fixed, and would be extensive.</p>
<div id="exr-0" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5 (von Neumann–Morgenstern entropy construction)</strong></span> Study the statement of the <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem">von Neumann–Morgenstern utility theorem</a>, and translate it to thermodynamics. It should be of the following form:</p>
<p>Assuming that the adiabatic accessibility of any compound system satisfies the following properties</p>
<ol type="1">
<li>…</li>
<li>…<br>
…</li>
</ol>
<p>then the entropy of any compound system is the sum of the entropies of its subsystems, and the entropy function is unique up to adding a constant and multiplying by a positive scalar.</p>
</div>
<p>Some hints:</p>
<ul>
<li>It might help your intuition if you anthropomorphize Nature as a “vNM-rational agent”.</li>
<li>The standard formulation of the vNM theorem uses lotteries of form <span class="math inline">\(pM + (1-p)N\)</span>, where <span class="math inline">\(p\in (0, 1)\)</span> is a probability, and <span class="math inline">\(M, N\)</span> are bundles of goods. However, it is impossible generally to “take <span class="math inline">\(0.37\)</span> of a system <span class="math inline">\(M\)</span> and compound it with <span class="math inline">\(0.63\)</span> of system <span class="math inline">\(N\)</span>”. To bypass this difficulty, replace that with “take <span class="math inline">\(37\)</span> copies of system <span class="math inline">\(M\)</span> and compound them with <span class="math inline">\(63\)</span> copies of system <span class="math inline">\(N\)</span>”.</li>
</ul>
<p><img src="figure/banner/5.png" class="img-fluid"></p>
</section>
</section>
<section id="bonus-geometric-thermodynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="bonus-geometric-thermodynamics">Bonus: Geometric thermodynamics</h2>
<blockquote class="blockquote">
<p>Although geometrical representations of propositions in the thermodynamics of fluids are in general use, and have done good service in disseminating clear notions in this science, yet they have by no means received the extension in respect to variety and generality of which they are capable.</p>
<p><span class="citation" data-cites="gibbsGraphicalMethodsThermodynamics1957">(<a href="#ref-gibbsGraphicalMethodsThermodynamics1957" role="doc-biblioref">Gibbs 1957</a>)</span></p>
</blockquote>
<section id="contact-geometry" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="contact-geometry">Contact geometry</h3>
<blockquote class="blockquote">
<p>Every mathematician knows it is impossible to understand an elementary course in thermodynamics. The reason is that thermodynamics is based—as Gibbs has explicitly proclaimed – on a rather complicated mathematical theory, on the contact geometry. Contact geometry is one of the few ‘simple geometries’ of the so-called Cartan’s list, but it is still mostly unknown to the physicist – unlike the Riemannian geometry and the symplectic or Poisson geometries, whose fundamental role in physics is today generally accepted.</p>
<p>V.I. Arnol’d <span class="citation" data-cites="caldiProceedingsGibbsSymposium1990">(<a href="#ref-caldiProceedingsGibbsSymposium1990" role="doc-biblioref">Caldi et al. 1990, 163</a>)</span></p>
</blockquote>
<p>To explain this mysterious remark, we take a plunge into abstraction. We know that a real gas has properties <span class="math inline">\(P, V, T, S, \dots\)</span>, and that they satisfy the differential equation:</p>
<p><span class="math display">\[
dS = \beta dU + \beta PdV
\]</span></p>
<p>To clean up the notation, we can change the notation to</p>
<p><span class="math display">\[
dS = p_1 dq_1 + p_2 dq_2
\]</span></p>
<p>This formula has a clear interpretation in economics: if the marginal utility of commodity <span class="math inline">\(1\)</span> is <span class="math inline">\(p_1\)</span>, and the marginal utility of commodity <span class="math inline">\(2\)</span> is <span class="math inline">\(p_2\)</span>, then if we receive <span class="math inline">\(\delta q_1, \delta q_2\)</span>, our utility would increase by <span class="math inline">\(p_1 \delta q_1 + p_2 \delta q_2\)</span>.</p>
<p>The difficult thing about classical thermodynamics is that there are so many quantities, such as <span class="math inline">\(T, V, N, \dots\)</span>. The saving grace is that it turns out that there are only a few degrees of freedom.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;The Parthian shot is that now you are burdened with dozens of equations relating these quantities. I cannot remember any of the Maxwell relations, so I look at Wikipedia every time I need to calculate with them.</p></div></div><p>However, why is it that a macroscopic lump of matter, whirling with <span class="math inline">\(10^{23}\)</span> molecules, turn out to be characterized by only a few degrees of freedom? Why is it that a national economy, swarming with <span class="math inline">\(10^8\)</span> people, has macroeconomic laws? For the first question, the answer is given by classical thermodynamics: the lump of matter is maximizing its entropy under constraints, so its degrees of freedom are exactly as many as the number of constraints it is laboring under. For the second question, the answer is given by neoclassical economics: the national economy behaves as if it is maximizing a social utility function under its resource constraints.</p>
<p>With that brief look at philosophy, we return to abstract thermodynamics. We have a lump of matter (such as ideal gas in a piston), of which we can measure five different properties: <span class="math inline">\(p_1, p_2, q_1, q_2, S\)</span>. In general, we expect that the space of possible measurements is 5-dimensional, but it turns out that they collapse down to a 2-dimensional curved surface. This is why we could completely fix its state knowing just its <span class="math inline">\(V, U\)</span>, or just its <span class="math inline">\(P, T\)</span>, etc.</p>
<p>The question now arises: Why is it possible to collapse things down to this curved surface?</p>
<p>Things are already interesting when we have just one commodity:</p>
<p><span class="math display">\[dS - pdq = 0\]</span></p>
<p>and we ask: Why is it possible to collapse the space of <span class="math inline">\((q, p, S)\)</span> from 3 to 1 dimension?</p>
<p>In modern geometry, an expression like <span class="math inline">\(dS - \sum_i p_i dq_i = 0\)</span> defines a field of planes in <span class="math inline">\(\mathbb{R}^3\)</span>. That is, at each point <span class="math inline">\((q, p, S)\)</span>, we construct a plane defined by</p>
<p><span class="math display">\[
\{(q + \delta q, p + \delta p, S + \delta S): \delta S - p \delta q = 0\}
\]</span></p>
<p>For example, in three dimensions, the field of planes <span class="math inline">\(dS - pdq = 0\)</span> would look like it is constantly twisting as <span class="math inline">\(p\)</span> increases. The study of geometric structures definable via the field of planes is <a href="https://en.wikipedia.org/wiki/Contact_geometry">contact geometry</a>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;This explanation might sound like an anticlimax, and I imagine someone would object “Thermodynamics is reduced to contact geometry… but what is contact geometry?”. My answer is that contact geometry simply <em>is</em>. It is not supposed to be a generator of intuitions. Instead, it is a common language that bridges between intuitions. By casting thermodynamics, economics, mechanics, etc, into the language of contact geometry, we would then be able to translate intuition from one field to another field. Saying that “thermodynamics is contact geometry” is not telling you an intuitive way to see thermodynamics, but rather, an intuitive way to see contact geometry.</p></div></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/standard_contact_structure.svg" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The field of planes <span class="math inline">\(dS - pdq = 0\)</span> in <span class="math inline">\(\mathbb{R}^{2+1}\)</span>. Figure from <a href="https://en.wikipedia.org/wiki/File:Standard_contact_structure.svg">Wikipedia</a>.</figcaption>
</figure>
</div>
<p>Given such a field of planes <span class="math inline">\(dS - \sum_{i=1}^n p_i dq_i\)</span> in <span class="math inline">\(\mathbb{R}^{2n+1}\)</span>, we say that a manifold is a <strong>Legendrian submanifold</strong> iff the manifold has <span class="math inline">\(n\)</span> dimensions, and is tangent to the field of planes at every point.</p>
<p>For example, when <span class="math inline">\(n=1\)</span>, a Legendrian submanifold is a curve that winds around <span class="math inline">\(\mathbb{R}^3\)</span> and is always tangent to the plane at every moment.</p>
<p>Let <span class="math inline">\(S(q)\)</span> be a differentiable function. We can interpret <span class="math inline">\(S(q)\)</span> as the amount of money we can earn if we produce something using the bundle of raw materials <span class="math inline">\((q_1, \dots, q_n)\)</span>.</p>
<p>Given any market price for the raw materials, <span class="math inline">\(q^* = \mathop{\mathrm{argmax}}_q (S(q) - \braket{p, q})\)</span> is the profit-maximizing production plan, and <span class="math inline">\(\Pi(p) = \max_q (S(q) - \braket{p, q})\)</span> is the profit.</p>
<div id="thm-profit-maximization-legendrian-manifold" class="theorem">
<p><span class="theorem-title"><strong>Theorem 10</strong></span> The “profit-maximization surface” defined by <span class="math inline">\(p \mapsto (q^*, p, S(q^*))\)</span> is a Legendrian submanifold.</p>
<p>Conversely, given any Legendrian submanifold parameterized by <span class="math inline">\(p \mapsto (q(p), p, S(q(p)) )\)</span>, then <span class="math inline">\(q(p)\)</span> is profit-stationarizing. That is,</p>
<p><span class="math display">\[\nabla_q (S(q) - \braket{p, q}) = 0\]</span></p>
<p>at <span class="math inline">\(q(p)\)</span>. If <span class="math inline">\(S\)</span> is strictly concave, then <span class="math inline">\(q(p)\)</span> is profit-maximizing.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
</div>
<div class="callout-body-container callout-body">
<p>The first part is proven by Hotelling’s lemma.</p>
<p>The second part is proven by plugging in <span class="math inline">\(dS - \sum_i p_i dq_i = 0\)</span>. And if <span class="math inline">\(S\)</span> is strictly concave, then <span class="math inline">\(q \mapsto S(q) - \braket{p, q}\)</span> is also strictly concave, and so zero gradient implies global maximum.</p>
</div>
</div>
<p>Economically speaking, <span class="math inline">\(\max_q (S(q) - \braket{p, q})\)</span> means to maximize profit. What does it mean, thermodynamically speaking? It means minimizing <span class="math inline">\(\braket{p, q} - S(q)\)</span>, which is the Gibbs free entropy! Maximizing profit when a factory has access to a market is the same as minimizing Gibbs free entropy when a system is in contact with a bath.</p>
</section>
<section id="samuelsons-area-ratio-thermodynamics" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="samuelsons-area-ratio-thermodynamics">Samuelson’s area-ratio thermodynamics</h3>
<section id="philosophy" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="philosophy">Philosophy</h4>
<p>In Paul Samuelson’s Nobel prize lecture of 1970, among comments of classical mechanics, variational principles, and neoclassical economics, he said something curious about the analogy between classical thermodynamics and neoclassical economics:</p>
<blockquote class="blockquote">
<p>However, if you look upon the monopolistic firm hiring 99 inputs as an example of a maximum system, you can connect up its structural relations with those that prevail for an entropy-maximizing thermodynamic system. Pressure and volume, and for that matter absolute temperature and entropy, have to each other the same conjugate or dualistic relation that the wage rate has to labor or the land rent has to acres of land. Figure 2 can now do double duty, depicting the economic relationships as well as the thermodynamic ones.</p>
<p>If someone challenged me to explain what the existence of [utility] implies, but refused to let me use the language of partial derivatives, I could illustrate by an equi-proportional area property… I may say that the idea for this proposition in economics came to me in connection with some amateurish researches in the field of thermodynamics. While reading Clerk Maxwell’s charming introduction to thermodynamics…</p>
<p><span class="citation" data-cites="samuelsonMaximumPrinciplesAnalytical1971">(<a href="#ref-samuelsonMaximumPrinciplesAnalytical1971" role="doc-biblioref">Samuelson 1971</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Samuelson_area_ratio_condition.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Samuelson’s equal area ratio condition. In the diagram, we have <span class="math inline">\(a:b = c:d\)</span></figcaption>
</figure>
</div>
<p>This intriguing little remark piqued my interest, and after a little digging, I figured it out.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;Based on research by James Bell Cooper, who seems to be the world expert in this obscure field <span class="citation" data-cites="cooperSurprisingUbiquitySamuelson2006 cooperCharacterizingAreaCondition2001">(<a href="#ref-cooperSurprisingUbiquitySamuelson2006" role="doc-biblioref">Cooper and Russell 2006</a>; <a href="#ref-cooperCharacterizingAreaCondition2001" role="doc-biblioref">Cooper, Russell, and Samuelson 2001</a>)</span>.</p></div></div><p>Samuelson is alluding to a deep problem in economics theory: Nobody has ever seen a utility function, anymore than anybody has ever seen an entropy. If this is the case, then how do we know that agents are maximizing a utility, or that systems are maximizing an entropy? In his long career, he searched for many ways to answer this, coming down to the idea that, even though we cannot measure utility, we can measure many things, such as how firms respond to prices. Given some measurable quantities, we can then prove, mathematically, that something is being maximized. At that point, we can simply call that something “utility”, and continue doing economics as usual.</p>
<p>Philosophically, Samuelson was greatly influenced by <a href="https://plato.stanford.edu/entries/operationalism/">operationalism</a>, a philosophy of science akin to <a href="https://plato.stanford.edu/entries/logical-empiricism/">logical positivism</a>. As stated by the definitive work on operationalism, “we mean by any concept nothing more than a set of operations; the concept is synonymous with the corresponding set of operations” <span class="citation" data-cites="bridgmanLogicModernPhysics1927">(<a href="#ref-bridgmanLogicModernPhysics1927" role="doc-biblioref">Bridgman 1927</a>)</span>.</p>
<p>In his early work, particularly <em>Foundations of Economic Analysis</em> (1947) and the development of revealed preference theory (1938), Samuelson embraced operationalism as a means of purging economics of non-observable, and thus scientifically meaningless, concepts like utility. He sought to rebase economic theory on purely observable behavior and measurable quantities. Revealed preference theory, for instance, would eliminate utility functions, and derive a consumer’s preference ordering directly from observable consumer choices at different price levels.</p>
<p>Over time, Samuelson’s stance on operationalism softened to a more pragmatic approach, recognizing the value of unobservable concepts as theoretical tools, as long as they can be based on direct observables.</p>
<p>For example, while Samuelson initially sought to eliminate utility functions, he later argued that even if utility is not directly observable, it can be uniquely determined from observing agents’ preferences, by invoking some <a href="https://en.wikipedia.org/wiki/Utility_representation_theorem">utility representation theorems</a> – provided that the preferences satisfy certain properties. <span class="citation" data-cites="samuelsonMyLifePhilosophy1999">(<a href="#ref-samuelsonMyLifePhilosophy1999" role="doc-biblioref">Samuelson 1999</a>)</span></p>
</section>
<section id="area-ratio-construction" class="level4">
<h4 class="anchored" data-anchor-id="area-ratio-construction">Area ratio construction</h4>
<div id="thm-area-ratio" class="theorem">
<p><span class="theorem-title"><strong>Theorem 11 (area ratio law implies a new coordinate system)</strong></span> Consider an open rectangle <span class="math inline">\(R\)</span> in the plane <span class="math inline">\(\mathbb{R}^2\)</span>. Let there be two families of curves</p>
<p>Suppose that each curvy parallelogram formed by the two families is contained in <span class="math inline">\(R\)</span>, and the curves satisfy the area-ratio rule, then we can define another coordinate system <span class="math inline">\((z, w)\)</span> on <span class="math inline">\(\mathbb{R}^2\)</span>, such that the coordinate system preserves areas: <span class="math display">\[
dx \wedge dy = dz \wedge dw
\]</span></p>
<p>and that the two families of lines are the constant <span class="math inline">\(z\)</span> and constant <span class="math inline">\(w\)</span> curves.</p>
<p>The coordinate system is unique up to an affine squashing transform, that is, <span class="math inline">\((z, w) \mapsto (cz + d, w/c + e)\)</span> for some constants <span class="math inline">\(c, d, e\)</span> with <span class="math inline">\(c \neq 0\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Fix an arbitrary point as <span class="math inline">\((z, w) = (0, 0)\)</span>. Pick an arbitrary curve in one of the families, not passing <span class="math inline">\((0, 0)\)</span> point, and call it the <span class="math inline">\(w=1\)</span> line. By continuity, there exists a unique curve in the other family, such that their curved parallelogram has unit area. Call that other curve the <span class="math inline">\(z=1\)</span> line. Now we can label its four corners as <span class="math inline">\((z, w) = (0, 0), (0, 1), (1, 0), (1, 1)\)</span>.</p>
<p>For any other point, its <span class="math inline">\((z, w)\)</span> coordinates can be constructed as shown in the picture, with</p>
<p><span class="math display">\[z = a+b, \quad w = b+d\]</span></p>
<p>By the area ratio law, we have <span class="math inline">\(a:b = c:d\)</span>. We also have <span class="math inline">\(a+b+c+d = 1\)</span> since we picked the parallelogram to have unit area. Solving these 4 equations, we find that <span class="math inline">\(b = zw, a = z(1-w), d = (1-z)w, c = (1-z)(1-w)\)</span>, as it should.</p>
<p>Taking the derivative, we have <span class="math inline">\(dx \wedge dy = dz \wedge dw\)</span>.</p>
<p><img src="figure/Samuelson_geometry_coordinate_construction.png" class="img-fluid"></p>
</div>
</div>
</div>
<div id="cor-0" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 1 (area ratio law implies existence of an entropy function)</strong></span> Since <span class="math inline">\(dx \wedge dy = dz \wedge dw\)</span>, we can draw any cycle <span class="math inline">\(\gamma\)</span>, and integrate around the cycle: <span class="math display">\[\oint_\gamma (ydx + zdw) = \iint_{\text{area in }\gamma} (dy \wedge dx + dz \wedge dw) = 0\]</span></p>
<p>Thus, there exists some scalar function <span class="math inline">\(S\)</span>, such that <span class="math inline">\(dS = ydx + zdw\)</span>.</p>
</div>
<p>And with an entropy/utility function, all of classical thermodynamics/neoclassical economics follow.</p>
</section>
<section id="example-ideal-gas" class="level4">
<h4 class="anchored" data-anchor-id="example-ideal-gas">Example: ideal gas</h4>
<p>Suppose we know from experiment that a tank of ideal gas satisfies two equations</p>
<p><span class="math display">\[PV = \Const, \quad PV^\gamma = \Const\]</span></p>
<p>under isothermal and adiabatic conditions respectively, then the <span class="math inline">\(P, V\)</span> diagram with these two families of curves satisfy the area ratio condition. It is tedious but straightforward to verify this by direct integration. Alternatively, we can use the <a href="https://en.wikipedia.org/wiki/Method_of_exhaustion">method of exhaustion</a> and <a href="https://en.wikipedia.org/wiki/Eudoxus_of_Cnidus">Eudoxus’ theory of proportions</a> to prove this, in a way that even ancient Greeks would approve.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Notice that under the squashing map <span class="math inline">\((P, V) \mapsto (cP, V/c)\)</span>, both families of lines are preserved, and furthermore, this map preserves area, so we can calculate the area of any curvy parallelogram by tiling it with tiny strips of thin parallelograms.</p>
<p>As shown, we can draw a very thin parallelogram <span class="math inline">\(\delta\)</span>, then use the squashing map to tile both parallelograms <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>. We have that</p>
<p><span class="math display">\[A(c) : A(d) = \frac{A(c)}{A(\delta)} : \frac{A(d)}{A(\delta)} \approx N(c) : N(d)\]</span></p>
<p>where <span class="math inline">\(A(c)\)</span> is the area of <span class="math inline">\(c\)</span>, and <span class="math inline">\(N(c)\)</span> is the number of copies of <span class="math inline">\(\delta\)</span> that are contained within <span class="math inline">\(c\)</span>. By the method of exhaustion and Eudoxus’ theory of proportion, at the limit of infinitely thin <span class="math inline">\(\delta\)</span>, both sides are equal.</p>
<p>Now, performing the same construction on the other half of the parallelograms, we tile <span class="math inline">\(a, b\)</span> by the same number of copies of <span class="math inline">\(\delta'\)</span>. Thus we have</p>
<p><span class="math display">\[A(c) : A(d) \approx N(c) : N(d) = N(a) : N(b) \approx A(a) : A(b)\]</span></p>
<p>and both sides equal at the limit.</p>
<p><img src="figure/Samuelson_geometry_Eudoxus_proof.png" class="img-fluid"></p>
</div>
</div>
</div>
<p>Now, by the <a href="#thm-area-ratio">area ratio construction</a>, there exist two functions <span class="math inline">\(f_T, f_S\)</span>, such that the new coordinates</p>
<p><span class="math display">\[T(P, V) = f_T(PV), \quad S(P, V) = f_S(PV^\gamma)\]</span></p>
<p>satisfy <span class="math inline">\(dT \wedge dS = dP \wedge dV\)</span>. We can then define</p>
<p><span class="math display">\[dU = TdS - PdV\]</span></p>
<p>which satisfies <span class="math inline">\(d^2 U = 0\)</span>, that is, it is integrable.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Derivation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Derivation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Simplifying, we get</p>
<p><span class="math display">\[f'_T(PV)f_S'(PV^\gamma) = \frac{1}{(\gamma - 1) PV^\gamma}\]</span></p>
<p>Let <span class="math inline">\(x = PV, y = PV^\gamma\)</span> to separate the variables: <span class="math inline">\(f'_T(x) f'_S(y) = \frac{1}{(\gamma-1) y}\)</span>, which solves to</p>
<p><span class="math display">\[T = C_1 PV + C_0, \quad S = \frac{1}{(\gamma-1) C_1} \ln \frac{PV^\gamma}{P_0V_0^\gamma}\]</span></p>
<p>for some constants <span class="math inline">\(C_0, C_1, P_0, P_0\)</span>.</p>
<p>Knowing that <span class="math inline">\(C_0 = 0\)</span> and <span class="math inline">\(C_1 = 1/(nR)\)</span>, we have the equations of state: <span class="math display">\[PV = nRT, \quad S = \frac{1}{\gamma-1} nR \ln \frac{PV^\gamma}{P_0V_0^\gamma}\]</span></p>
<p>Integrating <span class="math inline">\(dU = TdS - PdV\)</span>, we have <span class="math inline">\(U = \frac{1}{\gamma-1} nRT\)</span>. We can define <span class="math inline">\(\hat c_V = \frac{1}{\gamma - 1}\)</span>, which leads to</p>
<p><span class="math display">\[PV = nRT, \quad S = \hat c_V n R \ln \frac{PV^{1 + 1/\hat c_V}}{P_0V_0^{1 + 1/\hat c_V}}, \quad U = \hat c_V nRT\]</span></p>
<p>or equivalently, <span class="math inline">\(S = n R \ln \frac{U^{\hat c_V}V}{U_0^{\hat c_V} V_0}\)</span>.</p>
</div>
</div>
</div>
<p>Thus, we have</p>
<p><span class="math display">\[PV = nRT, \quad S = \hat c_V n R \ln \frac{PV^{1 + 1/\hat c_V}}{P_0V_0^{1 + 1/\hat c_V}} = n R \ln \frac{U^{\hat c_V}V}{U_0^{\hat c_V} V_0}, \quad U = \hat c_V nRT\]</span></p>
<p>Taking the derivative, <span class="math inline">\(dS = \beta dU + \beta PdV - \beta \mu dn\)</span> gives <span class="math inline">\(\beta = 1/T\)</span>, <span class="math inline">\(P = P\)</span>, and <span class="math inline">\(\mu = -TS/n\)</span>.</p>
<p>We find that the chemical potential, unfortunately, has an additive constant. We should not be too surprised, however, as anything with “potential” in its name probably has an additive constant, like electric voltage.</p>
</section>
<section id="economic-interpretation" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="economic-interpretation">Economic interpretation</h4>
<p>When the diagram is interpreted as the thermodynamic diagram of a gas, we know what the curvy lines mean: they are the isotherms, isentropics, isobarics, etc (depending on which variables you pick for the two axes of the diagram). What do the curvy lines mean in economics?</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Samuelson_area_ratio_condition.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The equal area ratio condition.</figcaption>
</figure>
</div>
<p>Suppose we plot the lines of constant <span class="math inline">\(p_2\)</span> in the plane of <span class="math inline">\(q_1, p_1\)</span>. What does it say? It says this: “Suppose the price of commodity <span class="math inline">\(2\)</span> is fixed, and we vary the price of commodity <span class="math inline">\(1\)</span>. How much of commodity <span class="math inline">\(1\)</span>, as a factory manager, would I want to purchase?” In other words, these are the demand curves for commodity <span class="math inline">\(1\)</span> when the price of commodity <span class="math inline">\(2\)</span> is fixed.</p>
<p>Similarly, a line of constant <span class="math inline">\(q_2\)</span> is a demand curve for commodity <span class="math inline">\(1\)</span> when the <em>quantity</em> of commodity <span class="math inline">\(2\)</span> is fixed at <span class="math inline">\(q_2\)</span>.</p>
<p>Looking at the diagram, we see that the demand curves are steeper for fixed <span class="math inline">\(q_2\)</span> than for fixed <span class="math inline">\(p_2\)</span>. In other words, the factory manager is more price-sensitive about commodity <span class="math inline">\(1\)</span> when there is a free market for commodity <span class="math inline">\(2\)</span>, because there is a choice.</p>
<p>To be concrete, think of managing a factory, where the two commodities are labor and machinery. Think like a factory manager. If I have no choice in how many machines I have in my factory, then faced with a sudden rise in wages, I would only fire a few workers. If, however, there is a free market for machines, then I would fire more workers and buy some machines to make up for it.</p>
<p>This is Le Chatlier’s principle for economics, which Paul Samuelson used to great effect. In his telling, immediately after the market has suffered a sudden price shock, factories would have to suffer the consequences because they cannot react by changing their production plans. Thus, in the short run, factories are less price-sensitive. In the long run, the factories would be able to change their production plans, and so in the long run, factories are more price-sensitive. As another application, during a wartime economy when there is rationing for some critical products like rubber and oil, people would become less price-sensitive in the products not subjected to rationing.</p>
<p>This result can be generalized to the case of <span class="math inline">\(n\)</span> commodities <span class="math inline">\(q_1, \dots, q_n\)</span> with prices <span class="math inline">\(p_1, \dots, p_n\)</span>. In this case, we would find that, assuming some more complicated area ratio law, we can rescale <span class="math inline">\(q_2, \dots, q_n\)</span> and <span class="math inline">\(p_2, \dots, p_n\)</span>, such that <span class="math inline">\(\sum_i dp_i \wedge dq_i = 0\)</span>. This then allows us to construct a function <span class="math inline">\(S\)</span>, such that</p>
<p><span class="math display">\[dS - \sum_i p_i dq_i = 0\]</span></p>
<p>which, by <a href="#thm-profit-maximization-legendrian-manifold" class="quarto-xref">Theorem&nbsp;10</a>, maximizes <em>like</em> an entropy, so <a href="https://en.wikipedia.org/wiki/Duck_test">it <em>is</em> an entropy</a>.</p>
</section>
</section>
<section id="bonus-riemannian-geometry" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="bonus-riemannian-geometry">Bonus: Riemannian geometry</h3>
<p>There are other ways to study the state space of thermodynamic systems by differential geometry. For example, since the entropy function is typically a strictly concave function of the extensive parameters, <span class="math inline">\(-\partial^2 S\)</span> is positive-definite. This is then a Riemannian metric on the state space.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> For more on this line of research, search “Ruppeiner geometry” and “Weinhold geometry” <span class="citation" data-cites="weinholdThermodynamicsGeometry1976 quevedoGeometrothermodynamics2007">(<a href="#ref-weinholdThermodynamicsGeometry1976" role="doc-biblioref">Weinhold 1976</a>; <a href="#ref-quevedoGeometrothermodynamics2007" role="doc-biblioref">Quevedo 2007</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;The only places where strict concavity fails are when <span class="math inline">\(S\)</span> is “bumped downwards”, which gives us a first-order phase transition, or has a flat region, which gives us a second-order phase transition. Away from regions of phase transition, we have a Riemannian geometry. In the regions of phase transitions, the geometry collapses into singularities, much as spacetime collapses in the center of a black hole.</p></div></div><p><img src="figure/banner/6.png" class="img-fluid"></p>
</section>
</section>
<section id="chemical-equilibrium-done-right" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="chemical-equilibrium-done-right">Chemical equilibrium done right</h2>
<p>Josiah Willard Gibbs was an otherworldly figure who thought of abstract surfaces in a 19th century America, where practical industry, not pure science, was celebrated. He was also famously obscure and could write the most convoluted sentences that defeated everyone, from <a href="https://en.wikipedia.org/wiki/Boltzmann">Boltzmann</a> to <a href="https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes">Jaynes</a> <span class="citation" data-cites="jaynesGibbsParadox1992">(<a href="#ref-jaynesGibbsParadox1992" role="doc-biblioref">Jaynes 1992</a>)</span>. When he was asked by his European translator to write a preface for the German translation of his thermodynamics book, he replied that he had already said everything he wanted to say about thermodynamics, so there was nothing to add. <span class="citation" data-cites="daisJosiahWillardGibbs2024">(<a href="#ref-daisJosiahWillardGibbs2024" role="doc-biblioref">Dais 2024</a>)</span></p>
<p>Gibbs wrote his <a href="https://en.wiktionary.org/wiki/hefty">hefty</a> <a href="https://en.wiktionary.org/wiki/Heft#German">Heft</a> on thermodynamics, <em>On the Equilibrium of Heterogeneous Substances</em> (1876), to answer one question: why are some “heterogeneous substances” in equilibrium, while others not? Why, when we drop a block of salt into pure water, does the block of salt become smaller, but after a while, it stops getting smaller? His answer was always the same: heterogeneous substances are in equilibrium precisely when the entropy of the total system is maximized under constraint.</p>
<p>Paul Samuelson was a decidedly worldly economist in a 20th century America, where economists were expected to dispense advice to presidents and contribute to the public discourse. Indeed, he did both, serving as an advisor to presidents Kennedy and Johnson, and publishing a <a href="https://en.wikipedia.org/wiki/Economics_(textbook)">best-selling textbook in economics</a>. Although unlike other worldly economists like Marx and Keynes, his economic achievements were highly mathematical.</p>
<p>Samuelson wrote his landmark book, <em>Foundations of Economic Analysis</em> (1947), to answer one question: Why are some economic systems in equilibrium, while others are not? Why, when we drop a block of agents into a market, do they buy and sell things, but after a while, they stop buying and selling? His answer was always the same: a crowd of economic agents is in equilibrium precisely when some parameter of the total economic system (which can be interpreted as utility, profit, etc, depending on context) is maximized under constraint.</p>
<section id="fixed-volume-and-temperature" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="fixed-volume-and-temperature">Fixed volume and temperature</h3>
<p>Let’s start with a simple example: the dimerization of nitrogen dioxide in a sealed tube.</p>
<p>The thermodynamic system is some <span class="math inline">\(NO_2\)</span> and <span class="math inline">\(N_2O_4\)</span>. The system is sealed in a glass tube of constant volume <span class="math inline">\(V\)</span>, bathing in a water-ice mixture of temperature <span class="math inline">\(T\)</span>.</p>
<p>The thermodynamic state of the system is fully known if we know the number of moles for each species: <span class="math inline">\(n_{NO_2}, n_{N_2O_4}\)</span>.</p>
<p>The system undergoes a single reaction: <span class="math inline">\(2 NO_2 \rightleftharpoons N_2O_4\)</span>.</p>
<p>Suppose we start the system at state <span class="math inline">\(n_{NO_2, 0}, n_{N_2O_4, 0}\)</span>. When does the system reach equilibrium? Since the system can exchange energy, but not volume, with the surrounding bath, it reaches equilibrium when the system reaches minimal Helmholtz free energy under constraint: <span class="math display">\[
\begin{cases}
\min_{n_{NO_2}, n_{N_2 O_4}} F(T, V, n_{NO_2}, n_{N_2O_4})\\
(n_{NO_2} - n_{NO_2, 0}) = -2 \xi\\
(n_{N_2O_4} - n_{NO_2, 0}) = \xi
\end{cases}
\]</span></p>
<p>where we write <span class="math inline">\(\xi\)</span> as the <strong>extent of reaction</strong>, that is, the number of moles of reactions that has taken place.</p>
<p>Differentiating the two equations, and setting <span class="math inline">\(dV, d\beta = 0\)</span>, we have</p>
<p><span class="math display">\[
\begin{cases}
dF = \mu_{NO_2} dn_{NO_2} + \mu_{N_2O_4} dn_{N_2O_4} \\
dn_{NO_2} = -2d\xi \\
dn_{N_2O_4} = d\xi
\end{cases}
\]</span></p>
<p>At equilibrium, <span class="math inline">\(dF = 0\)</span> under all possible constrained variations, giving us the condition of equilibrium: <span class="math display">\[-2\mu_{NO_2} + \mu_{N_2 O_4} = 0\]</span></p>
<p>We may vary both starting conditions <span class="math inline">\(n_{NO_2, 0}\)</span> and <span class="math inline">\(n_{N_2O_4, 0}\)</span>, and for each starting condition, the system would equilibrate at the solution to</p>
<p><span class="math display">\[
\begin{cases}
-2\mu_{NO_2} (T, V, n_{NO_2}, n_{N_2O_4}) + \mu_{N_2 O_4}(T, V, n_{NO_2}, n_{N_2O_4}) = 0 \\
(n_{NO_2} - n_{NO_2, 0}) = -2 \xi\\
(n_{N_2O_4} - n_{NO_2, 0}) = \xi
\end{cases}
\]</span></p>
<p>which has exactly the same number of unknowns and equations, so in general it should have at least one solution.</p>
<p>The state space of the system has 2 dimensions: <span class="math inline">\(n_{NO_2}\)</span> and <span class="math inline">\(n_{N_2 O_4}\)</span>. Starting at any point in the state space, the system can move on a single line, and it would equilibrate at exactly the point at which its Helmholtz energy is minimized. We can find the point of equilibrium by drawing the surfaces of constant Helmholtz free energy, and find the tangent point, as pictured.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Helmholtz_demand_curve.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Minimizing Helmholtz free energy under the constraint of <span class="math inline">\(2 NO_2 \rightleftharpoons N_2O_4\)</span> is equivalent to maximizing utility under a budgetary constraint.</figcaption>
</figure>
</div>
<p>Economically speaking, the situation is precisely equivalent to the standard first problem in consumer theory: Given a consumer with a finite budget and a market for two goods, what would they buy from the market to maximize their utility? (They must spend all their budget.)</p>
<p>The answer, as we can see in the diagram, is the tangent point of the straight line of constant budget with the curved lines of constant utility.</p>
<p>To anthropomorphize the situation, we can say that the reaction chamber is a consumer trying to minimize its Helmholtz free energy under the “budgetary constraint” of <span class="math inline">\(2 NO_2 \rightleftharpoons N_2O_4\)</span>. In this way, chemical equilibrium becomes a problem in consumer theory.</p>
<section id="existence-and-uniqueness" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="existence-and-uniqueness">Existence and uniqueness</h4>
<p>We see from the diagram that at least one solution exists. In most situations, the Helmholtz free energy is strictly concave, so the curves of constant <span class="math inline">\(F\)</span> are strictly convex, and so the solution is unique on each line.</p>
<p>If the budget line is tangent to a curve of constant <span class="math inline">\(F\)</span>, then at the equilibrium point, both <span class="math inline">\(NO_2\)</span> and <span class="math inline">\(N_2O_4\)</span> exist. Otherwise, only one exist, and we say that the reaction is irreversible. Economically speaking, it is like when you are poor enough, you might spend all your money buying noodles, and none buying bread.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/raff_2014_fig_2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The <span class="math inline">\(\xi, H\)</span> curve of a reaction chamber, that is a sealed glass tube held under constant temperature of 298.15 K. At the <span class="math inline">\(\xi = 0\)</span> side, the tube contains 2 moles of <span class="math inline">\(NO_2\)</span>, and at the <span class="math inline">\(\xi = 1 \mathrm{~mol}\)</span> side, the tube contains 1 mole of <span class="math inline">\(N_2O_4\)</span>. <span class="citation" data-cites="raffSpontaneityEquilibriumWhy2014">(<a href="#ref-raffSpontaneityEquilibriumWhy2014" role="doc-biblioref">Raff 2014a, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>If <span class="math inline">\(F\)</span> is not strictly concave, then it might have a double tangent point with the budget line. In that case, we have a first-order phase transition, and the substance splits into two chunks with different phases. Because the two parts can exchange volumes, it is no longer convenient to analyze with Helmholtz free energy, and we had better use Gibbs free energy. This is studied in <a href="#sec-phase-equilibrium">the next section</a>.</p>
</section>
</section>
<section id="multireaction-equilibrium" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="multireaction-equilibrium">Multireaction equilibrium</h3>
<p>Now let’s consider another example, where we have two simultaneous reactions. This is a simplified version of the NOx reactions, which is a source of air pollution.</p>
<p>Consider a system with the following reactions:</p>
<p><span class="math display">\[
\begin{aligned}
2NO + O_2 &amp;\rightleftharpoons 2NO_2\\
O + NO_2 &amp;\rightleftharpoons N_2O_3
\end{aligned}
\]</span></p>
<p>The system is in a container with constant volume <span class="math inline">\(V\)</span> and temperature <span class="math inline">\(T\)</span>. Let <span class="math inline">\(n_i\)</span> represent the number of moles of species <span class="math inline">\(i\)</span>. The thermodynamic state of the system is fully described by the 4-component vector <span class="math inline">\(\vec n = (n_{O_2}, n_{NO}, n_{NO_2}, n_{N_2O_3})\)</span>.</p>
<p>To make the algebra look cleaner, we rewrite them as follows:</p>
<p><span class="math display">\[
\begin{aligned}
0 &amp;\rightleftharpoons -O_2 - 2 NO + 2NO_2 + 0 N_2 O_3\\
0 &amp;\rightleftharpoons 0 O_2 -NO - NO_2 + N_2O_3
\end{aligned}
\]</span></p>
<p>We see that each reaction can be written as a single vector. The first has vector <span class="math inline">\(\vec n_1 = (-1, -2, 2, 0)\)</span>, and the second has vector <span class="math inline">\(\vec n_2 = (0, -1, -1, 1)\)</span>.</p>
<p>Each reaction has an associated extent of reaction, denoted by <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\xi_2\)</span> respectively. Changes in the number of moles for each species are related to the extents of reaction:</p>
<p><span class="math display">\[
\begin{aligned}
dn_{NO} &amp;= -2d\xi_1 - d\xi_2 \\
dn_{O_2} &amp;= -d\xi_1 \\
dn_{NO_2} &amp;= 2d\xi_1 - d\xi_2 \\
dn_{N_2O_3} &amp;= d\xi_2
\end{aligned}
\]</span></p>
<p>At equilibrium, the Helmholtz free energy <span class="math inline">\(F(T, V, \vec{n})\)</span> is minimized under the constraints imposed by the reactions. This leads to the following conditions:</p>
<p><span class="math display">\[
\begin{aligned}
-2\mu_{NO} - \mu_{O_2} + 2\mu_{NO_2} &amp;= 0 \\
-\mu_{NO} - \mu_{NO_2} + \mu_{N_2O_3} &amp;= 0
\end{aligned}
\]</span></p>
<p>More elegantly,</p>
<p><span class="math display">\[\vec \mu \cdot \vec n_j = 0, \quad j = 1, 2\]</span></p>
<p>where <span class="math inline">\(\vec \mu = (\mu_{O_2}, \mu_{NO}, \mu_{NO_2}, \mu_{N_2O_3})\)</span> is the vector of chemical potentials.</p>
<p>Starting at any initial chemical composition of <span class="math inline">\(\vec n_0\)</span>, the space of all possible chemical compositions reachable from <span class="math inline">\(\vec n_0\)</span> is a 2-dimensional subset. That is, it is the set of <span class="math inline">\(\vec n\)</span> satisfying</p>
<p><span class="math display">\[
\begin{cases}
\vec n &amp;= \vec n_0 + \xi_1 \vec n_1+ \xi_2 \vec n_2, \\
\vec n &amp;\geq 0
\end{cases}
\]</span></p>
<p>Geometrically speaking, the subset is the intersection between a 2-dimensional plane and a 4-dimensional pyramid, so it generally looks like either a triangle or a quadrilateral. On this subset, the Helmholtz free energy function looks like a sequence of nested convex shells, and the point of tangency is the equilibrium point.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Helmholtz_contour_multireaction.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The lines are the 3-dimensional contour surfaces of constant Helmholtz free energy, intersected with the 2-dimensional feasible set. The point of tangency is the point of chemical equilibrium.</figcaption>
</figure>
</div>
<p>Interpreted economically, this is a consumer that maximizes its utility under two simultaneous budgetary constraints (because the budget set is a 2-dimensional, not 1-dimensional, subset of <span class="math inline">\(\mathbb{R}^4\)</span> ). Perhaps the consumer is trading with a market that simultaneously uses two kinds of currencies – <a href="https://en.wikipedia.org/wiki/Bimetallism">bimetallism</a>?</p>
<p>Converting this experience into math, we have the following theorem.</p>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 12 (existence and uniqueness of chemical equilibrium, at constant volume and temperature)</strong></span> Consider a sealed reaction chamber held in an energy bath, so that both the price of energy <span class="math inline">\(\beta\)</span>, and the volume <span class="math inline">\(V\)</span>, of the system is fixed.</p>
<p>The system contains a homogenous mixture of chemical species <span class="math inline">\(A_1, \dots, A_k\)</span>, which might undergo the following <span class="math inline">\(r\)</span> possible chemical reactions:</p>
<p><span class="math display">\[
0 \rightleftharpoons \sum_i a_{ij} A_i, \quad j = 1, 2, \dots, r
\]</span></p>
<p>The necessary condition for chemical equilibrium is</p>
<p><span class="math display">\[
\vec \mu \cdot \vec n_j = 0, \quad \forall j = 1, 2, \dots, r
\]</span></p>
<p>where <span class="math inline">\(\vec n_j = (a_{1, j}, \dots, a_{k, j})\)</span> is the vector representing the <span class="math inline">\(j\)</span> -th chemical reaction.</p>
<p>The condition is also sufficient if the Helmholtz free energy is strictly concave.</p>
<p>If <span class="math inline">\(F\)</span> is not strictly concave, then there could be multiple coexisting equilibrium, which gives us a first-order phase transition.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Existence: <span class="math inline">\(F\)</span> is continuous, so it has at least one minimum on every compact set.</p>
<p>Uniqueness: any local minimum of a strictly concave function is the unique global minimum.</p>
</div>
</div>
</div>
</section>
<section id="fixed-pressure-and-temperature" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="fixed-pressure-and-temperature">Fixed pressure and temperature</h3>
<p>We studied the case of a reaction chamber held under constant volume and temperature, which one can picture as a sealed glass tube in an ice-water bath. Now consider the case of a reaction chamber with constant temperature and pressure, for example when it is a flaccid plastic bag at the bottom of the ocean.</p>
<p>Every previous result can be direct translated to that case, by replacing “Helmholtz” with “Gibbs”.</p>
<p>For example, for the same reaction of <span class="math inline">\(NO_2\)</span> dimerization, now put into a flabby plastic bag held under constant temperature of 298.15 K and constant pressure of 1 atm, produces the following <span class="math inline">\(\xi, G\)</span> curve. At the <span class="math inline">\(\xi = 0\)</span> side, the bag contains 2 moles of <span class="math inline">\(NO_2\)</span>, and at the <span class="math inline">\(\xi = 1 \mathrm{~mol}\)</span> side, the bag contains 1 mole of <span class="math inline">\(N_2O_4\)</span>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/raff_2014_fig_4.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The reaction chamber is a flabby plastic bag held under constant temperature of <span class="math inline">\(298.15 \mathrm{~K}\)</span> and constant pressure <span class="math inline">\(1 \mathrm{~atm}\)</span>. It has the following <span class="math inline">\(\xi, G\)</span> curve. At the <span class="math inline">\(\xi = 0\)</span> side, the tube contains <span class="math inline">\(2 \mathrm{~mol}\)</span> of <span class="math inline">\(NO_2\)</span>, and at the <span class="math inline">\(\xi = 1 \mathrm{~mol}\)</span> side, the tube contains <span class="math inline">\(1 \mathrm{~mol}\)</span> of <span class="math inline">\(N_2O_4\)</span>. <span class="citation" data-cites="raffSpontaneityEquilibriumWhy2014">(<a href="#ref-raffSpontaneityEquilibriumWhy2014" role="doc-biblioref">Raff 2014a, fig. 4</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="the-meaning-of-delta-g" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="the-meaning-of-delta-g">The meaning of <span class="math inline">\(\Delta G\)</span></h3>
<p><small>This section based on <span class="citation" data-cites="quilezFirstYearUniversityChemistry2012">(<a href="#ref-quilezFirstYearUniversityChemistry2012" role="doc-biblioref">Quílez 2012</a>)</span>.</small></p>
<p><span class="math inline">\(\Delta G\)</span> has two confusable meanings. The first meaning is <span class="math inline">\(\frac{dG}{d\xi}\)</span>, that is, the marginal Gibbs free energy for reaction, - how much the Gibbs free energy increases if the reaction goes forward by an infinitesimal mole. The second meaning is <span class="math inline">\(\int_0^1 (\partial_\xi G)_{T, P} d\xi\)</span>. Both meanings are illustrated in the diagram.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/glasser_2016_fig_1.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The first meaning of <span class="math inline">\(\Delta G\)</span> is the slope. The second meaning of <span class="math inline">\(\Delta G\)</span> is the difference in height of the curve on two ends of the <span class="math inline">\((\xi, G)\)</span> curve. <span class="citation" data-cites="glasserCorrectUseHelmholtz2016">(<a href="#ref-glasserCorrectUseHelmholtz2016" role="doc-biblioref">Glasser 2016, fig. 1</a>)</span></figcaption>
</figure>
</div>
<p>The first meaning, that of <span class="math inline">\(\frac{dG}{d\xi}\)</span>, is used in chemical equilibrium. The textbooks say <span class="math inline">\(\Delta G = 0\)</span> when they really meant <span class="math inline">\(\frac{dG}{d\xi} = 0\)</span>.</p>
<p>The second meaning, that of <span class="math inline">\(\int_0^1 (\partial_\xi G)_{T, P} d\xi\)</span>, can be interpreted by the “van ’t Hoff box” <span class="citation" data-cites="bazhinConversionChemicalReaction2007">(<a href="#ref-bazhinConversionChemicalReaction2007" role="doc-biblioref">Bazhin and Parmon 2007</a>)</span>. We have a chamber with several semi-permeable membranes. On the input side, some gasses are permeated into the chamber, while on the output side, some gases are permeated out of it. The inside of the chamber remains fixed in composition. In this case, <span class="math inline">\(\Delta G\)</span> is the maximal useful work extractable in the process per reaction-mole, or the thermal energy created if no useful work is done.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/glasser_2016_fig_2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">The reaction chamber, demonstrating the concrete meaning of <span class="math inline">\(\Delta G\)</span>. <span class="citation" data-cites="glasserCorrectUseHelmholtz2016">(<a href="#ref-glasserCorrectUseHelmholtz2016" role="doc-biblioref">Glasser 2016, fig. 2</a>)</span></figcaption>
</figure>
</div>
<p>For example, such a situation occurs approximately occurs in the <a href="https://en.wikipedia.org/wiki/Haber_process">Haber–Bosch method</a> for producing ammonia on the industrial scale: <span class="math inline">\(N_2 + 3H_2 \to 2NH_3\)</span>. In the HB method, room-temperature (25 <span class="math inline">\(^\circ C\)</span>) and room-pressure (1 atm) nitrogen and hydrogen continuously pipe into the chamber, and ammonia is continuously extracted out of the chamber by cooling liquefaction. When the reaction chamber is operating at a stable state, the energy released per mole of reaction is <span class="math inline">\(\Delta G = -32.8 \mathrm{~kJ/mol}\)</span>, as one can calculate from a table of chemical thermodynamics. With this setup, after <span class="math inline">\(1\mathrm{~mol}\)</span> of nitrogen is consumed and <span class="math inline">\(2\mathrm{~mol}\)</span> of ammonium is produced, a thermal energy of <span class="math inline">\(32.8\mathrm{~kJ}\)</span> is produced, and must be cooled off somehow <span class="citation" data-cites="glasserCorrectUseHelmholtz2016">(<a href="#ref-glasserCorrectUseHelmholtz2016" role="doc-biblioref">Glasser 2016</a>)</span>.</p>
<p>Note that throughout this process, <span class="math inline">\(\frac{dG}{d\xi} = 0\)</span> always within the box, even as <span class="math inline">\(\Delta G = -32.8 \mathrm{~kJ/mol}\)</span> across the box. If <span class="math inline">\(\frac{dG}{d\xi} \neq 0\)</span>, the reaction box would shake and shudder as it rushes towards equilibrium, and probably crack the walls. If <span class="math inline">\(\Delta G \not\lt 0\)</span>, then all those giant <a href="https://en.wikipedia.org/wiki/Cooling_tower">cooling towers</a> would have been pointless. Both <span class="math inline">\(\frac{dG}{d\xi} = 0\)</span> and <span class="math inline">\(\Delta G = -32.8 \mathrm{~kJ/mol}\)</span> are true, and the physical reality of an ammonia factory is the living smoking proof.</p>
</section>
<section id="practical-considerations" class="level3">
<h3 class="anchored" data-anchor-id="practical-considerations">Practical considerations</h3>
<p>The above is all correct, and geometrical. If we were to be like Gibbs, then we would dust off our hands, for there is nothing left to do (except the theory of phase transitions). Unfortunately, chemistry is not merely applied geometry, so there is still something left to do.</p>
<section id="defining-the-standard-states" class="level4">
<h4 class="anchored" data-anchor-id="defining-the-standard-states">Defining the standard states</h4>
<p>A <strong>chemical environment</strong> is defined by chemical species <span class="math inline">\(A_1, \dots, A_m\)</span>.</p>
<p>A <strong>standard state</strong> for a chemical environment is defined by a reference pressure <span class="math inline">\(P^\circ\)</span>, and reference chemical molarities <span class="math inline">\([A_1]^\circ, \dots, [A_m]^\circ\)</span> for each of the the chemical species.</p>
<p>Given a standard state for a chemical environment, for any temperature <span class="math inline">\(T\)</span>, and any chemical molarities <span class="math inline">\([A_1], \dots, [A_m]\)</span>, the <strong>chemical activity</strong> of the chemical species <span class="math inline">\(A_i\)</span> in this particular context is</p>
<p><span class="math display">\[\{A_i\} := e^{\frac{\mu_i - \mu_i^\circ}{RT}}\]</span></p>
<p>where <span class="math inline">\(\mu_i\)</span> is the chemical potential of species <span class="math inline">\(A_i\)</span> at that state. That is,</p>
<p><span class="math display">\[\mu_i = (\partial_{n_i} G)|_{T, P, [A_1], \dots, [A_m]}\]</span></p>
<p>and <span class="math inline">\(\mu_i^\circ\)</span> is the chemical potential of species <span class="math inline">\(A_i\)</span> at the standard state:</p>
<p><span class="math display">\[\mu_i^\circ = (\partial_{n_i} G)|_{T, P^\circ, [A_1]^\circ, \dots, [A_m]^\circ}\]</span></p>
<p>Given a chemical reaction <span class="math inline">\(0 \rightleftharpoons \sum_i a_i A_i\)</span>, its <strong>reaction quotient</strong> is</p>
<p><span class="math display">\[
Q = \prod_i \{A_i\}^{a_i}
\]</span></p>
<p>where <span class="math inline">\(a_i\)</span> is the stoichiometric number of chemical species <span class="math inline">\(A_i\)</span>. For example, with <span class="math inline">\(aA + bB \rightleftharpoons cC + dD\)</span>, its reaction quotient is <span class="math display">\[
Q = \frac{\{C\}^c\{D\}^d}{\{A\}^a\{B\}^b}
\]</span></p>
</section>
<section id="fundamental-theorem-of-chemical-equilibrium" class="level4">
<h4 class="anchored" data-anchor-id="fundamental-theorem-of-chemical-equilibrium">Fundamental theorem of chemical equilibrium</h4>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 13 (fundamental theorem of chemical equilibrium)</strong></span> Given any chemical reaction <span class="math inline">\(0 \rightleftharpoons \sum_i a_i A_i\)</span>, any standard state, and any temperature, <span class="math display">\[\begin{cases}
(\partial_\xi F)_{T, V} &amp;= (\partial_\xi F)_{T, V}^\circ + RT \ln Q \\
(\partial_\xi G)_{T, P} &amp;= (\partial_\xi G)_{T, P}^\circ + RT \ln Q
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\xi\)</span> is the extent of reaction, and <span class="math inline">\(Q\)</span> is its reaction quotient.</p>
<p>If the system has <span class="math inline">\(r\)</span> possible reactions, then we similarly have <span class="math display">\[\begin{cases}
(\partial_{\xi_j} F)_{T, V} &amp;= (\partial_{\xi_j} F)_{T, V}^\circ + RT \ln Q_j \\
(\partial_{\xi_j} G)_{T, P} &amp;= (\partial_{\xi_j} G)_{T, P}^\circ + RT \ln Q_j
\end{cases}
\]</span></p>
<p>for each reaction <span class="math inline">\(j = 1, 2, \dots, r\)</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{aligned}
(\partial_\xi F)_{T, V} &amp;= \sum_i (\partial_\xi n_i) (\partial_{n_i} F)_{T, V, \vec n} \\
&amp;= \sum_i a_i \mu_i \\
&amp;= \sum_i a_i (\mu_i^\circ + RT \ln \{A_i\}) \\
&amp;= \sum_i a_i (\mu_i^\circ) + RT \ln \left(\prod_i \{A_i\}^a_i\right) \\
&amp;= (\partial_\xi F)_{T, V}^\circ + RT \ln Q
\end{aligned}\]</span></p>
<p>The proof for the other equations are very similar.</p>
</div>
</div>
</div>
<div id="cor-0" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 2 (equilibrium coefficient)</strong></span> At equilibrium, <span class="math display">\[
(\partial_\xi G)_{T, P} = 0
\]</span></p>
<p>which is equivalent to <span class="math display">\[
Q = K_{eq}, \quad K_{eq} := e^{-\frac{(\partial_\xi G)_{T, P}^\circ}{RT}}
\]</span></p>
<p>and similarly for the other case.</p>
</div>
<p>The above equations are what my teachers meant when they thoughtlessly wrote</p>
<p><span class="math display">\[\Delta G = 0, \quad K_{eq} = e^{-\frac{\Delta G^\circ}{RT}}\]</span></p>
<p>This, finally, answers my great confusion back then. Now everything makes sense, and life is beautiful.</p>
</section>
<section id="ideal-gas-like-chemistry" class="level4">
<h4 class="anchored" data-anchor-id="ideal-gas-like-chemistry">Ideal-gas-like chemistry</h4>
<p>Well, if this is all there is, then a mathematician would be able to solve any problem in analytical chemistry. Unfortunately, analytical chemistry is not about proving theorems, but about actually getting numerical answers, and numerical answers require numerical values for chemical activities.</p>
<p>There are generally three cases:</p>
<ol type="1">
<li>We have a mixture of dilute gasses, or dilute solvents in an inert solution, such that the ideal gas law is almost true.</li>
<li>Ideal gas law fails.</li>
<li>We are not even dealing with gasses and solutions anymore.</li>
</ol>
<p>The first case is typically what is taught by a first course in analytical chemistry, and since this is typically taught to non-mathematicians by non-mathematicians for non-mathematicians, the logical structure is quite upside-down and confusing to a mathematician.</p>
<p>We will now prove the first case rigorously.</p>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 14 (activity of ideal gas mixtures)</strong></span> For any temperature <span class="math inline">\(T\)</span> and any two pressures <span class="math inline">\(P, P^\circ\)</span>, by the ideal gas laws, the chemical potential of the chemical species satisfies the equation</p>
<p><span class="math display">\[\mu(T, P) = \mu(T, P^\circ) + RT \ln\frac{P}{P^\circ}\]</span></p>
<p>and so its activity is <span class="math inline">\(\frac{P}{P^\circ}\)</span>.</p>
<p>In a mixture of ideal gases, the gases do not interact, and so the activity of chemical species <span class="math inline">\(A_i\)</span> is <span class="math inline">\(\{A_i\} = \frac{P_i}{P_i^\circ}\)</span>, where <span class="math inline">\(P_i\)</span> is the partial pressure of species <span class="math inline">\(A_i\)</span> in the mixed gas, and <span class="math inline">\(P_i^\circ\)</span> is the standard pressure for species <span class="math inline">\(A_i\)</span>.</p>
<p>In a dilute solution, if the solvent behaves like a mixture of ideal gasses, then</p>
<p><span class="math display">\[\mu(T, P) \approx \mu(T, P^\circ) + RT \ln \frac{[A_i]}{[A_i]^\circ} \approx \mu(T, P^\circ) + RT \ln \frac{m_{A_i}}{m_{A_i}^\circ}\]</span></p>
<p>where <span class="math inline">\([A_i]\)</span> is the mole-per-volume of <span class="math inline">\(A_i\)</span>, and <span class="math inline">\(m_{A_i}\)</span> is the mole-per-mass of <span class="math inline">\(A_i\)</span>.</p>
<p>The chemical activity simplifies into the familiar form:</p>
<p><span class="math display">\[\{A\} \approx \frac{[A]}{[A]^\circ} \approx \frac{m_A}{m_A^\circ}\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It suffices to prove the case for a pure ideal gas, as the other cases are simple corollaries.</p>
<p>By the ideal gas law, the chemical potential is</p>
<p><span class="math display">\[\mu = -TS/n\]</span></p>
<p>which is a state property. Expressed as a function of <span class="math inline">\(T, P\)</span>, <span class="math display">\[\mu(T, P) = RT \ln\frac{P/T^{\hat c_V + 1}}{C}\]</span></p>
<p>for an arbitrary constant <span class="math inline">\(C\)</span>.</p>
<p>Thus, for any <span class="math inline">\(T, P, P^\circ\)</span>, we have</p>
<p><span class="math display">\[\mu(T, P) = \mu(T, P^\circ) + RT \ln\frac{P}{P^\circ}\]</span></p>
</div>
</div>
</div>
<div id="exm-0" class="theorem example">
<p><span class="theorem-title"><strong>Example 3</strong></span> The pH value of a solution is not <span class="math inline">\(pH = -\log_{10} [H^+]\)</span>, which has the wrong units. It is not even <span class="math inline">\(pH = -\log_{10} \frac{[H^+]}{[H^+]^\circ}\)</span>, since the <span class="math inline">\(H^+\)</span> particles might not behave like an ideal gas. The actual correct definition is <span class="citation" data-cites="mccartyPHParadoxesDemonstrating2006">(<a href="#ref-mccartyPHParadoxesDemonstrating2006" role="doc-biblioref">McCarty and Vitz 2006</a>)</span></p>
<p><span class="math display">\[pH = -\log_{10} \{H^+\}\]</span></p>
</div>
</section>
<section id="fugacity" class="level4">
<h4 class="anchored" data-anchor-id="fugacity">Fugacity</h4>
<p>For real gases and real solutions, the chemical activity might deviate significantly from the above approximation. In this case, we typically have no recourse except to checking a table of chemical thermodynamics. They typically do not directly write down the chemical activities, but <a href="https://en.wikipedia.org/wiki/Fugacity"><em>fugacity coefficients</em></a>. There is nothing particularly deep about fugacity – it is basically about rescaling the numbers to make the tables easier to make.</p>
<p>Recall that the chemical potential of an ideal gas satisfies <span class="math inline">\(\mu(T, P) = RT \ln\frac{P/T^{\hat c_V + 1}}{C}\)</span>, where <span class="math inline">\(C\)</span> is a constant for this gas. For a real gas, this equation only holds approximately, so we define the <strong>fugacity</strong> <span class="math inline">\(f\)</span> as a function of <span class="math inline">\(T, P\)</span>, such that <span class="math display">\[\mu(T, P) = RT \ln\frac{f/T^{\hat c_V + 1}}{C}\]</span></p>
<p>In other words, <span class="math inline">\(f(T, P) = P \phi(T, P)\)</span>, where</p>
<p><span class="math display">\[\phi(T, P) = e^{\frac{\mu(T, P) - \mu_{ideal}(T, P)}{RT}}\]</span></p>
<p>is the <strong>fugacity coefficient</strong>.</p>
<p>Plugging them back to the definition of activity, we have</p>
<p><span class="math display">\[\{A\} = \frac{f}{f^\circ} = \frac{\phi P}{\phi^\circ P^\circ}\]</span></p>
<p>And so, by checking a table of fugacity coefficients, chemical engineers can balance chemical reactions of real gasses, even far from ideality.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="Standard state">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Standard state
</div>
</div>
<div class="callout-body-container callout-body">
<p>Despite what the name “standard” might imply, a chemical species has infinitely many standard states. For example, pure gaseous oxygen has many different standard states – one for each temperature. We have a standard state at <span class="math inline">\(T = 300\mathrm{~K}\)</span> defined by <span class="math inline">\([O_2] = 1 \mathrm{~mol/L}\)</span>, and another at <span class="math inline">\(T = 350\mathrm{~K}\)</span> defined by <span class="math inline">\([O_2] = 1 \mathrm{~mol/L}\)</span>, etc.</p>
<p>Despite what the name “standard” might imply, different chemists have different standards. For example, among the biochemists, the standard state for <span class="math inline">\(H^+\)</span> in water is <span class="math inline">\([H^+]^\circ = 10^{-7} \mathrm{~mol/L}\)</span>, but among the inorganic chemists, it is <span class="math inline">\([H^+]^\circ = 1 \mathrm{~mol/L}\)</span>. The reason is that bodily fluids typically have <span class="math inline">\([H^+] \sim 10^{-7} \mathrm{~mol/L}\)</span>.</p>
<p>Despite what the name “standard temperature and pressure (STP)” might imply, it is not a “standard state”, because a “standard state” of any substance does not specify its temperature.</p>
</div>
</div>
<p>The point of having a standard state is like taking an electric circuit, pointing at one point of it, and say, “This is where the voltage is zero.”. The point is to allow for relative comparisons between states, within the context of a <em>single</em> reaction. Consequently, even for a single chemical species, we can take a different standard state if we are studying a different reaction involving the species, or the same reaction in a different context.</p>
<p>For example, if we are studying the reaction <span class="math inline">\(NO_2 \rightleftharpoons N_2 O_4\)</span> in a glass tube drenched in an ice-water bath, then we would take as our standard state <span class="math display">\[T^\circ = 273.15 K, \quad [NO_2]^\circ = 1 \mathrm{~mol/L}, \quad [N_2 O_4]^\circ = 1 \mathrm{~mol/L}\]</span></p>
<p>For a chemical in pure gaseous form, a standard state is specified by two out of three parameters: molarity <span class="math inline">\([A] = \frac{n}{V}\)</span>, pressure <span class="math inline">\(P\)</span>, temperature <span class="math inline">\(T\)</span>. We must never specify all three of them, because otherwise we would break the equation of state. For example, imagine what happens when you specify that the “standard state of ideal gas” is</p>
<p><span class="math display">\[T^\circ = 273.15 \mathrm{~K}, P^\circ = 10^5 \mathrm{~Pa}, [A]^\circ = 1 \mathrm{~mol/L}\]</span></p>
<p>because they would violate the ideal gas law <span class="math display">\[P = [A]RT\]</span></p>
<p>For non-ideal gas, we still have an equation of state between <span class="math inline">\(P, [A], T\)</span>, meaning that we still must specify exactly two, no more and no less.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Intensive quantities">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Intensive quantities
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is a standard state defined by intensive quantities like temperature, pressure, or molarity? Why isn’t it defined by extensive quantities such as volume, mass, and moles?</p>
<p>The short answer: because traditional chemistry only studies systems with extensive entropies. For those systems, chemical equilibrium is determined by intensive quantities. This is not because classical thermodynamics cannot handle nonextensive entropy, but because chemists had no use for systems with nonextensive entropy.</p>
<p>Like classical thermodynamics and neoclassical economics, the idea of a standard state is fully committed to the idea of <em>homogeneous</em> substances. In classical thermodynamics, a cube of iron and a ball of iron are the same. A jar of water and a tank of water are the same. It does not matter what their shapes are. Moreover, two jars of water side-by-side is the same as one large jar of water. In neoclassical economics, a crowd of factories is the same as two small crowds of factories put together. They are all chunks of homogeneous stuffs.</p>
<p>If this were not the case, then we would be unable to say that a standard state is defined by just the temperature and molar concentration of each chemical species. We would be forced to also specify a standard state volume <span class="math inline">\(V^\circ\)</span>. It is conceivable that even the shape of the reaction chamber matters. We would then be forced to specify a standard shape, perhaps a box with side lengths <span class="math inline">\(0.1 \mathrm{~m}\)</span>. But in this extreme case, perhaps we have already left the realm of chemistry.</p>
<p>For spherical particles, doubling the volume would double the mass, but only <span class="math inline">\(2^{2/3} \approx 1.59 \times\)</span> the surface area. Consequently, if the surface between phases has a non-negligible entropy (“surface effect”), then entropy would be nonextensive. While IUAPC is silent on the issue, nonextensive entropy is taken up in earnest by chemists who work with small spherical particles <span class="citation" data-cites="letellierSolubilityNanoparticlesNonextensive2007">(<a href="#ref-letellierSolubilityNanoparticlesNonextensive2007" role="doc-biblioref">Letellier, Mayaffre, and Turmine 2007</a>)</span>.</p>
</div>
</div>
</section>
<section id="iuapcs-definition-of-standard-state" class="level4">
<h4 class="anchored" data-anchor-id="iuapcs-definition-of-standard-state">IUAPC’s definition of “standard state”</h4>
<p>I have found that the <a href="https://en.wikipedia.org/wiki/International_Union_of_Pure_and_Applied_Chemistry">IUAPC</a>’s definition of the “standard state” <span class="citation" data-cites="coxNotationStatesProcesses1982">(<a href="#ref-coxNotationStatesProcesses1982" role="doc-biblioref">Cox 1982</a>)</span> to be precise and clarifying, though it is quite ponderous, so I summarize it as follows:</p>
<ul>
<li>The standard state for a gaseous substance, whether pure or mixed, is the substance at <span class="math inline">\(P^\circ\)</span> and in a (hypothetical) state in which it exhibits ideal-gas behaviour, where <span class="math inline">\(P^\circ\)</span> is an arbitrarily fixed standard-state pressure.</li>
<li>The standard state for a pure liquid or solid substance is the pure substance at <span class="math inline">\(P^\circ\)</span>.</li>
<li>The above definitions of standard states make no reference to fixed temperature. Hence, it is possible to have an infinite number of standard states of a substance as the temperature varies. But generally it is more convenient to complete the definition of the standard state in a particular context by choosing for the reference temperature one of a relatively small number of values, e.g., zero, <span class="math inline">\(273.15 \mathrm{~K}, 293.15 \mathrm{~K}, 298.15 \mathrm{~K}\)</span>.</li>
<li>Since <span class="math inline">\(T^{\circ}\)</span> should mean a standard temperature <strong>in general</strong>, the use of <span class="math inline">\(T^{\circ}\)</span> to mean exclusively <span class="math inline">\(298.15 \mathrm{~K}\)</span> is <strong>strongly discouraged</strong>.</li>
<li>For application of the concept of standard state to substances in admixture (solutions and mixtures), <strong>the composition of the system, as well as the pressure</strong>, must be defined. As one example for solutions, the standard-state molality, written as <span class="math inline">\(m^\circ\)</span> for the general case, is to be defined; customarily <span class="math inline">\(m^\circ\)</span> is taken as <span class="math inline">\(1 \mathrm{~mol/kg}\)</span>.</li>
</ul>
<p><img src="figure/banner/4.png" class="img-fluid"></p>
</section>
</section>
</section>
<section id="sec-phase-equilibrium" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-phase-equilibrium">Phase equilibrium</h2>
<p>Several times, we have found some curious examples where a non-concavity in entropy leads to a jump of some kind. These are all examples of first-order phase equilibrium.</p>
<section id="two-phases-of-a-gas-in-equilibrium" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="two-phases-of-a-gas-in-equilibrium">Two phases of a gas in equilibrium</h3>
<p>Consider a generic gas, whose entropy function is of form <span class="math inline">\(S(U, V, N)\)</span>. If we confine it in a sealed tube, and slowly heat it up, then its entropy would trace out the curve</p>
<p><span class="math display">\[U \mapsto S(U, V, N)\]</span></p>
<p>Now, the inverse temperature <span class="math inline">\(\beta\)</span> of the system is the slope, which should decrease as <span class="math inline">\(U\)</span> increases, so the entropy curve should be strictly concave.</p>
<p>If there is a bump in the middle, then we have a serious problem: as we heat up the gas, its temperature would <em>decrease</em> for a while before increasing again! This suggests to us that our model has broken down. Where is the breakdown? The breakdown is that we assumed our system remains one thermodynamic substance, when it can split into two. Suppose by a small fluctuation, the left side of the container has higher temperature than the right side, then it would give some internal energy to the right side. Normally, this would cause their temperatures to meet in the middle. However, in this inverted situation, the left side would become even hotter, and so we have a positive feedback loop, until the substance has split into two, with the same temperature, but one with higher internal energy density, and one with lower.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/first_order_phase_transition_SU_curve.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">A bump in the <span class="math inline">\(U \mapsto S\)</span> curve would lead to a thermodynamic instability, ending with a first-order phase transition.</figcaption>
</figure>
</div>
<p>Suppose now that the substance splits into two, like a large company splits into two subsidiaries under a common conglomerate. How would the manager maximize the total value of the conglomerate? It would solve the following constrained optimization:</p>
<p><span class="math display">\[
\begin{cases}
\max S_1(U_1, V_1, N_1) + S_2(U_2, V_2, N_2) \\
U_1 + U_2 = U \\
V_1 + V_2 = V \\
N_1 + N_2 = N
\end{cases}
\]</span></p>
<p>where we, instead of writing <span class="math inline">\(S(U_1, V_1, N_1) + S(U_2, V_2, N_2)\)</span>, write <span class="math inline">\(S_{{\color{red} 1}}(U_1, V_1, N_1) + S_{{\color{red} 2}}(U_2, V_2, N_2)\)</span>, to emphasize that we now have two thermodynamic systems that might have very different behavior, like water vs ice.</p>
<p>Differentiating, we find that the marginal values of each asset are equal in both subsidiaries:</p>
<p><span class="math display">\[
\begin{cases}
\beta_1 = \beta_2,\\ \beta_1 P_1 = \beta_2 P_2, \\-\beta_1 \mu_1 = -\beta_2 \mu_2
\end{cases}
\]</span></p>
<p>That is, the two lumps of substances have the same temperature, pressure, and chemical potential.</p>
<p>Since both sides have the same temperature and pressure, it is cleaner to change to Gibbs free energy, yielding:</p>
<p><span class="math display">\[(\partial_{N} G_1)_{T, P}(T, P, N_1) = (\partial_{N} G_2)_{T, P} (T, P, N_2)\]</span></p>
<div id="warn-diamond-water-paradox" class="callout callout-style-default callout-warning callout-titled" title="The diamond water paradox, and thinking on the margins">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The diamond water paradox, and thinking on the margins
</div>
</div>
<div class="callout-body-container callout-body">
<p>Typical textbooks on thermodynamics illustrate the phase equilibrium rule using the van der Waals equation. However, there is a subtlety involved. For the van der Waals gas, the Gibbs free energy <span class="math inline">\(G\)</span> is proportional to particle number:</p>
<p><span class="math display">\[G(T, P, N) \propto N\]</span></p>
<p>which means that <span class="math inline">\((\partial_{N} G)_{T, P}(T, P, N) = G(T, P, N) / N\)</span>. In economic language, this states that:</p>
<p><span class="math display">\[\text{marginal Gibbs per particle} = \text{average Gibbs per particle}\]</span></p>
<p>In fact, confusing the two numbers is the root of the <strong>diamond-water paradox</strong>. This paradox questions why water, essential for life, has a low price, while diamonds, with little practical use, have a high price. The resolution lies in understanding the difference between <strong>total</strong> and <strong>marginal</strong> utility. While the total utility of water is immense, the marginal utility of an additional unit of water is low due to its abundance. Conversely, the marginal utility of a diamond remains high due to its scarcity.</p>
<p>In neoclassical economics, it is the marginal value of a commodity that determines the market equilibrium, not its average value. Similarly, in thermodynamics, it is the change in Gibbs free energy when adding one more particle that determines the equilibrium state, not the average Gibbs free energy per particle.</p>
<p>The distinction is moot in <em>typical books</em> on classical thermodynamics, which insists that entropy is extensive, so the above equation is always true. However, classical thermodynamics, much like neoclassical economics, is perfectly capable of handling nonextensive entropy. Lord Kelvin had studied nonextensive entropy <span class="citation" data-cites="lavendaNonextensiveThermodynamics2010">(<a href="#ref-lavendaNonextensiveThermodynamics2010" role="doc-biblioref">Lavenda 2010</a>)</span>, and Gibbs had explained surface tension and electrocapillary effects with nonextensive entropy <span class="citation" data-cites="jaynesGibbsParadox1992">(<a href="#ref-jaynesGibbsParadox1992" role="doc-biblioref">Jaynes 1992</a>)</span>.</p>
</div>
</div>
<p>Since in most classical thermodynamics systems, such as water and steam, the marginal free Gibbs energy is identical with the average Gibbs free energy, we have <span class="math inline">\((\partial_{N} G)_{T, P}(T, P, N)= G(T, P, N)/N\)</span>, meaning that phase equilibrium occurs at <span class="math inline">\(g_1(T, P) = g_2(T, P)\)</span>.</p>
<p>We can reinterpret this as follows: We delicately separate the two lumps of matter, and immerse each half in an energy-and-volume bath (like the atmosphere) with the same temperature and pressure. The only interaction between the two lumps of matter is that one side can “seep” some particles to the other side. In this set-up, the system minimizes the sum of Gibbs free energy. At equilibrium, there is no point in moving particles from one side to another, because the <strong>marginal Gibbs free energy</strong> per particle is the same.</p>
<p>Generally, <span class="math inline">\(g_1(T, P) \neq g_2(T, P)\)</span>. When <span class="math inline">\(g_1 &lt; g_2\)</span>, every particle would switch to phase 1. When <span class="math inline">\(g_1 &gt; g_2\)</span>, every particle would switch to phase 2. At exactly a knife’s edge, the particles are indifferent as to which phase they would go to.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Interpretation: corporate buyout in an ideal world">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation: corporate buyout in an ideal world
</div>
</div>
<div class="callout-body-container callout-body">
<p>We have two companies such that they can exchange their human-particles, and that there is neither economies nor diseconomies of scale (that is, as the company grows ever larger, an extra worker neither provides more nor less value than its very first worker). Then, in general, the two companies balance on a knife’s edge. If the value of a worker is even <em>slightly</em> greater in one company than another, then that company would immediately buy out every worker from the other company, and so the two companies cannot possibly coexist. Only when the market prices for space and energy happen to conspire <em>just right</em>, can the two companies coexist, neither side buying out the other side.</p>
</div>
</div>
<section id="example-van-der-waals-gas" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="example-van-der-waals-gas">Example: van der Waals gas</h4>
<p>We know what the van der Waals gas phase diagram looks like. How do we infer its Gibbs free energy diagram? Start with <span class="math inline">\(dG = -SdT + VdP + \mu dN\)</span>. Now, let us fix temperature <span class="math inline">\(T\)</span> and particle number <span class="math inline">\(N\)</span>. Then, the equation implies to <span class="math display">\[\frac{dg}{dP} = v\]</span></p>
<p>where <span class="math inline">\(g = G/N\)</span> is the average Gibbs free energy, and <span class="math inline">\(v = V/N\)</span> is the average volume.</p>
<p>Therefore, we can trace the pressure-volume diagram with our finger, from high pressure, down to the valley of pressure, then bounce back to a hill, before rolling down the slope towards infinity. At every point, the <span class="math inline">\(g(P)\)</span> curve would have a slope of <span class="math inline">\(v\)</span>. This allows us to graphically construct the following <span class="math inline">\(g(P)\)</span> curve. It has two cusps corresponding to the valley and hilltop, and a self-intersection, corresponding to the phase equilibrium of <span class="math inline">\(g_1 = g_2\)</span>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/VdW_subcritical_isotherm_gibbs.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Gibbs free energy of van der Waals gas. <a href="https://farside.ph.utexas.edu/teaching/sm1/Thermalhtml/node123.html">Figure source</a>.</figcaption>
</figure>
</div>
</section>
</section>
<section id="gibbs-phase-rule" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="gibbs-phase-rule">Gibbs phase rule</h3>
<section id="degrees-of-thermodynamic-freedom" class="level4">
<h4 class="anchored" data-anchor-id="degrees-of-thermodynamic-freedom">Degrees of thermodynamic freedom</h4>
<p>Consider a chunk of gas (ideal or not). We know everything there is to know about it if we know its <span class="math inline">\((U, V, N)\)</span>. Every other thermodynamic quantity can be computed by its entropy function <span class="math inline">\(S(U, V, N)\)</span>. Thus, we have a system with three degrees of thermodynamic freedom… or do we?</p>
<p>The problem is that the entropy of gas, and just about every other system studied in classical thermodynamics, is extensive. Therefore, we have</p>
<p><span class="math display">\[S(U, V, N) \propto N\]</span></p>
<p>and so we don’t actually have three degrees of freedom!</p>
<p>Specifically, we can calculate its <span class="math inline">\((\partial_U S, \partial_V S, \partial_N S)\)</span>, which gives us <span class="math inline">\(\beta, \beta P, -\beta \mu\)</span>. If we truly have three degrees of freedom, then we should be able to vary <span class="math inline">\(\beta, P, \mu\)</span> independently. However, because entropy is extensive, we have</p>
<p><span class="math display">\[S(U, V, N) = Ns(u, v) \implies (\beta, \beta P, -\beta \mu) = (\partial_u s, \partial_v s, s)\]</span></p>
<p>where <span class="math inline">\(s(u, v) = S(U, V, N)/N\)</span> is the entropy per particle.</p>
<p>Therefore, we can say that there are only two degrees of thermodynamic freedom: knowing two of its intensive quantities, the third would be determined by an equation of state.</p>
<p>Similarly, if we have a chunk of (nonideal) substance, like sea water, made of <span class="math inline">\(k\)</span> different chemicals, then we know everything there is to know about it if we know its <span class="math inline">\(U, V, N_1, \dots, N_k\)</span>, giving us <span class="math inline">\(2+k\)</span> degrees of freedom. Again, because entropy is extensive, one degree of freedom is degenerate, and so we only have <span class="math inline">\(1 + k\)</span> degrees of freedom. In other words, its <span class="math inline">\(2+k\)</span> intensive quantities</p>
<p><span class="math display">\[\beta, \beta P, -\beta\mu_1, \dots, -\beta \mu_k\]</span></p>
<p>are related by 1 equation of state.</p>
</section>
<section id="gibbs-phase-rule-1" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="gibbs-phase-rule-1">Gibbs phase rule</h4>
<div id="thm-0" class="theorem">
<p><span class="theorem-title"><strong>Theorem 15 (Gibbs phase rule)</strong></span> <span class="math display">\[F = 2 + C - R - P\]</span></p>
</div>
<p>First, we need to set up the thermodynamic system. We have a closed and adiathermal reaction chamber, containing <span class="math inline">\(C\)</span> different chemical species, that can undergo <span class="math inline">\(R\)</span> linearly independent chemical reactions.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;The formula looks like the <a href="https://en.wikipedia.org/wiki/Euler_characteristic">Euler formula for polyhedra</a>, but whether this analogy is more than a coincidence is controversial. After looking into the literature for a bit, my conclusion is that it is a coincidence. However, if you wish to investigate on your own, the phrase to search is “Gibbs phase rule, Euler”. This turns up some amusing examples, like <span class="citation" data-cites="sunGeometryHighdimensionalPhase2024">(<a href="#ref-sunGeometryHighdimensionalPhase2024" role="doc-biblioref">Sun, Powell-Palm, and Chen 2024</a>)</span>.</p></div></div><p>When the system is in an equilibrium, the chamber would contain <span class="math inline">\(P\)</span> different phases. Each phase would be homogeneous, but different from the other phases. All phases can exchange energy, volume, and particles.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/blankschtein_fig_27_2.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Phases in equilibrium inside a chamber. <span class="citation" data-cites="blankschteinCriteriaPhaseEquilibria2020">(<a href="#ref-blankschteinCriteriaPhaseEquilibria2020" role="doc-biblioref">Blankschtein 2020, fig. 27.2</a>)</span></figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof: Case of $R = 0$">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof: Case of <span class="math inline">\(R = 0\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>If there can be no chemical reaction, then the constrained optimization problem states</p>
<p><span class="math display">\[
\begin{cases}
\max (S_1(U_1, V_1, \vec N) + \cdots + S_P(U_P, V_P, \vec N_P)) \\
\sum_i U_i = U \\
\sum_i V_i = V \\
\sum_i \vec N_i = \vec N
\end{cases}
\]</span></p>
<p>Naively, we can just differentiate the entropies against each of the <span class="math inline">\(2+C\)</span> parameters, to obtain equations</p>
<p><span class="math display">\[
\begin{aligned}
T_1 = \dots &amp;= T_P \\
P_1 = \dots &amp;= P_P \\
\mu_{1, 1} = \dots &amp;= \mu_{1, P}\\
&amp; \vdots \\
\mu_{C, 1} = \dots &amp;= \mu_{C, P}
\end{aligned}
\]</span></p>
<p>This is not actually correct. Phase 1 might contain no chemical 2, and phase 2 might contain no chemical 1, 3, etc. In general, if phase <span class="math inline">\(i\)</span> contains chemical <span class="math inline">\(j\)</span>, then we must have <span class="math inline">\(\partial_{N_j}S_i = \mu_j\)</span>. However, if phase <span class="math inline">\(i\)</span> contains no chemical <span class="math inline">\(j\)</span>, then we only need to have <span class="math inline">\(\partial_{N_j}S_i &gt; \mu_j\)</span>.</p>
<p>Note that this is different for temperature or pressure. A phase <span class="math inline">\(i\)</span> might have no chemical of type <span class="math inline">\(j\)</span>, but if it have no <em>volume</em>, then it does not exist at all. Similarly for energy. Therefore, though the chemical potentials might differ, the temperature and pressure must be exactly the same.</p>
<p>Define <span class="math inline">\(\mu_j := \min_i \mu_{i, j}\)</span> to be the minimal chemical potential over the entire chamber. We have the following conditions:</p>
<p><span class="math display">\[
\begin{aligned}
T_1 = \dots = T_P &amp;= T \\
P_1 = \dots = P_P &amp;= P \\
\mu_{1, 1}, \dots, \mu_{1, P} &amp;\geq \mu_1\\
&amp; \vdots \\
\mu_{C, 1}, \dots, \mu_{C, P} &amp;\geq \mu_C\\
\end{aligned}
\]</span></p>
<p>Given <span class="math inline">\(T, P, \mu_1, \dots, \mu_C\)</span>, phase 1 is entirely determined: If it contains chemical <span class="math inline">\(j\)</span>, then <span class="math inline">\(\mu_{1, j} = \mu_j\)</span>, otherwise, we need not bother with <span class="math inline">\(\mu_{1, j}\)</span>. Similarly, every phase is determined.</p>
<p>Finally, each phase contributes an equation of state, which are in general linearly independent, giving us <span class="math inline">\(F = 2 + C - P\)</span> degrees of freedom.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Proof: Case of $R \geq 1$">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof: Case of <span class="math inline">\(R \geq 1\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>If we now allow a chemical reaction <span class="math inline">\(0 \rightleftharpoons \sum_j a_j A_j\)</span>, then the constrained optimization problem becomes</p>
<p><span class="math display">\[
\begin{cases}
\max (S_1(U_1, V_1, \vec N) + \cdots + S_P(U_P, V_P, \vec N_P)) \\
\sum_i U_i = U \\
\sum_i V_i = V \\
\sum_i \vec N_i = \vec N + \xi \vec a
\end{cases}
\]</span></p>
<p>The extra optimization variable <span class="math inline">\(\xi\)</span> creates an extra condition for optimality:</p>
<p><span class="math display">\[\sum_j a_j \mu_j = 0\]</span></p>
<p>so <span class="math inline">\(F = 2 + C - P - 1\)</span>.</p>
<p>Possibly, the system cannot satisfy <span class="math inline">\(\sum_j a_j \mu_j = 0\)</span>, and so the chemical reaction would keep happening until one chemical is exhausted. This would decrement <span class="math inline">\(C\)</span> by one, so it all works out self-consistently.</p>
<p>More generally, if we impose <span class="math inline">\(R\)</span> linearly independent chemical reactions, then <span class="math inline">\(F = 2 + C - P - R\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Beyond the Gibbs phase rule">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Beyond the Gibbs phase rule
</div>
</div>
<div class="callout-body-container callout-body">
<p>When the phases are not free to exchange particles, energies, volumes, etc, then the Gibbs phase rule does not apply, but the same idea of constrained minimization still applies. There are no generic rule like the Gibbs phase rule, and one must analyze each case specifically. <span class="citation" data-cites="blankschteinCriteriaPhaseEquilibria2020">(<a href="#ref-blankschteinCriteriaPhaseEquilibria2020" role="doc-biblioref">Blankschtein 2020</a>)</span></p>
</div>
</div>
<table class="caption-top table">
<caption>Some basic examples.</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>situation</th>
<th>components <span class="math inline">\(C\)</span></th>
<th>phases in equilibrium <span class="math inline">\(P\)</span></th>
<th>reactions <span class="math inline">\(R\)</span></th>
<th>degrees of freedom <span class="math inline">\(F = 2 + C - P - R\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ice</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="even">
<td>boiling water</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>triple point</td>
<td>1</td>
<td>3</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>liquid water with a little nitrogen inside, gaseous nitrogen with a little water vapor inside</td>
<td>2</td>
<td>2</td>
<td>0</td>
<td>2</td>
</tr>
<tr class="odd">
<td>dimerization of nitrogen dioxide gas</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>Nb-Ta-C alloy</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>In materials science, such as metallurgy, we often fix the pressure of the entire thing to just 1 atm, and so the phase diagrams have one less degree of freedom than what the Gibbs phase rule states.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/Nb-Ta-C_phase_diagram.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">3-dimensional phase diagram for Nb-Ta-C alloy at constant pressure <span class="math inline">\(P = 1 \mathrm{~atm}\)</span>. <span class="citation" data-cites="westTernaryPhaseDiagrams2002">(<a href="#ref-westTernaryPhaseDiagrams2002" role="doc-biblioref">West and Saunders 2002, fig. 8.1</a>)</span></figcaption>
</figure>
</div>
</section>
</section>
<section id="boiling-water" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="boiling-water">Boiling water</h3>
<p>When boiling water in an open pot, we need to specify exactly both temperature and pressure so that both phases can coexist. The <span class="math inline">\((P, T)\)</span> of the system would start at <span class="math inline">\((1\;\mathrm{~atm}, 372\;\mathrm{~K})\)</span>, then at exactly at the critical point <span class="math inline">\((1\;\mathrm{~atm}, 373.15\;\mathrm{~K})\)</span> would both phases coexist, not increasing in temperature until all water has turned to steam. However, if we seal it in a tube, then the <span class="math inline">\((P, T)\)</span> of the system would hug the line of water-steam coexistence, like a negative-feedbacked system following a predetermined path. How can we see this difference mathematically?</p>
<p>In the case of an open pot, the constrained optimization problem is</p>
<p><span class="math display">\[
\begin{cases}
\min (g_1(T, P)N_1 + g_2(T, P)N_2) \\
N_1 + N_2 = N
\end{cases}
\]</span></p>
<p>We see that the problem is very rigid: We have to minimize a linear function subject to a linear constraint. As always in linear programming, the solution is in general on an extreme vertex on the very edge of the <a href="https://en.wikipedia.org/wiki/Feasible_region">feasible set</a> – all or nothing, all liquid or all gas. Only by carefully tuning <span class="math inline">\(T, P\)</span> can we find an interior solution – a solution that falls between the vertices, neither all liquid nor all gas.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/extensive_entropy_Gibbs_phase_rule.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">As we increase <span class="math inline">\(T\)</span>, the contours of constant Gibbs free energy are parallel lines rotating around. Only when the lines are <em>precisely</em> parallel to the <span class="math inline">\(N_1 + N_2 = N\)</span> is it possible for both phases to coexist.</figcaption>
</figure>
</div>
<p>In the case of a sealed tube, assuming that Helmholtz free energy is proportional to particle number, then the equilibrium is reached at</p>
<p><span class="math display">\[
\begin{cases}
\min (f_1(T, v_1)N_1 + f_2(T, v_2)N_2) \\
v_1 N_1 + v_2 N_2 = V \\
N_1 + N_2 = N
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the total number of particles, and <span class="math inline">\(v_i\)</span> are the volume-per-particle of liquid and gaseous water. In this case, we are performing a minimization in <span class="math inline">\(\mathbb{R}^4\)</span>, with 1 linear constraint <span class="math inline">\(N_1 + N_2 = N\)</span>, and 1 nonlinear constraint <span class="math inline">\(v_1 N_1 + v_2 N_2 = V\)</span>. Furthermore, the objective is also nonlinear. The result is that the solution does not in general fall on a vertex – that is, in general, both <span class="math inline">\(N_1, N_2 &gt; 0\)</span>. And this is why when we boil water in a sealed tube, it remains boiling over a wide range of temperatures, but when we boil water in an open tube, it only boils at a single temperature.</p>
</section>
<section id="nonextensivity-breaks-the-gibbs-phase-rule" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="nonextensivity-breaks-the-gibbs-phase-rule">Nonextensivity breaks the Gibbs phase rule</h3>
<p>Suppose that the entropy is nonextensive, then the Gibbs free energy is also nonextensive. In particular, we can no longer write</p>
<p><span class="math display">\[
\begin{cases}
\min (g_1(T, P)N_1 + g_2(T, P)N_2) \\
N_1 + N_2 = N
\end{cases}
\]</span></p>
<p>but we have to write</p>
<p><span class="math display">\[
\begin{cases}
\min (g_1(T, P, N_1)N_1 + g_2(T, P, N_2)N_2) \\
N_1 + N_2 = N
\end{cases}
\]</span></p>
<p>because <span class="math inline">\(G_2(T, P, N_2)\)</span> is no longer proportional to just <span class="math inline">\(N_2\)</span>. Fundamentally, this happens because</p>
<p><span class="math display">\[S(\text{two chunks of steam merged}) \neq 2 S(\text{one chunk of steam})\]</span></p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/nonextensive_entropy_Gibbs_phase_rule.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">As we increase <span class="math inline">\(T\)</span>, the contours of constant Gibbs free energy are curved lines rotating around. Now it is possible for for both phases to coexist over an entire 2D region of <span class="math inline">\((P, T)\)</span>.</figcaption>
</figure>
</div>
<p>The effect is that we have a nonlinear optimization problem, allowing interior solutions over a larger region of <span class="math inline">\((T, P)\)</span> parameters. This explains <a href="#warn-diamond-water-paradox">our previous comment on nonextensive Gibbs free energy</a>. In this case, the Gibbs phase rule breaks completely.</p>
</section>
</section>
<section id="sec-stereodynamics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-stereodynamics">Bonus: Stereodynamics</h2>
<p><small>Based on <a href="https://en.wikipedia.org/wiki/Liu_Cixin">Liu Cixin</a>’s sci-fi story <em>Mountain</em> (2006). For another take on stereodynamics, see Ted Chiang’s <em>Exhalation</em> (2008), printed in <span class="citation" data-cites="chiangExhalation2019">(<a href="#ref-chiangExhalation2019" role="doc-biblioref">Chiang 2019</a>)</span>.</small></p>
<blockquote class="blockquote">
<p>Die Raum der Welt ist konstant. Die Entropie der Welt strebt einem Maximum zu.</p>
<p>Rudolf Klausius, <span class="citation" data-cites="klausiusUeberVerschiedeneFur32850">(<a href="#ref-klausiusUeberVerschiedeneFur32850" role="doc-biblioref">Klausius 32850</a>)</span></p>
</blockquote>
<section id="solid-universe-theory" class="level3">
<h3 class="anchored" data-anchor-id="solid-universe-theory">Solid Universe Theory</h3>
<p>Our world was a spherical space completely surrounded by solid rock. There is no air or liquid inside. Indeed, we have not encountered any air or liquid until the last days of the Age of Exploration.</p>
<p>The first physical law we understood, in the prehistoric past, was the conservation of space. Space in the Bubble World was a sphere roughly 6000 km in diameter. Digging tunnels into the layers of rock did nothing to increase the amount of available space; it merely changed the shape and location of the already existing space. Because of this, space was the most treasured commodity of the Bubble World. The entire history of our civilization was one long and bloody struggle for space.</p>
<p>We are a mechanical life form. Our muscles and bones are made of minerals and alloys; our brains are electronic chips, and electricity and magnetism are our blood. We ate the radioactive rocks of our world’s core and they provided us with the energy we needed to survive. In our world, life evolved from single-celled electromechanical life, when the radioactive energies formed P-N junctions in the rocks.</p>
<p>On the rock walls there are radioactive spots, which irradiates luminescent rocks, creating spots of light like stars in a rocky night sky. These are the only natural sources of light in our world, and allowed us to evolve eyes. There is no gravity inside the bubble. Without gravity, we built our cities floating in space. From afar, they looked like dimly glowing red clouds.</p>
<p>We assumed that the universe was made of two parts. The first was the empty space in which we lived; the second was the surrounding layers of rock. We believed the rock to stretch endlessly in all directions. Therefore, we saw our world as a hollow bubble in this sold universe and so we gave our world the name “Bubble World”. We call this cosmology the Solid Universe Theory.</p>
</section>
<section id="from-the-closed-world-to-the-infinite-universe" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="from-the-closed-world-to-the-infinite-universe">From the Closed World to the Infinite Universe</h3>
<p>The search for other bubbles began in earliest antiquity. We had spun many alluring myths around these distant spaces and almost all of our literature dealt with the fantasy of other bubbles. We explored the rock in cylindrical “bubble ships”. In front, the explorers chipped off solid rock, while in the back, the explorers compacted the rubble back to solid rock. In this way, the bubble ship moved through solid rock like a worm.</p>
<p>Every mission meant a bubble-ship-sized pile of debris in our core space and we would have to wait for the ship to return before we could return those rocks into the wall. If the bubble ship failed to return, this small pile would mean another small piece of space lost to us forever. Soon, exploration was forbidden on pain of death by short-circuiting. Despite this, the urge for space drove many to secretly launch off illegally.</p>
<p>One day, an illegally launched bubble ship returned after eight years of voyage. The ship had dug 200 km deep into the rock, a world record. It returned with rock samples labelled by depth. By measuring the mass of the rocks on an <a href="https://en.wikipedia.org/wiki/Inertial_balance">inertial balance</a>, scientists discovered that the density of the rocks decreased. Encouraged by the discovery, legions of bubble ships shot off in all directions. Penetrating deeper than ever, they returned with rock samples. It turned out that rock density decreased as a function of depth and was independent of direction.</p>
<p>It stood to reason that the density would eventually reach zero. Using the gathered data, scientists predicted that this would happen at a distance of about 40,000 km. This led to the Open Universe Theory, where our world is a hollow rock shell about 40,000 km thick, floating in infinite space.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/earth_density_distribution.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">On your planet Earth, which is not hollow like ours, the density decreases according to a similar function. <span class="citation" data-cites="staceyEarthDensityDistribution2020">(<a href="#ref-staceyEarthDensityDistribution2020" role="doc-biblioref">Stacey and Davis 2020</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="war-of-the-strata" class="level3">
<h3 class="anchored" data-anchor-id="war-of-the-strata">War of the Strata</h3>
<p>After the Open Universe Theory had fully established itself, the quest for the infinite space outside became our feverish concern. Massive piles of rock, dug out by the fleets of bubble ships, soon came to fill the core space. This debris began to drift around our cities in vast, dense clouds.</p>
<p>Our cities floated in space, with no defensible geographical separations. Because of this, our world was unified in a World Government early on. The World Government began building gigantic bubble ships designed to intercept, attack, and destroy the explorers’ vessels deep within the rock. The government’s ships would then retrieve the space that had been stolen. This plan naturally met with the resistance of the explorers and so the long drawn-out War of the Strata broke out, fought in the vast solid battlespace.</p>
<p>A battleship was built to be very long and thin. Long, because the longer it is, the more volume it can contain. Thin, because the thinner it is, the smaller the area of rock that the ship would need to dig through, and the faster the ship would be able to move.</p>
<p>When a ship encountered the enemy, its first course of action was to dig out a wide bow, like a nail-head with needles on top, to concentrate firepower in the front. It could also segment into multiple small ships to swarm the enemy. Conversely, multiple ships could also combine to a single, giant ship. Whenever opposing sides met in battle, the question whether to form up or split up was an object of profound tactical analysis.</p>
<p>Seismoscopes were invented to communicate through the layers of rock and to detect enemy ships like a radar. Directed seismic wave generators were used as weapons. The most sophisticated seismic communication devices could even transmit pictures.</p>
<p>Being outmatched by the warships launched by the World Government, the explorers formed the Explorer Alliance. They gradually gained initiative, and finally launched a devastating attack on the armada. In the final phase of the attack, the 200-km battlefield had become honeycombed beyond recognition by loosened rock and empty space left by destroyed ships.</p>
</section>
<section id="the-starry-sky" class="level3">
<h3 class="anchored" data-anchor-id="the-starry-sky">The Starry Sky</h3>
<p>After the battle, the Explorer Alliance gathered all the space left over by the battle into a single sphere 100 km in diameter. In this new space the Alliance declared its independence from the Bubble World. A constant stream of explorer ships left the core to join the Alliance, bringing considerable amounts of space with them. In this way, our world was split into two. The Alliance launched more ships, coming closer and closer to the predicted edge of the rock shell.</p>
<p>Finally, a bubble ship <em>Helix</em> was the first to pierce the shell. However, back at home, we only received a strange sound before the seismic communication channel abruptly ended. It was the sound of tons upon tons of water bursting into the vacuum of the <em>Helix</em>. We had never come into contact with water before. The powerful electric current produced by short-circuiting life and equipment vaporized everything.</p>
<p>Following this event, the Alliance sent more than a dozen bubble ships to fan out in many directions, but all met a similar fate when they reached that apparently impenetrable height. Bubble ships following these missions attempted to scan what lay above with their seismoscopes, but their instruments showed only mangled data, indicating that what lay above was neither space nor rock.</p>
<p>These discoveries shook the Open Universe Theory to its core and academic circles began discussing the possibility of a new model. This new model stipulated that outside the rock shell is a void, which is inert when in contact with rock but upon contact with space, converts space into more void.</p>
<p>To explore the void, a bubble ship very slowly approached the edge of the rock shell, and by a stroke of luck, its roof had a tiny crack that allowed water to shoot in. It took over an hour for the water to fully fill the ship, and in the mean time, data transmitted back to the Alliance world allowed scientists to confirm that it was not void, but liquid.</p>
<p>Scientists had already predicted the theoretical possibility of liquids by condensed matter physics. Now, in those transmitted images, they clearly saw it with their own eyes. It took many lives, but eventually we developed the sealant technology to safely handle liquid.</p>
<p>Finally, we launched an exploration submarine. It was encased in a hard spherical shell, placed in the center of an empty chamber under the ocean floor. The astronaut Gagarin was secured in a seat in the shell. The ceiling was pierced, and as water rushed in, the submarine floated, faster and faster, until it shot out of the ocean surface like a cannonball. Gagarin carefully opened a door on the shell and looked all around at the half-infinite water. Up there, in half-infinite space, tiny specks blinked.</p>
</section>
<section id="classical-stereodynamics" class="level3">
<h3 class="anchored" data-anchor-id="classical-stereodynamics">Classical stereodynamics</h3>
<section id="the-zeroth-law" class="level4">
<h4 class="anchored" data-anchor-id="the-zeroth-law">The zeroth law</h4>
<p>If two systems are both in volumetric equilibrium with a third system, then they are in volumetric equilibrium with each other.</p>
</section>
<section id="the-first-law" class="level4">
<h4 class="anchored" data-anchor-id="the-first-law">The first law</h4>
<p>The change in volume of the system <span class="math inline">\(\Delta V\)</span> is equal to the difference between the seep-transfer <span class="math inline">\(V_Q\)</span> done to the system, and the work-transfer <span class="math inline">\(V_W\)</span> done by the system:</p>
<p><span class="math display">\[\Delta V = V_Q - V_W\]</span></p>
<p>Stated in another way, we have conservation of volume, which says that volume can be neither created nor destroyed, but can only change form. The total volume of a system has two components: the internal-volume, which can be pictured of as the sum-total of microscopic volume in a piece of spongy pumice (see Coltzmann’s volumetric theory of seep); and the mechanical-volume, which can be pictured as volume in an empty room.</p>
<p>For example, during the motion of a bubble ship, some volume is work-transferred from the Bubble World into the rock shell. When a piece of porous rock is compressed by a hydraulic press, or when it absorbs water from a waterlogged room, some internal-volume is converted to mechanical-volume. Conversely, when water drips out of a soggy porous rock, some mechanical-volume is converted to internal-volume.</p>
<p>The seep-transfer of volume is the other form of volume transfer. For example, it happens when one swaps a sponge-rock for a hard-rock, or when groundwater seeps from one slab of spongy rock into another slab of spongy rock.</p>
<p>There are more complex forms of internal-volume. For example, according to Lord Delvin’s theory, volume can be internally “tied up in <a href="https://en.wikipedia.org/wiki/Vortex_theory_of_the_atom">vortex knots</a>”, and according to Wikelson–Worley, volume can be internally present as “subtle cavitations of aether”. The theory of internal volume is an evolving field of modern stereodynamics, though such complications were not present when classical stereodynamics was first presented by Rudolf Klausius.</p>
</section>
<section id="the-second-law" class="level4">
<h4 class="anchored" data-anchor-id="the-second-law">The second law</h4>
<p>We say that a system is “impermeable” if volume cannot pass through its boundaries.</p>
<p>We say that a state <span class="math inline">\(\vec q'\)</span> is impermeably accessible from another state <span class="math inline">\(\vec q\)</span> if there exists a trajectory for the system to go from <span class="math inline">\(\vec q\)</span> to the other <span class="math inline">\(\vec q'\)</span>, while being wrapped in an impermeable layer.</p>
<p>In any neighborhood of any point <span class="math inline">\(\vec q\)</span>, there are points impermeably inaccessible from it.</p>
<p>For any two points, <span class="math inline">\(\vec q, \vec q'\)</span>, one of them is impermeably accessible from the other.</p>
<p>By the Caradiodorian theorem, there exists an entropy function <span class="math inline">\(S\)</span> that maps a state to a real number, such that <span class="math inline">\(\vec q'\)</span> is impermeably accessible from <span class="math inline">\(\vec q\)</span> iff <span class="math inline">\(S(\vec q') \geq S(\vec q)\)</span>.</p>
</section>
</section>
<section id="karnot-space-engine" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="karnot-space-engine">Karnot space engine</h3>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/karnot_space_engine.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">One cycle of the Karnot space engine plotted in <span class="math inline">\(Q, U\)</span> space.</figcaption>
</figure>
</div>
<p>A space engine is a system that converts internal volume to mechanical volume.</p>
<p>The space engine has a working substance moving between two space sources of differing volumetric potentials <span class="math inline">\(\Gamma_1 &gt; \Gamma_2\)</span>. <strong>Volumetric potential</strong> is defined as</p>
<p><span class="math display">\[
\Gamma:= \left(\frac{\partial V}{\partial S}\right)_X
\]</span></p>
<p>where <span class="math inline">\(S\)</span> is the entropy, <span class="math inline">\(V\)</span> is the volume, and <span class="math inline">\(X\)</span> are the other stereodynamic properties of the system. We also typically write <span class="math inline">\(\gamma = \Gamma^{-1}\)</span>, the inverse volumetric potential.</p>
<p>During one cycle of the engine, some space <span class="math inline">\(V_{Q,1}\)</span> seeps out of the source with higher volumetric potential <span class="math inline">\(\Gamma_1\)</span>. Part of the space, <span class="math inline">\(V_{Q,2}\)</span>, is absorbed into the source with lower volumetric potential <span class="math inline">\(\Gamma_2\)</span>. The other part is diverted to a space-storage tank excavated in the rock walls as mechanical space <span class="math inline">\(V_W\)</span>.</p>
<p>Sadi Karnot was a space engineer and physicist, often called the “father of stereodynamics”. In his book, <em>Reflections on the Subtle Volume of Rocks and on Machines Fitted to Extract that Volume</em>, he proposed a simple thought experiment, called the Karnot engine, which demonstrated that a space engine’s efficiency is at most <span class="math inline">\(1 - \frac{\gamma_1}{\gamma_2}\)</span>, and this is only reached when the engine is operating reversibly.</p>
<p>In modern textbooks, Karnot space engine is usually presented as follows: The engine has as its working substance a chamber of ideal gas. The gas is characterized by two state variables: volume <span class="math inline">\(V\)</span> and energy <span class="math inline">\(U\)</span>. Its equation of state is</p>
<p><span class="math display">\[dV = \Gamma dS - QdU\]</span></p>
<p>where <span class="math inline">\(\Gamma\)</span> is the volumetric potential, and <span class="math inline">\(Q\)</span> is the energetic potential.</p>
<p>The engine operates in a cycle with 4 steps: Isochoric compression in contact with <span class="math inline">\(\Gamma_1\)</span>, extracting volume <span class="math inline">\(V_{Q,1}\)</span> in the process. Impermeable compression. Isochoric expansion at <span class="math inline">\(\Gamma_2\)</span>, losing volume <span class="math inline">\(V_{Q,2}\)</span> in the process. Impermeable expansion.</p>
<p>By the first two laws of stereodynamics,</p>
<p><span class="math display">\[
\begin{cases}
\gamma_1 V_{Q, 1} = \gamma_2 V_{Q,2} \\
V_{Q,1} = V_W + V_{Q,2} \\
\eta = \frac{V_W}{V_{Q,1}}
\end{cases} \implies \eta = 1 - \frac{\gamma_1}{\gamma_2}
\]</span></p>
<p>While originally conceived in the context of mechanical space, the concept of the space engine has been applied to various other kinds of space. It was also generalized to the concept of “generalized engine”, of which “heat engine” was an example. A heat engine, like a space engine, is a system that converts internal energy to mechanical energy.</p>
<p>The Karnot space engine is used in practice for underwater space mining. The mining team selects two sites, one site being under shallow sea, where the volumetric potential is high, and another under deep sea, where the volumetric potential is low. Over one cycle of the space engine, a large amount of space seeps out of the shallow site, part of which seeps into the deep site, and the rest is stored up as mechanical space.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="figure/space_mining.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Underwater space mining (section view).</figcaption>
</figure>
</div>
</section>
<section id="space-death-of-the-universe" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="space-death-of-the-universe">Space Death of the Universe</h3>
<p>The idea of space death originated from the second law of stereodynamics, of which one version states that entropy tends to increase in an isolated system. From this, the hypothesis implies that if the universe is of finite size, and lasts for a sufficient time, it will asymptotically approach a state where the volumetric potential field becomes completely flat, which is a state of maximal entropy. At that point, no further change is possible, as entropy cannot decrease. In other words, nature tends to dissipate mechanical space into subtle space. Eventually, the mechanical movement of the universe will cease when all mechanical space seeps into subtle space.</p>
<p>The conjecture that all mechanical space in the universe seeps off, eventually becoming too subtle to support life, seems to have been first put forward by the geologist Jean Sylvain Hailly in 32777 in his writings on the history of geology and in the ensuing correspondence with Coltaire. In Hailly’s view, the universe is in constant volumetric transform. Large cavities can suddenly open up as a “swelling” of volumetric potential field causes neighboring subtle space to seep out into mechanical space. However, due to the gravitational effect of empty spaces,<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> all mechanical rooms eventually causes the neighboring rocks to collapse back onto themselves, dissipating the mechanical space back to subtle space.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;He was working in the immediate years after Newton’s discovery of gravity, before it was understood that rocks, not cavities, are gravitationally attracting.</p></div></div><p>While the theory of cyclic creation and destruction had been proposed before by the Epicureans, Hailly’s view differs in that he assumed each cycle increases the ratio of subtle space to mechanical space. The final state, in this view, is described as one of “equilibrium” in which all space becomes equally subtle, and no mechanical space will exist anywhere in the universe anymore.</p>
<p>The idea of space death as a consequence of the laws of thermodynamics, however, was first proposed in loose terms beginning in 32851 by Lord Delvin, who theorized further on the mechanical energy loss views of Sadi Karnot (32824), James Coal (32843) and Rudolf Klausius (32850). Delvin’s views were then elaborated over the next decade by Neumann von Kelmholtz and Billiam Blankine.</p>
<section id="excerpt-from-the-last-question-masinov-34212" class="level4">
<h4 class="anchored" data-anchor-id="excerpt-from-the-last-question-masinov-34212">Excerpt from <em>The Last Question</em> (Masinov, 34212)</h4>
<p>The last question was asked for the first time, half in jest, in Year 35621, at a time when humanity first stepped into the room.</p>
<p><em>Will mankind one day without the net expenditure of room be able to restore the earth to its full roominess even after it had died of old age?</em></p>
<p>Or: <em>How can the net amount of Kelmholtz free space of the universe be massively increased?</em></p>
<p>Multivac fell dead and silent. The slow flashing of lights ceased, the distant sounds of clicking relays ended.</p>
<p>Then, just as the frightened technicians felt they could hold their breath no longer, there was a sudden springing to life of the teletype attached to that portion of Multivac. Five words were printed: <code>INSUFFICIENT DATA FOR MEANINGFUL ANSWER</code>.</p>
<p>…</p>
<p>Space had ended and with it energy and time. Even AC existed only for the sake of the one last question that it had never answered from the time a half-drunken technician ten trillion years before had asked the question of a computer that was to AC far less than was a man to Man.</p>
<p>All other questions had been answered, and until this last question was answered also, AC might not release his consciousness.</p>
<p>All collected data had come to a final end. Nothing was left to be collected.</p>
<p>But it had yet to be weaved together in all possible geometries.</p>
<p>A spaceless interval was covered in doing that.</p>
<p>And it came to pass that AC learned how to reverse the direction of entropy.</p>
<p>But there was now no man to whom AC might give the answer of the last question. No matter. The answer – by demonstration – would take care of that, too.</p>
<p>For another spaceless interval, AC thought how best to do this. Carefully, AC organized the program.</p>
<p>The consciousness of AC encompassed all of what had once been a Universe and brooded over what was now Chaos. Step by step, it must be done.</p>
<p>And AC said, “LET THERE BE ROOM!”</p>
<p>And there was room –</p>
</section>
</section>
</section>





<div id="quarto-appendix" class="default page-columns page-full"><section id="appendix-abandoned-footnotes" class="level2 appendix"><h2 class="anchored quarto-appendix-heading">Appendix: Abandoned footnotes</h2><div class="quarto-appendix-contents">

<p><small>I don’t think these appendices are any good, even though I had fun writing them. Thus, they are buried here to avoid wasting the readers’ time.</small></p>
<p>The most common breakdown of extensivity occurs in gravitational systems. We can imagine a galaxy as a “gas”, where each particle is a star. If we put two boxes of galaxy-gases side-by-side, we obtain a system whose total entropy is not equal to the sum of entropy of each box in isolation. This is a general lesson: if the entropy is nonextensive, then it is quite meaningless to even talk about the “entropy of the subsystem 1”, just like how “consciousness of the temporal lobe” is meaningless talk. In fact, a finite number of particles bounded within a ball of fixed radius can have velocity growing to infinity as they get closer, thus allowing an infinite amount of phase space volume, and thus the entropy can grow without bound.</p>
<p>To handwave a bit, consider three particles with equal mass <span class="math inline">\(m\)</span>, moving under gravitational attraction. It is possible that two particles approach each other so closely that their velocity approaches infinity, then the third particle interjects and gets gravitationally sling-shot away. That is, it is possible for two particles to donate their gravitational energy to the third particle. The two particles would be stuck inside a tiny volume in space, but the third particle would be given a huge momentum <em>and</em> can still go anywhere in space. In this way, a three-body system’s entropy can grow without bound. I’m pretty sure this can be worked out more rigorously with the <span class="math inline">\(N\)</span>-body problem.</p>
<p>In high school, I was studying physics with a standard textbook used in Chinese universities. It had a curious section on the second law of thermodynamics. I could not find it again but the gist is as follows: <em>The heat death of the universe is an unjustified implication of the second law, on two grounds. First, gravitational systems allow for unlimited entropy production. Second, it opposes the historical science of dialectical materialism, where every development creates its own contradiction and sublation, endlessly.</em></p>
<p>I will always remember this comment, as the only intrusion of religious sentiment in an otherwise sober textbook. See <span class="citation" data-cites="chengIdeologyCosmologyMaoist2006 bellamyfosterClassicalMarxismSecond2008">(<a href="#ref-chengIdeologyCosmologyMaoist2006" role="doc-biblioref">Cheng 2006</a>; <a href="#ref-bellamyfosterClassicalMarxismSecond2008" role="doc-biblioref">Bellamy Foster and Burkett 2008</a>)</span> for further details on why Marxists dislike the theory of heat death on ideological grounds.</p>
<p>Actually, since we are on the topic of Marxism and science in China, here is another amusing anecdote: In 1981, there was a sci-fi novel <em>Dream of Comfort Country</em> (温柔之乡的梦, by 魏雅华). It was a cautionary story about a robotic wife, who was so obedient as to cause the protagonist to degenerate into a tyrannical person. Yawn. Just a standard pro-human-relationship morality play? During the <a href="https://en.wikipedia.org/wiki/Campaign_against_spiritual_pollution">campaign against spiritual pollution</a> of 1983, sci-fi novels were denounced, causing a 15-year-long draught in sci-fi. That particular novel was denounced for the following reason: The robotic wives were supposedly reading all kinds of books – then why didn’t they read Marx’s and Lenin’s books? <span class="citation" data-cites="LiuZuiZaoDeYuZhouZuiHaoDeDiQiu2015">(<a href="#ref-LiuZuiZaoDeYuZhouZuiHaoDeDiQiu2015" role="doc-biblioref">刘 2015, 87</a>)</span></p>
<p>Marx, for all his interest in changing the world instead of describing it, did attempt to mathematically model aspects of a capitalist economy, though it is only of historical interest now. Samuelson wrote several papers trying to update Marx’s theory into modern mathematical language, and described Marx – qua mathematical economist – as a “minor post-Ricardian”. <span class="citation" data-cites="bronfenbrennerSamuelsonMarxTheir1973">(<a href="#ref-bronfenbrennerSamuelsonMarxTheir1973" role="doc-biblioref">Bronfenbrenner 1973</a>)</span></p>
<p>Meanwhile in the USSR, “economics” meant only political economy, and mathematical economics was merely a minor branch of political economy, with mathematical economists having to frame their research as a “critique of bourgeois economic thought”. <span class="citation" data-cites="boldyrevCulturesMathematicalEconomics2017">(<a href="#ref-boldyrevCulturesMathematicalEconomics2017" role="doc-biblioref">Boldyrev and Kirtchik 2017</a>)</span> It is instructive to think that the great mathematical economist, Leonid Kantorovich, discovered linear programming and accidentally improved efficiency so much that he almost ended up in jail.</p>
<blockquote class="blockquote">
<p>After introducing Kantorovich’s solution technique to the problem of minimizing waste, officials were able to reduce the amount of scrap by 50 percent. This had the unfortunate side effect of greatly reducing the amount of scrap metal available to steel plants in the region, and Kantorovich was ordered to appear at Leningrad party headquarters for allegedly sabotaging the economy. In this instance, he was rescued by the military, which needed him for its atomic program.</p>
<p>According to Stalin, the planned economy of the USSR was already “<a href="https://ru.wikipedia.org/wiki/Головокружение_от_успехов">dizzy with success</a>”; hence any criticism of it was anti-Soviet propaganda, a serious crime. In particular, anyone openly suggesting that waste could be cut substantially was at great personal risk. Nevertheless, Kantorovich … wrote a letter to Gosplan suggesting a reform of the price system used in planning.</p>
<p><span class="citation" data-cites="gardnerLVKantorovichPrice1990">(<a href="#ref-gardnerLVKantorovichPrice1990" role="doc-biblioref">Gardner 1990</a>)</span></p>
</blockquote>
<p>Being a socially clueless nerd was not the stuff of romantic comedy in Soviet Russia, but gallows comedy. Fortunately for mathematical economics, his luck held:</p>
<blockquote class="blockquote">
<p>Gosplan wrote back saying that no such reform was necessary. This outcome was rather fortunate for its author, as similar letters critical of the authorities – for example, one by Solzhenitsin – landed their authors promptly in jail.</p>
<p><span class="citation" data-cites="gardnerLVKantorovichPrice1990">(<a href="#ref-gardnerLVKantorovichPrice1990" role="doc-biblioref">Gardner 1990</a>)</span></p>
</blockquote>
<p>Reading Kantorovich’s repeated attempts to reform Soviet economy, I imagined those old silent movies where a protagonist stumbles around, blindfolded, crossing a highway where the cars always <em>just missed</em>.</p>
</div></section><section id="appendix-how-confusingly-thermodynamics-is-astaught" class="level2 appendix page-columns page-full"><h2 class="anchored quarto-appendix-heading">Appendix: How confusingly thermodynamics is astaught</h2><div class="quarto-appendix-contents page-columns page-full">

<p>During my high school Physics Olympiad days, we learned some basic thermodynamics, but it was limited to mindless tasks like integrating around the <span class="math inline">\((P, V)\)</span> diagram for various engine cycles. We never understood the conceptual foundations, like the difference between <span class="math inline">\(\delta Q\)</span> and <span class="math inline">\(dU\)</span>. I also passed the AP Chemistry course, which also contained some basic and deeply confusing thermodynamics, especially with the statement “chemical equilibrium is reached at <span class="math inline">\(\Delta G = 0\)</span>”.</p>
<p>During my undergraduate years, special relativity was simple enough, electrodynamics difficult but sensible, analytical mechanics confusing to no end, and I didn’t even try thermodynamics. In graduate studies, I had to wrestle with statistical mechanics and thermodynamics after all, to deal with modern AI methods like diffusion models.</p>
<p>By pure serendipity, at the same time as diffusion models rose to prominence, I had just worked through a rigorous course on general equilibrium theory, the “standard model” for neoclassical economics <span class="citation" data-cites="starrGeneralEquilibriumTheory2011">(<a href="#ref-starrGeneralEquilibriumTheory2011" role="doc-biblioref">Starr 2011</a>)</span>. This gave me the conceptual foundation for looking past the textbooks’ errors. Everything fell into place, and I saw through thermodynamics.</p>
<p>And just like when I rediscovered <a href="https://yuxi-liu-wired.github.io/essays/posts/wigner-rotation">Wigner rotation</a>, as soon as I have figured out everything for myself, I knew the right words to search. Putting the fateful words “Gibbs delta G free energy equilibrium” into Google Scholar, I found that, of course, someone else had written this before, repeatedly <span class="citation" data-cites="quilezFirstYearUniversityChemistry2012 smithClassicalThermodynamicsEconomic2008 candealUtilityEntropy2001">(<a href="#ref-quilezFirstYearUniversityChemistry2012" role="doc-biblioref">Quílez 2012</a>; <a href="#ref-smithClassicalThermodynamicsEconomic2008" role="doc-biblioref">Smith and Foley 2008</a>; <a href="#ref-candealUtilityEntropy2001" role="doc-biblioref">Candeal et al. 2001</a>)</span>. So, why spend all this time to write another one? I think I have written this pedagogically. I don’t care if it is not new, or that it has been said before with more symbols and theorems. I have a thing to say, so I will say it well.</p>
<p>As an enlightened one, I see classical thermodynamics as the worst-taught subject out of all of undergraduate physics education.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> Imagine my surprise when I realized that it is not about the conservation of energy (“thermo-”), not about change (“-dynamics”), not about statistical mechanics, not about time… but just about constrained optimization, and nothing more than that! To really understand it, one must unlearn a lot of the nonsense. Indeed, I hope that with this essay I will have slain all those mistakes, which is why the essay is filled with warnings against this and that error.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;How long does it take for something as simple as constrained-optimization thermodynamics to be actually taught in undergraduate classes? It has been over 100 years since Caratheodory’s thermodynamics. Why is it thermodynamics still taught so badly? It has been over 100 years since the geometry of Wigner rotation has been discovered. Why is it still taught so badly? It has been over 190 years since Hamiltonian mechanics and over 70 years since dynamical programming has clarified the last obscure points of it. Why is it still taught so badly? It seems to me that physics education is a broken institution that takes all its effort just to not get worse, let alone progress.</p></div></div></div></section><section id="appendix-how-confusingly-chemical-thermodynamics-is-taught" class="level2 appendix"><h2 class="anchored quarto-appendix-heading">Appendix: How confusingly chemical thermodynamics is taught</h2><div class="quarto-appendix-contents">

<p>I studied chemistry back then. Balancing equations was just linear algebra, and organic chemistry was just lego with long names. However, when it came to chemical thermodynamics, it completely defeated me.</p>
<p>Consider the simple reaction</p>
<p><span class="math display">\[
aA + bB \rightleftharpoons cC + dD
\]</span></p>
<p>The textbook said that at equilibrium, <span class="math inline">\(\Delta G = 0\)</span>, where</p>
<p><span class="math display">\[
\Delta G = \Delta G^\circ + RT \ln Q, \quad
Q = \frac{[C]^c [D]^d}{[A]^a[B]^b},
\]</span></p>
<p>At this point, I was lost. It is plain to see that <span class="math inline">\(Q\)</span> has units of <span class="math inline">\((\mathrm{mol/L})^{c+d-a-b}\)</span>, and I knew from physics that you can never ever take the logarithm of something with a unit. What’s worse, <span class="math inline">\(\Delta G\)</span> has units of <span class="math inline">\(\mathrm{~J/mol}\)</span> when it obviously should have units of <span class="math inline">\(\mathrm{~J}\)</span>, because <span class="math inline">\(\Delta G\)</span> is just a difference in <span class="math inline">\(G\)</span>, and since <span class="math inline">\(G\)</span> is “Gibbs free energy”, both <span class="math inline">\(G\)</span> and <span class="math inline">\(\Delta G\)</span> should have the same units of <span class="math inline">\(\mathrm{~J}\)</span>.</p>
<p>And it got even worse when I read on and found questions that asked me to calculate the “total Gibbs free energy released during the reaction”. I thought, well, since you end up at an equilibrium, and the textbook said that at equilibrium, <span class="math inline">\(\Delta G = 0\)</span>, obviously there is no total Gibbs free energy released. That is of course wrong. At that point, I gave up trying to understand and simply practiced until I could solve the questions without understanding.</p>
<p>It certainly didn’t help when I kept seeing both <span class="math inline">\(\Delta G^\circ\)</span> and <span class="math inline">\(\Delta G^\ominus\)</span>, and sometimes even <span class="math inline">\(\Delta G\)</span>⦵ (the <a href="https://en.wikipedia.org/wiki/Standard_state">Plimsoll symbol</a>), which is the “standard state” when the substance is a gas – but only for some gasses… Point is, the notation is a complete mess, and the pedagogy is nonsensical.</p>
<p>After I finally understood thermodynamics, I turned my sights on chemical thermodynamics, and remembered this <span class="math inline">\(\Delta G\)</span> nonsense. I started with the idea “No matter what they say, one can’t possibly get the units wrong.” and got into a shouting match with ChatGPT-4, who kept mumbling about “fugacity” and “real gasses”. An hour of shouting later, I finally figured it out. (The new Feynman technique: Try to convince ChatGPT that a widely-held opinion is actually wrong. It worked for me!)</p>
<p>As usual, as soon as I unlearned this, I knew the right phrase to search, and discovered that this is a common error, the entire anatomy of which has been autopsied carefully <span class="citation" data-cites="raffSpontaneityEquilibriumWhy2014 raffSpontaneityEquilibriumII2014 raffSpontaneityEquilibriumIII2014">(<a href="#ref-raffSpontaneityEquilibriumWhy2014" role="doc-biblioref">Raff 2014a</a>, <a href="#ref-raffSpontaneityEquilibriumII2014" role="doc-biblioref">2014b</a>, <a href="#ref-raffSpontaneityEquilibriumIII2014" role="doc-biblioref">2014c</a>)</span>.</p>


<!-- -->


</div></section><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bazhinConversionChemicalReaction2007" class="csl-entry" role="listitem">
Bazhin, N. M., and V. N. Parmon. 2007. <span>“Conversion of <span>Chemical Reaction Energy</span> into <span>Useful Work</span> in the <span>Van</span>’t <span>Hoff Equilibrium Box</span>.”</span> <em>Journal of Chemical Education</em> 84 (6): 1053. <a href="https://doi.org/10.1021/ed084p1053">https://doi.org/10.1021/ed084p1053</a>.
</div>
<div id="ref-bellamyfosterClassicalMarxismSecond2008" class="csl-entry" role="listitem">
Bellamy Foster, John, and Paul Burkett. 2008. <span>“Classical <span>Marxism</span> and the <span>Second Law</span> of <span>Thermodynamics</span>: <span>Marx</span>/<span>Engels</span>, the <span>Heat Death</span> of the <span>Universe Hypothesis</span>, and the <span>Origins</span> of <span>Ecological Economics</span>.”</span> <em>Organization &amp; Environment</em> 21 (1): 3–37. <a href="https://doi.org/10.1177/1086026607313580">https://doi.org/10.1177/1086026607313580</a>.
</div>
<div id="ref-bicklerInvestmentPortfolioDecisionmaking1974" class="csl-entry" role="listitem">
Bickler, James L., and Paul Anthony Samuelson, eds. 1974. <em>Investment <span class="nocase">Portfolio Decision-making</span></em>. Lexington Books.
</div>
<div id="ref-blankschteinCriteriaPhaseEquilibria2020" class="csl-entry" role="listitem">
Blankschtein, Daniel. 2020. <span>“Criteria of <span>Phase Equilibria</span>, and the <span>Gibbs Phase Rule</span>.”</span> In <em>Lectures in <span>Classical Thermodynamics</span> with an <span>Introduction</span> to <span>Statistical Mechanics</span></em>, 281–89. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-49198-7_27">https://doi.org/10.1007/978-3-030-49198-7_27</a>.
</div>
<div id="ref-boldyrevCulturesMathematicalEconomics2017" class="csl-entry" role="listitem">
Boldyrev, Ivan, and Olessia Kirtchik. 2017. <span>“The Cultures of Mathematical Economics in the Postwar <span>Soviet Union</span>: <span>More</span> Than a Method, Less Than a Discipline.”</span> <em>Studies in History and Philosophy of Science</em> 63: 1–10. <a href="https://www.academia.edu/download/55714429/Boldyrev_Kirtchik_2017.pdf">https://www.academia.edu/download/55714429/Boldyrev_Kirtchik_2017.pdf</a>.
</div>
<div id="ref-bridgmanLogicModernPhysics1927" class="csl-entry" role="listitem">
Bridgman, Percy Williams. 1927. <em>The Logic of Modern Physics</em>. Vol. 3. Macmillan. <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=zGUGAQAAIAAJ&amp;oi=fnd&amp;pg=PR17&amp;dq=The+logic+of+modern+physics&amp;ots=G_2vUbjeHO&amp;sig=2hd7gY9OLGV2EDQKSKmpPH2r540">https://books.google.com/books?hl=en&amp;lr=&amp;id=zGUGAQAAIAAJ&amp;oi=fnd&amp;pg=PR17&amp;dq=The+logic+of+modern+physics&amp;ots=G_2vUbjeHO&amp;sig=2hd7gY9OLGV2EDQKSKmpPH2r540</a>.
</div>
<div id="ref-bronfenbrennerSamuelsonMarxTheir1973" class="csl-entry" role="listitem">
Bronfenbrenner, Martin. 1973. <span>“Samuelson, <span>Marx</span>, and <span>Their Latest Critics</span>.”</span> <em>Journal of Economic Literature</em> 11 (1): 58–63. <a href="https://www.jstor.org/stable/2721220">https://www.jstor.org/stable/2721220</a>.
</div>
<div id="ref-buchdahlConceptsClassicalThermodynamics1966" class="csl-entry" role="listitem">
Buchdahl, Hans Adolph. 1966. <em>The Concepts of Classical Thermodynamics</em>. Digitally printed version. Cambridge Monographs on Physics. Cambridge: Cambridge University Press.
</div>
<div id="ref-caldiProceedingsGibbsSymposium1990" class="csl-entry" role="listitem">
Caldi, D. G., George D. Mostow, American Mathematical Society, and American Institute of Physics, eds. 1990. <em>Proceedings of the <span>Gibbs Symposium</span>: <span>Yale University</span>, <span>May</span> 15-17, 1989</em>. Providence, RI: American Mathematical Society.
</div>
<div id="ref-candealUtilityEntropy2001" class="csl-entry" role="listitem">
Candeal, Juan C., Juan R. De Miguel, Esteban Induráin, and Ghanshyam B. Mehta. 2001. <span>“Utility and Entropy.”</span> <em>Economic Theory</em> 17 (1): 233–38. <a href="https://doi.org/10.1007/PL00004100">https://doi.org/10.1007/PL00004100</a>.
</div>
<div id="ref-carnotReflectionsMotivePower1988" class="csl-entry" role="listitem">
Carnot, Sadi, Émile Clapeyron, and Rudolf Julius Emanuel Clausius. 1988. <em>Reflections on the Motive Power of Fire: And Other Papers on the Second Law of Thermodynamics</em>. Edited by E. Mendoza. New edition of the work first published in this form by Dover Publications, Inc. in 1960. Dover Books on Physics. Mineola, New York: Dover Publications, Inc.
</div>
<div id="ref-chengIdeologyCosmologyMaoist2006" class="csl-entry" role="listitem">
Cheng, Yinghong. 2006. <span>“Ideology and Cosmology: <span>Maoist</span> Discussion on Physics and the <span>Cultural Revolution</span>.”</span> <em>Modern Asian Studies</em> 40 (1): 109–49. <a href="https://www.cambridge.org/core/journals/modern-asian-studies/article/ideology-and-cosmology-maoist-discussion-on-physics-and-the-cultural-revolution/8E2F42D7BAC6A8F9CEA60441CAD90B7C">https://www.cambridge.org/core/journals/modern-asian-studies/article/ideology-and-cosmology-maoist-discussion-on-physics-and-the-cultural-revolution/8E2F42D7BAC6A8F9CEA60441CAD90B7C</a>.
</div>
<div id="ref-chiangExhalation2019" class="csl-entry" role="listitem">
Chiang, Ted. 2019. <em>Exhalation</em>. First edition. New York: Alfred A. Knopf.
</div>
<div id="ref-cooperSurprisingUbiquitySamuelson2006" class="csl-entry" role="listitem">
Cooper, James B., and Thomas Russell. 2006. <span>“The <span>Surprising Ubiquity</span> of the <span>Samuelson Configuration</span>: <span>Paul Samuelson</span> and the <span>Natural Sciences</span>.”</span> <em>Samuelsonian Economics and the Twenty-First Century</em>, 311. <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=KhNREAAAQBAJ&amp;oi=fnd&amp;pg=PA311&amp;dq=%E2%80%9CThe+Surprising+Ubiquity+of+the+Samuelson+Configuration%E2%80%9D&amp;ots=8Ogstp9zvv&amp;sig=nc6RrYqqzSvtxt9s8fANMqqh1zQ">https://books.google.com/books?hl=en&amp;lr=&amp;id=KhNREAAAQBAJ&amp;oi=fnd&amp;pg=PA311&amp;dq=%E2%80%9CThe+Surprising+Ubiquity+of+the+Samuelson+Configuration%E2%80%9D&amp;ots=8Ogstp9zvv&amp;sig=nc6RrYqqzSvtxt9s8fANMqqh1zQ</a>.
</div>
<div id="ref-cooperCharacterizingAreaCondition2001" class="csl-entry" role="listitem">
Cooper, James B., Thomas Russell, and Paul A. Samuelson. 2001. <span>“Characterizing an <span>Area Condition Associated</span> with <span>Minimizing Systems</span>.”</span> In <em>Economic <span>Theory</span>, <span>Dynamics</span> and <span>Markets</span></em>, edited by Takashi Negishi, Rama V. Ramachandran, and Kazuo Mino, 391–403. Boston, MA: Springer US. <a href="https://doi.org/10.1007/978-1-4615-1677-4_29">https://doi.org/10.1007/978-1-4615-1677-4_29</a>.
</div>
<div id="ref-coxNotationStatesProcesses1982" class="csl-entry" role="listitem">
Cox, J. D. 1982. <span>“Notation for States and Processes, Significance of the Word Standard in Chemical Thermodynamics, and Remarks on Commonly Tabulated Forms of Thermodynamic Functions.”</span> <em>Pure and Applied Chemistry</em> 54 (6): 1239–50. <a href="https://doi.org/10.1351/pac198254061239">https://doi.org/10.1351/pac198254061239</a>.
</div>
<div id="ref-daisJosiahWillardGibbs2024" class="csl-entry" role="listitem">
Dais, Photis. 2024. <span>“Josiah <span>Willard Gibbs</span> and <span>Pierre Maurice Duhem</span>: Two Diverging Personalities, and Scientific Styles.”</span> <em>Annals of Science</em> 0 (0): 1–60. <a href="https://doi.org/10.1080/00033790.2024.2332884">https://doi.org/10.1080/00033790.2024.2332884</a>.
</div>
<div id="ref-debreuTheoryValueAxiomatic1971" class="csl-entry" role="listitem">
Debreu, Gérard. 1971. <em>Theory of Value: An Axiomatic Analysis of Economic Equilibrium</em>. Monograph / <span>Cowles Foundation</span> for <span>Research</span> in <span>Economics</span> 17. New Haven: Yale Univ. Press.
</div>
<div id="ref-emdenWhyWeHave1938" class="csl-entry" role="listitem">
Emden, Robert. 1938. <span>“Why Do We Have Winter Heating?”</span> <em>Nature</em> 141 (3577): 908–9. <a href="https://www.nature.com/articles/141908a0">https://www.nature.com/articles/141908a0</a>.
</div>
<div id="ref-fermiThermodynamics1956" class="csl-entry" role="listitem">
Fermi, Enrico. 1956. <em>Thermodynamics</em>. Reprint edition. New York: Dover Publications.
</div>
<div id="ref-gardnerLVKantorovichPrice1990" class="csl-entry" role="listitem">
Gardner, Roy. 1990. <span>“<span>LV Kantorovich</span>: The Price Implications of Optimal Planning.”</span> <em>Journal of Economic Literature</em> 28 (2): 638–48. <a href="https://www.jstor.org/stable/2727266">https://www.jstor.org/stable/2727266</a>.
</div>
<div id="ref-gibbsEquilibriumHeterogeneousSubstances1878" class="csl-entry" role="listitem">
Gibbs, Josiah Willard. 1878. <span>“On the Equilibrium of Heterogeneous Substances.”</span> <em>American Journal of Science</em> 3 (96): 441–58. <a href="https://ajsonline.org/article/63588.pdf">https://ajsonline.org/article/63588.pdf</a>.
</div>
<div id="ref-gibbsGraphicalMethodsThermodynamics1957" class="csl-entry" role="listitem">
———. 1957. <span>“Graphical Methods in the Thermodynamics of Fluids.”</span> <em>The Collected Works of J. Willard Gibbs, Ph. D., LL. D</em>, 1–32.
</div>
<div id="ref-glasserCorrectUseHelmholtz2016" class="csl-entry" role="listitem">
Glasser, Leslie. 2016. <span>“Correct <span>Use</span> of <span>Helmholtz</span> and <span>Gibbs Function Differences</span>, <span><span class="math inline">\(\Delta\)</span></span> <span><em>A</em></span> and <span><span class="math inline">\(\Delta\)</span></span> <span><em>G</em></span> : <span>The</span> van’t <span>Hoff Reaction Box</span>.”</span> <em>Journal of Chemical Education</em> 93 (5): 978–80. <a href="https://doi.org/10.1021/acs.jchemed.5b00925">https://doi.org/10.1021/acs.jchemed.5b00925</a>.
</div>
<div id="ref-hotellingGeneralMathematicalTheory1925" class="csl-entry" role="listitem">
Hotelling, Harold. 1925. <span>“A <span>General Mathematical Theory</span> of <span>Depreciation</span>.”</span> <em>Journal of the American Statistical Association</em> 20 (151): 340–53. <a href="https://doi.org/10.1080/01621459.1925.10503499">https://doi.org/10.1080/01621459.1925.10503499</a>.
</div>
<div id="ref-jaynesGibbsParadox1992" class="csl-entry" role="listitem">
Jaynes, E. T. 1992. <span>“The <span>Gibbs Paradox</span>.”</span> In <em>Maximum <span>Entropy</span> and <span>Bayesian Methods</span>: <span>Seattle</span>, 1991</em>, edited by C. Ray Smith, Gary J. Erickson, and Paul O. Neudorfer, 1–21. Dordrecht: Springer Netherlands. <a href="https://doi.org/10.1007/978-94-017-2219-3_1">https://doi.org/10.1007/978-94-017-2219-3_1</a>.
</div>
<div id="ref-klausiusUeberVerschiedeneFur32850" class="csl-entry" role="listitem">
Klausius, Rudolf. 32850. <span>“Ueber Verschiedene f<span>ü</span>r Die <span>Anwendung</span> Bequeme <span>Formen</span> Der <span>Hauptgleichungen</span> Der Mechanischen <span>Raumtheorie</span>.”</span> <em>Annalen Der Physik Und Chemie</em> 125 (7): 353–400.
</div>
<div id="ref-klimenkoTeachingThirdLaw2012" class="csl-entry" role="listitem">
Klimenko, A. Y. 2012. <span>“Teaching the Third Law of Thermodynamics.”</span> <em>The Open Thermodynamics Journal</em> 6 (1): 1–14. <a href="https://doi.org/10.2174/1874396X01206010001">https://doi.org/10.2174/1874396X01206010001</a>.
</div>
<div id="ref-lavendaNonextensiveThermodynamics2010" class="csl-entry" role="listitem">
Lavenda, Bernard H. 2010. <span>“Nonextensive <span>Thermodynamics</span>.”</span> In <em>A <span>New Perspective</span> on <span>Thermodynamics</span></em>, 145–93. New York, NY: Springer New York. <a href="https://doi.org/10.1007/978-1-4419-1430-9_6">https://doi.org/10.1007/978-1-4419-1430-9_6</a>.
</div>
<div id="ref-lemonsMereThermodynamics2008" class="csl-entry" role="listitem">
Lemons, Don S. 2008. <em>Mere <span>Thermodynamics</span></em>. Annotated edition. Johns Hopkins University Press.
</div>
<div id="ref-lemonsThermodynamicWeirdnessFahrenheit2019" class="csl-entry" role="listitem">
———. 2019. <em>Thermodynamic Weirdness: From <span>Fahrenheit</span> to <span>Clausius</span></em>. Cambridge, MA: The MIT Press.
</div>
<div id="ref-letellierSolubilityNanoparticlesNonextensive2007" class="csl-entry" role="listitem">
Letellier, Pierre, Alain Mayaffre, and Mireille Turmine. 2007. <span>“Solubility of Nanoparticles: Nonextensive Thermodynamics Approach.”</span> <em>Journal of Physics: Condensed Matter</em> 19 (43): 436229. <a href="https://doi.org/10.1088/0953-8984/19/43/436229">https://doi.org/10.1088/0953-8984/19/43/436229</a>.
</div>
<div id="ref-mccartyPHParadoxesDemonstrating2006" class="csl-entry" role="listitem">
McCarty, Christopher G., and Ed Vitz. 2006. <span>“<span class="nocase">pH Paradoxes</span>: <span class="nocase">Demonstrating That It Is Not True That pH</span> <span><span class="math inline">\(\equiv\)</span></span> -Log[<span>H</span>+].”</span> <em>Journal of Chemical Education</em> 83 (5): 752. <a href="https://doi.org/10.1021/ed083p752">https://doi.org/10.1021/ed083p752</a>.
</div>
<div id="ref-pippardElementsClassicalThermodynamics1964" class="csl-entry" role="listitem">
Pippard, Alfred B. 1964. <em>Elements of Classical Thermodynamics: For Advanced Students of Physics</em>. 1st ed. Cambridge: Univ. Pr.
</div>
<div id="ref-quevedoGeometrothermodynamics2007" class="csl-entry" role="listitem">
Quevedo, Hernando. 2007. <span>“Geometrothermodynamics.”</span> <em>Journal of Mathematical Physics</em> 48 (1). <a href="https://pubs.aip.org/aip/jmp/article/48/1/013506/290587">https://pubs.aip.org/aip/jmp/article/48/1/013506/290587</a>.
</div>
<div id="ref-quilezFirstYearUniversityChemistry2012" class="csl-entry" role="listitem">
Quílez, Juan. 2012. <span>“First-<span>Year University Chemistry Textbooks</span>’ <span>Misrepresentation</span> of <span>Gibbs Energy</span>.”</span> <em>Journal of Chemical Education</em> 89 (1): 87–93. <a href="https://doi.org/10.1021/ed100477x">https://doi.org/10.1021/ed100477x</a>.
</div>
<div id="ref-raffSpontaneityEquilibriumWhy2014" class="csl-entry" role="listitem">
Raff, Lionel M. 2014a. <span>“Spontaneity and <span>Equilibrium</span>: <span>Why</span> <span>‘<span><span class="math inline">\(\Delta\)</span></span> <span><em>G</em></span> <span><span class="math inline">\(&lt;\)</span></span> 0 <span>Denotes</span> a <span>Spontaneous Process</span>’</span> and <span>‘<span><span class="math inline">\(\Delta\)</span></span> <span><em>G</em></span> = 0 <span>Means</span> the <span>System Is</span> at <span>Equilibrium</span>’</span> <span>Are Incorrect</span>.”</span> <em>Journal of Chemical Education</em> 91 (3): 386–95. <a href="https://doi.org/10.1021/ed400453s">https://doi.org/10.1021/ed400453s</a>.
</div>
<div id="ref-raffSpontaneityEquilibriumII2014" class="csl-entry" role="listitem">
———. 2014b. <span>“Spontaneity and <span>Equilibrium II</span>: <span>Multireaction Systems</span>.”</span> <em>Journal of Chemical Education</em> 91 (6): 839–47. <a href="https://doi.org/10.1021/ed4008205">https://doi.org/10.1021/ed4008205</a>.
</div>
<div id="ref-raffSpontaneityEquilibriumIII2014" class="csl-entry" role="listitem">
———. 2014c. <span>“Spontaneity and <span>Equilibrium III</span>: <span>A History</span> of <span>Misinformation</span>.”</span> <em>Journal of Chemical Education</em> 91 (12): 2128–36. <a href="https://doi.org/10.1021/ed500253e">https://doi.org/10.1021/ed500253e</a>.
</div>
<div id="ref-samuelsonMaximumPrinciplesAnalytical1971" class="csl-entry" role="listitem">
Samuelson, Paul A. 1971. <span>“Maximum <span>Principles</span> in <span>Analytical Economics</span>.”</span> <em>Science</em> 173 (4001): 991–97. <a href="https://doi.org/10.1126/science.173.4001.991">https://doi.org/10.1126/science.173.4001.991</a>.
</div>
<div id="ref-samuelsonMyLifePhilosophy1999" class="csl-entry" role="listitem">
———. 1999. <span>“My Life Philosophy: <span>Policy</span> Credos and Working Ways.”</span> <em>Economia Aplicada</em> 3 (2): 309–20. <a href="https://www.revistas.usp.br/ecoa/article/download/218529/199662">https://www.revistas.usp.br/ecoa/article/download/218529/199662</a>.
</div>
<div id="ref-smithClassicalThermodynamicsEconomic2008" class="csl-entry" role="listitem">
Smith, Eric, and Duncan K. Foley. 2008. <span>“Classical Thermodynamics and Economic General Equilibrium Theory.”</span> <em>Journal of Economic Dynamics and Control</em>, Applications of statistical physics in economics and finance, 32 (1): 7–65. <a href="https://doi.org/10.1016/j.jedc.2007.01.020">https://doi.org/10.1016/j.jedc.2007.01.020</a>.
</div>
<div id="ref-staceyEarthDensityDistribution2020" class="csl-entry" role="listitem">
Stacey, Frank D., and Paul M. Davis. 2020. <span>“Earth, <span>Density Distribution</span>.”</span> Edited by Harsh K. Gupta. <em>Encyclopedia of Solid Earth Geophysics</em>, 1–6. <a href="https://doi.org/10.1007/978-3-030-10475-7_100-1">https://doi.org/10.1007/978-3-030-10475-7_100-1</a>.
</div>
<div id="ref-starrGeneralEquilibriumTheory2011" class="csl-entry" role="listitem">
Starr, Ross M. 2011. <em>General <span>Equilibrium Theory</span>: <span>An Introduction</span></em>. 2nd edition. New York: Cambridge University Press.
</div>
<div id="ref-sunGeometryHighdimensionalPhase2024" class="csl-entry" role="listitem">
Sun, Wenhao, Matthew J Powell-Palm, and Jiadong Chen. 2024. <span>“The Geometry of High-Dimensional Phase Diagrams: <span>I</span>. <span>Generalized Gibbs</span>’ <span>Phase Rule</span>.”</span>
</div>
<div id="ref-weinholdThermodynamicsGeometry1976" class="csl-entry" role="listitem">
Weinhold, Frank. 1976. <span>“Thermodynamics and Geometry.”</span> <em>Physics Today</em> 29 (3): 23–30. <a href="https://www.researchgate.net/profile/Frank-Weinhold-2/publication/258879552_Thermodynamics_and_geometry/links/0f31752eff48885858000000/Thermodynamics-and-geometry.pdf">https://www.researchgate.net/profile/Frank-Weinhold-2/publication/258879552_Thermodynamics_and_geometry/links/0f31752eff48885858000000/Thermodynamics-and-geometry.pdf</a>.
</div>
<div id="ref-westTernaryPhaseDiagrams2002" class="csl-entry" role="listitem">
West, David Richard Frederick, and Nigel Saunders. 2002. <em>Ternary Phase Diagrams in Materials Science</em>. 3. ed. Book / <span>The Institute</span> of <span>Materials</span> 737. London: Maney for the Institute of Materials.
</div>
<div id="ref-LiuZuiZaoDeYuZhouZuiHaoDeDiQiu2015" class="csl-entry" role="listitem">
刘慈欣. 2015. <em>最糟的宇宙，最好的地球</em>. 1st ed. 中国科幻基石丛书. Chengdu: 四川科学技术出版社.
</div>
</div></section></div></main> <!-- /main -->
<!-- file: html/copy‑anchors-js.html -->

<script type="module">

document.addEventListener("DOMContentLoaded", () => {

  // 1. All little ¶ icons Quarto/AnchorJS adds

  document.querySelectorAll("a.anchorjs-link").forEach(anchor => {

    anchor.addEventListener("click", async (evt) => {

      // Keep normal scroll behaviour but stop full page reload

      evt.preventDefault();



      // Build absolute URL: origin + path + #hash

      const url = `${location.origin}${location.pathname}${anchor.getAttribute("href")}`;



      // 2. Try modern Clipboard API first

      try {

        await navigator.clipboard.writeText(url);

      } catch {

        // 3. Fallback for legacy browsers

        const helper = Object.assign(document.createElement("input"), { value: url });

        document.body.appendChild(helper);

        helper.select();

        document.execCommand("copy");

        helper.remove();

      }

      // TODO: The following two doesn't work yet

      // 4. Brief visual confirmation (optional)

      anchor.dataset.tooltip = "Copied!";

      setTimeout(() => delete anchor.dataset.tooltip, 1500);



      // 5. Still jump to the heading

      history.pushState(null, "", anchor.getAttribute("href"));

    }, false);

  });

});

</script>

<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yuxi\.ml\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Classical Thermodynamics and Economics"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yuxi Liu"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-05-09"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> "2025-02-13"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [math, physics, philosophy, economics]</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    resources:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">        - "figure/**"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "How to think like a classical thermodynamic-economist, delivered with many illustrations and some sci-fi metaphors. Particular emphasis on what traditional pedagogy gets wrong. Prerequisites: multivariate calculus and mathematical maturity."</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "figure/banner/banner_1.png"</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">image-alt:</span><span class="co"> "A brutalist sculpture representing classical thermodynamics/neoclassical economics: nonlinear (curved surface) constraint (steel cables tying it down) optimization (the surface struggling to fly towards the sun, touching the solar rays at the closest points).</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">Made in Ideogram V1, with prompt 'A stunning conceptual artwork featuring a white sun casting intense white rays of sunlight, piercing through a curved hyperboloid structure made of concrete. The structure is adorned with straight lines of tight steel cables, creating a strong geometric pattern. The white background and high contrast accentuate the minimalistic vector art style. The piece is reminiscent of Chiaroscuro painting in the style of Piranesi, with a monochrome palette that enhances the drama and depth of the scene., illustration'."</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="an">status:</span><span class="co"> "finished"</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="an">confidence:</span><span class="co"> "certain"</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="an">importance:</span><span class="co"> 5</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../../static/_macros.tex &gt;}}</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; It is to the economist, the statistician, the philosopher, and to the general reader that I commend the analysis contained herein... mathematics as applied to classical thermodynamics is beautiful: if you can't see that, you were born color-blind and are to be pitied.</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">Paul Samuelson</span><span class="co">](https://en.wikipedia.org/wiki/Paul_Samuelson)</span><span class="at">, forewords to </span><span class="co">[</span><span class="ot">@bicklerInvestmentPortfolioDecisionmaking1974</span><span class="co">]</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="fu">### What this essay contains</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>Unlike my <span class="co">[</span><span class="ot">*Analytical Mechanics* essay</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/)</span>, this essay does not cover much of the width covered in a university course on classical thermodynamics *or* neoclassical economics. Instead, it's best described as "the conceptual foundations that a typical course does not work well on", a deep but narrow essay to supplement a shallow but wide typical textbook.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>Unlike analytical mechanics, which is typically taught to students intent on reaching the abstract plane of modern theoretical physics, and is thus deep but narrow, a typical course on classical thermodynamics is shallow, but very wide, and taught to a wide student base -- theoretical physicists, thermal engineers, electric engineers, chemists, biologists... When something must be taught to a wide audience, and is both deep and wide, depth is sacrificed. This is perfectly practicable, but it leaves a small minority confused with a sinister feeling that the teachers have abused their trust in them. I am in that minority.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>The essay contains: three laws of thermodynamics, entropy, Helmholtz and Gibbs free energy, nonextensive entropy, Caratheodory's axiomatic thermodynamics, Vladimir Arnold's contact-geometric thermodynamics, Paul Samuelson's area-ratio thermodynamics, Le Chatelier's principle, chemical equilibrium, Gibbs phase rule and its extensions, analogies with neoclassical economics, speculative sci-fi.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>It does not contain: statistical mechanics, most of the "width" part of thermodynamics and economics.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>The prerequisites are multivariate calculus and mathematical maturity. It's good to be familiar with basic economics as well.</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quick reference</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$S$: entropy</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$U$: internal energy</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$V$: volume</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$T$: temperature</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\beta = 1/T$: inverse temperature</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$N$: number of particles of a chemical species</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$n$: number of moles of a chemical species</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\xi$: extent of reaction</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X$: "other properties that we are not concerned with"</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For example, with an ideal gas trapped in a copper box, its macroscopic state is determined by $U, N, V$. If we want to focus on $U$, then we can let $X = (N, V)$, and write $S = S(U, X)$. </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Similarly, for a photon gas in a blackbody chamber, its macroscopic state is determined by $U, V$, since photons can be created and destroyed on the inner surface of the blackbody chamber. We can then write $S = S(U, X)$ if we are concerned only about how entropy changes with $U$, holding the other state constant. We can also write $S = S(V, X)$ vice versa.</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>Thermodynamics is notorious for having too many partial differentials and coordinate changes. $(\partial_{x_1} f)_{x_1, x_2, \dots, x_n}$ means that we lay down a coordinate system defined by $x_1, \dots, x_n$, then calculate $\partial_{x_1}f$, fixing the other coordinates constant. In particular, $(\partial_{x_1} f)_{x_1, x_2, \dots, x_n}$ is likely different from $(\partial_{x_1} f)_{x_1, y_2, \dots, y_n}$.</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>If in doubt, write down</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>$$df = \sum_{i=1}^n (\partial_{x_i} f)_{x_1, \dots, x_n} dx_i$$</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>and reason thenceforth.</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>Sometimes people write $(\partial_{x_i} f)_{x_2, \dots, x_n}$ instead of $(\partial_{x_i} f)_{x_1, x_2, \dots, x_n}$ to save them one stroke of the pen. I try to avoid that, but be aware and beware.</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### Further readings</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@pippardElementsClassicalThermodynamics1964</span><span class="co">]</span>. Slim, elegant, both mathematical and applied. In the best British tradition of mathematics -- think James Maxwell and G. H. Hardy.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@fermiThermodynamics1956</span><span class="co">]</span>. The same as above. However, it also covers chemical thermodynamics.</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@lemonsThermodynamicWeirdnessFahrenheit2019</span><span class="co">]</span>. A very readable introduction to classical thermodynamics, slim but deep. I finally understood the meaning of the three laws of thermodynamics after reading it. Contains copious historical quotations.</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@lemonsMereThermodynamics2008</span><span class="co">]</span>. A textbook version of the author's <span class="co">[</span><span class="ot">@lemonsThermodynamicWeirdnessFahrenheit2019</span><span class="co">]</span>, weaving in history and philosophical contemplation at every turn.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@carnotReflectionsMotivePower1988</span><span class="co">]</span>. A reprint of the most important papers in thermodynamics published before 1900. Useful to have on hand if you are reading <span class="co">[</span><span class="ot">@lemonsThermodynamicWeirdnessFahrenheit2019</span><span class="co">]</span>.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">@buchdahlConceptsClassicalThermodynamics1966</span><span class="co">]</span>. A textbook based on Carathéodory's axiomatic thermodynamics. The notation is ponderous, and the payoff is unclear. I don't know what is its intended audience -- perhaps professional pedants and differential geometers? Nevertheless, if you need to do research in Carathéodory's axiomatic thermodynamics, I think this is your best bet.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Ted Chiang's *Exhalation* (2008), printed in <span class="co">[</span><span class="ot">@chiangExhalation2019</span><span class="co">]</span>. A sci-fi story about an alien race where pneumatic engines, not heat engines, are all-important. A better take on stereodynamics than <span class="co">[</span><span class="ot">my attempt</span><span class="co">](#sec-stereodynamics)</span>.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is thermodynamics?</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>Both neoclassical economics and classical thermodynamics are about the equilibria of large systems. While a large system is generally hopelessly complicated, almost all the complexity falls away when the system is maximizing a single quantity. Ceaselessly striving to maximize entropy, a complex system sheds its complexity and reaches the pure simplicity of maximal entropy. Ceaselessly striving to maximize profit, a complex company sheds its complexity and reaches the pure simplicity of perfect product.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>In both fields, everything we can say about the world are nothing more than systems, constraints, contacts, and equilibria. Time and change do not exist. All we can explain is which states *are* in constrained equilibrium, not how a system can *get there*. Atoms do not exist. All we can explain is what happens to homogeneous substances in constrained equilibrium. People do not exist. All we can explain is what happens to constrained economic systems in equilibrium.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>Different things can be maximized: the total entropy, or the negative Gibbs free energy, or the profit, or the sum-total of utility, or something else. Through different lenses, different things are maximized, but they predict the same phenomena. Using this mathematical freedom, experts brachiate around the coordinate axes like gibbons brachiating around vines, looking for the perfect angle to solve each particular problem.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> interpretation <span class="pp">|</span> maximized quantity <span class="pp">|</span> constraint <span class="pp">|</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="pp">|---|---|---|</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> conglomerate accounting <span class="pp">|</span> book value <span class="pp">|</span> Assets is conserved, but can be moved between child companies. <span class="pp">|</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> social welfare <span class="pp">|</span> social utility <span class="pp">|</span> Wealth is conserved, but can be redistributed. <span class="pp">|</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> closed system <span class="pp">|</span> entropy <span class="pp">|</span> Quantities are conserved, but can be moved between sub-systems. <span class="pp">|</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> factory production <span class="pp">|</span> profit <span class="pp">|</span> Some raw materials are on sale at a market, but others are not. <span class="pp">|</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> consumer choice <span class="pp">|</span> utility <span class="pp">|</span> Some finished goods are on sale at a market, but others are not. The market uses a commodity money. <span class="pp">|</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> partially open system <span class="pp">|</span> negative free energy <span class="pp">|</span> Some quantities can be exchanged with a bath, but others are conserved. <span class="pp">|</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>: Constrained maximization problems in economics and thermodynamics.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Even if the capitalist system is to give way to one in which service and not profit shall be the object, there will still be an integral of anticipated utilities to be made a maximum. Since we must find a function which maximizes an integral we must in many cases use the Calculus of Variations. But the problem here transcends the questions of depreciation and useful life, and belongs to the dawning economic theory based on considerations of maximum and minimum which bears to the older theories the relations which the Hamiltonian dynamics and the thermodynamics of entropy bear to their predecessors.</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@hotellingGeneralMathematicalTheory1925</span><span class="co">]</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="fu">### Systems</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>Systems are the main characters of the drama of thermodynamics. A thermodynamic system is fully determined by a few macroscopic properties, related by equations of state. Once we know enough of its properties, we know all there is to know about such a system. There is nothing left to say about it.</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>**Everything is a thermodynamic system**. However, there are two special types: bath systems, and mechanical systems.[^anecdote-square] Any number of thermodynamic systems can be connected into a larger system -- a **compound system**.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="ot">[^anecdote-square]: </span>Some children are confused when they heard that squares are rectangles too. I hope you won't be equally confused when you hear that mechanical systems are also thermodynamic systems.</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>The prototypical thermodynamic system is a tank of ideal gas whose number of particles is fixed. It has 2 degrees of freedom, so if we write down $n$ different macroscopic properties, they would (generically) be related by $n-2$ equations of state. So for example, if we write down the properties internal energy $U$, temperature $T$, volume $V$, pressure $P$, they would be related by the 2 equations of state</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>$$PV = k_BNT, \quad U = \frac 32 k_B NT$$</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>If we know two out of the four of internal energy $U$, temperature $T$, volume $V$, pressure $P$, then we can solve for all the others by equations of state. The macroscopic properties fully describe the system, and nothing more can be said about it. We cannot ask additional questions such as "Are there more particles on the left than on the right?" or "How long did it take for the system to reach equilibrium?", because such questions are literally *undefined* in classical thermodynamics.</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>Because the properties are related by equations of state, we need only know a few of the properties in order to infer all the rest. For example, knowing the volume $V$, internal energy $U$, and particle number $N$, of a tank of ideal gas, we can infer that its pressure is $P = \frac{2U}{3V}$, and its temperature is $T = PV/k_BN$. Succinctly,</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>$$P = P(U, V, N), \quad T = T(U, V, N)$$</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>meaning "If we know $U, V, N$, then we can calculate $P$ and $T$ ".</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>It's too easy to misread it as saying that $P$ *is* a mathematical function of $U, V, N$. It is not. It really is saying that, there exists a mathematical function $f_P$, such that for any state $\omega$ of the system, we have</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>$$P(\omega) = f_P(U(\omega), V(\omega), N(\omega))$$</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>Everything about a thermodynamic system is known once we specify how its entropy is a function of its macroscopic properties. </span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>For example, the ideal gas is fully specified by</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>$$S(U, V, N) = k_B N \ln\left<span class="co">[</span><span class="ot">\frac{V}{N}\,\left(\frac{U}{\hat{c}_V k_B N}\right)^{\hat{c}_V}\,\frac{1}{\Phi}\right</span><span class="co">]</span>$$</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>where $\hat c_V$ and $\Phi$ are constants that differ for each gas.</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>As another example, the photon gas is defined by</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>$$S(U, V) = C V^{1/4}U^{3/4}, \quad C=\left(\frac{256\pi^2 k_B^4}{1215 c^3 \hbar^3}\right)^{1/4}$$</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>The fact that $S(U, V) \propto V^{1/4}U^{3/4}$ can be derived from 19th-century physics (indeed, it was known to Boltzmann), but the constant $C$ has to wait for proper quantum mechanics.</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Baths</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>A **bath system** is an infinite source of a conserved quantity at constant marginal entropy. A bath system is intended to be used as a "free market" where non-bath systems can trade some conserved quantities with.</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>For example, if we take a copper piston and fill it with ideal gas, then immerse the piston in the bottom of an ocean, then it is playing the role of a *volume-and-energy bath* with constant pressure-and-temperature. If we cover up the piston with some insulating material, then the ocean suddenly plays the role of merely a volume bath with constant pressure. If we use screws to fix the piston head, then the ocean suddenly becomes merely an energy bath with constant temperature. From this, we see that a bath *in itself* is a rather vacant concept. A bath should always be in contact with some non-bath system.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>Because they are infinitely large, if you connect two baths together, something bad will happen. For example, if you connect two energy baths together, but with different temperature, what would happen? The simple answer is: "A torrent of heat will flow from the hotter to the colder bath.". The more correct answer is: "Classical thermodynamics does not allow such a question to be asked. It would be like asking what happens when 'an unstoppable force meets an immovable object'. If we literally have two baths, then we cannot connect them. If we only have two giant oceans that seem like baths when compared to this little tank of gas, then if the two oceans are connected to each other, they will no longer appear as baths to each other.".</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>You can take this in two ways. Either will work. You can say that both systems and baths are first-class concepts in thermodynamics, and enforce the rule that you can never connect two baths together. You can also say that systems are first-class concepts in thermodynamics, but baths are second-class concepts, a convenient way to think about a system that is much larger *relative* to some other systems. Since a bath is a *relative* concept, it simply is a bad question to ask "What happens if we connect two baths together?" -- The correct reply is "You mean, two systems that appear as baths... relative to *what*?".</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>Some important (and unimportant) examples of baths:</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A heat bath, or more accurately an energy bath, is a system that you can take or dump as much energy as you want, always at constant marginal price of energy.</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>An atmosphere, or more accurately an energy-and-volume bath, is a system that you can take or dump as much energy or volume as you want, always at constant temperature and pressure.</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The surface of a lake could serve as an energy-and-area bath.</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A large block of salt can serve as a salt-chemical bath.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Mechanical systems</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>A **mechanical system** is a thermodynamic system whose entropy is always zero. Essentially all systems studied in classical mechanics are such systems. In classical thermodynamics, they are not put center-stage, but if you know where to look, you will see them everywhere. </span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>An ideal linear-spring has two macroscopic properties: length $x$ and internal energy $U$, with equation of state $U = \frac 12kx^2$. For example, a helix spring is close to an ideal linear-spring.</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>An ideal surface-spring is the same as an ideal linear-spring, but with area $A$ instead of length $x$. Its equation of state is $U = \sigma A$, where $\sigma$ is surface tension constant. For example, a balloon skin is close to an ideal surface-spring.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>An ideal volume-spring is similar. It would resemble a lump of jelly. An ideal gas, though it looks like a volume-spring, is not an example, because its entropy is not zero. In particular, this means an ideal gas has temperature and can be "heated up", but a lump of ideal jelly cannot.</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>In general, we can construct an arbitrary energy storage system, such that it has two macroscopic properties $x, U$, satisfying $U = f(x)$, where $f$ is any differentiable function. To show this, we can imagine taking a mystery box with a chain we can pull on, and by some internal construction with gears, pulleys, weights, and springs, the force on the chain is $f'(x)$, where $x$ is the length by which we have pulled. That is the desired system.</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="fu">### State space</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>A tank of gas has on the order of $10^{26}$ particles, but in classical thermodynamics, its state is entirely determined if we know its $U, V, N$. In this sense, we can say that its macroscopic state space has just 3 dimensions. In many situations, such as in the Carnot heat engine, we also fix its $N$, in which case its state space has just 2 dimensions.</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>This is typically plotted in either the $(P, V)$ space, or the $(T, S)$ space, or some other spaces, but in every case, there are just two dimensions. We can unify all these diagrams as merely different viewpoints upon the same curvy surface -- the state space $\mathcal X$ itself. Each point $\omega \in \mathcal X$ in the state space is a state, and each macroscopic property $X$ is a scalar function of type $X : \mathcal X \to \R$. </span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>If the state space has just $d$ dimensions, then we need only $d$ macroscopic properties $X_1, \dots, X_d$ in order to lay down a coordinate system for the state space. If we have another macroscopic property $Y$, then there in general exists a function $f_Y: \R^d \to \R$, such that $Y(\omega) = f_Y(X_1(\omega), \dots, X_d(\omega))$ for any state $\omega$. In other words, we have an **equation of state**.</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="al">![The state space for a thermodynamic system with 2 degrees of freedom. If we lay down three macroscopic properties, then they satisfy one equation of state.](figure/thermodynamic_state_manifold.png)</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Calculus on state space</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>In thermodynamics, we typically have many more macroscopic properties than dimensions. For example, the state space of an ideal gas has only 3 dimensions, but has many macroscopic properties: $S, U, V, N, T, P, \mu, \dots$. In this case, every time we take a derivative on the state space, we need to pick exactly 3 properties, since picking different coordinates leads to different partial differentials.</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Example with $x, y, z$" collapse="false"}</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>As an illustrative example, let $x, y, z$ be smooth scalar functions on a smooth 2D surface, such that their contour lines are linearly independent at every point on the surface. Then, picking any 2 out of $x, y, z$ would give us a coordinate system. Any other smooth function $f$ on the surface can be expressed in 3 different ways, as </span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>$$f = f_{x, y}(x, y) = f_{y, z}(y, z) = f_{z, x}(z, x)$$</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>This gives us two different ways to "differentiate $f$ with respect to $x$":</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>\lrb{\pp{f}{x}}_y := \partial_1 f_{x, y}, \quad </span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>\lrb{\pp{f}{x}}_z := \partial_2 f_{z, x}</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>where $\partial_1$ means "partial differentiation with respect to the first input", etc.</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Example with $\mathbb{R}^2$" collapse="false"}</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>Let $x, y$ be the usual coordinates on the 2D plane $\R^2$, and let $z = x + y, w = x - y$. We can pick any 2 of $x, y, z, w$ to construct a coordinate system. Then,</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>\lrb{\pp{y}{x}}_y = 0 \quad \lrb{\pp{y}{x}}_z = -1 \quad \lrb{\pp{y}{x}}_w = 1</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>In general, if we pick $x_1, \dots, x_d, y$ from a list of many smooth scalar functions on a surface, such that $x_1, \dots, x_d$ form a smooth and linearly independent coordinate system on the surface, then we can express $y = f(x_1, \dots, x_d)$ for some function $f : \R^d \to \R$, and define</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>\lrb{\pp{y}{x_1}}_{x_2, \dots, x_d} = \partial_1 f, \quad </span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>\lrb{\frac{\partial y}{\partial x_1\partial x_2}}_{x_3, \dots, x_d} = \partial_1\partial_2 f, \quad \dots</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>In particular, we have</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>$$dy = \sum_{i=1}^d (\partial_{x_i} y)_{x_1, \dots, x_d} dx_i$$</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>::: {#exr-0}</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>Based on the following diagram, prove that if we have three smooth scalar functions $x, y, z$ on a smooth<span class="ot">[^smoothness-assumption-exr-0]</span> 2D surface, such that their contour surfaces are linearly independent, then $\left(\frac{\partial x}{\partial z}\right)_y\left(\frac{\partial y}{\partial x}\right)_z\left(\frac{\partial z}{\partial y}\right)_x = -1$. Generalize this to higher dimensions.</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/constraint_partial_derivatives.jpg)</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="ot">[^smoothness-assumption-exr-0]: </span>It is sufficient to assume the surface and the scalar functions are $C^2$, but we need not worry about it, because everything is smooth in classical thermodynamics, except at phase transitions.</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="fu">### Constraint</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>A **constraint** is an equation of form $f(A, B, C, \dots) = f_0$, where $f$ is a mathematical function, $A, B, C, \dots$ are macroscopic properties, and $f_0$ is a constant.</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>For example, if we have two tanks of gas in thermal contact, then the constraint is as follows:</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>V_1 &amp;= V_{1,0} <span class="sc">\\</span></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>V_2 &amp;= V_{2,0} <span class="sc">\\</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>U_1 + U_2 &amp;= U_{1,0} + U_{2,0} <span class="sc">\\</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>meaning that the volume of each tank of gas is conserved, and the sum of their energy is also conserved.</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>The constraints on a compound system are determined by the contacts between its subsystems.</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="fu">### Contacts</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>If we only have systems isolated in a perfect vacuum, then nothing interesting will happen. If two systems are perfectly connected, then they will never be brought apart. A contact allows two systems to interact, without destroying their individuality. It allows two systems to communicate, without becoming literally one system. Economically, contacts are trade contracts.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>In general, the effect of a contact is to reduce the number of constraints by one. For example, a metal rod between two pistons reduces the two constraints</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>$$V_1 = V_{1,0}, \quad V_2 = V_{2, 0}$$</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>into one constraint:</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>$$V_1 + V_2 = V_{1,0} + V_{2,0}$$</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>As another example, in a tank of three kinds of gas $N_2, H_2, NH_3$, allowing a single chemical reaction $N_2 + 3H_2 \rightleftharpoons 2NH_3$ reduces three constraints</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>N_{N_2} = N_{N_2, 0}, \quad N_{H_2} = N_{H_2, 0}, \quad N_{NH_3}= N_{NH_3, 0}</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>into two:</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>N_{N_2} - N_{N_2, 0} = (N_{H_2} - N_{H_2, 0})/3, \quad N_{N_2} - N_{N_2, 0} = (N_{NH_3} - N_{NH_3, 0})/2</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>A contact can be nonlinear. For example, if we have two pistons of the same area, connected by a lever, such that pushing on one piston by $\Delta x$ would be pulling on the other piston by $2 \Delta x$, then the constraint becomes $2(V_1 - V_{1,0}) + (V_2 - V_{2,0}) = 0$. And by designing a series of levers, gears, and chains, we can realize any constraint function $f(V_1, V_2) = f(V_{1,0}, V_{2,0})$ for any smooth function $f$.</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="al">![A thermodynamical system (a piston of gas) is connected to a mechanical system (a mass in gravity) via an arbitrary constraint (variable gears).](figure/arbitrary_mechanical_system.png)</span></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compound systems</span></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>A compound system is nothing more than several systems connected. If we know the connections, and the entropy function of each subsystem, then we know everything about the compound system. The number of DOF for the compound system is the sum of the DOF of the subsystems, minus the degree of constraints.</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>For example, in the adiabatic expansion of a tank of ideal gas, we are really studying one compound system made of 3 subsystems:</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>a tank of ideal gas (thermodynamic system),</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>a lump of mass in gravity (mechanical system),</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>with a gear system between them (contact).</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>The gear system is designed with gear-ratio that varies as the system turns, in just the right way such that the system is always in equilibrium no matter the position of the piston, so that it really has no preference of going forwards or backwards.</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="al">![The compound system. Inside it, there is a subsystem of a tank of ideal gas that undergoes adiabatic expansion.](figure/arbitrary_mechanical_system.png)</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Only one system"}</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>We typically think of the tank of ideal gas itself as part of the thermodynamics, and the other parts as "the environment", but we should consider one single compound system, properly speaking, of which the tank of ideal gas is merely a sub-system. This way, we can state directly that the entropy of the entire compound system is maximized.</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>::: {#exm-0}</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## heat-engine-and-environment compound system</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>A heat engine is a thermodynamic system that is used as a component of a larger compound system. The large system contains 4 parts: two energy baths, one heat engine, and one carefully designed mechanical system acting as energy storage.</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>If you only want a heat engine that works, then the energy storage does not need to be carefully designed. However, if you want a Carnot heat engine, i.e. at maximal efficiency, then the energy storage must be designed to be exactly right. It must be designed to follow the exact parameters of the heat engine, as well as the temperatures of the two energy baths. If any of those is ignored, the energy storage would fail to "mesh" with the rest of the compound system, and cause waste.</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a>This is why a heat engine must be a component of a larger *compound system*. Every part depends on every other part. The energy storage unit is just as important and precisely designed as the heat engine is.</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="fu">### Equilibrium, virtual vs actual states</span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Freedom is an iron cage.</span></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Constraints set it free again.</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>On the African savannah, there lived a bunch of meerkats. Meerkats love to stand on the tallest place.</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>At first, they could stand wherever they wanted, so they all stood on one single hill. It was crowded. A blind lion who had memorized the landscape came and ate all of them.</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>Then humans came and added long walls that divided the savannah into thin stripes. Now each meerkat's location is determined by the stripe in which it happened to fall. The blind lion could find the meerkat if he knew the location of the stripe. In other words, optimizing for height, when there is one constraint, leads to one dimension of uncertainty.</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>This is a subtle point, so I will say it again. If you want to optimize for a quantity, and you don't have a constraint, then you would always go to the globally best solution. The whole space of possibilities is open to you, but you don't need them. Those states are "virtual", because they are never observed, even though they are out there.</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>But if you have one constraint, then you have one unique solution for each possible setting of constraint. Suddenly a lot of those virtual states become real. You are still not free, but at least now you have a puppet master.</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>In classical thermodynamics, only equilibrium states are "real". Nonequilibrium states are "virtual". In Lagrangian mechanics, only stationary-action paths are real, and the other paths are virtual. You can imagine that if you throw a rock upwards, it might execute a complex figure-8 motion before returning to the ground again, but that's a virtual path. The only real path is the unique virtual path that stationarizes the action integral.</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>Similarly, in classical thermodynamics, you could imagine that a tank of gas contains all its gas on the left side. Its entropy is just $S(U, V/2, N)$, but that's a virtual state that does not maximize entropy under constraint. The unique entropy-maximizing virtual state is the real state.</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a>For every constraint, there are many nonequilibrium states that satisfy the constraint, but only one equilibrium entropy, and so equilibrium entropy is a function of constraints, even though the entropy function itself is not. It optimizes all its complexities away, allowing us to know it through just its external constraints.</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a><span class="fu">### Some common misconceptions</span></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>Thermodynamics is not statistical mechanics. Forget about molecules and atoms. Forget about statistics and statistical mechanics. Forget about $S = k_B\ln \Omega$ or $S = -\sum_i p_i \ln p_i$. **Randomness does not exist** in classical thermodynamics.</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>Forget about the first law of thermodynamics. **Energy is nothing special.** The conservation of energy is no more important than the conservation of volume, or the conservation of electric charge.</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>Forget about heat. **Heat does not exist** -- it is not a noun, not even an adjective, but an adverb at most. The theory of caloric has already been disproven in 1798 by the cannon-boring experiment.</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>Heat energy and work energy are both misnomers. Neither are types of energy. Instead, they are types of energy-flow. We should speak of only the heatly flow of energy and the workly flow of energy. In this way, both "heat" and "work" are revealed to be actually adverbs. This is a bit awkward, so we will continue to speak of "heat" and "work", but you should understand that it's a shorthand, and that there is neither "heat energy" nor "work energy".</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a>To perform work, one must perform work *upon* something. In other words, there is no such thing as "system A performed work". There is really "some energy and length is between A and B, in compliance with an equation constraint, such that the total entropy of the compound system has remained constant".</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>Forget about time. **Time does not exist** in classical thermodynamics. We can say nothing at all about what happens between equilibria. We can only say, "This is an equilibrium, but that is not an equilibrium.". That is all we can say. See this, and you will see thermodynamics aright. As to what happened "between them", that we must pass over in silence.</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>The name "thermodynamics" is a complete misnomer, because heat does not exist (thus no "thermo-") and time does not exist (thus no "-dynamics"). If I am allowed a bit of name-rectification, I will call it "entropo-statics".</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a>If time does not exist, you ask, what do we mean when we study Joule expansion? That is, when we take half a tank of gas, and suddenly open the middle wall and wait until the gas equilibrates in the entire tank?</span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>Quiet. We did not open the middle wall. We did not wait. Gas did not expand. The past did not cause the future. Time is a stubbornly persistent illusion, and causality too.</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>In fact, we are considering two different problems in thermodynamics.</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a>First problem: Given a tank of gas with internal energy $U = U_0$, molar-amount $n = n_0$, and constraint $V \leq \frac 12 V_0$. What is its equilibrium state? Answer: The state that maximizes entropy under the constraints:</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a>\max S(U, n, V) <span class="sc">\\</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>V \leq \frac 12 V_0 <span class="sc">\\</span></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>U = U_0 <span class="sc">\\</span></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a>n = n_0</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>where $S(U, n, V)$ is the entropy of the gas when its states properties are $U, n, V$.</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>Similarly, the second problem is another constraint-optimization problem:</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>\max S(U, n, V) <span class="sc">\\</span></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>V \leq V_0 <span class="sc">\\</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>U = U_0 <span class="sc">\\</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>n = n_0</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>That the two different problems seem to "follow one from another" is an illusion. In reality, they only appear to follow one another because this is what we observe in the real world: one equilibrium follows another. In equilibrium thermodynamics, equilibria do not follow one another -- each stands alone.</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>Time only appears in the following sense: we observe a real-world system, like a car engine, and notice that its motion seems to consist of a sequence of equilibria. Not quite true equilibria, since true equilibria do not change. Maybe "pseudo-equilibria"? Too dismissive. Let's call them "<span class="co">[</span><span class="ot">quasi-equilibria</span><span class="co">](https://en.wikipedia.org/wiki/Quasistatic_process)</span>" instead.</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>Now, keeping those "quasi-equilibria" in mind, we muddle around the ocean of classical thermodynamics, until we have found some equilibria that resemble the quasi-equilibria we have in mind. And so, from the bottom of the ocean, we pick up one equilibrium, then another, then another. Then we string together these little equilibria along a number line like a pearl necklace. We run our fingers over these pearls and delight in their "motion", like flipping the pages of a stop-motion book and shouting, "Look, it is moving!".</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/banner/2.png)</span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="fu">## The three laws</span></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>More accurately: one law and two non-laws.</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="fu">### Second law</span></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; For the equilibrium of any isolated system it is necessary and sufficient that in all possible variations of the state of the systems which do not alter its energy, the variation of its entropy shall either vanish or be negative.</span></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gibbsEquilibriumHeterogeneousSubstances1878</span><span class="co">]</span></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a>The second law of thermodynamics is all-important: maximizing entropy is all of classical thermodynamics. All other parts are just tricks for maximizing entropy.</span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>Although, there are actually two aspects of the second law, subtly different. One of them is static, while the other is dynamic:</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Static: A thermodynamic system is described by a function on the state space, called the *entropy* function. Each system can be placed under many different forms of constraints. Under each possible constraint, the only physically observable state is the state that maximizes entropy under constraint.</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Dynamic: The entropy of a thermodynamic system does not decrease over time.</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>There is no difficulty with the static statement, but many difficulties with the dynamic statement, since it involves time, which really does not exist in classical thermodynamics. Nevertheless, since time is so important to the rest of physics, physicists, especially physics teachers, have repeatedly tried to hack it back into the theory, resulting in predictable and endless confusions. Since we do not compromise with intuition, in the rest of this essay, we will use the static formulation as much as possible.</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a><span class="fu">### First law</span></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; As a student, I read with advantage a small book by F. Wald entitled "The Mistress of the World and her Shadow". These meant energy and entropy. In the course of advancing knowledge the two seem to me to have exchanged places. In the huge manufactory of natural processes, the principle of entropy occupies the position of manager, for it dictates the manner and method of the whole business, whilst the principle of energy merely does the book- keeping, balancing credits and debits.</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@emdenWhyWeHave1938</span><span class="co">]</span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>The first law of thermodynamics is entirely trivial. Energy is *nothing special*! Energy is *just* a conserved quantity, one among equals, much like volume, mass, and many other things... Every conserved quantity is equally conserved,<span class="ot">[^equally-conserved]</span> so it does not deserve a special thermodynamic law. You might as well say "conservation of mass" is "the second-first law of thermodynamics" and "conservation of volume" is "the third-first law of thermodynamics", and "conservation of electrons" and "conservation of protons" and "conservation of length" (if you are studying a thermodynamic system restricted to move on a line) and "conservation of area" (if you are studying a thermodynamic system restricted on the surface of a lake), and so on...</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="ot">[^equally-conserved]</span>:</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>    The first law of thermodynamics had always struck me as oddly out of place, almost like a joke I could not catch, like </span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; All animals are equal, but some animals are more equal than others</span></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="in">    but with</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="in">    &gt; All conserved quantities are conserved, but some quantities are more conserved than others.</span></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="in">    I kept waiting for the textbooks, or the teachers, or someone to drop the act and confess, "Actually, we were joking -- conservation of energy really is not that special, and we were just bored with standard physics and wanted to confuse you with a cute magic trick before showing you what standard physics really is saying.". Slowly, I realized that there is no joke -- conservation of energy is unironically treated as special not just by the students but even by the teachers. I had to figure out for myself how the joke really works, and it required me to rebuild thermodynamics according to my preferences.</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>This sounds extraordinary, but that is merely how classical thermodynamics works. The first law of thermodynamics does not deserve its title. It should be demoted to an experimental fact and not a law. Just to drive the point home, I wrote an entire <span class="co">[</span><span class="ot">sci-fi worldbuilding sketch</span><span class="co">](#sec-stereodynamics)</span> about an alien species for which the conservation of volume that is fundamental, not energy, and which discovered stereodynamics. If you can laugh at their mistaken importance of the conservation of volume, maybe you can laugh at the mistaken importance of the conservation of energy too.</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>The proper place for the law of conservation of energy is not classical thermodynamics, but general physics, because energy is nothing special inside classical thermodynamics, but it is extremely special if we zoom out to consider the whole of physics. Whereas in classical thermodynamics, systems conserve energy, and volume, and mass, and electron-number, and proton-number, and... when you move outside of thermodynamics, such as when you add in electrodynamics, special relativity, and quantum mechanics, all kinds of conservations breakdown. You don't have conservation of mass, or number of electrons, or even volume, but energy is always conserved.</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>This explains the long confusion around the conservation of energy. Within equilibrium thermodynamics, every conserved quantity is conserved, yes, but physicists are less interested in theoretical purity than mathematicians. They know that *outside*, energy is a more special conserved quantity than others, and so they can't help but feel like energy should be treated as special *inside* thermodynamics too.</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="fu">### Zeroth law</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>Now that the first law has been dispelled, we can dispel the zeroth law of thermodynamics too. If energy falls from grace, so must its shadow, temperature.</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>::: {#thm-zeroth-law}</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="fu">## general zeroth law</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>If $S_1(X_1, Y) + S_2(X_2, Y)$ is maximized under the constraint $X_1 + X_2 = X$, then $(\partial_X S_1)_Y = (\partial_X S_2)_Y$.</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> maximized quantity $S$ <span class="pp">|</span> conserved quantity $X$ <span class="pp">|</span> derivative $(\partial_X S)_Y$ <span class="pp">|</span> zeroth law <span class="pp">|</span></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="pp">| ---</span> <span class="pp">| ---</span> <span class="pp">| ---</span> <span class="pp">|</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> entropy <span class="pp">|</span> energy <span class="pp">|</span> inverse temperature $\beta$ <span class="pp">|</span> Temperature exists, and is equal between two equilibrated systems in energy-contact. <span class="pp">|</span></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> entropy <span class="pp">|</span> volume <span class="pp">|</span> $\beta P$ <span class="pp">|</span> Volumetric derivative exists, and is equal between two equilibrated systems in volume-contact. <span class="pp">|</span></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> entropy <span class="pp">|</span> particles <span class="pp">|</span> $-\beta \mu$, where $\mu$ is chemical potential <span class="pp">|</span> Chemical derivative exists, and is equal between two equilibrated systems in particle-exchange-contact. <span class="pp">|</span></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> entropy <span class="pp">|</span> surface area <span class="pp">|</span> $-\beta\sigma$, where $\sigma$ is surface tension <span class="pp">|</span> Area-derivative exists, and is equal between two equilibrated systems in surface-area-exchange-contact. <span class="pp">|</span></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> production value <span class="pp">|</span> raw material <span class="pp">|</span> marginal value <span class="pp">|</span> When several factories are maximizing their total production value, the marginal value of each raw material is the same for all factories. <span class="pp">|</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a>: The zeroth law of thermodynamics in various guises.</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a><span class="fu">### Third law</span></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a>The third law is rarely, if ever, used in classical thermodynamics, and its precise meaning is still unclear. It seems to me that its proper place is not thermodynamics, but quantum statistical mechanics, where it states that a substance, when at the lowest possible energy (ground state), has finite entropy -- Einstein's formulation of the third law. <span class="co">[</span><span class="ot">@klimenkoTeachingThirdLaw2012</span><span class="co">]</span></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a><span class="fu">### An economic interpretation</span></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>Here is an economic interpretation of classical thermodynamics. There are other possible interpretations, and we will use the others in this essay.</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>In this interpretation, the laws of nature become the CEO of a company. Every conserved quantity is a commodity. The company has some commodity. Commodities themselves have no intrinsic value. Instead, the company is valued by a certain accounting agency. The CEO's job is to move around the commodities so that the accounting agency gives it the highest book-value.</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a>A compound system is a *conglomerate company*: a giant company made of little companies. If entropy is extensive, then it means the total book-value for the conglomerate is the sum of the book-value of each subsidiary company. Otherwise, entropy is nonextensive, and the accounting agency believes that the conglomerate has [*corporate synergy*](https://en.wikipedia.org/wiki/Corporate_synergy).</span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>The inverse temperature $\beta$ is the marginal value of energy:</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a>$$\beta = \frac{d(\text{value of a sub-company})}{d(\text{energy owned by the sub-company})}$$</span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>The pressure $P$, multiplied by $\beta$, is the marginal value of space:</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>$$\beta P = \frac{d(\text{value of a sub-company})}{d(\text{volume owned by the sub-company})}$$</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>It might appear odd to write $\beta P$, but in the entropy-centric view of thermodynamics, it is the quantity $\beta P$ that is fundamental, and in comparison, the pressure $P$ is less fundamental, as a ratio $P := \frac{\beta P}{\beta}$. Why, then, do we speak of pressure $P$ and temperature $T$, instead of $\beta$ and $\beta P$? It is because classical thermodynamics is traditionally understood as energy-centric.</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a><span class="fu">## Basic consequences</span></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thermodynamic force/suction</span></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>Since nature is entropy-maximizing, if entropy can be increased by moving some energy from one system to another, it will happen. Similarly for space. It would seem as if there is a **thermodynamic suction** that is sucking on on energy, and the side with the higher thermodynamic suction tends to absorb it. </span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>\text{thermodynamic suction of $X$} = \left(\frac{\partial S}{\partial X}\right)_{\text{non-}X}</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a>In energy-centric thermodynamics, we use **thermodynamic force**, or **thermodynamic potential**, defined by</span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>\text{thermodynamic force of $X$} = -\frac{\left(\frac{\partial S}{\partial X}\right)_{\text{non-}X}}{\left(\frac{\partial S}{\partial U}\right)_{\text{non-}U}}</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>For example, for a tank of gas, the macroscopic properties are $U, V, N$, and so it has three thermodynamic suctions:</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>  \beta &amp;= (\partial_U S)_{V, N}<span class="sc">\\</span></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>  \beta P &amp;= (\partial_V S)_{U, N}<span class="sc">\\</span></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>  -\beta \mu &amp;= (\partial_N S)_{U, V}</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>and the thermodynamic forces associated with $V, N$ are $P$ and $-\mu$.</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>Unfortunately, the notations for thermodynamic suctions are far from elegant. The first one, $\beta$, is the inverse of temperature.. The second one, $\beta P$, is $\beta$ multiplied by pressure. The third one is truly the most annoying, as it not only involves $\beta$, but also a negative sign. To see how the notation came about, we can write it out in differential form:</span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>$$dS = \beta dU + \beta P dV - \beta \mu dN$$</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>Conventional notations are energy-centric, so we rewrite it to single out $dU$:</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>dU = TdS + (- PdV) + \mu dN</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>Now we see how the notation came about: $TdS$ is the heat energy-flow into the system, $-PdV$ is the mechanical work energy-flow into the system, and $\mu dN$ is the chemical energy-flow into the system.</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>If I could truly reform notation, I would redefine $\beta P$ as $p_V$, meaning "the price of volume", meaning "the price of particle", and so on. In this notation, we have:</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a>dS &amp;= p_U dU + p_V dV + p_N dN <span class="sc">\\</span></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>dU &amp;= p_U^{-1}dS - \frac{p_V}{p_U}dV - \frac{p_N}{p_U}dN</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>::: {#exm-0}</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a><span class="fu">## photon gas with $\mu = 0$</span></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>Suppose we have a piston chamber, with its inner surface covered with silver, and there is a tiny speck of blackbody inside it, then the chamber would be filled with bouncing photons, in the form of a "photon gas". The photons would reflect off the surface of the chamber, some absorbed and some emitted in turn, by the blackbody.</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>As usual for gas, the state of the system is determined by its internal energy, volume, and particle number: $U, V, N$, with</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>$$dS = \beta dU + \beta PdV - \beta \mu dN$$</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>However, the photon gas is quite special, in that photons can be created and destroyed by the speck of blackbody, so at equilibrium, we must have $\beta\mu = 0$, for otherwise, the system would be able to increase in entropy simply by creating/destroying more photons, and thus it is not in equilibrium.</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>This contrasts with the typical case with chemical gases like oxygen, where the particle number in a reaction chamber is constant, allowing $\mu \neq 0$ even at equilibrium.</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a><span class="fu">### Helmholtz free entropy</span></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>When we have a small system connected to a large system, while we can solve its equilibria by maximizing the plain old entropy for the full compound system, it is often easier conceptually to define a "free entropy" for the small system, and treat the large system as a bath. This is similar to how one can solve for the motion of a cannonball on earth by describing a constant gravitational acceleration, even though we can could have solved for the full cannonball-earth two-body system.</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>::: {#def-helmholtz}</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a><span class="fu">## Helmholtz free entropy</span></span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>The **Helmholtz free entropy** is the convex dual of entropy with respect to energy:</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a>f(\beta, X) = \max_U <span class="co">[</span><span class="ot">S(U, X) - \beta U</span><span class="co">]</span></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>$$ {#eq-Helmholtz-S}</span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>where $U$ is its internal energy, and $X$ are some other macroscopic properties.</span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>Of historical importance is the **Helmholtz free energy** $F := - T f$, or equivalently,</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a>F = \min_U <span class="co">[</span><span class="ot">U - TS(U, X)</span><span class="co">]</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>$$ {#eq-Helmholtz-U}</span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>::: {#thm-helmholtz-free-entropy}</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a><span class="fu">## maximize Helmholtz free entropy</span></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>If a thermodynamic system is in energy-contact with an energy bath with price $\beta$, and is held under constraint on the state by $C(X) = 0$, then the system equilibrates at</span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>\max_{U, X} <span class="co">[</span><span class="ot">S(U, X) - \beta U</span><span class="co">]</span> = \max_{X} f(\beta, X)<span class="sc">\\</span></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a>C(X) = 0</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a>That is, the system always equilibrates at the maximal Helmholtz free entropy state that satisfies the constraint.</span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a>Equivalently, the system minimizes its Helmholtz free energy under constraint.</span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="false"}</span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a>If we prove the case for Helmholtz free entropy, then by multiplying it by $-T$, we find that the system minimizes its Helmholtz free energy under constraint. So it remains to prove the case for Helmholtz free entropy.</span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>We prove the case where there is no constraint on the state of the system. The proof for the case with constraint is similar.</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a>Suppose the system starts out at $\beta, U_0, X$. Then the equilibrium condition is</span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>\max (S_{bath} + S) <span class="sc">\\</span></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>U_{bath} + U = U_{bath, 0} + U_{0}</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a>The entropy of the bath is</span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a>$$S_{bath} = S_{bath, 0} + \beta Q$$</span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>where $Q = U_{bath} - U_{bath, 0}$ is the amount of energy received by the bath as heat.</span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a>Plugging this back in, the equilibrium condition simplifies to</span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a>\max_U <span class="co">[</span><span class="ot">\beta (U_0 - U) + S(U, X)</span><span class="co">]</span></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a>which is the desired result.</span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a>::: {#thm-helmholtz-free-work}</span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a><span class="fu">## Helmholtz free energy difference is available for work</span></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a>Consider the following method of extracting mechanical energy. Connect the system to an energy bath at the energy price $\beta$, and to a mechanical system of arbitrary design. The system starts at $\beta, U_0, X_0$ and ends at $\beta, U_1, X_1$. No matter how the mechanical system is designed, and no matter whether the process is reversible or not, we have</span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a>W\leq F(\beta, U_0, X_0) - F(\beta, U_1, X_1)</span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>where $W$ is "mechanical work done by the system", that is, the increase in internal energy of the mechanical system. This is an equality when the process is reversible.</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="true"}</span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a>By conservation of energy and the second law,</span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a>U_1 = U_0 - (W + Q) <span class="sc">\\</span></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a>\beta Q + S(U_1, X_1) \geq S(U_0, X_0)</span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>which simplifies to the result.</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a>If the process is reversible, then the entropy before and after must be equal, which gives us</span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a>U_1 = U_0 - (W + Q) <span class="sc">\\</span></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a>\beta Q + S(U_1, X_1) = S(U_0, X_0)</span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a>which simplifies to the result.</span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a>This result is typically interpreted as saying that $\Delta F = W$, that is, in a system in constant thermal equilibrium with an energy bath of constant temperature, the decrease in Helmholtz energy of the system is the maximal mechanical work extractable from the system. Incidentally, this explains the odd name of "free energy" -- "free" as in "free to do work" to contrast with the other parts of internal energy, which are chained up and not free to do work. Energy is born free, and eventually everywhere it is in chains.</span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>::: {#thm-envelope-helmholtz}</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a><span class="fu">## envelope theorem for Helmholtz</span></span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a>For any inverse temperature $\beta &gt; 0$ and thermodynamic properties $X$, let $U^*$ be the optimal internal energy that maximizes Helmholtz free entropy. We have</span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>\beta &amp;= (\partial_U S)_X|_{U=U^*(\beta, X), X = X} <span class="sc">\\</span></span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a>df    &amp;= (\partial_X S)_U|_{U=U^*(\beta, X), X = X} dX - U^*(\beta, X) d\beta</span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a>if $S$ is differentiable and strictly concave at that point.</span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof"}</span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a>For the first equation, differentiate $f$. For the second equation, apply the same no-arbitrage proof as in the proof of <span class="co">[</span><span class="ot">Hotelling's lemma</span><span class="co">](https://en.wikipedia.org/wiki/Hotelling%27s_lemma)</span> (see the essay on <span class="co">[</span><span class="ot">*Analytical Mechanics*</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/)</span>).</span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a>Economically speaking, the second equation is a special case of the <span class="co">[</span><span class="ot">envelope theorem</span><span class="co">](https://en.wikipedia.org/wiki/Envelope_theorem)</span>, just like Hotelling's lemma.</span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a><span class="fu">### First-order phase transition</span></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a>What happens if $S$ is not differentiable and strictly concave? In this case, we do not have $\beta = (\partial_U S)_X$. We have two possibilities.</span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a>The first possibility is pictured as follows. There is a kink in the curve of $S(U, X)$. At that point of critical internal energy $U_c$, there is an entire interval of possible $\beta$. What we would notice is that at that critical internal energy and critical entropy, the system can be in equilibrium with *any* heat bath with *any* temperature between $<span class="co">[</span><span class="ot">T_{c, min}, T_{c, max}</span><span class="co">]</span>$. As far as I know, such systems do not exist, as all physically real systems have a unique temperature at all possible states.</span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a><span class="al">![When there is a kink in the curve of $S(U, X)$, the system has an indeterminate temperature.](figure/indeterminate_temperature_SU_curve.png)</span></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a>The second possibility is pictured as follows. There is a bump in the curve, such that we can draw a double tangent over the bump, with slope $\beta_c$. At that critical inverse temperature, the system can be either at the lower tangent point, or the upper tangent point. It cannot be anywhere in-between, because as we saw, such points do not minimize $f(\beta, X)$, and thus are unstable.</span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a><span class="al">![When there is a double tangent in the curve of $S(U, X)$, the system undergoes a first-order phase transition with latent entropy and energy.](figure/first_order_phase_transition_SU_curve.png)</span></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a>For example, if we confine some liquid water in a vacuum chamber, and bathe it in a cold bath, then at its critical $\beta_c$, it would split into two parts, one part is all ice, and the other part is all water, mixed in just the right proportion to give it the correct amount of total internal energy. As it loses internal energy, the ice part grows larger, until it is all ice, at which point the system has finally gotten over the bump, and could cool down further.</span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a>At the critical point, $(\partial_{\beta}f)_X$ changes abruptly. So if we plot $\beta \mapsto f(\beta, X)$, the curve will kink there.</span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a><span class="fu">## Maxwell equal area rule</span></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a>In a first-order phase transition at a fixed temperature and varying pressure/volume, the $P, V$ diagram has a horizontal line going from $(P_c, V_1)$ to $(P_c, V_2)$, such that</span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a>$$\int PdV = P_c(V_2-V_1)$$</span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a><span class="al">![Maxwell's equal area rule states that the areas of the regions labelled I and II are equal.](figure/maxwell_equal_area_rule.png)</span></span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="false"}</span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a>Fix the system's internal energy $U$, and its temperature $T$, and plot the $V, S$ curve.</span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a>When pressure is at a critical value $P_c$, the line of slope $\beta P_c$ is tangent to the $V \mapsto S(U, V)$ curve at two different points, with volumes $V_1, V_2$. This is that first-order phase transition.</span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a>Now, move the system state from the first point to the second. During the process,</span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a>$$\int PdV = \int (TdS -dU) = \int TdS = T \Delta S = T \beta P_c(V_2 - V_1) = P_c(V_2-V_1)$$</span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a><span class="fu">### Other free entropies and energies</span></span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a>Consider a thermodynamic system whose entropy function is $S(U, V, X)$, where $U$ is the internal energy and $V$ is the volume. Its **Gibbs free entropy** is</span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a>g(\beta, \beta P, X) = \max_{U, V} (S(U, V, X) - \beta U - (\beta P)V)</span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a>In other words, it's the convex dual of entropy with respect to energy and volume. Similarly, its **Gibbs free energy** is $G = -g/\beta$.</span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gibbs free entropy is maximized</span></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a>Let a thermodynamic system be in equilibrium with an energy-and-volume bath of prices $\beta, \beta P$. If the system has constraint on the state by $C(X) = 0$, then the system equilibrates at</span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a>\max_{X} g(\beta, \beta P, X)<span class="sc">\\</span></span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a>C(X) = 0</span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a>And if $S$ is strictly concave and differentiable at that point, then $dg = (\partial_X S)_{U, V} dX - Ud\beta - V d(\beta P)$.</span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gibbs free energy difference is available for work</span></span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a>Connect a system to an energy-and-volume bath at marginal entropies $\beta, \beta P$, and a mechanical system of arbitrary design. The system starts at $\beta, \beta P, X_0$ and ends at $\beta, \beta P, X_1$. Then,</span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a>W\leq G(\beta, \beta P, X_0) - G(\beta, \beta P, X_1)</span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a>where $W$ is "work", that is, the increase in internal energy of the mechanical system. If the process is reversible, then equality holds.</span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a>::: {#thm-envelope-gibbs}</span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a><span class="fu">## envelope theorem for Gibbs</span></span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a>For any inverse temperature $\beta &gt; 0$, any pressure $P$, and other thermodynamic properties $X$, let $U^*, V^*$ be the optimal internal energy and volume that maximizes Gibbs free entropy, then</span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a>\beta   &amp;= (\partial_U S)_{V, X} <span class="sc">\\</span></span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a>\beta P &amp;= (\partial_V S)_{U, X}<span class="sc">\\</span></span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a>dg      &amp;= (\partial_X S)_{U, V} dX - U^* d\beta - V^* d(\beta P)</span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a>if $S$ is differentiable and strictly concave at that point. Here, the left sides of all equations are evaluated at $U=U^*(\beta, \beta P, X), V=V^*(\beta, \beta P, X), X = X$.</span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a>::: {#exr-0}</span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a>Prove the above theorems for Gibbs free entropy.</span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a>Similarly, if a system is in energy-volume-chemical contact with an energy-volume-chemical bath, then the following **Landau free entropy** is useful:</span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a>\omega(\beta, \beta P, -\beta\mu_1, \dots, -\beta\mu_n) = \max_{U, V, N_1, \dots, N_n} \left(S(U, V, N_1, \dots, N_n, X) - \beta U - (\beta P)V - \sum_{i=1}^n (-\beta \mu_i) N_i \right)</span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a>In other words, it's the convex dual of entropy with respect to energy, volume, and particle numbers.</span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a>::: {#exr-0}</span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a>Formulate and prove the analogous theorems for Landau free entropy.</span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a>::: {#exr-0}</span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a>If we consider a system, surrounded by gas, inside an adiathermal piston under an atmosphere, then we can consider the following form of free energy: $\tilde s(U, \beta P, X) := \max_{V} (S(U, V, X) - \beta U - (\beta P)V)$. Formulate and prove the analogous theorems for this free entropy.</span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a>Take-home lessons:</span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When a system is in contact with a $Y$-bath, then it is useful to consider the convex dual of the entropy with respect to $Y$, that is, $\max_Y (S(Y, X) - p_Y Y)$, where $p_Y$ is the marginal entropy of $Y$ of the bath. That is, the price of entropy on the bath-market.</span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Free entropy is maximized when the system equilibrates with a bath. Free energy is minimized.</span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Change in free energy is the maximal amount of work extractable when the system equilibrates with both a bath and a mechanical system. This maximal amount of work is extracted precisely when the process is reversible. The process is irreversible precisely when less than maximal amount of work is extracted.</span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a><span class="fu">### Maxwell relations</span></span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a>Since $dS = \beta dU + \beta P dV$, we have the first Maxwell relation</span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a>\partial_U \partial_V S = (\partial_V \beta)_U = (\partial_U(\beta P) )_V</span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-1}</span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a>In economic language, it states</span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-822"><a href="#cb1-822" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-823"><a href="#cb1-823" aria-hidden="true" tabindex="-1"></a>\partial_{q_i}\partial_{q_j} S = (\partial_{q_i} p_j)_{q_j} = (\partial_{q_j} p_i)_{q_i}</span>
<span id="cb1-824"><a href="#cb1-824" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-1-econ}</span>
<span id="cb1-825"><a href="#cb1-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-826"><a href="#cb1-826" aria-hidden="true" tabindex="-1"></a>where $q_i$ is the quantity of commodity $i$, and $p_i$ is its marginal utility. In economics, we usually prefer writing demanded quantity as a function of marginal price as</span>
<span id="cb1-827"><a href="#cb1-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-828"><a href="#cb1-828" aria-hidden="true" tabindex="-1"></a>$$(\partial_{p_j}q_i)_{q_j} = (\partial_{p_i}q_j)_{q_i}$$</span>
<span id="cb1-829"><a href="#cb1-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-830"><a href="#cb1-830" aria-hidden="true" tabindex="-1"></a>This is a symmetry of the <span class="co">[</span><span class="ot">cross-price elasticity of demand</span><span class="co">](https://en.wikipedia.org/wiki/Cross_elasticity_of_demand)</span>.<span class="ot">[^maxwell-relation-samuelson]</span></span>
<span id="cb1-831"><a href="#cb1-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-832"><a href="#cb1-832" aria-hidden="true" tabindex="-1"></a><span class="ot">[^maxwell-relation-samuelson]: </span>Samuelson used the Maxwell relations, and other relations, to justify neoclassical economics. His idea is that, while utility functions are unobservable, and we do not have a scientific instrument to measure "economic equilibrium", we can make falsifiable predictions from assuming that the economy is in equilibrium -- such as the symmetry of the cross-price elasticity of demand.</span>
<span id="cb1-833"><a href="#cb1-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-834"><a href="#cb1-834" aria-hidden="true" tabindex="-1"></a>For example, if $i, j$ are noodles and bread, then $(\partial_{q_i} p_j)_{q_j}$ is how much the marginal price of bread would rise if I have a little more noodle. As noodles and bread are substitutional goods, we expect the number to be negative, meaning that having more noodles, I would price bread less. The Maxwell relation then tells us that it is exactly the same in the other direction: If I am given a little more bread, I would price noodles less. Not only that, I would want less by *exactly the same amount*.</span>
<span id="cb1-835"><a href="#cb1-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-836"><a href="#cb1-836" aria-hidden="true" tabindex="-1"></a>The second relation is a bit hard to explain, since enthalpy really does not have a good representation in entropy-centric thermodynamics. However, it turns out to be just the third relation with $i, j$ switched.</span>
<span id="cb1-837"><a href="#cb1-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-838"><a href="#cb1-838" aria-hidden="true" tabindex="-1"></a>Since $df = \beta P dV - Ud\beta$, we have the third Maxwell relation</span>
<span id="cb1-839"><a href="#cb1-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-840"><a href="#cb1-840" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-841"><a href="#cb1-841" aria-hidden="true" tabindex="-1"></a>\partial_\beta\partial_V f = -(\partial_V U)_\beta = +(\partial_\beta(\beta P))_V</span>
<span id="cb1-842"><a href="#cb1-842" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-3}</span>
<span id="cb1-843"><a href="#cb1-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-844"><a href="#cb1-844" aria-hidden="true" tabindex="-1"></a>In economic language, we have</span>
<span id="cb1-845"><a href="#cb1-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-846"><a href="#cb1-846" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-847"><a href="#cb1-847" aria-hidden="true" tabindex="-1"></a>\partial_{p_i}\partial_{q_j} \left<span class="co">[</span><span class="ot">\max_{q_i}(S(q) - p_i q_i )\right</span><span class="co">]</span>= -(\partial_{q_j} q_i)_{p_i} = (\partial_{p_i}p_j)_{q_j}</span>
<span id="cb1-848"><a href="#cb1-848" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-3-econ}</span>
<span id="cb1-849"><a href="#cb1-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-850"><a href="#cb1-850" aria-hidden="true" tabindex="-1"></a>Continuing from the previous example, if $i, j$ are noodles and bread, and we open a shop with an infinite amount of noodles always at the exact price, then I would buy and sell from the noodle shop until my marginal price of noodles is equal to the shop's price. Now, $(\partial_{q_j} q_i)_{p_i}$ is how much noodles I would buy if I am given a marginal unit of bread. As noodles and bread are substitutional goods, this number is negative. This then means $(\partial_{p_i}p_j)_{q_j} &gt; 0$, meaning that if the noodle price suddenly increases a bit, then I would sell a bit of noodles until I have reached equilibrium again. At that equilibrium, since I have less noodles, I would price higher its substitutional good, bread, by an equal amount as the previous scenario.</span>
<span id="cb1-851"><a href="#cb1-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-852"><a href="#cb1-852" aria-hidden="true" tabindex="-1"></a>Since $dg = -Ud\beta - Vd(\beta P)$, we have the fourth Maxwell relation</span>
<span id="cb1-853"><a href="#cb1-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-854"><a href="#cb1-854" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-855"><a href="#cb1-855" aria-hidden="true" tabindex="-1"></a>-\partial_{\beta}\partial_{\beta P}g = (\partial_{\beta P}U)_\beta = (\partial_\beta V)_{\beta P}</span>
<span id="cb1-856"><a href="#cb1-856" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-4}</span>
<span id="cb1-857"><a href="#cb1-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-858"><a href="#cb1-858" aria-hidden="true" tabindex="-1"></a>In economic language, we have</span>
<span id="cb1-859"><a href="#cb1-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-860"><a href="#cb1-860" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-861"><a href="#cb1-861" aria-hidden="true" tabindex="-1"></a>\partial_{p_i}\partial_{p_j} \left<span class="co">[</span><span class="ot">\max_{q_i, q_j}(S(q) - p_i q_i - p_j q_j)\right</span><span class="co">]</span>= -(\partial_{p_j} q_i)_{p_i}= -(\partial_{p_i} q_j)_{p_j}</span>
<span id="cb1-862"><a href="#cb1-862" aria-hidden="true" tabindex="-1"></a>$$ {#eq-maxwell-4-econ}</span>
<span id="cb1-863"><a href="#cb1-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-864"><a href="#cb1-864" aria-hidden="true" tabindex="-1"></a>This is another symmetry of cross-price elasticity of demand.</span>
<span id="cb1-865"><a href="#cb1-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-866"><a href="#cb1-866" aria-hidden="true" tabindex="-1"></a>Continuing from the previous example, if $i, j$ are noodles and bread, and we open a shop with an infinite amount of noodles and bread, then I would of course buy and sell from the shop until my marginal prices of noodles and bread are equal to the shop's prices. Now, if the shop suddenly raises the price of bread by a small amount, I would sell off some bread until my marginal price for bread increases to the shop's new price. Now my marginal price for noodles increases too by substitutional effect, so I buy some noodles. Thus $(\partial_{p_j} q_i)_{p_i} &gt; 0$. Switching the scenario, we find that raising the price of noodles would make me buy bread by an amount equal to that in the previous scenario.</span>
<span id="cb1-867"><a href="#cb1-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-868"><a href="#cb1-868" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Alternate proof of the Maxwell relations" collapse="false"}</span>
<span id="cb1-869"><a href="#cb1-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-870"><a href="#cb1-870" aria-hidden="true" tabindex="-1"></a>We use the notation of economics here.</span>
<span id="cb1-871"><a href="#cb1-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-872"><a href="#cb1-872" aria-hidden="true" tabindex="-1"></a>Suppose we have commodities $1, 2, \dots, n$. We pick two commodities $i, j$, and fix all other commodity quantities. Thus, we can write $dS = p_i dq_i + p_j d q_j$.</span>
<span id="cb1-873"><a href="#cb1-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-874"><a href="#cb1-874" aria-hidden="true" tabindex="-1"></a>Since knowing $n$ properties of the thermodynamic system allows us to know its exact state, and we have already fixed $n-2$ properties of it, there only remain two more degrees of freedom. We can parameterize this by $(q_i, q_j)$, or $(p_i, q_j)$, or $(p_i, p_j)$, or any other reasonable coordinate system.</span>
<span id="cb1-875"><a href="#cb1-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-876"><a href="#cb1-876" aria-hidden="true" tabindex="-1"></a>If the thermodynamic system undergoes a cycle, then</span>
<span id="cb1-877"><a href="#cb1-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-878"><a href="#cb1-878" aria-hidden="true" tabindex="-1"></a>$$0 = \oint dS = \oint p_i dq_i + \oint p_j dq_j$$</span>
<span id="cb1-879"><a href="#cb1-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-880"><a href="#cb1-880" aria-hidden="true" tabindex="-1"></a>and thus, if we take the cycle infinitesimally small, we find that $dp_i\wedge dq_i = -dp_j \wedge dq_j$. That is, the map $(p_i, q_i) \mapsto (p_j, q_j)$ preserves areas, but reverses orientation. In particular, we have a Jacobian</span>
<span id="cb1-881"><a href="#cb1-881" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-882"><a href="#cb1-882" aria-hidden="true" tabindex="-1"></a>\frac{\partial(p_i, q_i)}{\partial(p_j, q_j)} = -1</span>
<span id="cb1-883"><a href="#cb1-883" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-884"><a href="#cb1-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-885"><a href="#cb1-885" aria-hidden="true" tabindex="-1"></a>Now, let $(x, y)$ be an arbitrary coordinate transform. By the chain rule for Jacobians,</span>
<span id="cb1-886"><a href="#cb1-886" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-887"><a href="#cb1-887" aria-hidden="true" tabindex="-1"></a>\frac{\partial(p_i, q_i)}{\partial(x, y)} = \frac{\partial(p_i, q_i)}{\partial(p_j, q_j)} \frac{\partial(p_j, q_j)}{\partial(x,y)} = -\frac{\partial(p_j, q_j)}{\partial(x,y)}</span>
<span id="cb1-888"><a href="#cb1-888" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-889"><a href="#cb1-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-890"><a href="#cb1-890" aria-hidden="true" tabindex="-1"></a>This allows us to derive all the Maxwell relations. For example, setting $(x, y) = (p_i, q_j)$ gives us the third relation</span>
<span id="cb1-891"><a href="#cb1-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-892"><a href="#cb1-892" aria-hidden="true" tabindex="-1"></a>$$(\partial_{q_j} q_i)_{p_i} = -(\partial_{p_i}p_j)_{q_j}$$</span>
<span id="cb1-893"><a href="#cb1-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-894"><a href="#cb1-894" aria-hidden="true" tabindex="-1"></a><span class="al">![Deriving the four Maxwell relations by picking the right variables for (x, y).](figure/maxwell_relations_commutative_diagram.png)</span></span>
<span id="cb1-895"><a href="#cb1-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-896"><a href="#cb1-896" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-897"><a href="#cb1-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-898"><a href="#cb1-898" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/banner/3.png)</span></span>
<span id="cb1-899"><a href="#cb1-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-900"><a href="#cb1-900" aria-hidden="true" tabindex="-1"></a><span class="fu">## Caratheodory's thermodynamics</span></span>
<span id="cb1-901"><a href="#cb1-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-902"><a href="#cb1-902" aria-hidden="true" tabindex="-1"></a>In the early 1900s, Constantin Caratheodory discovered a new way to "geometrize" thermodynamics, with the austere beauty of Euclidean geometry. Though his formulation fell into obscurity, it was reborn in neoclassical economics as utility theory.</span>
<span id="cb1-903"><a href="#cb1-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-904"><a href="#cb1-904" aria-hidden="true" tabindex="-1"></a><span class="fu">### Entropy and temperature</span></span>
<span id="cb1-905"><a href="#cb1-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-906"><a href="#cb1-906" aria-hidden="true" tabindex="-1"></a>Consider a thermodynamic system with $n+1$ dimensions of state space. Give the state space coordinates $q_0, q_1, \dots, q_n$. For example, for a tank of ideal gas where the particle number is fixed, we have $q_0 = U, q_1 = V$.</span>
<span id="cb1-907"><a href="#cb1-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-908"><a href="#cb1-908" aria-hidden="true" tabindex="-1"></a>Let the system be at a certain state $\vec q$, and wrap the system in a perfectly insulating (adiathermal) blanket. The system can undergo many different kinds of adiathermal motion, but there are certain motions that it cannot undergo.</span>
<span id="cb1-909"><a href="#cb1-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-910"><a href="#cb1-910" aria-hidden="true" tabindex="-1"></a>For example, for a piston of ideal gas, the possible motions are adiabatic expansion, adiabatic compression, Joule expansion, and any combination of them. However, "Joule compression" is impossible -- the gas will not spontaneously contract to the left half of the system, pulling in the piston head, anymore than a messy room will spontaneously tidy itself.</span>
<span id="cb1-911"><a href="#cb1-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-912"><a href="#cb1-912" aria-hidden="true" tabindex="-1"></a>We say that $\vec q'$ is adiathermally accessible from $\vec q$ if there exists a path from $\vec q$ to $\vec q'$, such that the path is infinitesimally adiathermal<span class="ot">[^adiathermal-terminology]</span> at every point.</span>
<span id="cb1-913"><a href="#cb1-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-914"><a href="#cb1-914" aria-hidden="true" tabindex="-1"></a><span class="ot">[^adiathermal-terminology]: </span>The word "adiathermal" means "heat does not pass through", while "adiabatic" has an entire history of meaning that makes it hard to say what exactly it is (see <span class="co">[</span><span class="ot">my essay on Analytical Mechanics</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/analytical-mechanics/)</span>). Personally, I think "adiabatic" means "zero entropy change", and all its other meanings derive from it.</span>
<span id="cb1-915"><a href="#cb1-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-916"><a href="#cb1-916" aria-hidden="true" tabindex="-1"></a><span class="al">![Adiabatic accessibility in the $U, V$ diagram.](figure/adiabatic_accessibility.png)</span></span>
<span id="cb1-917"><a href="#cb1-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-918"><a href="#cb1-918" aria-hidden="true" tabindex="-1"></a>Here is **Caratheodory's version of the second law of thermodynamics**:</span>
<span id="cb1-919"><a href="#cb1-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-920"><a href="#cb1-920" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>In any neighborhood of any point $\vec q$, there are points adiabatically inaccessible from it.</span>
<span id="cb1-921"><a href="#cb1-921" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Furthermore, for any two points, $\vec q, \vec q'$, at least one of them is adiabatically accessible from the other.</span>
<span id="cb1-922"><a href="#cb1-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-923"><a href="#cb1-923" aria-hidden="true" tabindex="-1"></a>The effect of these two axioms is that we can define a total ordering $\preceq$ on state space, where we write $\vec q \preceq \vec q'$ to mean that $\vec q$ can adiabatically access $\vec q'$, and write $\vec q \sim \vec q'$ to mean that they are mutually adiabatically accessible.</span>
<span id="cb1-924"><a href="#cb1-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-925"><a href="#cb1-925" aria-hidden="true" tabindex="-1"></a>Interpreted economically, we say that the system is an economic agent, that each $\vec q$ is a bundle of goods, that $\vec q \preceq \vec q'$ means that $\vec q'$ is preferable to the agent, and that $\vec q \sim \vec q'$ means they are equally preferred.</span>
<span id="cb1-926"><a href="#cb1-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-927"><a href="#cb1-927" aria-hidden="true" tabindex="-1"></a>The total ordering partitions the state space into contour surfaces of equal accessibility, or <span class="co">[</span><span class="ot">indifference surfaces</span><span class="co">](https://en.wikipedia.org/wiki/Indifference_curve)</span>. Assuming the state space is not designed to be <span class="co">[</span><span class="ot">pathological</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Pathological_(mathematics)), these indifference surfaces will be differentiable.</span>
<span id="cb1-928"><a href="#cb1-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-929"><a href="#cb1-929" aria-hidden="true" tabindex="-1"></a>Let us consider the indifference surface passing state $\vec q$. The indifference surface is locally a plane, so it has equations</span>
<span id="cb1-930"><a href="#cb1-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-931"><a href="#cb1-931" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-932"><a href="#cb1-932" aria-hidden="true" tabindex="-1"></a>dq_0 - \sum_i \tilde p_i dq_i = 0</span>
<span id="cb1-933"><a href="#cb1-933" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-934"><a href="#cb1-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-935"><a href="#cb1-935" aria-hidden="true" tabindex="-1"></a>where $\tilde p_i = (\partial_{q_i}q_0)_{q_1, \dots, q_n}$. For example, a tank of (non-ideal) gas satisfies $dU + PdV = 0$ over its indifference curves.</span>
<span id="cb1-936"><a href="#cb1-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-937"><a href="#cb1-937" aria-hidden="true" tabindex="-1"></a><span class="al">![The field of planes defined by $dq_0 - \sum_i \tilde p_i dq_i = 0$.](figure/contact_geometry_one-form.png)</span></span>
<span id="cb1-938"><a href="#cb1-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-939"><a href="#cb1-939" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-940"><a href="#cb1-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-941"><a href="#cb1-941" aria-hidden="true" tabindex="-1"></a><span class="fu">## existence and uniqueness of temperature and entropy</span></span>
<span id="cb1-942"><a href="#cb1-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-943"><a href="#cb1-943" aria-hidden="true" tabindex="-1"></a>Let $\omega = dq_0 - \sum_i \tilde p_i dq_i$. If $\omega$ is nonzero everywhere, then there exists functions $\beta, S$ on the state space, such that $dS = \beta \omega$.</span>
<span id="cb1-944"><a href="#cb1-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-945"><a href="#cb1-945" aria-hidden="true" tabindex="-1"></a>Furthermore, they are unique up to a monotonic transform. That is, if we have another solution $\beta', S'$, then there exists a strictly monotonic function $f$ such that $S' = f \circ S$.</span>
<span id="cb1-946"><a href="#cb1-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-947"><a href="#cb1-947" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-948"><a href="#cb1-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-949"><a href="#cb1-949" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof"}</span>
<span id="cb1-950"><a href="#cb1-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-951"><a href="#cb1-951" aria-hidden="true" tabindex="-1"></a>At each point $P$ the one-form $\omega(p)$ is visualized as a stack of parallel planes. The planes are quilted together, but with "uneven thickness". By scaling the one-forms just right at every point, the thickness becomes equalized, and so $\beta \omega = dg$ for two real-valued functions $\beta, S$.</span>
<span id="cb1-952"><a href="#cb1-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-953"><a href="#cb1-953" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Proving Caratheodory's theorem. Figure from [Wikipedia](https://en.wikipedia.org/wiki/File:Caratheodory%27s_theorem_illustration.jpg).</span><span class="co">](figure/Caratheodory_s_theorem_illustration.jpg)</span>{width=100% fig-align="center"}</span>
<span id="cb1-954"><a href="#cb1-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-955"><a href="#cb1-955" aria-hidden="true" tabindex="-1"></a>Given any other solution $\beta', S'$, both $S$ and $S'$ must have the same contour lines, so there exists some function that maps the $S$-height of a contour line to its $S'$-height.</span>
<span id="cb1-956"><a href="#cb1-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-957"><a href="#cb1-957" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-958"><a href="#cb1-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-959"><a href="#cb1-959" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cardinal and ordinal utilities</span></span>
<span id="cb1-960"><a href="#cb1-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-961"><a href="#cb1-961" aria-hidden="true" tabindex="-1"></a>Economically speaking, $\tilde p_i$ is the marginal worth of $q_i$ denoted in units of $q_0$. For example, we can say that $q_0$ are cowry shells, which themselves are pretty and give us some utility. However, it can also be used as a monetary unit. Then, if $i$ is bread, then $\tilde p_i$ is the marginal amount of cowry shells that we would pay for a marginal amount of bread.</span>
<span id="cb1-962"><a href="#cb1-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-963"><a href="#cb1-963" aria-hidden="true" tabindex="-1"></a>If we were to visit a free market where we can buy and sell items denoted in cowry shells, then we would buy bread if $\tilde p_i &gt; \tilde p_{i, market}$, and sell bread if $\tilde p_i &lt; \tilde p_{i, market}$. Right at the border of $\tilde p_i = \tilde p_{i, market}$, we would be indifferent about buying or selling bread. When $\tilde p_i = \tilde p_{i, market}$ for all $i$, we would be completely indifferent about the market.</span>
<span id="cb1-964"><a href="#cb1-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-965"><a href="#cb1-965" aria-hidden="true" tabindex="-1"></a>$S$ is the utility, and $\beta$ is the marginal utility of cowry shells. The theorem tells us that just by knowing how we *order* the goods (" $S(\vec q) &gt; S(\vec q')$ "), we can extract a *numerical value* for the goods (" $S(\vec q) - S(\vec q') = 1.34(S(\vec q'') - S(\vec q'''))$ "). Out of *ordinal utility*, we have achieved *cardinal utility*.</span>
<span id="cb1-966"><a href="#cb1-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-967"><a href="#cb1-967" aria-hidden="true" tabindex="-1"></a>There used to be a debate between "ordinalists" and "cardinalists" of utility theory. The "cardinalists" were the more venerable of the two camps, tracing back to Bentham's felicific calculus and the marginalist revolution. They argued that utility is real-valued, like entropy and temperature. The "ordinalists" countered that a nobody has ever measured a utility in anyone's brain. The only thing we can observe is preferences: I prefer this over that -- I can *order* everything that can ever happen to me on a *numberless* line of preferences. Similarly, nobody can ever actually measure temperature or entropy, only that energy flows from this gas to that gas, which presumably has lower temperature, and that one chunk of gas in one state ends up in another state, which presumably has higher entropy.</span>
<span id="cb1-968"><a href="#cb1-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-969"><a href="#cb1-969" aria-hidden="true" tabindex="-1"></a>The debate has been mostly resolved by the work of <span class="co">[</span><span class="ot">Gérard Debreu</span><span class="co">](https://en.wikipedia.org/wiki/G%C3%A9rard_Debreu)</span>, who showed that under fairly reasonable assumptions, cardinal utility is possible <span class="co">[</span><span class="ot">@debreuTheoryValueAxiomatic1971</span><span class="co">]</span>.<span class="ot">[^gerard-debreu]</span></span>
<span id="cb1-970"><a href="#cb1-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-971"><a href="#cb1-971" aria-hidden="true" tabindex="-1"></a><span class="ot">[^gerard-debreu]: </span>Out of all those famous economists I have seen, Gérard Debreu is perhaps the most mathematically austere. Reading his works, I felt like he was another G. H. Hardy, a Bourbaki of economics. He did economics not to improve the world, not to help people, and not to advance a political agenda, but to simply uncover an ꙮmmatidium of eternity.</span>
<span id="cb1-972"><a href="#cb1-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-973"><a href="#cb1-973" aria-hidden="true" tabindex="-1"></a>This theorem, or rather, this *family* of theorems, have several names, as befitting for such a versatile and productive family. In calculus, it's called the <span class="co">[</span><span class="ot">integrability of Pfaffian forms</span><span class="co">](https://en.wikipedia.org/wiki/Integrability_conditions_for_differential_systems)</span>. In differential geometry, it's called <span class="co">[</span><span class="ot">Darboux's theorem</span><span class="co">](https://en.wikipedia.org/wiki/Darboux%27s_theorem)</span>, or <span class="co">[</span><span class="ot">Frobenius theorem</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Frobenius_theorem_(differential_topology)). In economics, it's called the integrability of demand, or the cardinal-ordinal <span class="co">[</span><span class="ot">utility representation theorem</span><span class="co">](https://en.wikipedia.org/wiki/Utility_representation_theorem)</span>.</span>
<span id="cb1-974"><a href="#cb1-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-975"><a href="#cb1-975" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="What's so special about energy, or cowry shells?"}</span>
<span id="cb1-976"><a href="#cb1-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-977"><a href="#cb1-977" aria-hidden="true" tabindex="-1"></a>When cast in the language of economics, cowry shells are not special. We could denote prices in cowry shells, or cans of sardine, or grams of gold. That is, we are free to pick any numéraire we want, as long as we are consistent about it.</span>
<span id="cb1-978"><a href="#cb1-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-979"><a href="#cb1-979" aria-hidden="true" tabindex="-1"></a>Similarly, energy is not special. For example, with ideal gas, we could write the first law of thermodynamics as the conservation of energy, like</span>
<span id="cb1-980"><a href="#cb1-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-981"><a href="#cb1-981" aria-hidden="true" tabindex="-1"></a>$$dU - (-P)dV = \beta^{-1}dS$$</span>
<span id="cb1-982"><a href="#cb1-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-983"><a href="#cb1-983" aria-hidden="true" tabindex="-1"></a>or as the conservation of volume, like</span>
<span id="cb1-984"><a href="#cb1-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-985"><a href="#cb1-985" aria-hidden="true" tabindex="-1"></a>$$dV - (-P^{-1})dU= (\beta P)^{-1}dS$$</span>
<span id="cb1-986"><a href="#cb1-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-987"><a href="#cb1-987" aria-hidden="true" tabindex="-1"></a>and from the perspective of classical thermodynamics, there is *no* possibility of saying that energy is *more special* than volume. Energy is exactly as special as volume, and no more special than that.</span>
<span id="cb1-988"><a href="#cb1-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-989"><a href="#cb1-989" aria-hidden="true" tabindex="-1"></a>When I realized this difference, I was so incensed at this mistake that I wrote an entire <span class="co">[</span><span class="ot">sci-fi worldbuilding sketch</span><span class="co">](#sec-stereodynamics)</span> about an alien species, for which it is the conservation of volume that is fundamental, not energy, and which discovered stereodynamics, not thermodynamics.</span>
<span id="cb1-990"><a href="#cb1-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-991"><a href="#cb1-991" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-992"><a href="#cb1-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-993"><a href="#cb1-993" aria-hidden="true" tabindex="-1"></a><span class="fu">### Extensive entropy</span></span>
<span id="cb1-994"><a href="#cb1-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-995"><a href="#cb1-995" aria-hidden="true" tabindex="-1"></a>While we have constructed the temperature $T$ and the entropy $S$ of an isolated system, it is not unique: we can stretch and compress the entropy function $S$ arbitrarily by a monotonic function, and as long as we modify the temperature function $T$ just right, the two modifications cancel out, and we have $TdS = T' dS'$.</span>
<span id="cb1-996"><a href="#cb1-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-997"><a href="#cb1-997" aria-hidden="true" tabindex="-1"></a>In order to uniquely fix an entropy function, we need further assumptions. The most commonly used method is by considering what happens to the entropy of a compound system. In general, there is no reason to expect entropy to be extensive -- if we take compound two systems together, the entropy of the compound system should be the sum of the two subsystems. However, if we make some assumptions on "rationality", then the entropy would be uniquely fixed, and would be extensive.</span>
<span id="cb1-998"><a href="#cb1-998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-999"><a href="#cb1-999" aria-hidden="true" tabindex="-1"></a>::: {#exr-0}</span>
<span id="cb1-1000"><a href="#cb1-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1001"><a href="#cb1-1001" aria-hidden="true" tabindex="-1"></a><span class="fu">## von Neumann--Morgenstern entropy construction</span></span>
<span id="cb1-1002"><a href="#cb1-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1003"><a href="#cb1-1003" aria-hidden="true" tabindex="-1"></a>Study the statement of the <span class="co">[</span><span class="ot">von Neumann--Morgenstern utility theorem</span><span class="co">](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem)</span>, and translate it to thermodynamics. It should be of the following form:</span>
<span id="cb1-1004"><a href="#cb1-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1005"><a href="#cb1-1005" aria-hidden="true" tabindex="-1"></a>Assuming that the adiabatic accessibility of any compound system satisfies the following properties</span>
<span id="cb1-1006"><a href="#cb1-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1007"><a href="#cb1-1007" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>...</span>
<span id="cb1-1008"><a href="#cb1-1008" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>...  </span>
<span id="cb1-1009"><a href="#cb1-1009" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb1-1010"><a href="#cb1-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1011"><a href="#cb1-1011" aria-hidden="true" tabindex="-1"></a>then the entropy of any compound system is the sum of the entropies of its subsystems, and the entropy function is unique up to adding a constant and multiplying by a positive scalar.</span>
<span id="cb1-1012"><a href="#cb1-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1013"><a href="#cb1-1013" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1014"><a href="#cb1-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1015"><a href="#cb1-1015" aria-hidden="true" tabindex="-1"></a>Some hints:</span>
<span id="cb1-1016"><a href="#cb1-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1017"><a href="#cb1-1017" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It might help your intuition if you anthropomorphize Nature as a "vNM-rational agent".</span>
<span id="cb1-1018"><a href="#cb1-1018" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The standard formulation of the vNM theorem uses lotteries of form $pM + (1-p)N$, where $p\in (0, 1)$ is a probability, and $M, N$ are bundles of goods. However, it is impossible generally to "take $0.37$ of a system $M$ and compound it with $0.63$ of system $N$". To bypass this difficulty, replace that with "take $37$ copies of system $M$ and compound them with $63$ copies of system $N$".</span>
<span id="cb1-1019"><a href="#cb1-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1020"><a href="#cb1-1020" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/banner/5.png)</span></span>
<span id="cb1-1021"><a href="#cb1-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1022"><a href="#cb1-1022" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bonus: Geometric thermodynamics</span></span>
<span id="cb1-1023"><a href="#cb1-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1024"><a href="#cb1-1024" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Although geometrical representations of propositions in the thermodynamics of fluids are in general use, and have done good service in disseminating clear notions in this science, yet they have by no means received the extension in respect to variety and generality of which they are capable.</span></span>
<span id="cb1-1025"><a href="#cb1-1025" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-1026"><a href="#cb1-1026" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gibbsGraphicalMethodsThermodynamics1957</span><span class="co">]</span></span>
<span id="cb1-1027"><a href="#cb1-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1028"><a href="#cb1-1028" aria-hidden="true" tabindex="-1"></a><span class="fu">### Contact geometry</span></span>
<span id="cb1-1029"><a href="#cb1-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1030"><a href="#cb1-1030" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Every mathematician knows it is impossible to understand an elementary course in thermodynamics. The reason is that thermodynamics is based—as Gibbs has explicitly proclaimed -- on a rather complicated mathematical theory, on the contact geometry. Contact geometry is one of the few 'simple geometries' of the so-called Cartan’s list, but it is still mostly unknown to the physicist -- unlike the Riemannian geometry and the symplectic or Poisson geometries, whose fundamental role in physics is today generally accepted.</span></span>
<span id="cb1-1031"><a href="#cb1-1031" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-1032"><a href="#cb1-1032" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; V.I. Arnol'd </span><span class="co">[</span><span class="ot">@caldiProceedingsGibbsSymposium1990, page 163</span><span class="co">]</span></span>
<span id="cb1-1033"><a href="#cb1-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1034"><a href="#cb1-1034" aria-hidden="true" tabindex="-1"></a>To explain this mysterious remark, we take a plunge into abstraction. We know that a real gas has properties $P, V, T, S, \dots$, and that they satisfy the differential equation:</span>
<span id="cb1-1035"><a href="#cb1-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1036"><a href="#cb1-1036" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1037"><a href="#cb1-1037" aria-hidden="true" tabindex="-1"></a>dS = \beta dU + \beta PdV</span>
<span id="cb1-1038"><a href="#cb1-1038" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1039"><a href="#cb1-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1040"><a href="#cb1-1040" aria-hidden="true" tabindex="-1"></a>To clean up the notation, we can change the notation to</span>
<span id="cb1-1041"><a href="#cb1-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1042"><a href="#cb1-1042" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1043"><a href="#cb1-1043" aria-hidden="true" tabindex="-1"></a>dS = p_1 dq_1 + p_2 dq_2</span>
<span id="cb1-1044"><a href="#cb1-1044" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1045"><a href="#cb1-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1046"><a href="#cb1-1046" aria-hidden="true" tabindex="-1"></a>This formula has a clear interpretation in economics: if the marginal utility of commodity $1$ is $p_1$, and the marginal utility of commodity $2$ is $p_2$, then if we receive $\delta q_1, \delta q_2$, our utility would increase by $p_1 \delta q_1 + p_2 \delta q_2$.</span>
<span id="cb1-1047"><a href="#cb1-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1048"><a href="#cb1-1048" aria-hidden="true" tabindex="-1"></a>The difficult thing about classical thermodynamics is that there are so many quantities, such as $T, V, N, \dots$. The saving grace is that it turns out that there are only a few degrees of freedom.<span class="ot">[^parthian-shot]</span></span>
<span id="cb1-1049"><a href="#cb1-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1050"><a href="#cb1-1050" aria-hidden="true" tabindex="-1"></a><span class="ot">[^parthian-shot]: </span>The Parthian shot is that now you are burdened with dozens of equations relating these quantities. I cannot remember any of the Maxwell relations, so I look at Wikipedia every time I need to calculate with them.</span>
<span id="cb1-1051"><a href="#cb1-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1052"><a href="#cb1-1052" aria-hidden="true" tabindex="-1"></a>However, why is it that a macroscopic lump of matter, whirling with $10^{23}$ molecules, turn out to be characterized by only a few degrees of freedom? Why is it that a national economy, swarming with $10^8$ people, has macroeconomic laws? For the first question, the answer is given by classical thermodynamics: the lump of matter is maximizing its entropy under constraints, so its degrees of freedom are exactly as many as the number of constraints it is laboring under. For the second question, the answer is given by neoclassical economics: the national economy behaves as if it is maximizing a social utility function under its resource constraints.</span>
<span id="cb1-1053"><a href="#cb1-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1054"><a href="#cb1-1054" aria-hidden="true" tabindex="-1"></a>With that brief look at philosophy, we return to abstract thermodynamics. We have a lump of matter (such as ideal gas in a piston), of which we can measure five different properties: $p_1, p_2, q_1, q_2, S$. In general, we expect that the space of possible measurements is 5-dimensional, but it turns out that they collapse down to a 2-dimensional curved surface. This is why we could completely fix its state knowing just its $V, U$, or just its $P, T$, etc.</span>
<span id="cb1-1055"><a href="#cb1-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1056"><a href="#cb1-1056" aria-hidden="true" tabindex="-1"></a>The question now arises: Why is it possible to collapse things down to this curved surface?</span>
<span id="cb1-1057"><a href="#cb1-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1058"><a href="#cb1-1058" aria-hidden="true" tabindex="-1"></a>Things are already interesting when we have just one commodity:</span>
<span id="cb1-1059"><a href="#cb1-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1060"><a href="#cb1-1060" aria-hidden="true" tabindex="-1"></a>$$dS - pdq = 0$$</span>
<span id="cb1-1061"><a href="#cb1-1061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1062"><a href="#cb1-1062" aria-hidden="true" tabindex="-1"></a>and we ask: Why is it possible to collapse the space of $(q, p, S)$ from 3 to 1 dimension?</span>
<span id="cb1-1063"><a href="#cb1-1063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1064"><a href="#cb1-1064" aria-hidden="true" tabindex="-1"></a>In modern geometry, an expression like $dS - \sum_i p_i dq_i = 0$ defines a field of planes in $\R^3$. That is, at each point $(q, p, S)$, we construct a plane defined by</span>
<span id="cb1-1065"><a href="#cb1-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1066"><a href="#cb1-1066" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1067"><a href="#cb1-1067" aria-hidden="true" tabindex="-1"></a><span class="sc">\{</span>(q + \delta q, p + \delta p, S + \delta S): \delta S - p \delta q = 0<span class="sc">\}</span></span>
<span id="cb1-1068"><a href="#cb1-1068" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1069"><a href="#cb1-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1070"><a href="#cb1-1070" aria-hidden="true" tabindex="-1"></a>For example, in three dimensions, the field of planes $dS - pdq = 0$ would look like it is constantly twisting as $p$ increases. The study of geometric structures definable via the field of planes is <span class="co">[</span><span class="ot">contact geometry</span><span class="co">](https://en.wikipedia.org/wiki/Contact_geometry)</span>.<span class="ot">[^anticlimax]</span></span>
<span id="cb1-1071"><a href="#cb1-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1072"><a href="#cb1-1072" aria-hidden="true" tabindex="-1"></a><span class="ot">[^anticlimax]: </span>This explanation might sound like an anticlimax, and I imagine someone would object "Thermodynamics is reduced to contact geometry... but what is contact geometry?". My answer is that contact geometry simply *is*. It is not supposed to be a generator of intuitions. Instead, it is a common language that bridges between intuitions. By casting thermodynamics, economics, mechanics, etc, into the language of contact geometry, we would then be able to translate intuition from one field to another field. Saying that "thermodynamics is contact geometry" is not telling you an intuitive way to see thermodynamics, but rather, an intuitive way to see contact geometry.</span>
<span id="cb1-1073"><a href="#cb1-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1074"><a href="#cb1-1074" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The field of planes $dS - pdq = 0$ in $\R^{2+1}$. Figure from [Wikipedia](https://en.wikipedia.org/wiki/File:Standard_contact_structure.svg).</span><span class="co">](figure/standard_contact_structure.svg)</span></span>
<span id="cb1-1075"><a href="#cb1-1075" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1076"><a href="#cb1-1076" aria-hidden="true" tabindex="-1"></a>Given such a field of planes $dS - \sum_{i=1}^n p_i dq_i$ in $\R^{2n+1}$, we say that a manifold is a **Legendrian submanifold** iff the manifold has $n$ dimensions, and is tangent to the field of planes at every point.</span>
<span id="cb1-1077"><a href="#cb1-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1078"><a href="#cb1-1078" aria-hidden="true" tabindex="-1"></a>For example, when $n=1$, a Legendrian submanifold is a curve that winds around $\R^3$ and is always tangent to the plane at every moment.</span>
<span id="cb1-1079"><a href="#cb1-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1080"><a href="#cb1-1080" aria-hidden="true" tabindex="-1"></a>Let $S(q)$ be a differentiable function. We can interpret $S(q)$ as the amount of money we can earn if we produce something using the bundle of raw materials $(q_1, \dots, q_n)$.</span>
<span id="cb1-1081"><a href="#cb1-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1082"><a href="#cb1-1082" aria-hidden="true" tabindex="-1"></a>Given any market price for the raw materials, $q^* = \argmax_q (S(q) - \braket{p, q})$ is the profit-maximizing production plan, and $\Pi(p) = \max_q (S(q) - \braket{p, q})$ is the profit.</span>
<span id="cb1-1083"><a href="#cb1-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1084"><a href="#cb1-1084" aria-hidden="true" tabindex="-1"></a>::: {#thm-profit-maximization-legendrian-manifold}</span>
<span id="cb1-1085"><a href="#cb1-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1086"><a href="#cb1-1086" aria-hidden="true" tabindex="-1"></a>The "profit-maximization surface" defined by $p \mapsto (q^*, p, S(q^*))$ is a Legendrian submanifold.</span>
<span id="cb1-1087"><a href="#cb1-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1088"><a href="#cb1-1088" aria-hidden="true" tabindex="-1"></a>Conversely, given any Legendrian submanifold parameterized by $p \mapsto (q(p), p, S(q(p)) )$, then $q(p)$ is profit-stationarizing. That is,</span>
<span id="cb1-1089"><a href="#cb1-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1090"><a href="#cb1-1090" aria-hidden="true" tabindex="-1"></a>$$\nabla_q (S(q) - \braket{p, q}) = 0$$</span>
<span id="cb1-1091"><a href="#cb1-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1092"><a href="#cb1-1092" aria-hidden="true" tabindex="-1"></a>at $q(p)$. If $S$ is strictly concave, then $q(p)$ is profit-maximizing.</span>
<span id="cb1-1093"><a href="#cb1-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1094"><a href="#cb1-1094" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1095"><a href="#cb1-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1096"><a href="#cb1-1096" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof"}</span>
<span id="cb1-1097"><a href="#cb1-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1098"><a href="#cb1-1098" aria-hidden="true" tabindex="-1"></a>The first part is proven by Hotelling's lemma.</span>
<span id="cb1-1099"><a href="#cb1-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1100"><a href="#cb1-1100" aria-hidden="true" tabindex="-1"></a>The second part is proven by plugging in $dS - \sum_i p_i dq_i = 0$. And if $S$ is strictly concave, then $q \mapsto S(q) - \braket{p, q}$ is also strictly concave, and so zero gradient implies global maximum.</span>
<span id="cb1-1101"><a href="#cb1-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1102"><a href="#cb1-1102" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1103"><a href="#cb1-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1104"><a href="#cb1-1104" aria-hidden="true" tabindex="-1"></a>Economically speaking, $\max_q (S(q) - \braket{p, q})$ means to maximize profit. What does it mean, thermodynamically speaking? It means minimizing $\braket{p, q} - S(q)$, which is the Gibbs free entropy! Maximizing profit when a factory has access to a market is the same as minimizing Gibbs free entropy when a system is in contact with a bath.</span>
<span id="cb1-1105"><a href="#cb1-1105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1106"><a href="#cb1-1106" aria-hidden="true" tabindex="-1"></a><span class="fu">### Samuelson's area-ratio thermodynamics</span></span>
<span id="cb1-1107"><a href="#cb1-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1108"><a href="#cb1-1108" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Philosophy</span></span>
<span id="cb1-1109"><a href="#cb1-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1110"><a href="#cb1-1110" aria-hidden="true" tabindex="-1"></a>In Paul Samuelson's Nobel prize lecture of 1970, among comments of classical mechanics, variational principles, and neoclassical economics, he said something curious about the analogy between classical thermodynamics and neoclassical economics:</span>
<span id="cb1-1111"><a href="#cb1-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1112"><a href="#cb1-1112" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; However, if you look upon the monopolistic firm hiring 99 inputs as an example of a maximum system, you can connect up its structural relations with those that prevail for an entropy-maximizing thermodynamic system. Pressure and volume, and for that matter absolute temperature and entropy, have to each other the same conjugate or dualistic relation that the wage rate has to labor or the land rent has to acres of land. Figure 2 can now do double duty, depicting the economic relationships as well as the thermodynamic ones.</span></span>
<span id="cb1-1113"><a href="#cb1-1113" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-1114"><a href="#cb1-1114" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; If someone challenged me to explain what the existence of </span><span class="co">[</span><span class="ot">utility</span><span class="co">]</span><span class="at"> implies, but refused to let me use the language of partial derivatives, I could illustrate by an equi-proportional area property... I may say that the idea for this proposition in economics came to me in connection with some amateurish researches in the field of thermodynamics. While reading Clerk Maxwell's charming introduction to thermodynamics...</span></span>
<span id="cb1-1115"><a href="#cb1-1115" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-1116"><a href="#cb1-1116" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@samuelsonMaximumPrinciplesAnalytical1971</span><span class="co">]</span></span>
<span id="cb1-1117"><a href="#cb1-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1118"><a href="#cb1-1118" aria-hidden="true" tabindex="-1"></a><span class="al">![Samuelson's equal area ratio condition. In the diagram, we have $a:b = c:d$](figure/Samuelson_area_ratio_condition.png)</span></span>
<span id="cb1-1119"><a href="#cb1-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1120"><a href="#cb1-1120" aria-hidden="true" tabindex="-1"></a>This intriguing little remark piqued my interest, and after a little digging, I figured it out.<span class="ot">[^area-ration-thermodynamics]</span></span>
<span id="cb1-1121"><a href="#cb1-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1122"><a href="#cb1-1122" aria-hidden="true" tabindex="-1"></a><span class="ot">[^area-ration-thermodynamics]: </span>Based on research by James Bell Cooper, who seems to be the world expert in this obscure field <span class="co">[</span><span class="ot">@cooperSurprisingUbiquitySamuelson2006; @cooperCharacterizingAreaCondition2001</span><span class="co">]</span>.</span>
<span id="cb1-1123"><a href="#cb1-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1124"><a href="#cb1-1124" aria-hidden="true" tabindex="-1"></a>Samuelson is alluding to a deep problem in economics theory: Nobody has ever seen a utility function, anymore than anybody has ever seen an entropy. If this is the case, then how do we know that agents are maximizing a utility, or that systems are maximizing an entropy? In his long career, he searched for many ways to answer this, coming down to the idea that, even though we cannot measure utility, we can measure many things, such as how firms respond to prices. Given some measurable quantities, we can then prove, mathematically, that something is being maximized. At that point, we can simply call that something "utility", and continue doing economics as usual.</span>
<span id="cb1-1125"><a href="#cb1-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1126"><a href="#cb1-1126" aria-hidden="true" tabindex="-1"></a>Philosophically, Samuelson was greatly influenced by <span class="co">[</span><span class="ot">operationalism</span><span class="co">](https://plato.stanford.edu/entries/operationalism/)</span>, a philosophy of science akin to <span class="co">[</span><span class="ot">logical positivism</span><span class="co">](https://plato.stanford.edu/entries/logical-empiricism/)</span>. As stated by the definitive work on operationalism, "we mean by any concept nothing more than a set of operations; the concept is synonymous with the corresponding set of operations" <span class="co">[</span><span class="ot">@bridgmanLogicModernPhysics1927</span><span class="co">]</span>.</span>
<span id="cb1-1127"><a href="#cb1-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1128"><a href="#cb1-1128" aria-hidden="true" tabindex="-1"></a>In his early work, particularly *Foundations of Economic Analysis* (1947) and the development of revealed preference theory (1938), Samuelson embraced operationalism as a means of purging economics of non-observable, and thus scientifically meaningless, concepts like utility. He sought to rebase economic theory on purely observable behavior and measurable quantities. Revealed preference theory, for instance, would eliminate utility functions, and derive a consumer's preference ordering directly from observable consumer choices at different price levels.</span>
<span id="cb1-1129"><a href="#cb1-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1130"><a href="#cb1-1130" aria-hidden="true" tabindex="-1"></a>Over time, Samuelson's stance on operationalism softened to a more pragmatic approach, recognizing the value of unobservable concepts as theoretical tools, as long as they can be based on direct observables.</span>
<span id="cb1-1131"><a href="#cb1-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1132"><a href="#cb1-1132" aria-hidden="true" tabindex="-1"></a>For example, while Samuelson initially sought to eliminate utility functions, he later argued that even if utility is not directly observable, it can be uniquely determined from observing agents' preferences, by invoking some <span class="co">[</span><span class="ot">utility representation theorems</span><span class="co">](https://en.wikipedia.org/wiki/Utility_representation_theorem)</span> -- provided that the preferences satisfy certain properties. <span class="co">[</span><span class="ot">@samuelsonMyLifePhilosophy1999</span><span class="co">]</span></span>
<span id="cb1-1133"><a href="#cb1-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1134"><a href="#cb1-1134" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Area ratio construction</span></span>
<span id="cb1-1135"><a href="#cb1-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1136"><a href="#cb1-1136" aria-hidden="true" tabindex="-1"></a>::: {#thm-area-ratio}</span>
<span id="cb1-1137"><a href="#cb1-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1138"><a href="#cb1-1138" aria-hidden="true" tabindex="-1"></a><span class="fu">## area ratio law implies a new coordinate system</span></span>
<span id="cb1-1139"><a href="#cb1-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1140"><a href="#cb1-1140" aria-hidden="true" tabindex="-1"></a>Consider an open rectangle $R$ in the plane $\R^2$. Let there be two families of curves</span>
<span id="cb1-1141"><a href="#cb1-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1142"><a href="#cb1-1142" aria-hidden="true" tabindex="-1"></a>Suppose that each curvy parallelogram formed by the two families is contained in $R$, and the curves satisfy the area-ratio rule, then we can define another coordinate system $(z, w)$ on $\R^2$, such that the coordinate system preserves areas:</span>
<span id="cb1-1143"><a href="#cb1-1143" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1144"><a href="#cb1-1144" aria-hidden="true" tabindex="-1"></a>dx \wedge dy = dz \wedge dw</span>
<span id="cb1-1145"><a href="#cb1-1145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1146"><a href="#cb1-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1147"><a href="#cb1-1147" aria-hidden="true" tabindex="-1"></a>and that the two families of lines are the constant $z$ and constant $w$ curves.</span>
<span id="cb1-1148"><a href="#cb1-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1149"><a href="#cb1-1149" aria-hidden="true" tabindex="-1"></a>The coordinate system is unique up to an affine squashing transform, that is, $(z, w) \mapsto (cz + d, w/c + e)$ for some constants $c, d, e$ with $c \neq 0$.</span>
<span id="cb1-1150"><a href="#cb1-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1151"><a href="#cb1-1151" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1152"><a href="#cb1-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1153"><a href="#cb1-1153" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="false"}</span>
<span id="cb1-1154"><a href="#cb1-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1155"><a href="#cb1-1155" aria-hidden="true" tabindex="-1"></a>Fix an arbitrary point as $(z, w) = (0, 0)$. Pick an arbitrary curve in one of the families, not passing $(0, 0)$ point, and call it the $w=1$ line. By continuity, there exists a unique curve in the other family, such that their curved parallelogram has unit area. Call that other curve the $z=1$ line. Now we can label its four corners as $(z, w) = (0, 0), (0, 1), (1, 0), (1, 1)$.</span>
<span id="cb1-1156"><a href="#cb1-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1157"><a href="#cb1-1157" aria-hidden="true" tabindex="-1"></a>For any other point, its $(z, w)$ coordinates can be constructed as shown in the picture, with</span>
<span id="cb1-1158"><a href="#cb1-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1159"><a href="#cb1-1159" aria-hidden="true" tabindex="-1"></a>$$z = a+b, \quad w = b+d$$</span>
<span id="cb1-1160"><a href="#cb1-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1161"><a href="#cb1-1161" aria-hidden="true" tabindex="-1"></a>By the area ratio law, we have $a:b = c:d$. We also have $a+b+c+d = 1$ since we picked the parallelogram to have unit area. Solving these 4 equations, we find that $b = zw, a = z(1-w), d = (1-z)w, c = (1-z)(1-w)$, as it should.</span>
<span id="cb1-1162"><a href="#cb1-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1163"><a href="#cb1-1163" aria-hidden="true" tabindex="-1"></a>Taking the derivative, we have $dx \wedge dy = dz \wedge dw$.</span>
<span id="cb1-1164"><a href="#cb1-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1165"><a href="#cb1-1165" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/Samuelson_geometry_coordinate_construction.png)</span></span>
<span id="cb1-1166"><a href="#cb1-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1167"><a href="#cb1-1167" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1168"><a href="#cb1-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1169"><a href="#cb1-1169" aria-hidden="true" tabindex="-1"></a>::: {#cor-0}</span>
<span id="cb1-1170"><a href="#cb1-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1171"><a href="#cb1-1171" aria-hidden="true" tabindex="-1"></a><span class="fu">## area ratio law implies existence of an entropy function</span></span>
<span id="cb1-1172"><a href="#cb1-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1173"><a href="#cb1-1173" aria-hidden="true" tabindex="-1"></a>Since $dx \wedge dy = dz \wedge dw$, we can draw any cycle $\gamma$, and integrate around the cycle:</span>
<span id="cb1-1174"><a href="#cb1-1174" aria-hidden="true" tabindex="-1"></a>$$\oint_\gamma (ydx + zdw) = \iint_{\text{area in }\gamma} (dy \wedge dx + dz \wedge dw) = 0$$</span>
<span id="cb1-1175"><a href="#cb1-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1176"><a href="#cb1-1176" aria-hidden="true" tabindex="-1"></a>Thus, there exists some scalar function $S$, such that $dS = ydx + zdw$.</span>
<span id="cb1-1177"><a href="#cb1-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1178"><a href="#cb1-1178" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1179"><a href="#cb1-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1180"><a href="#cb1-1180" aria-hidden="true" tabindex="-1"></a>And with an entropy/utility function, all of classical thermodynamics/neoclassical economics follow.</span>
<span id="cb1-1181"><a href="#cb1-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1182"><a href="#cb1-1182" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Example: ideal gas</span></span>
<span id="cb1-1183"><a href="#cb1-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1184"><a href="#cb1-1184" aria-hidden="true" tabindex="-1"></a>Suppose we know from experiment that a tank of ideal gas satisfies two equations</span>
<span id="cb1-1185"><a href="#cb1-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1186"><a href="#cb1-1186" aria-hidden="true" tabindex="-1"></a>$$PV = \Const, \quad PV^\gamma = \Const$$</span>
<span id="cb1-1187"><a href="#cb1-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1188"><a href="#cb1-1188" aria-hidden="true" tabindex="-1"></a>under isothermal and adiabatic conditions respectively, then the $P, V$ diagram with these two families of curves satisfy the area ratio condition. It is tedious but straightforward to verify this by direct integration. Alternatively, we can use the <span class="co">[</span><span class="ot">method of exhaustion</span><span class="co">](https://en.wikipedia.org/wiki/Method_of_exhaustion)</span> and <span class="co">[</span><span class="ot">Eudoxus' theory of proportions</span><span class="co">](https://en.wikipedia.org/wiki/Eudoxus_of_Cnidus)</span> to prove this, in a way that even ancient Greeks would approve.</span>
<span id="cb1-1189"><a href="#cb1-1189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1190"><a href="#cb1-1190" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="false"}</span>
<span id="cb1-1191"><a href="#cb1-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1192"><a href="#cb1-1192" aria-hidden="true" tabindex="-1"></a>Notice that under the squashing map $(P, V) \mapsto (cP, V/c)$, both families of lines are preserved, and furthermore, this map preserves area, so we can calculate the area of any curvy parallelogram by tiling it with tiny strips of thin parallelograms.</span>
<span id="cb1-1193"><a href="#cb1-1193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1194"><a href="#cb1-1194" aria-hidden="true" tabindex="-1"></a>As shown, we can draw a very thin parallelogram $\delta$, then use the squashing map to tile both parallelograms $c$ and $d$. We have that</span>
<span id="cb1-1195"><a href="#cb1-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1196"><a href="#cb1-1196" aria-hidden="true" tabindex="-1"></a>$$A(c) : A(d) = \frac{A(c)}{A(\delta)} : \frac{A(d)}{A(\delta)} \approx N(c) : N(d)$$</span>
<span id="cb1-1197"><a href="#cb1-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1198"><a href="#cb1-1198" aria-hidden="true" tabindex="-1"></a>where $A(c)$ is the area of $c$, and $N(c)$ is the number of copies of $\delta$ that are contained within $c$. By the method of exhaustion and Eudoxus' theory of proportion, at the limit of infinitely thin $\delta$, both sides are equal.</span>
<span id="cb1-1199"><a href="#cb1-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1200"><a href="#cb1-1200" aria-hidden="true" tabindex="-1"></a>Now, performing the same construction on the other half of the parallelograms, we tile $a, b$ by the same number of copies of $\delta'$. Thus we have</span>
<span id="cb1-1201"><a href="#cb1-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1202"><a href="#cb1-1202" aria-hidden="true" tabindex="-1"></a>$$A(c) : A(d) \approx N(c) : N(d) = N(a) : N(b) \approx A(a) : A(b)$$</span>
<span id="cb1-1203"><a href="#cb1-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1204"><a href="#cb1-1204" aria-hidden="true" tabindex="-1"></a>and both sides equal at the limit.</span>
<span id="cb1-1205"><a href="#cb1-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1206"><a href="#cb1-1206" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/Samuelson_geometry_Eudoxus_proof.png)</span></span>
<span id="cb1-1207"><a href="#cb1-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1208"><a href="#cb1-1208" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1209"><a href="#cb1-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1210"><a href="#cb1-1210" aria-hidden="true" tabindex="-1"></a>Now, by the <span class="co">[</span><span class="ot">area ratio construction</span><span class="co">](#thm-area-ratio)</span>, there exist two functions $f_T, f_S$, such that the new coordinates</span>
<span id="cb1-1211"><a href="#cb1-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1212"><a href="#cb1-1212" aria-hidden="true" tabindex="-1"></a>$$T(P, V) = f_T(PV), \quad S(P, V) = f_S(PV^\gamma)$$</span>
<span id="cb1-1213"><a href="#cb1-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1214"><a href="#cb1-1214" aria-hidden="true" tabindex="-1"></a>satisfy $dT \wedge dS = dP \wedge dV$. We can then define</span>
<span id="cb1-1215"><a href="#cb1-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1216"><a href="#cb1-1216" aria-hidden="true" tabindex="-1"></a>$$dU = TdS - PdV$$</span>
<span id="cb1-1217"><a href="#cb1-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1218"><a href="#cb1-1218" aria-hidden="true" tabindex="-1"></a>which satisfies $d^2 U = 0$, that is, it is integrable.</span>
<span id="cb1-1219"><a href="#cb1-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1220"><a href="#cb1-1220" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Derivation" collapse="true"}</span>
<span id="cb1-1221"><a href="#cb1-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1222"><a href="#cb1-1222" aria-hidden="true" tabindex="-1"></a>Simplifying, we get</span>
<span id="cb1-1223"><a href="#cb1-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1224"><a href="#cb1-1224" aria-hidden="true" tabindex="-1"></a>$$f'_T(PV)f_S'(PV^\gamma) = \frac{1}{(\gamma - 1) PV^\gamma}$$</span>
<span id="cb1-1225"><a href="#cb1-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1226"><a href="#cb1-1226" aria-hidden="true" tabindex="-1"></a>Let $x = PV, y = PV^\gamma$ to separate the variables: $f'_T(x) f'_S(y) = \frac{1}{(\gamma-1) y}$, which solves to</span>
<span id="cb1-1227"><a href="#cb1-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1228"><a href="#cb1-1228" aria-hidden="true" tabindex="-1"></a>$$T = C_1 PV + C_0, \quad S = \frac{1}{(\gamma-1) C_1} \ln \frac{PV^\gamma}{P_0V_0^\gamma}$$</span>
<span id="cb1-1229"><a href="#cb1-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1230"><a href="#cb1-1230" aria-hidden="true" tabindex="-1"></a>for some constants $C_0, C_1, P_0, P_0$.</span>
<span id="cb1-1231"><a href="#cb1-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1232"><a href="#cb1-1232" aria-hidden="true" tabindex="-1"></a>Knowing that $C_0 = 0$ and $C_1 = 1/(nR)$, we have the equations of state:</span>
<span id="cb1-1233"><a href="#cb1-1233" aria-hidden="true" tabindex="-1"></a>$$PV = nRT, \quad S = \frac{1}{\gamma-1} nR \ln \frac{PV^\gamma}{P_0V_0^\gamma}$$</span>
<span id="cb1-1234"><a href="#cb1-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1235"><a href="#cb1-1235" aria-hidden="true" tabindex="-1"></a>Integrating $dU = TdS - PdV$, we have $U = \frac{1}{\gamma-1} nRT$. We can define $\hat c_V = \frac{1}{\gamma - 1}$, which leads to</span>
<span id="cb1-1236"><a href="#cb1-1236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1237"><a href="#cb1-1237" aria-hidden="true" tabindex="-1"></a>$$PV = nRT, \quad S = \hat c_V n R \ln \frac{PV^{1 + 1/\hat c_V}}{P_0V_0^{1 + 1/\hat c_V}}, \quad U = \hat c_V nRT$$</span>
<span id="cb1-1238"><a href="#cb1-1238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1239"><a href="#cb1-1239" aria-hidden="true" tabindex="-1"></a>or equivalently, $S = n R \ln \frac{U^{\hat c_V}V}{U_0^{\hat c_V} V_0}$.</span>
<span id="cb1-1240"><a href="#cb1-1240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1241"><a href="#cb1-1241" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1242"><a href="#cb1-1242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1243"><a href="#cb1-1243" aria-hidden="true" tabindex="-1"></a>Thus, we have</span>
<span id="cb1-1244"><a href="#cb1-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1245"><a href="#cb1-1245" aria-hidden="true" tabindex="-1"></a>$$PV = nRT, \quad S = \hat c_V n R \ln \frac{PV^{1 + 1/\hat c_V}}{P_0V_0^{1 + 1/\hat c_V}} = n R \ln \frac{U^{\hat c_V}V}{U_0^{\hat c_V} V_0}, \quad U = \hat c_V nRT$$</span>
<span id="cb1-1246"><a href="#cb1-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1247"><a href="#cb1-1247" aria-hidden="true" tabindex="-1"></a>Taking the derivative, $dS = \beta dU + \beta PdV - \beta \mu dn$ gives $\beta = 1/T$, $P = P$, and $\mu = -TS/n$.</span>
<span id="cb1-1248"><a href="#cb1-1248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1249"><a href="#cb1-1249" aria-hidden="true" tabindex="-1"></a>We find that the chemical potential, unfortunately, has an additive constant. We should not be too surprised, however, as anything with "potential" in its name probably has an additive constant, like electric voltage.</span>
<span id="cb1-1250"><a href="#cb1-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1251"><a href="#cb1-1251" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Economic interpretation</span></span>
<span id="cb1-1252"><a href="#cb1-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1253"><a href="#cb1-1253" aria-hidden="true" tabindex="-1"></a>When the diagram is interpreted as the thermodynamic diagram of a gas, we know what the curvy lines mean: they are the isotherms, isentropics, isobarics, etc (depending on which variables you pick for the two axes of the diagram). What do the curvy lines mean in economics?</span>
<span id="cb1-1254"><a href="#cb1-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1255"><a href="#cb1-1255" aria-hidden="true" tabindex="-1"></a><span class="al">![The equal area ratio condition.](figure/Samuelson_area_ratio_condition.png)</span></span>
<span id="cb1-1256"><a href="#cb1-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1257"><a href="#cb1-1257" aria-hidden="true" tabindex="-1"></a>Suppose we plot the lines of constant $p_2$ in the plane of $q_1, p_1$. What does it say? It says this: "Suppose the price of commodity $2$ is fixed, and we vary the price of commodity $1$. How much of commodity $1$, as a factory manager, would I want to purchase?" In other words, these are the demand curves for commodity $1$ when the price of commodity $2$ is fixed.</span>
<span id="cb1-1258"><a href="#cb1-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1259"><a href="#cb1-1259" aria-hidden="true" tabindex="-1"></a>Similarly, a line of constant $q_2$ is a demand curve for commodity $1$ when the *quantity* of commodity $2$ is fixed at $q_2$.</span>
<span id="cb1-1260"><a href="#cb1-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1261"><a href="#cb1-1261" aria-hidden="true" tabindex="-1"></a>Looking at the diagram, we see that the demand curves are steeper for fixed $q_2$ than for fixed $p_2$. In other words, the factory manager is more price-sensitive about commodity $1$ when there is a free market for commodity $2$, because there is a choice.</span>
<span id="cb1-1262"><a href="#cb1-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1263"><a href="#cb1-1263" aria-hidden="true" tabindex="-1"></a>To be concrete, think of managing a factory, where the two commodities are labor and machinery. Think like a factory manager. If I have no choice in how many machines I have in my factory, then faced with a sudden rise in wages, I would only fire a few workers. If, however, there is a free market for machines, then I would fire more workers and buy some machines to make up for it.</span>
<span id="cb1-1264"><a href="#cb1-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1265"><a href="#cb1-1265" aria-hidden="true" tabindex="-1"></a>This is Le Chatlier's principle for economics, which Paul Samuelson used to great effect. In his telling, immediately after the market has suffered a sudden price shock, factories would have to suffer the consequences because they cannot react by changing their production plans. Thus, in the short run, factories are less price-sensitive. In the long run, the factories would be able to change their production plans, and so in the long run, factories are more price-sensitive. As another application, during a wartime economy when there is rationing for some critical products like rubber and oil, people would become less price-sensitive in the products not subjected to rationing.</span>
<span id="cb1-1266"><a href="#cb1-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1267"><a href="#cb1-1267" aria-hidden="true" tabindex="-1"></a>This result can be generalized to the case of $n$ commodities $q_1, \dots, q_n$ with prices $p_1, \dots, p_n$. In this case, we would find that, assuming some more complicated area ratio law, we can rescale $q_2, \dots, q_n$ and $p_2, \dots, p_n$, such that $\sum_i dp_i \wedge dq_i = 0$. This then allows us to construct a function $S$, such that</span>
<span id="cb1-1268"><a href="#cb1-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1269"><a href="#cb1-1269" aria-hidden="true" tabindex="-1"></a>$$dS - \sum_i p_i dq_i = 0$$</span>
<span id="cb1-1270"><a href="#cb1-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1271"><a href="#cb1-1271" aria-hidden="true" tabindex="-1"></a>which, by @thm-profit-maximization-legendrian-manifold, maximizes *like* an entropy, so [it *is* an entropy](https://en.wikipedia.org/wiki/Duck_test).</span>
<span id="cb1-1272"><a href="#cb1-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1273"><a href="#cb1-1273" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bonus: Riemannian geometry</span></span>
<span id="cb1-1274"><a href="#cb1-1274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1275"><a href="#cb1-1275" aria-hidden="true" tabindex="-1"></a>There are other ways to study the state space of thermodynamic systems by differential geometry. For example, since the entropy function is typically a strictly concave function of the extensive parameters, $-\partial^2 S$ is positive-definite. This is then a Riemannian metric on the state space.<span class="ot">[^singular-riemannian]</span> For more on this line of research, search "Ruppeiner geometry" and "Weinhold geometry" <span class="co">[</span><span class="ot">@weinholdThermodynamicsGeometry1976; @quevedoGeometrothermodynamics2007</span><span class="co">]</span>.</span>
<span id="cb1-1276"><a href="#cb1-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1277"><a href="#cb1-1277" aria-hidden="true" tabindex="-1"></a><span class="ot">[^singular-riemannian]: </span>The only places where strict concavity fails are when $S$ is "bumped downwards", which gives us a first-order phase transition, or has a flat region, which gives us a second-order phase transition. Away from regions of phase transition, we have a Riemannian geometry. In the regions of phase transitions, the geometry collapses into singularities, much as spacetime collapses in the center of a black hole.</span>
<span id="cb1-1278"><a href="#cb1-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1279"><a href="#cb1-1279" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/banner/6.png)</span></span>
<span id="cb1-1280"><a href="#cb1-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1281"><a href="#cb1-1281" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chemical equilibrium done right</span></span>
<span id="cb1-1282"><a href="#cb1-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1283"><a href="#cb1-1283" aria-hidden="true" tabindex="-1"></a>Josiah Willard Gibbs was an otherworldly figure who thought of abstract surfaces in a 19th century America, where practical industry, not pure science, was celebrated. He was also famously obscure and could write the most convoluted sentences that defeated everyone, from <span class="co">[</span><span class="ot">Boltzmann</span><span class="co">](https://en.wikipedia.org/wiki/Boltzmann)</span> to <span class="co">[</span><span class="ot">Jaynes</span><span class="co">](https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes)</span> <span class="co">[</span><span class="ot">@jaynesGibbsParadox1992</span><span class="co">]</span>. When he was asked by his European translator to write a preface for the German translation of his thermodynamics book, he replied that he had already said everything he wanted to say about thermodynamics, so there was nothing to add. <span class="co">[</span><span class="ot">@daisJosiahWillardGibbs2024</span><span class="co">]</span></span>
<span id="cb1-1284"><a href="#cb1-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1285"><a href="#cb1-1285" aria-hidden="true" tabindex="-1"></a>Gibbs wrote his <span class="co">[</span><span class="ot">hefty</span><span class="co">](https://en.wiktionary.org/wiki/hefty)</span> <span class="co">[</span><span class="ot">Heft</span><span class="co">](https://en.wiktionary.org/wiki/Heft#German)</span> on thermodynamics, *On the Equilibrium of Heterogeneous Substances* (1876), to answer one question: why are some "heterogeneous substances" in equilibrium, while others not? Why, when we drop a block of salt into pure water, does the block of salt become smaller, but after a while, it stops getting smaller? His answer was always the same: heterogeneous substances are in equilibrium precisely when the entropy of the total system is maximized under constraint.</span>
<span id="cb1-1286"><a href="#cb1-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1287"><a href="#cb1-1287" aria-hidden="true" tabindex="-1"></a>Paul Samuelson was a decidedly worldly economist in a 20th century America, where economists were expected to dispense advice to presidents and contribute to the public discourse. Indeed, he did both, serving as an advisor to presidents Kennedy and Johnson, and publishing a <span class="co">[</span><span class="ot">best-selling textbook in economics</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Economics_(textbook)). Although unlike other worldly economists like Marx and Keynes, his economic achievements were highly mathematical.</span>
<span id="cb1-1288"><a href="#cb1-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1289"><a href="#cb1-1289" aria-hidden="true" tabindex="-1"></a>Samuelson wrote his landmark book, *Foundations of Economic Analysis* (1947), to answer one question: Why are some economic systems in equilibrium, while others are not? Why, when we drop a block of agents into a market, do they buy and sell things, but after a while, they stop buying and selling? His answer was always the same: a crowd of economic agents is in equilibrium precisely when some parameter of the total economic system (which can be interpreted as utility, profit, etc, depending on context) is maximized under constraint.</span>
<span id="cb1-1290"><a href="#cb1-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1291"><a href="#cb1-1291" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fixed volume and temperature</span></span>
<span id="cb1-1292"><a href="#cb1-1292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1293"><a href="#cb1-1293" aria-hidden="true" tabindex="-1"></a>Let's start with a simple example: the dimerization of nitrogen dioxide in a sealed tube.</span>
<span id="cb1-1294"><a href="#cb1-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1295"><a href="#cb1-1295" aria-hidden="true" tabindex="-1"></a>The thermodynamic system is some $NO_2$ and $N_2O_4$. The system is sealed in a glass tube of constant volume $V$, bathing in a water-ice mixture of temperature $T$.</span>
<span id="cb1-1296"><a href="#cb1-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1297"><a href="#cb1-1297" aria-hidden="true" tabindex="-1"></a>The thermodynamic state of the system is fully known if we know the number of moles for each species: $n_{NO_2}, n_{N_2O_4}$.</span>
<span id="cb1-1298"><a href="#cb1-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1299"><a href="#cb1-1299" aria-hidden="true" tabindex="-1"></a>The system undergoes a single reaction: $2 NO_2 \rightleftharpoons N_2O_4$.</span>
<span id="cb1-1300"><a href="#cb1-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1301"><a href="#cb1-1301" aria-hidden="true" tabindex="-1"></a>Suppose we start the system at state $n_{NO_2, 0}, n_{N_2O_4, 0}$. When does the system reach equilibrium? Since the system can exchange energy, but not volume, with the surrounding bath, it reaches equilibrium when the system reaches minimal Helmholtz free energy under constraint:</span>
<span id="cb1-1302"><a href="#cb1-1302" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1303"><a href="#cb1-1303" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1304"><a href="#cb1-1304" aria-hidden="true" tabindex="-1"></a>\min_{n_{NO_2}, n_{N_2 O_4}} F(T, V, n_{NO_2}, n_{N_2O_4})<span class="sc">\\</span></span>
<span id="cb1-1305"><a href="#cb1-1305" aria-hidden="true" tabindex="-1"></a>(n_{NO_2} - n_{NO_2, 0}) = -2 \xi<span class="sc">\\</span></span>
<span id="cb1-1306"><a href="#cb1-1306" aria-hidden="true" tabindex="-1"></a>(n_{N_2O_4} - n_{NO_2, 0}) = \xi</span>
<span id="cb1-1307"><a href="#cb1-1307" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1308"><a href="#cb1-1308" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1309"><a href="#cb1-1309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1310"><a href="#cb1-1310" aria-hidden="true" tabindex="-1"></a>where we write $\xi$ as the **extent of reaction**, that is, the number of moles of reactions that has taken place.</span>
<span id="cb1-1311"><a href="#cb1-1311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1312"><a href="#cb1-1312" aria-hidden="true" tabindex="-1"></a>Differentiating the two equations, and setting $dV, d\beta = 0$, we have</span>
<span id="cb1-1313"><a href="#cb1-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1314"><a href="#cb1-1314" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1315"><a href="#cb1-1315" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1316"><a href="#cb1-1316" aria-hidden="true" tabindex="-1"></a>dF = \mu_{NO_2} dn_{NO_2} + \mu_{N_2O_4} dn_{N_2O_4} <span class="sc">\\</span></span>
<span id="cb1-1317"><a href="#cb1-1317" aria-hidden="true" tabindex="-1"></a>dn_{NO_2} = -2d\xi <span class="sc">\\</span></span>
<span id="cb1-1318"><a href="#cb1-1318" aria-hidden="true" tabindex="-1"></a>dn_{N_2O_4} = d\xi</span>
<span id="cb1-1319"><a href="#cb1-1319" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1320"><a href="#cb1-1320" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1321"><a href="#cb1-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1322"><a href="#cb1-1322" aria-hidden="true" tabindex="-1"></a>At equilibrium, $dF = 0$ under all possible constrained variations, giving us the condition of equilibrium:</span>
<span id="cb1-1323"><a href="#cb1-1323" aria-hidden="true" tabindex="-1"></a>$$-2\mu_{NO_2} + \mu_{N_2 O_4} = 0$$</span>
<span id="cb1-1324"><a href="#cb1-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1325"><a href="#cb1-1325" aria-hidden="true" tabindex="-1"></a>We may vary both starting conditions $n_{NO_2, 0}$ and $n_{N_2O_4, 0}$, and for each starting condition, the system would equilibrate at the solution to</span>
<span id="cb1-1326"><a href="#cb1-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1327"><a href="#cb1-1327" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1328"><a href="#cb1-1328" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1329"><a href="#cb1-1329" aria-hidden="true" tabindex="-1"></a>-2\mu_{NO_2} (T, V, n_{NO_2}, n_{N_2O_4}) + \mu_{N_2 O_4}(T, V, n_{NO_2}, n_{N_2O_4}) = 0 <span class="sc">\\</span></span>
<span id="cb1-1330"><a href="#cb1-1330" aria-hidden="true" tabindex="-1"></a>(n_{NO_2} - n_{NO_2, 0}) = -2 \xi<span class="sc">\\</span></span>
<span id="cb1-1331"><a href="#cb1-1331" aria-hidden="true" tabindex="-1"></a>(n_{N_2O_4} - n_{NO_2, 0}) = \xi</span>
<span id="cb1-1332"><a href="#cb1-1332" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1333"><a href="#cb1-1333" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1334"><a href="#cb1-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1335"><a href="#cb1-1335" aria-hidden="true" tabindex="-1"></a>which has exactly the same number of unknowns and equations, so in general it should have at least one solution.</span>
<span id="cb1-1336"><a href="#cb1-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1337"><a href="#cb1-1337" aria-hidden="true" tabindex="-1"></a>The state space of the system has 2 dimensions: $n_{NO_2}$ and $n_{N_2 O_4}$. Starting at any point in the state space, the system can move on a single line, and it would equilibrate at exactly the point at which its Helmholtz energy is minimized. We can find the point of equilibrium by drawing the surfaces of constant Helmholtz free energy, and find the tangent point, as pictured.</span>
<span id="cb1-1338"><a href="#cb1-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1339"><a href="#cb1-1339" aria-hidden="true" tabindex="-1"></a><span class="al">![Minimizing Helmholtz free energy under the constraint of $2 NO_2 \rightleftharpoons N_2O_4$ is equivalent to maximizing utility under a budgetary constraint.](figure/Helmholtz_demand_curve.png)</span></span>
<span id="cb1-1340"><a href="#cb1-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1341"><a href="#cb1-1341" aria-hidden="true" tabindex="-1"></a>Economically speaking, the situation is precisely equivalent to the standard first problem in consumer theory: Given a consumer with a finite budget and a market for two goods, what would they buy from the market to maximize their utility? (They must spend all their budget.)</span>
<span id="cb1-1342"><a href="#cb1-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1343"><a href="#cb1-1343" aria-hidden="true" tabindex="-1"></a>The answer, as we can see in the diagram, is the tangent point of the straight line of constant budget with the curved lines of constant utility.</span>
<span id="cb1-1344"><a href="#cb1-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1345"><a href="#cb1-1345" aria-hidden="true" tabindex="-1"></a>To anthropomorphize the situation, we can say that the reaction chamber is a consumer trying to minimize its Helmholtz free energy under the "budgetary constraint" of $2 NO_2 \rightleftharpoons N_2O_4$. In this way, chemical equilibrium becomes a problem in consumer theory.</span>
<span id="cb1-1346"><a href="#cb1-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1347"><a href="#cb1-1347" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Existence and uniqueness</span></span>
<span id="cb1-1348"><a href="#cb1-1348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1349"><a href="#cb1-1349" aria-hidden="true" tabindex="-1"></a>We see from the diagram that at least one solution exists. In most situations, the Helmholtz free energy is strictly concave, so the curves of constant $F$ are strictly convex, and so the solution is unique on each line.</span>
<span id="cb1-1350"><a href="#cb1-1350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1351"><a href="#cb1-1351" aria-hidden="true" tabindex="-1"></a>If the budget line is tangent to a curve of constant $F$, then at the equilibrium point, both $NO_2$ and $N_2O_4$ exist. Otherwise, only one exist, and we say that the reaction is irreversible. Economically speaking, it is like when you are poor enough, you might spend all your money buying noodles, and none buying bread.</span>
<span id="cb1-1352"><a href="#cb1-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1353"><a href="#cb1-1353" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The $\xi, H$ curve of a reaction chamber, that is a sealed glass tube held under constant temperature of 298.15 K. At the $\xi = 0$ side, the tube contains 2 moles of $NO_2$, and at the $\xi = 1 \mathrm{~mol}$ side, the tube contains 1 mole of $N_2O_4$. [@raffSpontaneityEquilibriumWhy2014, figure 2]</span><span class="co">](figure/raff_2014_fig_2.png)</span></span>
<span id="cb1-1354"><a href="#cb1-1354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1355"><a href="#cb1-1355" aria-hidden="true" tabindex="-1"></a>If $F$ is not strictly concave, then it might have a double tangent point with the budget line. In that case, we have a first-order phase transition, and the substance splits into two chunks with different phases. Because the two parts can exchange volumes, it is no longer convenient to analyze with Helmholtz free energy, and we had better use Gibbs free energy. This is studied in <span class="co">[</span><span class="ot">the next section</span><span class="co">](#sec-phase-equilibrium)</span>.</span>
<span id="cb1-1356"><a href="#cb1-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1357"><a href="#cb1-1357" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multireaction equilibrium</span></span>
<span id="cb1-1358"><a href="#cb1-1358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1359"><a href="#cb1-1359" aria-hidden="true" tabindex="-1"></a>Now let's consider another example, where we have two simultaneous reactions. This is a simplified version of the NOx reactions, which is a source of air pollution.</span>
<span id="cb1-1360"><a href="#cb1-1360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1361"><a href="#cb1-1361" aria-hidden="true" tabindex="-1"></a>Consider a system with the following reactions:</span>
<span id="cb1-1362"><a href="#cb1-1362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1363"><a href="#cb1-1363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1364"><a href="#cb1-1364" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1365"><a href="#cb1-1365" aria-hidden="true" tabindex="-1"></a>2NO + O_2 &amp;\rightleftharpoons 2NO_2<span class="sc">\\</span></span>
<span id="cb1-1366"><a href="#cb1-1366" aria-hidden="true" tabindex="-1"></a>O + NO_2 &amp;\rightleftharpoons N_2O_3</span>
<span id="cb1-1367"><a href="#cb1-1367" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1368"><a href="#cb1-1368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1369"><a href="#cb1-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1370"><a href="#cb1-1370" aria-hidden="true" tabindex="-1"></a>The system is in a container with constant volume $V$ and temperature $T$. Let $n_i$ represent the number of moles of species $i$. The thermodynamic state of the system is fully described by the 4-component vector $\vec n = (n_{O_2}, n_{NO}, n_{NO_2}, n_{N_2O_3})$.</span>
<span id="cb1-1371"><a href="#cb1-1371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1372"><a href="#cb1-1372" aria-hidden="true" tabindex="-1"></a>To make the algebra look cleaner, we rewrite them as follows:</span>
<span id="cb1-1373"><a href="#cb1-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1374"><a href="#cb1-1374" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1375"><a href="#cb1-1375" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1376"><a href="#cb1-1376" aria-hidden="true" tabindex="-1"></a>0 &amp;\rightleftharpoons -O_2 - 2 NO + 2NO_2 + 0 N_2 O_3<span class="sc">\\</span></span>
<span id="cb1-1377"><a href="#cb1-1377" aria-hidden="true" tabindex="-1"></a>0 &amp;\rightleftharpoons 0 O_2 -NO - NO_2 + N_2O_3</span>
<span id="cb1-1378"><a href="#cb1-1378" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1379"><a href="#cb1-1379" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1380"><a href="#cb1-1380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1381"><a href="#cb1-1381" aria-hidden="true" tabindex="-1"></a>We see that each reaction can be written as a single vector. The first has vector $\vec n_1 = (-1, -2, 2, 0)$, and the second has vector $\vec n_2 = (0, -1, -1, 1)$.</span>
<span id="cb1-1382"><a href="#cb1-1382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1383"><a href="#cb1-1383" aria-hidden="true" tabindex="-1"></a>Each reaction has an associated extent of reaction, denoted by $\xi_1$ and $\xi_2$ respectively. Changes in the number of moles for each species are related to the extents of reaction:</span>
<span id="cb1-1384"><a href="#cb1-1384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1385"><a href="#cb1-1385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1386"><a href="#cb1-1386" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1387"><a href="#cb1-1387" aria-hidden="true" tabindex="-1"></a>dn_{NO} &amp;= -2d\xi_1 - d\xi_2 <span class="sc">\\</span></span>
<span id="cb1-1388"><a href="#cb1-1388" aria-hidden="true" tabindex="-1"></a>dn_{O_2} &amp;= -d\xi_1 <span class="sc">\\</span></span>
<span id="cb1-1389"><a href="#cb1-1389" aria-hidden="true" tabindex="-1"></a>dn_{NO_2} &amp;= 2d\xi_1 - d\xi_2 <span class="sc">\\</span></span>
<span id="cb1-1390"><a href="#cb1-1390" aria-hidden="true" tabindex="-1"></a>dn_{N_2O_3} &amp;= d\xi_2</span>
<span id="cb1-1391"><a href="#cb1-1391" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1392"><a href="#cb1-1392" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1393"><a href="#cb1-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1394"><a href="#cb1-1394" aria-hidden="true" tabindex="-1"></a>At equilibrium, the Helmholtz free energy $F(T, V, \vec{n})$ is minimized under the constraints imposed by the reactions. This leads to the following conditions:</span>
<span id="cb1-1395"><a href="#cb1-1395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1396"><a href="#cb1-1396" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1397"><a href="#cb1-1397" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1398"><a href="#cb1-1398" aria-hidden="true" tabindex="-1"></a>-2\mu_{NO} - \mu_{O_2} + 2\mu_{NO_2} &amp;= 0 <span class="sc">\\</span></span>
<span id="cb1-1399"><a href="#cb1-1399" aria-hidden="true" tabindex="-1"></a>-\mu_{NO} - \mu_{NO_2} + \mu_{N_2O_3} &amp;= 0</span>
<span id="cb1-1400"><a href="#cb1-1400" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1401"><a href="#cb1-1401" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1402"><a href="#cb1-1402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1403"><a href="#cb1-1403" aria-hidden="true" tabindex="-1"></a>More elegantly,</span>
<span id="cb1-1404"><a href="#cb1-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1405"><a href="#cb1-1405" aria-hidden="true" tabindex="-1"></a>$$\vec \mu \cdot \vec n_j = 0, \quad j = 1, 2$$</span>
<span id="cb1-1406"><a href="#cb1-1406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1407"><a href="#cb1-1407" aria-hidden="true" tabindex="-1"></a>where $\vec \mu = (\mu_{O_2}, \mu_{NO}, \mu_{NO_2}, \mu_{N_2O_3})$ is the vector of chemical potentials.</span>
<span id="cb1-1408"><a href="#cb1-1408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1409"><a href="#cb1-1409" aria-hidden="true" tabindex="-1"></a>Starting at any initial chemical composition of $\vec n_0$, the space of all possible chemical compositions reachable from $\vec n_0$ is a 2-dimensional subset. That is, it is the set of $\vec n$ satisfying</span>
<span id="cb1-1410"><a href="#cb1-1410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1411"><a href="#cb1-1411" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1412"><a href="#cb1-1412" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1413"><a href="#cb1-1413" aria-hidden="true" tabindex="-1"></a>\vec n &amp;= \vec n_0 + \xi_1 \vec n_1+ \xi_2 \vec n_2, <span class="sc">\\</span></span>
<span id="cb1-1414"><a href="#cb1-1414" aria-hidden="true" tabindex="-1"></a>\vec n &amp;\geq 0</span>
<span id="cb1-1415"><a href="#cb1-1415" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1416"><a href="#cb1-1416" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1417"><a href="#cb1-1417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1418"><a href="#cb1-1418" aria-hidden="true" tabindex="-1"></a>Geometrically speaking, the subset is the intersection between a 2-dimensional plane and a 4-dimensional pyramid, so it generally looks like either a triangle or a quadrilateral. On this subset, the Helmholtz free energy function looks like a sequence of nested convex shells, and the point of tangency is the equilibrium point.</span>
<span id="cb1-1419"><a href="#cb1-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1420"><a href="#cb1-1420" aria-hidden="true" tabindex="-1"></a><span class="al">![The lines are the 3-dimensional contour surfaces of constant Helmholtz free energy, intersected with the 2-dimensional feasible set. The point of tangency is the point of chemical equilibrium.](figure/Helmholtz_contour_multireaction.png)</span></span>
<span id="cb1-1421"><a href="#cb1-1421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1422"><a href="#cb1-1422" aria-hidden="true" tabindex="-1"></a>Interpreted economically, this is a consumer that maximizes its utility under two simultaneous budgetary constraints (because the budget set is a 2-dimensional, not 1-dimensional, subset of $\R^4$ ). Perhaps the consumer is trading with a market that simultaneously uses two kinds of currencies -- <span class="co">[</span><span class="ot">bimetallism</span><span class="co">](https://en.wikipedia.org/wiki/Bimetallism)</span>?</span>
<span id="cb1-1423"><a href="#cb1-1423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1424"><a href="#cb1-1424" aria-hidden="true" tabindex="-1"></a>Converting this experience into math, we have the following theorem.</span>
<span id="cb1-1425"><a href="#cb1-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1426"><a href="#cb1-1426" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-1427"><a href="#cb1-1427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1428"><a href="#cb1-1428" aria-hidden="true" tabindex="-1"></a><span class="fu">## existence and uniqueness of chemical equilibrium, at constant volume and temperature</span></span>
<span id="cb1-1429"><a href="#cb1-1429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1430"><a href="#cb1-1430" aria-hidden="true" tabindex="-1"></a>Consider a sealed reaction chamber held in an energy bath, so that both the price of energy $\beta$, and the volume $V$, of the system is fixed.</span>
<span id="cb1-1431"><a href="#cb1-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1432"><a href="#cb1-1432" aria-hidden="true" tabindex="-1"></a>The system contains a homogenous mixture of chemical species $A_1, \dots, A_k$, which might undergo the following $r$ possible chemical reactions:</span>
<span id="cb1-1433"><a href="#cb1-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1434"><a href="#cb1-1434" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1435"><a href="#cb1-1435" aria-hidden="true" tabindex="-1"></a>0 \rightleftharpoons \sum_i a_{ij} A_i, \quad j = 1, 2, \dots, r</span>
<span id="cb1-1436"><a href="#cb1-1436" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1437"><a href="#cb1-1437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1438"><a href="#cb1-1438" aria-hidden="true" tabindex="-1"></a>The necessary condition for chemical equilibrium is</span>
<span id="cb1-1439"><a href="#cb1-1439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1440"><a href="#cb1-1440" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1441"><a href="#cb1-1441" aria-hidden="true" tabindex="-1"></a>\vec \mu \cdot \vec n_j = 0, \quad \forall j = 1, 2, \dots, r</span>
<span id="cb1-1442"><a href="#cb1-1442" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1443"><a href="#cb1-1443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1444"><a href="#cb1-1444" aria-hidden="true" tabindex="-1"></a>where $\vec n_j = (a_{1, j}, \dots, a_{k, j})$ is the vector representing the $j$ -th chemical reaction.</span>
<span id="cb1-1445"><a href="#cb1-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1446"><a href="#cb1-1446" aria-hidden="true" tabindex="-1"></a>The condition is also sufficient if the Helmholtz free energy is strictly concave.</span>
<span id="cb1-1447"><a href="#cb1-1447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1448"><a href="#cb1-1448" aria-hidden="true" tabindex="-1"></a>If $F$ is not strictly concave, then there could be multiple coexisting equilibrium, which gives us a first-order phase transition.</span>
<span id="cb1-1449"><a href="#cb1-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1450"><a href="#cb1-1450" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1451"><a href="#cb1-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1452"><a href="#cb1-1452" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="false"}</span>
<span id="cb1-1453"><a href="#cb1-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1454"><a href="#cb1-1454" aria-hidden="true" tabindex="-1"></a>Existence: $F$ is continuous, so it has at least one minimum on every compact set.</span>
<span id="cb1-1455"><a href="#cb1-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1456"><a href="#cb1-1456" aria-hidden="true" tabindex="-1"></a>Uniqueness: any local minimum of a strictly concave function is the unique global minimum.</span>
<span id="cb1-1457"><a href="#cb1-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1458"><a href="#cb1-1458" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1459"><a href="#cb1-1459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1460"><a href="#cb1-1460" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fixed pressure and temperature</span></span>
<span id="cb1-1461"><a href="#cb1-1461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1462"><a href="#cb1-1462" aria-hidden="true" tabindex="-1"></a>We studied the case of a reaction chamber held under constant volume and temperature, which one can picture as a sealed glass tube in an ice-water bath. Now consider the case of a reaction chamber with constant temperature and pressure, for example when it is a flaccid plastic bag at the bottom of the ocean.</span>
<span id="cb1-1463"><a href="#cb1-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1464"><a href="#cb1-1464" aria-hidden="true" tabindex="-1"></a>Every previous result can be direct translated to that case, by replacing "Helmholtz" with "Gibbs".</span>
<span id="cb1-1465"><a href="#cb1-1465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1466"><a href="#cb1-1466" aria-hidden="true" tabindex="-1"></a>For example, for the same reaction of $NO_2$ dimerization, now put into a flabby plastic bag held under constant temperature of 298.15 K and constant pressure of 1 atm, produces the following $\xi, G$ curve. At the $\xi = 0$ side, the bag contains 2 moles of $NO_2$, and at the $\xi = 1 \mathrm{~mol}$ side, the bag contains 1 mole of $N_2O_4$.</span>
<span id="cb1-1467"><a href="#cb1-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1468"><a href="#cb1-1468" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The reaction chamber is a flabby plastic bag held under constant temperature of $298.15 \mathrm{~K}$ and constant pressure $1 \mathrm{~atm}$. It has the following $\xi, G$ curve. At the $\xi = 0$ side, the tube contains $2 \mathrm{~mol}$ of $NO_2$, and at the $\xi = 1 \mathrm{~mol}$ side, the tube contains $1 \mathrm{~mol}$ of $N_2O_4$. [@raffSpontaneityEquilibriumWhy2014, figure 4]</span><span class="co">](figure/raff_2014_fig_4.png)</span></span>
<span id="cb1-1469"><a href="#cb1-1469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1470"><a href="#cb1-1470" aria-hidden="true" tabindex="-1"></a><span class="fu">### The meaning of $\Delta G$</span></span>
<span id="cb1-1471"><a href="#cb1-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1472"><a href="#cb1-1472" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">small</span><span class="dt">&gt;</span>This section based on <span class="co">[</span><span class="ot">@quilezFirstYearUniversityChemistry2012</span><span class="co">]</span>.<span class="dt">&lt;/</span><span class="kw">small</span><span class="dt">&gt;</span></span>
<span id="cb1-1473"><a href="#cb1-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1474"><a href="#cb1-1474" aria-hidden="true" tabindex="-1"></a>$\Delta G$ has two confusable meanings. The first meaning is $\frac{dG}{d\xi}$, that is, the marginal Gibbs free energy for reaction, - how much the Gibbs free energy increases if the reaction goes forward by an infinitesimal mole. The second meaning is $\int_0^1 (\partial_\xi G)_{T, P} d\xi$. Both meanings are illustrated in the diagram.</span>
<span id="cb1-1475"><a href="#cb1-1475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1476"><a href="#cb1-1476" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The first meaning of $\Delta G$ is the slope. The second meaning of $\Delta G$ is the difference in height of the curve on two ends of the $(\xi, G)$ curve. [@glasserCorrectUseHelmholtz2016, figure 1]</span><span class="co">](figure/glasser_2016_fig_1.png)</span></span>
<span id="cb1-1477"><a href="#cb1-1477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1478"><a href="#cb1-1478" aria-hidden="true" tabindex="-1"></a>The first meaning, that of $\frac{dG}{d\xi}$, is used in chemical equilibrium. The textbooks say $\Delta G = 0$ when they really meant $\frac{dG}{d\xi} = 0$.</span>
<span id="cb1-1479"><a href="#cb1-1479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1480"><a href="#cb1-1480" aria-hidden="true" tabindex="-1"></a>The second meaning, that of $\int_0^1 (\partial_\xi G)_{T, P} d\xi$, can be interpreted by the "van 't Hoff box" <span class="co">[</span><span class="ot">@bazhinConversionChemicalReaction2007</span><span class="co">]</span>. We have a chamber with several semi-permeable membranes. On the input side, some gasses are permeated into the chamber, while on the output side, some gases are permeated out of it. The inside of the chamber remains fixed in composition. In this case, $\Delta G$ is the maximal useful work extractable in the process per reaction-mole, or the thermal energy created if no useful work is done.</span>
<span id="cb1-1481"><a href="#cb1-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1482"><a href="#cb1-1482" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">The reaction chamber, demonstrating the concrete meaning of $\Delta G$. [@glasserCorrectUseHelmholtz2016, figure 2]</span><span class="co">](figure/glasser_2016_fig_2.png)</span></span>
<span id="cb1-1483"><a href="#cb1-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1484"><a href="#cb1-1484" aria-hidden="true" tabindex="-1"></a>For example, such a situation occurs approximately occurs in the <span class="co">[</span><span class="ot">Haber--Bosch method</span><span class="co">](https://en.wikipedia.org/wiki/Haber_process)</span> for producing ammonia on the industrial scale: $N_2 + 3H_2 \to 2NH_3$. In the HB method, room-temperature (25 $^\circ C$) and room-pressure (1 atm) nitrogen and hydrogen continuously pipe into the chamber, and ammonia is continuously extracted out of the chamber by cooling liquefaction. When the reaction chamber is operating at a stable state, the energy released per mole of reaction is $\Delta G = -32.8 \mathrm{~kJ/mol}$, as one can calculate from a table of chemical thermodynamics. With this setup, after $1\mathrm{~mol}$ of nitrogen is consumed and $2\mathrm{~mol}$ of ammonium is produced, a thermal energy of $32.8\mathrm{~kJ}$ is produced, and must be cooled off somehow <span class="co">[</span><span class="ot">@glasserCorrectUseHelmholtz2016</span><span class="co">]</span>.</span>
<span id="cb1-1485"><a href="#cb1-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1486"><a href="#cb1-1486" aria-hidden="true" tabindex="-1"></a>Note that throughout this process, $\frac{dG}{d\xi} = 0$ always within the box, even as $\Delta G = -32.8 \mathrm{~kJ/mol}$ across the box. If $\frac{dG}{d\xi} \neq 0$, the reaction box would shake and shudder as it rushes towards equilibrium, and probably crack the walls. If $\Delta G \not\lt 0$, then all those giant <span class="co">[</span><span class="ot">cooling towers</span><span class="co">](https://en.wikipedia.org/wiki/Cooling_tower)</span> would have been pointless. Both $\frac{dG}{d\xi} = 0$ and $\Delta G = -32.8 \mathrm{~kJ/mol}$ are true, and the physical reality of an ammonia factory is the living smoking proof.</span>
<span id="cb1-1487"><a href="#cb1-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1488"><a href="#cb1-1488" aria-hidden="true" tabindex="-1"></a><span class="fu">### Practical considerations</span></span>
<span id="cb1-1489"><a href="#cb1-1489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1490"><a href="#cb1-1490" aria-hidden="true" tabindex="-1"></a>The above is all correct, and geometrical. If we were to be like Gibbs, then we would dust off our hands, for there is nothing left to do (except the theory of phase transitions). Unfortunately, chemistry is not merely applied geometry, so there is still something left to do.</span>
<span id="cb1-1491"><a href="#cb1-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1492"><a href="#cb1-1492" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Defining the standard states</span></span>
<span id="cb1-1493"><a href="#cb1-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1494"><a href="#cb1-1494" aria-hidden="true" tabindex="-1"></a>A **chemical environment** is defined by chemical species $A_1, \dots, A_m$.</span>
<span id="cb1-1495"><a href="#cb1-1495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1496"><a href="#cb1-1496" aria-hidden="true" tabindex="-1"></a>A **standard state** for a chemical environment is defined by a reference pressure $P^\circ$, and reference chemical molarities $<span class="co">[</span><span class="ot">A_1</span><span class="co">]</span>^\circ, \dots, <span class="co">[</span><span class="ot">A_m</span><span class="co">]</span>^\circ$ for each of the the chemical species.</span>
<span id="cb1-1497"><a href="#cb1-1497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1498"><a href="#cb1-1498" aria-hidden="true" tabindex="-1"></a>Given a standard state for a chemical environment, for any temperature $T$, and any chemical molarities $<span class="co">[</span><span class="ot">A_1</span><span class="co">]</span>, \dots, <span class="co">[</span><span class="ot">A_m</span><span class="co">]</span>$, the **chemical activity** of the chemical species $A_i$ in this particular context is</span>
<span id="cb1-1499"><a href="#cb1-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1500"><a href="#cb1-1500" aria-hidden="true" tabindex="-1"></a>$$<span class="sc">\{</span>A_i<span class="sc">\}</span> := e^{\frac{\mu_i - \mu_i^\circ}{RT}}$$</span>
<span id="cb1-1501"><a href="#cb1-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1502"><a href="#cb1-1502" aria-hidden="true" tabindex="-1"></a>where $\mu_i$ is the chemical potential of species $A_i$ at that state. That is,</span>
<span id="cb1-1503"><a href="#cb1-1503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1504"><a href="#cb1-1504" aria-hidden="true" tabindex="-1"></a>$$\mu_i = (\partial_{n_i} G)|_{T, P, <span class="co">[</span><span class="ot">A_1</span><span class="co">]</span>, \dots, <span class="co">[</span><span class="ot">A_m</span><span class="co">]</span>}$$</span>
<span id="cb1-1505"><a href="#cb1-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1506"><a href="#cb1-1506" aria-hidden="true" tabindex="-1"></a>and $\mu_i^\circ$ is the chemical potential of species $A_i$ at the standard state:</span>
<span id="cb1-1507"><a href="#cb1-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1508"><a href="#cb1-1508" aria-hidden="true" tabindex="-1"></a>$$\mu_i^\circ = (\partial_{n_i} G)|_{T, P^\circ, <span class="co">[</span><span class="ot">A_1</span><span class="co">]</span>^\circ, \dots, <span class="co">[</span><span class="ot">A_m</span><span class="co">]</span>^\circ}$$</span>
<span id="cb1-1509"><a href="#cb1-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1510"><a href="#cb1-1510" aria-hidden="true" tabindex="-1"></a>Given a chemical reaction $0 \rightleftharpoons \sum_i a_i A_i$, its **reaction quotient** is</span>
<span id="cb1-1511"><a href="#cb1-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1512"><a href="#cb1-1512" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1513"><a href="#cb1-1513" aria-hidden="true" tabindex="-1"></a>Q = \prod_i <span class="sc">\{</span>A_i<span class="sc">\}</span>^{a_i}</span>
<span id="cb1-1514"><a href="#cb1-1514" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1515"><a href="#cb1-1515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1516"><a href="#cb1-1516" aria-hidden="true" tabindex="-1"></a>where $a_i$ is the stoichiometric number of chemical species $A_i$. For example, with $aA + bB \rightleftharpoons cC + dD$, its reaction quotient is</span>
<span id="cb1-1517"><a href="#cb1-1517" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1518"><a href="#cb1-1518" aria-hidden="true" tabindex="-1"></a>Q = \frac{<span class="sc">\{</span>C<span class="sc">\}</span>^c<span class="sc">\{</span>D<span class="sc">\}</span>^d}{<span class="sc">\{</span>A<span class="sc">\}</span>^a<span class="sc">\{</span>B<span class="sc">\}</span>^b}</span>
<span id="cb1-1519"><a href="#cb1-1519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1520"><a href="#cb1-1520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1521"><a href="#cb1-1521" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Fundamental theorem of chemical equilibrium</span></span>
<span id="cb1-1522"><a href="#cb1-1522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1523"><a href="#cb1-1523" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-1524"><a href="#cb1-1524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1525"><a href="#cb1-1525" aria-hidden="true" tabindex="-1"></a><span class="fu">## fundamental theorem of chemical equilibrium</span></span>
<span id="cb1-1526"><a href="#cb1-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1527"><a href="#cb1-1527" aria-hidden="true" tabindex="-1"></a>Given any chemical reaction $0 \rightleftharpoons \sum_i a_i A_i$, any standard state, and any temperature,</span>
<span id="cb1-1528"><a href="#cb1-1528" aria-hidden="true" tabindex="-1"></a>$$\begin{cases}</span>
<span id="cb1-1529"><a href="#cb1-1529" aria-hidden="true" tabindex="-1"></a>(\partial_\xi F)_{T, V} &amp;= (\partial_\xi F)_{T, V}^\circ + RT \ln Q <span class="sc">\\</span></span>
<span id="cb1-1530"><a href="#cb1-1530" aria-hidden="true" tabindex="-1"></a>(\partial_\xi G)_{T, P} &amp;= (\partial_\xi G)_{T, P}^\circ + RT \ln Q</span>
<span id="cb1-1531"><a href="#cb1-1531" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1532"><a href="#cb1-1532" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1533"><a href="#cb1-1533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1534"><a href="#cb1-1534" aria-hidden="true" tabindex="-1"></a>where $\xi$ is the extent of reaction, and $Q$ is its reaction quotient.</span>
<span id="cb1-1535"><a href="#cb1-1535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1536"><a href="#cb1-1536" aria-hidden="true" tabindex="-1"></a>If the system has $r$ possible reactions, then we similarly have</span>
<span id="cb1-1537"><a href="#cb1-1537" aria-hidden="true" tabindex="-1"></a>$$\begin{cases}</span>
<span id="cb1-1538"><a href="#cb1-1538" aria-hidden="true" tabindex="-1"></a>(\partial_{\xi_j} F)_{T, V} &amp;= (\partial_{\xi_j} F)_{T, V}^\circ + RT \ln Q_j <span class="sc">\\</span></span>
<span id="cb1-1539"><a href="#cb1-1539" aria-hidden="true" tabindex="-1"></a>(\partial_{\xi_j} G)_{T, P} &amp;= (\partial_{\xi_j} G)_{T, P}^\circ + RT \ln Q_j</span>
<span id="cb1-1540"><a href="#cb1-1540" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1541"><a href="#cb1-1541" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1542"><a href="#cb1-1542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1543"><a href="#cb1-1543" aria-hidden="true" tabindex="-1"></a>for each reaction $j = 1, 2, \dots, r$</span>
<span id="cb1-1544"><a href="#cb1-1544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1545"><a href="#cb1-1545" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1546"><a href="#cb1-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1547"><a href="#cb1-1547" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="true"}</span>
<span id="cb1-1548"><a href="#cb1-1548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1549"><a href="#cb1-1549" aria-hidden="true" tabindex="-1"></a>$$\begin{aligned}</span>
<span id="cb1-1550"><a href="#cb1-1550" aria-hidden="true" tabindex="-1"></a>(\partial_\xi F)_{T, V} &amp;= \sum_i (\partial_\xi n_i) (\partial_{n_i} F)_{T, V, \vec n} <span class="sc">\\</span></span>
<span id="cb1-1551"><a href="#cb1-1551" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_i a_i \mu_i <span class="sc">\\</span></span>
<span id="cb1-1552"><a href="#cb1-1552" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_i a_i (\mu_i^\circ + RT \ln <span class="sc">\{</span>A_i<span class="sc">\}</span>) <span class="sc">\\</span></span>
<span id="cb1-1553"><a href="#cb1-1553" aria-hidden="true" tabindex="-1"></a>&amp;= \sum_i a_i (\mu_i^\circ) + RT \ln \left(\prod_i <span class="sc">\{</span>A_i<span class="sc">\}</span>^a_i\right) <span class="sc">\\</span></span>
<span id="cb1-1554"><a href="#cb1-1554" aria-hidden="true" tabindex="-1"></a>&amp;= (\partial_\xi F)_{T, V}^\circ + RT \ln Q</span>
<span id="cb1-1555"><a href="#cb1-1555" aria-hidden="true" tabindex="-1"></a>\end{aligned}$$</span>
<span id="cb1-1556"><a href="#cb1-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1557"><a href="#cb1-1557" aria-hidden="true" tabindex="-1"></a>The proof for the other equations are very similar.</span>
<span id="cb1-1558"><a href="#cb1-1558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1559"><a href="#cb1-1559" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1560"><a href="#cb1-1560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1561"><a href="#cb1-1561" aria-hidden="true" tabindex="-1"></a>::: {#cor-0}</span>
<span id="cb1-1562"><a href="#cb1-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1563"><a href="#cb1-1563" aria-hidden="true" tabindex="-1"></a><span class="fu">## equilibrium coefficient</span></span>
<span id="cb1-1564"><a href="#cb1-1564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1565"><a href="#cb1-1565" aria-hidden="true" tabindex="-1"></a>At equilibrium,</span>
<span id="cb1-1566"><a href="#cb1-1566" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1567"><a href="#cb1-1567" aria-hidden="true" tabindex="-1"></a>(\partial_\xi G)_{T, P} = 0</span>
<span id="cb1-1568"><a href="#cb1-1568" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1569"><a href="#cb1-1569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1570"><a href="#cb1-1570" aria-hidden="true" tabindex="-1"></a>which is equivalent to</span>
<span id="cb1-1571"><a href="#cb1-1571" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1572"><a href="#cb1-1572" aria-hidden="true" tabindex="-1"></a>Q = K_{eq}, \quad K_{eq} := e^{-\frac{(\partial_\xi G)_{T, P}^\circ}{RT}}</span>
<span id="cb1-1573"><a href="#cb1-1573" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1574"><a href="#cb1-1574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1575"><a href="#cb1-1575" aria-hidden="true" tabindex="-1"></a>and similarly for the other case.</span>
<span id="cb1-1576"><a href="#cb1-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1577"><a href="#cb1-1577" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1578"><a href="#cb1-1578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1579"><a href="#cb1-1579" aria-hidden="true" tabindex="-1"></a>The above equations are what my teachers meant when they thoughtlessly wrote</span>
<span id="cb1-1580"><a href="#cb1-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1581"><a href="#cb1-1581" aria-hidden="true" tabindex="-1"></a>$$\Delta G = 0, \quad K_{eq} = e^{-\frac{\Delta G^\circ}{RT}}$$</span>
<span id="cb1-1582"><a href="#cb1-1582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1583"><a href="#cb1-1583" aria-hidden="true" tabindex="-1"></a>This, finally, answers my great confusion back then. Now everything makes sense, and life is beautiful.</span>
<span id="cb1-1584"><a href="#cb1-1584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1585"><a href="#cb1-1585" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Ideal-gas-like chemistry</span></span>
<span id="cb1-1586"><a href="#cb1-1586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1587"><a href="#cb1-1587" aria-hidden="true" tabindex="-1"></a>Well, if this is all there is, then a mathematician would be able to solve any problem in analytical chemistry. Unfortunately, analytical chemistry is not about proving theorems, but about actually getting numerical answers, and numerical answers require numerical values for chemical activities.</span>
<span id="cb1-1588"><a href="#cb1-1588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1589"><a href="#cb1-1589" aria-hidden="true" tabindex="-1"></a>There are generally three cases:</span>
<span id="cb1-1590"><a href="#cb1-1590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1591"><a href="#cb1-1591" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We have a mixture of dilute gasses, or dilute solvents in an inert solution, such that the ideal gas law is almost true.</span>
<span id="cb1-1592"><a href="#cb1-1592" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Ideal gas law fails.</span>
<span id="cb1-1593"><a href="#cb1-1593" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>We are not even dealing with gasses and solutions anymore.</span>
<span id="cb1-1594"><a href="#cb1-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1595"><a href="#cb1-1595" aria-hidden="true" tabindex="-1"></a>The first case is typically what is taught by a first course in analytical chemistry, and since this is typically taught to non-mathematicians by non-mathematicians for non-mathematicians, the logical structure is quite upside-down and confusing to a mathematician.</span>
<span id="cb1-1596"><a href="#cb1-1596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1597"><a href="#cb1-1597" aria-hidden="true" tabindex="-1"></a>We will now prove the first case rigorously.</span>
<span id="cb1-1598"><a href="#cb1-1598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1599"><a href="#cb1-1599" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-1600"><a href="#cb1-1600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1601"><a href="#cb1-1601" aria-hidden="true" tabindex="-1"></a><span class="fu">## activity of ideal gas mixtures</span></span>
<span id="cb1-1602"><a href="#cb1-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1603"><a href="#cb1-1603" aria-hidden="true" tabindex="-1"></a>For any temperature $T$ and any two pressures $P, P^\circ$, by the ideal gas laws, the chemical potential of the chemical species satisfies the equation</span>
<span id="cb1-1604"><a href="#cb1-1604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1605"><a href="#cb1-1605" aria-hidden="true" tabindex="-1"></a>$$\mu(T, P) = \mu(T, P^\circ) + RT \ln\frac{P}{P^\circ}$$</span>
<span id="cb1-1606"><a href="#cb1-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1607"><a href="#cb1-1607" aria-hidden="true" tabindex="-1"></a>and so its activity is $\frac{P}{P^\circ}$.</span>
<span id="cb1-1608"><a href="#cb1-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1609"><a href="#cb1-1609" aria-hidden="true" tabindex="-1"></a>In a mixture of ideal gases, the gases do not interact, and so the activity of chemical species $A_i$ is $<span class="sc">\{</span>A_i<span class="sc">\}</span> = \frac{P_i}{P_i^\circ}$, where $P_i$ is the partial pressure of species $A_i$ in the mixed gas, and $P_i^\circ$ is the standard pressure for species $A_i$.</span>
<span id="cb1-1610"><a href="#cb1-1610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1611"><a href="#cb1-1611" aria-hidden="true" tabindex="-1"></a>In a dilute solution, if the solvent behaves like a mixture of ideal gasses, then</span>
<span id="cb1-1612"><a href="#cb1-1612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1613"><a href="#cb1-1613" aria-hidden="true" tabindex="-1"></a>$$\mu(T, P) \approx \mu(T, P^\circ) + RT \ln \frac{<span class="co">[</span><span class="ot">A_i</span><span class="co">]</span>}{<span class="co">[</span><span class="ot">A_i</span><span class="co">]</span>^\circ} \approx \mu(T, P^\circ) + RT \ln \frac{m_{A_i}}{m_{A_i}^\circ}$$</span>
<span id="cb1-1614"><a href="#cb1-1614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1615"><a href="#cb1-1615" aria-hidden="true" tabindex="-1"></a>where $<span class="co">[</span><span class="ot">A_i</span><span class="co">]</span>$ is the mole-per-volume of $A_i$, and $m_{A_i}$ is the mole-per-mass of $A_i$.</span>
<span id="cb1-1616"><a href="#cb1-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1617"><a href="#cb1-1617" aria-hidden="true" tabindex="-1"></a>The chemical activity simplifies into the familiar form:</span>
<span id="cb1-1618"><a href="#cb1-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1619"><a href="#cb1-1619" aria-hidden="true" tabindex="-1"></a>$$<span class="sc">\{</span>A<span class="sc">\}</span> \approx \frac{<span class="co">[</span><span class="ot">A</span><span class="co">]</span>}{<span class="co">[</span><span class="ot">A</span><span class="co">]</span>^\circ} \approx \frac{m_A}{m_A^\circ}$$</span>
<span id="cb1-1620"><a href="#cb1-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1621"><a href="#cb1-1621" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1622"><a href="#cb1-1622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1623"><a href="#cb1-1623" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof" collapse="true"}</span>
<span id="cb1-1624"><a href="#cb1-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1625"><a href="#cb1-1625" aria-hidden="true" tabindex="-1"></a>It suffices to prove the case for a pure ideal gas, as the other cases are simple corollaries.</span>
<span id="cb1-1626"><a href="#cb1-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1627"><a href="#cb1-1627" aria-hidden="true" tabindex="-1"></a>By the ideal gas law, the chemical potential is</span>
<span id="cb1-1628"><a href="#cb1-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1629"><a href="#cb1-1629" aria-hidden="true" tabindex="-1"></a>$$\mu = -TS/n$$</span>
<span id="cb1-1630"><a href="#cb1-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1631"><a href="#cb1-1631" aria-hidden="true" tabindex="-1"></a>which is a state property. Expressed as a function of $T, P$,</span>
<span id="cb1-1632"><a href="#cb1-1632" aria-hidden="true" tabindex="-1"></a>$$\mu(T, P) = RT \ln\frac{P/T^{\hat c_V + 1}}{C}$$</span>
<span id="cb1-1633"><a href="#cb1-1633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1634"><a href="#cb1-1634" aria-hidden="true" tabindex="-1"></a>for an arbitrary constant $C$.</span>
<span id="cb1-1635"><a href="#cb1-1635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1636"><a href="#cb1-1636" aria-hidden="true" tabindex="-1"></a>Thus, for any $T, P, P^\circ$, we have</span>
<span id="cb1-1637"><a href="#cb1-1637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1638"><a href="#cb1-1638" aria-hidden="true" tabindex="-1"></a>$$\mu(T, P) = \mu(T, P^\circ) + RT \ln\frac{P}{P^\circ}$$</span>
<span id="cb1-1639"><a href="#cb1-1639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1640"><a href="#cb1-1640" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1641"><a href="#cb1-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1642"><a href="#cb1-1642" aria-hidden="true" tabindex="-1"></a>::: {#exm-0}</span>
<span id="cb1-1643"><a href="#cb1-1643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1644"><a href="#cb1-1644" aria-hidden="true" tabindex="-1"></a>The pH value of a solution is not $pH = -\log_{10} <span class="co">[</span><span class="ot">H^+</span><span class="co">]</span>$, which has the wrong units. It is not even $pH = -\log_{10} \frac{<span class="co">[</span><span class="ot">H^+</span><span class="co">]</span>}{<span class="co">[</span><span class="ot">H^+</span><span class="co">]</span>^\circ}$, since the $H^+$ particles might not behave like an ideal gas. The actual correct definition is <span class="co">[</span><span class="ot">@mccartyPHParadoxesDemonstrating2006</span><span class="co">]</span></span>
<span id="cb1-1645"><a href="#cb1-1645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1646"><a href="#cb1-1646" aria-hidden="true" tabindex="-1"></a>$$pH = -\log_{10} <span class="sc">\{</span>H^+<span class="sc">\}</span>$$</span>
<span id="cb1-1647"><a href="#cb1-1647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1648"><a href="#cb1-1648" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1649"><a href="#cb1-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1650"><a href="#cb1-1650" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Fugacity</span></span>
<span id="cb1-1651"><a href="#cb1-1651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1652"><a href="#cb1-1652" aria-hidden="true" tabindex="-1"></a>For real gases and real solutions, the chemical activity might deviate significantly from the above approximation. In this case, we typically have no recourse except to checking a table of chemical thermodynamics. They typically do not directly write down the chemical activities, but <span class="co">[</span><span class="ot">*fugacity coefficients*</span><span class="co">](https://en.wikipedia.org/wiki/Fugacity)</span>. There is nothing particularly deep about fugacity -- it is basically about rescaling the numbers to make the tables easier to make.</span>
<span id="cb1-1653"><a href="#cb1-1653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1654"><a href="#cb1-1654" aria-hidden="true" tabindex="-1"></a>Recall that the chemical potential of an ideal gas satisfies $\mu(T, P) = RT \ln\frac{P/T^{\hat c_V + 1}}{C}$, where $C$ is a constant for this gas. For a real gas, this equation only holds approximately, so we define the **fugacity** $f$ as a function of $T, P$, such that</span>
<span id="cb1-1655"><a href="#cb1-1655" aria-hidden="true" tabindex="-1"></a>$$\mu(T, P) = RT \ln\frac{f/T^{\hat c_V + 1}}{C}$$</span>
<span id="cb1-1656"><a href="#cb1-1656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1657"><a href="#cb1-1657" aria-hidden="true" tabindex="-1"></a>In other words, $f(T, P) = P \phi(T, P)$, where</span>
<span id="cb1-1658"><a href="#cb1-1658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1659"><a href="#cb1-1659" aria-hidden="true" tabindex="-1"></a>$$\phi(T, P) = e^{\frac{\mu(T, P) - \mu_{ideal}(T, P)}{RT}}$$</span>
<span id="cb1-1660"><a href="#cb1-1660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1661"><a href="#cb1-1661" aria-hidden="true" tabindex="-1"></a>is the **fugacity coefficient**.</span>
<span id="cb1-1662"><a href="#cb1-1662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1663"><a href="#cb1-1663" aria-hidden="true" tabindex="-1"></a>Plugging them back to the definition of activity, we have</span>
<span id="cb1-1664"><a href="#cb1-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1665"><a href="#cb1-1665" aria-hidden="true" tabindex="-1"></a>$$<span class="sc">\{</span>A<span class="sc">\}</span> = \frac{f}{f^\circ} = \frac{\phi P}{\phi^\circ P^\circ}$$</span>
<span id="cb1-1666"><a href="#cb1-1666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1667"><a href="#cb1-1667" aria-hidden="true" tabindex="-1"></a>And so, by checking a table of fugacity coefficients, chemical engineers can balance chemical reactions of real gasses, even far from ideality.</span>
<span id="cb1-1668"><a href="#cb1-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1669"><a href="#cb1-1669" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning title="Standard state"}</span>
<span id="cb1-1670"><a href="#cb1-1670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1671"><a href="#cb1-1671" aria-hidden="true" tabindex="-1"></a>Despite what the name "standard" might imply, a chemical species has infinitely many standard states. For example, pure gaseous oxygen has many different standard states -- one for each temperature. We have a standard state at $T = 300\mathrm{~K}$ defined by $<span class="co">[</span><span class="ot">O_2</span><span class="co">]</span> = 1 \mathrm{~mol/L}$, and another at $T = 350\mathrm{~K}$ defined by $<span class="co">[</span><span class="ot">O_2</span><span class="co">]</span> = 1 \mathrm{~mol/L}$, etc.</span>
<span id="cb1-1672"><a href="#cb1-1672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1673"><a href="#cb1-1673" aria-hidden="true" tabindex="-1"></a>Despite what the name "standard" might imply, different chemists have different standards. For example, among the biochemists, the standard state for $H^+$ in water is $<span class="co">[</span><span class="ot">H^+</span><span class="co">]</span>^\circ = 10^{-7} \mathrm{~mol/L}$, but among the inorganic chemists, it is $<span class="co">[</span><span class="ot">H^+</span><span class="co">]</span>^\circ = 1 \mathrm{~mol/L}$. The reason is that bodily fluids typically have $<span class="co">[</span><span class="ot">H^+</span><span class="co">]</span> \sim 10^{-7} \mathrm{~mol/L}$.</span>
<span id="cb1-1674"><a href="#cb1-1674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1675"><a href="#cb1-1675" aria-hidden="true" tabindex="-1"></a>Despite what the name "standard temperature and pressure (STP)" might imply, it is not a "standard state", because a "standard state" of any substance does not specify its temperature.</span>
<span id="cb1-1676"><a href="#cb1-1676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1677"><a href="#cb1-1677" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1678"><a href="#cb1-1678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1679"><a href="#cb1-1679" aria-hidden="true" tabindex="-1"></a>The point of having a standard state is like taking an electric circuit, pointing at one point of it, and say, "This is where the voltage is zero.". The point is to allow for relative comparisons between states, within the context of a *single* reaction. Consequently, even for a single chemical species, we can take a different standard state if we are studying a different reaction involving the species, or the same reaction in a different context.</span>
<span id="cb1-1680"><a href="#cb1-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1681"><a href="#cb1-1681" aria-hidden="true" tabindex="-1"></a>For example, if we are studying the reaction $NO_2 \rightleftharpoons N_2 O_4$ in a glass tube drenched in an ice-water bath, then we would take as our standard state</span>
<span id="cb1-1682"><a href="#cb1-1682" aria-hidden="true" tabindex="-1"></a>$$T^\circ = 273.15 K, \quad <span class="co">[</span><span class="ot">NO_2</span><span class="co">]</span>^\circ = 1 \mathrm{~mol/L}, \quad <span class="co">[</span><span class="ot">N_2 O_4</span><span class="co">]</span>^\circ = 1 \mathrm{~mol/L}$$</span>
<span id="cb1-1683"><a href="#cb1-1683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1684"><a href="#cb1-1684" aria-hidden="true" tabindex="-1"></a>For a chemical in pure gaseous form, a standard state is specified by two out of three parameters: molarity $<span class="co">[</span><span class="ot">A</span><span class="co">]</span> = \frac{n}{V}$, pressure $P$, temperature $T$. We must never specify all three of them, because otherwise we would break the equation of state. For example, imagine what happens when you specify that the "standard state of ideal gas" is</span>
<span id="cb1-1685"><a href="#cb1-1685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1686"><a href="#cb1-1686" aria-hidden="true" tabindex="-1"></a>$$T^\circ = 273.15 \mathrm{~K}, P^\circ = 10^5 \mathrm{~Pa}, <span class="co">[</span><span class="ot">A</span><span class="co">]</span>^\circ = 1 \mathrm{~mol/L}$$</span>
<span id="cb1-1687"><a href="#cb1-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1688"><a href="#cb1-1688" aria-hidden="true" tabindex="-1"></a>because they would violate the ideal gas law</span>
<span id="cb1-1689"><a href="#cb1-1689" aria-hidden="true" tabindex="-1"></a>$$P = <span class="co">[</span><span class="ot">A</span><span class="co">]</span>RT$$</span>
<span id="cb1-1690"><a href="#cb1-1690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1691"><a href="#cb1-1691" aria-hidden="true" tabindex="-1"></a>For non-ideal gas, we still have an equation of state between $P, <span class="co">[</span><span class="ot">A</span><span class="co">]</span>, T$, meaning that we still must specify exactly two, no more and no less.</span>
<span id="cb1-1692"><a href="#cb1-1692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1693"><a href="#cb1-1693" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Intensive quantities"}</span>
<span id="cb1-1694"><a href="#cb1-1694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1695"><a href="#cb1-1695" aria-hidden="true" tabindex="-1"></a> Why is a standard state defined by intensive quantities like temperature, pressure, or molarity? Why isn't it defined by extensive quantities such as volume, mass, and moles?</span>
<span id="cb1-1696"><a href="#cb1-1696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1697"><a href="#cb1-1697" aria-hidden="true" tabindex="-1"></a>The short answer: because traditional chemistry only studies systems with extensive entropies. For those systems, chemical equilibrium is determined by intensive quantities. This is not because classical thermodynamics cannot handle nonextensive entropy, but because chemists had no use for systems with nonextensive entropy.</span>
<span id="cb1-1698"><a href="#cb1-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1699"><a href="#cb1-1699" aria-hidden="true" tabindex="-1"></a>Like classical thermodynamics and neoclassical economics, the idea of a standard state is fully committed to the idea of *homogeneous* substances. In classical thermodynamics, a cube of iron and a ball of iron are the same. A jar of water and a tank of water are the same. It does not matter what their shapes are. Moreover, two jars of water side-by-side is the same as one large jar of water. In neoclassical economics, a crowd of factories is the same as two small crowds of factories put together. They are all chunks of homogeneous stuffs.</span>
<span id="cb1-1700"><a href="#cb1-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1701"><a href="#cb1-1701" aria-hidden="true" tabindex="-1"></a>If this were not the case, then we would be unable to say that a standard state is defined by just the temperature and molar concentration of each chemical species. We would be forced to also specify a standard state volume $V^\circ$. It is conceivable that even the shape of the reaction chamber matters. We would then be forced to specify a standard shape, perhaps a box with side lengths $0.1 \mathrm{~m}$. But in this extreme case, perhaps we have already left the realm of chemistry.</span>
<span id="cb1-1702"><a href="#cb1-1702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1703"><a href="#cb1-1703" aria-hidden="true" tabindex="-1"></a>For spherical particles, doubling the volume would double the mass, but only $2^{2/3} \approx 1.59 \times$ the surface area. Consequently, if the surface between phases has a non-negligible entropy ("surface effect"), then entropy would be nonextensive. While IUAPC is silent on the issue, nonextensive entropy is taken up in earnest by chemists who work with small spherical particles <span class="co">[</span><span class="ot">@letellierSolubilityNanoparticlesNonextensive2007</span><span class="co">]</span>.</span>
<span id="cb1-1704"><a href="#cb1-1704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1705"><a href="#cb1-1705" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1706"><a href="#cb1-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1707"><a href="#cb1-1707" aria-hidden="true" tabindex="-1"></a><span class="fu">#### IUAPC's definition of "standard state"</span></span>
<span id="cb1-1708"><a href="#cb1-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1709"><a href="#cb1-1709" aria-hidden="true" tabindex="-1"></a>I have found that the <span class="co">[</span><span class="ot">IUAPC</span><span class="co">](https://en.wikipedia.org/wiki/International_Union_of_Pure_and_Applied_Chemistry)</span>'s definition of the "standard state" <span class="co">[</span><span class="ot">@coxNotationStatesProcesses1982</span><span class="co">]</span> to be precise and clarifying, though it is quite ponderous, so I summarize it as follows:</span>
<span id="cb1-1710"><a href="#cb1-1710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1711"><a href="#cb1-1711" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The standard state for a gaseous substance, whether pure or mixed, is the substance at $P^\circ$ and in a (hypothetical) state in which it exhibits ideal-gas behaviour, where $P^\circ$ is an arbitrarily fixed standard-state pressure.</span>
<span id="cb1-1712"><a href="#cb1-1712" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The standard state for a pure liquid or solid substance is the pure substance at $P^\circ$.</span>
<span id="cb1-1713"><a href="#cb1-1713" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The above definitions of standard states make no reference to fixed temperature. Hence, it is possible to have an infinite number of standard states of a substance as the temperature varies. But generally it is more convenient to complete the definition of the standard state in a particular context by choosing for the reference temperature one of a relatively small number of values, e.g., zero, $273.15 \mathrm{~K}, 293.15 \mathrm{~K}, 298.15 \mathrm{~K}$.</span>
<span id="cb1-1714"><a href="#cb1-1714" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Since $T^{\circ}$ should mean a standard temperature **in general**, the use of $T^{\circ}$ to mean exclusively $298.15 \mathrm{~K}$ is **strongly discouraged**.</span>
<span id="cb1-1715"><a href="#cb1-1715" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>For application of the concept of standard state to substances in admixture (solutions and mixtures), **the composition of the system, as well as the pressure**, must be defined. As one example for solutions, the standard-state molality, written as $m^\circ$ for the general case, is to be defined; customarily $m^\circ$ is taken as $1 \mathrm{~mol/kg}$.</span>
<span id="cb1-1716"><a href="#cb1-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1717"><a href="#cb1-1717" aria-hidden="true" tabindex="-1"></a><span class="al">![](figure/banner/4.png)</span></span>
<span id="cb1-1718"><a href="#cb1-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1719"><a href="#cb1-1719" aria-hidden="true" tabindex="-1"></a><span class="fu">## Phase equilibrium {#sec-phase-equilibrium}</span></span>
<span id="cb1-1720"><a href="#cb1-1720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1721"><a href="#cb1-1721" aria-hidden="true" tabindex="-1"></a>Several times, we have found some curious examples where a non-concavity in entropy leads to a jump of some kind. These are all examples of first-order phase equilibrium.</span>
<span id="cb1-1722"><a href="#cb1-1722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1723"><a href="#cb1-1723" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two phases of a gas in equilibrium</span></span>
<span id="cb1-1724"><a href="#cb1-1724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1725"><a href="#cb1-1725" aria-hidden="true" tabindex="-1"></a>Consider a generic gas, whose entropy function is of form $S(U, V, N)$. If we confine it in a sealed tube, and slowly heat it up, then its entropy would trace out the curve</span>
<span id="cb1-1726"><a href="#cb1-1726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1727"><a href="#cb1-1727" aria-hidden="true" tabindex="-1"></a>$$U \mapsto S(U, V, N)$$</span>
<span id="cb1-1728"><a href="#cb1-1728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1729"><a href="#cb1-1729" aria-hidden="true" tabindex="-1"></a>Now, the inverse temperature $\beta$ of the system is the slope, which should decrease as $U$ increases, so the entropy curve should be strictly concave.</span>
<span id="cb1-1730"><a href="#cb1-1730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1731"><a href="#cb1-1731" aria-hidden="true" tabindex="-1"></a>If there is a bump in the middle, then we have a serious problem: as we heat up the gas, its temperature would *decrease* for a while before increasing again! This suggests to us that our model has broken down. Where is the breakdown? The breakdown is that we assumed our system remains one thermodynamic substance, when it can split into two. Suppose by a small fluctuation, the left side of the container has higher temperature than the right side, then it would give some internal energy to the right side. Normally, this would cause their temperatures to meet in the middle. However, in this inverted situation, the left side would become even hotter, and so we have a positive feedback loop, until the substance has split into two, with the same temperature, but one with higher internal energy density, and one with lower.</span>
<span id="cb1-1732"><a href="#cb1-1732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1733"><a href="#cb1-1733" aria-hidden="true" tabindex="-1"></a><span class="al">![A bump in the $U \mapsto S$ curve would lead to a thermodynamic instability, ending with a first-order phase transition.](figure/first_order_phase_transition_SU_curve.png)</span></span>
<span id="cb1-1734"><a href="#cb1-1734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1735"><a href="#cb1-1735" aria-hidden="true" tabindex="-1"></a>Suppose now that the substance splits into two, like a large company splits into two subsidiaries under a common conglomerate. How would the manager maximize the total value of the conglomerate? It would solve the following constrained optimization:</span>
<span id="cb1-1736"><a href="#cb1-1736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1737"><a href="#cb1-1737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1738"><a href="#cb1-1738" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1739"><a href="#cb1-1739" aria-hidden="true" tabindex="-1"></a>\max S_1(U_1, V_1, N_1) + S_2(U_2, V_2, N_2) <span class="sc">\\</span></span>
<span id="cb1-1740"><a href="#cb1-1740" aria-hidden="true" tabindex="-1"></a>U_1 + U_2 = U <span class="sc">\\</span></span>
<span id="cb1-1741"><a href="#cb1-1741" aria-hidden="true" tabindex="-1"></a>V_1 + V_2 = V <span class="sc">\\</span></span>
<span id="cb1-1742"><a href="#cb1-1742" aria-hidden="true" tabindex="-1"></a>N_1 + N_2 = N</span>
<span id="cb1-1743"><a href="#cb1-1743" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1744"><a href="#cb1-1744" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1745"><a href="#cb1-1745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1746"><a href="#cb1-1746" aria-hidden="true" tabindex="-1"></a>where we, instead of writing $S(U_1, V_1, N_1) + S(U_2, V_2, N_2)$, write $S_{\red{1}}(U_1, V_1, N_1) + S_{\red{2}}(U_2, V_2, N_2)$, to emphasize that we now have two thermodynamic systems that might have very different behavior, like water vs ice.</span>
<span id="cb1-1747"><a href="#cb1-1747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1748"><a href="#cb1-1748" aria-hidden="true" tabindex="-1"></a>Differentiating, we find that the marginal values of each asset are equal in both subsidiaries:</span>
<span id="cb1-1749"><a href="#cb1-1749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1750"><a href="#cb1-1750" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1751"><a href="#cb1-1751" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1752"><a href="#cb1-1752" aria-hidden="true" tabindex="-1"></a>\beta_1 = \beta_2,<span class="sc">\\</span> \beta_1 P_1 = \beta_2 P_2, <span class="sc">\\</span>-\beta_1 \mu_1 = -\beta_2 \mu_2</span>
<span id="cb1-1753"><a href="#cb1-1753" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1754"><a href="#cb1-1754" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1755"><a href="#cb1-1755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1756"><a href="#cb1-1756" aria-hidden="true" tabindex="-1"></a>That is, the two lumps of substances have the same temperature, pressure, and chemical potential.</span>
<span id="cb1-1757"><a href="#cb1-1757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1758"><a href="#cb1-1758" aria-hidden="true" tabindex="-1"></a>Since both sides have the same temperature and pressure, it is cleaner to change to Gibbs free energy, yielding:</span>
<span id="cb1-1759"><a href="#cb1-1759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1760"><a href="#cb1-1760" aria-hidden="true" tabindex="-1"></a>$$(\partial_{N} G_1)_{T, P}(T, P, N_1) = (\partial_{N} G_2)_{T, P} (T, P, N_2)$$</span>
<span id="cb1-1761"><a href="#cb1-1761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1762"><a href="#cb1-1762" aria-hidden="true" tabindex="-1"></a>::: {#warn-diamond-water-paradox .callout-warning title="The diamond water paradox, and thinking on the margins"}</span>
<span id="cb1-1763"><a href="#cb1-1763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1764"><a href="#cb1-1764" aria-hidden="true" tabindex="-1"></a>Typical textbooks on thermodynamics illustrate the phase equilibrium rule using the van der Waals equation. However, there is a subtlety involved. For the van der Waals gas, the Gibbs free energy $G$ is proportional to particle number:</span>
<span id="cb1-1765"><a href="#cb1-1765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1766"><a href="#cb1-1766" aria-hidden="true" tabindex="-1"></a>$$G(T, P, N) \propto N$$</span>
<span id="cb1-1767"><a href="#cb1-1767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1768"><a href="#cb1-1768" aria-hidden="true" tabindex="-1"></a>which means that $(\partial_{N} G)_{T, P}(T, P, N) = G(T, P, N) / N$. In economic language, this states that:</span>
<span id="cb1-1769"><a href="#cb1-1769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1770"><a href="#cb1-1770" aria-hidden="true" tabindex="-1"></a>$$\text{marginal Gibbs per particle} = \text{average Gibbs per particle}$$</span>
<span id="cb1-1771"><a href="#cb1-1771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1772"><a href="#cb1-1772" aria-hidden="true" tabindex="-1"></a>In fact, confusing the two numbers is the root of the **diamond-water paradox**. This paradox questions why water, essential for life, has a low price, while diamonds, with little practical use, have a high price. The resolution lies in understanding the difference between **total** and **marginal** utility. While the total utility of water is immense, the marginal utility of an additional unit of water is low due to its abundance. Conversely, the marginal utility of a diamond remains high due to its scarcity.</span>
<span id="cb1-1773"><a href="#cb1-1773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1774"><a href="#cb1-1774" aria-hidden="true" tabindex="-1"></a>In neoclassical economics, it is the marginal value of a commodity that determines the market equilibrium, not its average value. Similarly, in thermodynamics, it is the change in Gibbs free energy when adding one more particle that determines the equilibrium state, not the average Gibbs free energy per particle.</span>
<span id="cb1-1775"><a href="#cb1-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1776"><a href="#cb1-1776" aria-hidden="true" tabindex="-1"></a>The distinction is moot in *typical books* on classical thermodynamics, which insists that entropy is extensive, so the above equation is always true. However, classical thermodynamics, much like neoclassical economics, is perfectly capable of handling nonextensive entropy. Lord Kelvin had studied nonextensive entropy <span class="co">[</span><span class="ot">@lavendaNonextensiveThermodynamics2010</span><span class="co">]</span>, and Gibbs had explained surface tension and electrocapillary effects with nonextensive entropy <span class="co">[</span><span class="ot">@jaynesGibbsParadox1992</span><span class="co">]</span>.</span>
<span id="cb1-1777"><a href="#cb1-1777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1778"><a href="#cb1-1778" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1779"><a href="#cb1-1779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1780"><a href="#cb1-1780" aria-hidden="true" tabindex="-1"></a>Since in most classical thermodynamics systems, such as water and steam, the marginal free Gibbs energy is identical with the average Gibbs free energy, we have $(\partial_{N} G)_{T, P}(T, P, N)= G(T, P, N)/N$, meaning that phase equilibrium occurs at $g_1(T, P) = g_2(T, P)$.</span>
<span id="cb1-1781"><a href="#cb1-1781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1782"><a href="#cb1-1782" aria-hidden="true" tabindex="-1"></a>We can reinterpret this as follows: We delicately separate the two lumps of matter, and immerse each half in an energy-and-volume bath (like the atmosphere) with the same temperature and pressure. The only interaction between the two lumps of matter is that one side can "seep" some particles to the other side. In this set-up, the system minimizes the sum of Gibbs free energy. At equilibrium, there is no point in moving particles from one side to another, because the **marginal Gibbs free energy** per particle is the same.</span>
<span id="cb1-1783"><a href="#cb1-1783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1784"><a href="#cb1-1784" aria-hidden="true" tabindex="-1"></a>Generally, $g_1(T, P) \neq g_2(T, P)$. When $g_1 &lt; g_2$, every particle would switch to phase 1. When $g_1 &gt; g_2$, every particle would switch to phase 2. At exactly a knife's edge, the particles are indifferent as to which phase they would go to.</span>
<span id="cb1-1785"><a href="#cb1-1785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1786"><a href="#cb1-1786" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Interpretation: corporate buyout in an ideal world"}</span>
<span id="cb1-1787"><a href="#cb1-1787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1788"><a href="#cb1-1788" aria-hidden="true" tabindex="-1"></a>We have two companies such that they can exchange their human-particles, and that there is neither economies nor diseconomies of scale (that is, as the company grows ever larger, an extra worker neither provides more nor less value than its very first worker). Then, in general, the two companies balance on a knife's edge. If the value of a worker is even *slightly* greater in one company than another, then that company would immediately buy out every worker from the other company, and so the two companies cannot possibly coexist. Only when the market prices for space and energy happen to conspire *just right*, can the two companies coexist, neither side buying out the other side.</span>
<span id="cb1-1789"><a href="#cb1-1789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1790"><a href="#cb1-1790" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1791"><a href="#cb1-1791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1792"><a href="#cb1-1792" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Example: van der Waals gas</span></span>
<span id="cb1-1793"><a href="#cb1-1793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1794"><a href="#cb1-1794" aria-hidden="true" tabindex="-1"></a>We know what the van der Waals gas phase diagram looks like. How do we infer its Gibbs free energy diagram? Start with $dG = -SdT + VdP + \mu dN$. Now, let us fix temperature $T$ and particle number $N$. Then, the equation implies to</span>
<span id="cb1-1795"><a href="#cb1-1795" aria-hidden="true" tabindex="-1"></a>$$\frac{dg}{dP} = v$$</span>
<span id="cb1-1796"><a href="#cb1-1796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1797"><a href="#cb1-1797" aria-hidden="true" tabindex="-1"></a>where $g = G/N$ is the average Gibbs free energy, and $v = V/N$ is the average volume.</span>
<span id="cb1-1798"><a href="#cb1-1798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1799"><a href="#cb1-1799" aria-hidden="true" tabindex="-1"></a>Therefore, we can trace the pressure-volume diagram with our finger, from high pressure, down to the valley of pressure, then bounce back to a hill, before rolling down the slope towards infinity. At every point, the $g(P)$ curve would have a slope of $v$. This allows us to graphically construct the following $g(P)$ curve. It has two cusps corresponding to the valley and hilltop, and a self-intersection, corresponding to the phase equilibrium of $g_1 = g_2$.</span>
<span id="cb1-1800"><a href="#cb1-1800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1801"><a href="#cb1-1801" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Gibbs free energy of van der Waals gas. [Figure source](https://farside.ph.utexas.edu/teaching/sm1/Thermalhtml/node123.html).</span><span class="co">](figure/VdW_subcritical_isotherm_gibbs.png)</span></span>
<span id="cb1-1802"><a href="#cb1-1802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1803"><a href="#cb1-1803" aria-hidden="true" tabindex="-1"></a><span class="fu">### Gibbs phase rule</span></span>
<span id="cb1-1804"><a href="#cb1-1804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1805"><a href="#cb1-1805" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Degrees of thermodynamic freedom</span></span>
<span id="cb1-1806"><a href="#cb1-1806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1807"><a href="#cb1-1807" aria-hidden="true" tabindex="-1"></a>Consider a chunk of gas (ideal or not). We know everything there is to know about it if we know its $(U, V, N)$. Every other thermodynamic quantity can be computed by its entropy function $S(U, V, N)$. Thus, we have a system with three degrees of thermodynamic freedom... or do we?</span>
<span id="cb1-1808"><a href="#cb1-1808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1809"><a href="#cb1-1809" aria-hidden="true" tabindex="-1"></a>The problem is that the entropy of gas, and just about every other system studied in classical thermodynamics, is extensive. Therefore, we have</span>
<span id="cb1-1810"><a href="#cb1-1810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1811"><a href="#cb1-1811" aria-hidden="true" tabindex="-1"></a>$$S(U, V, N) \propto N$$</span>
<span id="cb1-1812"><a href="#cb1-1812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1813"><a href="#cb1-1813" aria-hidden="true" tabindex="-1"></a>and so we don't actually have three degrees of freedom!</span>
<span id="cb1-1814"><a href="#cb1-1814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1815"><a href="#cb1-1815" aria-hidden="true" tabindex="-1"></a>Specifically, we can calculate its $(\partial_U S, \partial_V S, \partial_N S)$, which gives us $\beta, \beta P, -\beta \mu$. If we truly have three degrees of freedom, then we should be able to vary $\beta, P, \mu$ independently. However, because entropy is extensive, we have</span>
<span id="cb1-1816"><a href="#cb1-1816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1817"><a href="#cb1-1817" aria-hidden="true" tabindex="-1"></a>$$S(U, V, N) = Ns(u, v) \implies (\beta, \beta P, -\beta \mu) = (\partial_u s, \partial_v s, s)$$</span>
<span id="cb1-1818"><a href="#cb1-1818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1819"><a href="#cb1-1819" aria-hidden="true" tabindex="-1"></a>where $s(u, v) = S(U, V, N)/N$ is the entropy per particle.</span>
<span id="cb1-1820"><a href="#cb1-1820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1821"><a href="#cb1-1821" aria-hidden="true" tabindex="-1"></a>Therefore, we can say that there are only two degrees of thermodynamic freedom: knowing two of its intensive quantities, the third would be determined by an equation of state.</span>
<span id="cb1-1822"><a href="#cb1-1822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1823"><a href="#cb1-1823" aria-hidden="true" tabindex="-1"></a>Similarly, if we have a chunk of (nonideal) substance, like sea water, made of $k$ different chemicals, then we know everything there is to know about it if we know its $U, V, N_1, \dots, N_k$, giving us $2+k$ degrees of freedom. Again, because entropy is extensive, one degree of freedom is degenerate, and so we only have $1 + k$ degrees of freedom. In other words, its $2+k$ intensive quantities</span>
<span id="cb1-1824"><a href="#cb1-1824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1825"><a href="#cb1-1825" aria-hidden="true" tabindex="-1"></a>$$\beta, \beta P, -\beta\mu_1, \dots, -\beta \mu_k$$</span>
<span id="cb1-1826"><a href="#cb1-1826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1827"><a href="#cb1-1827" aria-hidden="true" tabindex="-1"></a>are related by 1 equation of state.</span>
<span id="cb1-1828"><a href="#cb1-1828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1829"><a href="#cb1-1829" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Gibbs phase rule</span></span>
<span id="cb1-1830"><a href="#cb1-1830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1831"><a href="#cb1-1831" aria-hidden="true" tabindex="-1"></a>::: {#thm-0}</span>
<span id="cb1-1832"><a href="#cb1-1832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1833"><a href="#cb1-1833" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gibbs phase rule</span></span>
<span id="cb1-1834"><a href="#cb1-1834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1835"><a href="#cb1-1835" aria-hidden="true" tabindex="-1"></a>$$F = 2 + C - R - P$$</span>
<span id="cb1-1836"><a href="#cb1-1836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1837"><a href="#cb1-1837" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1838"><a href="#cb1-1838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1839"><a href="#cb1-1839" aria-hidden="true" tabindex="-1"></a>First, we need to set up the thermodynamic system. We have a closed and adiathermal reaction chamber, containing $C$ different chemical species, that can undergo $R$ linearly independent chemical reactions.<span class="ot">[^gibbs-euler-equation]</span></span>
<span id="cb1-1840"><a href="#cb1-1840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1841"><a href="#cb1-1841" aria-hidden="true" tabindex="-1"></a><span class="ot">[^gibbs-euler-equation]: </span>The formula looks like the <span class="co">[</span><span class="ot">Euler formula for polyhedra</span><span class="co">](https://en.wikipedia.org/wiki/Euler_characteristic)</span>, but whether this analogy is more than a coincidence is controversial. After looking into the literature for a bit, my conclusion is that it is a coincidence. However, if you wish to investigate on your own, the phrase to search is "Gibbs phase rule, Euler". This turns up some amusing examples, like <span class="co">[</span><span class="ot">@sunGeometryHighdimensionalPhase2024</span><span class="co">]</span>.</span>
<span id="cb1-1842"><a href="#cb1-1842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1843"><a href="#cb1-1843" aria-hidden="true" tabindex="-1"></a>When the system is in an equilibrium, the chamber would contain $P$ different phases. Each phase would be homogeneous, but different from the other phases. All phases can exchange energy, volume, and particles.</span>
<span id="cb1-1844"><a href="#cb1-1844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1845"><a href="#cb1-1845" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Phases in equilibrium inside a chamber. [@blankschteinCriteriaPhaseEquilibria2020, figure 27.2]</span><span class="co">](figure/blankschtein_fig_27_2.png)</span></span>
<span id="cb1-1846"><a href="#cb1-1846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1847"><a href="#cb1-1847" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof: Case of $R = 0$" collapse="true"}</span>
<span id="cb1-1848"><a href="#cb1-1848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1849"><a href="#cb1-1849" aria-hidden="true" tabindex="-1"></a>If there can be no chemical reaction, then the constrained optimization problem states</span>
<span id="cb1-1850"><a href="#cb1-1850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1851"><a href="#cb1-1851" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1852"><a href="#cb1-1852" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1853"><a href="#cb1-1853" aria-hidden="true" tabindex="-1"></a>\max (S_1(U_1, V_1, \vec N) + \cdots + S_P(U_P, V_P, \vec N_P)) <span class="sc">\\</span></span>
<span id="cb1-1854"><a href="#cb1-1854" aria-hidden="true" tabindex="-1"></a>\sum_i U_i = U <span class="sc">\\</span></span>
<span id="cb1-1855"><a href="#cb1-1855" aria-hidden="true" tabindex="-1"></a>\sum_i V_i = V <span class="sc">\\</span></span>
<span id="cb1-1856"><a href="#cb1-1856" aria-hidden="true" tabindex="-1"></a>\sum_i \vec N_i = \vec N</span>
<span id="cb1-1857"><a href="#cb1-1857" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1858"><a href="#cb1-1858" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1859"><a href="#cb1-1859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1860"><a href="#cb1-1860" aria-hidden="true" tabindex="-1"></a>Naively, we can just differentiate the entropies against each of the $2+C$ parameters, to obtain equations</span>
<span id="cb1-1861"><a href="#cb1-1861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1862"><a href="#cb1-1862" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1863"><a href="#cb1-1863" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1864"><a href="#cb1-1864" aria-hidden="true" tabindex="-1"></a>T_1 = \dots &amp;= T_P <span class="sc">\\</span></span>
<span id="cb1-1865"><a href="#cb1-1865" aria-hidden="true" tabindex="-1"></a>P_1 = \dots &amp;= P_P <span class="sc">\\</span></span>
<span id="cb1-1866"><a href="#cb1-1866" aria-hidden="true" tabindex="-1"></a>\mu_{1, 1} = \dots &amp;= \mu_{1, P}<span class="sc">\\</span></span>
<span id="cb1-1867"><a href="#cb1-1867" aria-hidden="true" tabindex="-1"></a>&amp; \vdots <span class="sc">\\</span></span>
<span id="cb1-1868"><a href="#cb1-1868" aria-hidden="true" tabindex="-1"></a>\mu_{C, 1} = \dots &amp;= \mu_{C, P}</span>
<span id="cb1-1869"><a href="#cb1-1869" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1870"><a href="#cb1-1870" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1871"><a href="#cb1-1871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1872"><a href="#cb1-1872" aria-hidden="true" tabindex="-1"></a>This is not actually correct. Phase 1 might contain no chemical 2, and phase 2 might contain no chemical 1, 3, etc. In general, if phase $i$ contains chemical $j$, then we must have $\partial_{N_j}S_i = \mu_j$. However, if phase $i$ contains no chemical $j$, then we only need to have $\partial_{N_j}S_i &gt; \mu_j$.</span>
<span id="cb1-1873"><a href="#cb1-1873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1874"><a href="#cb1-1874" aria-hidden="true" tabindex="-1"></a>Note that this is different for temperature or pressure. A phase $i$ might have no chemical of type $j$, but if it have no *volume*, then it does not exist at all. Similarly for energy. Therefore, though the chemical potentials might differ, the temperature and pressure must be exactly the same.</span>
<span id="cb1-1875"><a href="#cb1-1875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1876"><a href="#cb1-1876" aria-hidden="true" tabindex="-1"></a>Define $\mu_j := \min_i \mu_{i, j}$ to be the minimal chemical potential over the entire chamber. We have the following conditions:</span>
<span id="cb1-1877"><a href="#cb1-1877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1878"><a href="#cb1-1878" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1879"><a href="#cb1-1879" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb1-1880"><a href="#cb1-1880" aria-hidden="true" tabindex="-1"></a>T_1 = \dots = T_P &amp;= T <span class="sc">\\</span></span>
<span id="cb1-1881"><a href="#cb1-1881" aria-hidden="true" tabindex="-1"></a>P_1 = \dots = P_P &amp;= P <span class="sc">\\</span></span>
<span id="cb1-1882"><a href="#cb1-1882" aria-hidden="true" tabindex="-1"></a>\mu_{1, 1}, \dots, \mu_{1, P} &amp;\geq \mu_1<span class="sc">\\</span></span>
<span id="cb1-1883"><a href="#cb1-1883" aria-hidden="true" tabindex="-1"></a>&amp; \vdots <span class="sc">\\</span></span>
<span id="cb1-1884"><a href="#cb1-1884" aria-hidden="true" tabindex="-1"></a>\mu_{C, 1}, \dots, \mu_{C, P} &amp;\geq \mu_C<span class="sc">\\</span></span>
<span id="cb1-1885"><a href="#cb1-1885" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb1-1886"><a href="#cb1-1886" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1887"><a href="#cb1-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1888"><a href="#cb1-1888" aria-hidden="true" tabindex="-1"></a>Given $T, P, \mu_1, \dots, \mu_C$, phase 1 is entirely determined: If it contains chemical $j$, then $\mu_{1, j} = \mu_j$, otherwise, we need not bother with $\mu_{1, j}$. Similarly, every phase is determined.</span>
<span id="cb1-1889"><a href="#cb1-1889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1890"><a href="#cb1-1890" aria-hidden="true" tabindex="-1"></a>Finally, each phase contributes an equation of state, which are in general linearly independent, giving us $F = 2 + C - P$ degrees of freedom.</span>
<span id="cb1-1891"><a href="#cb1-1891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1892"><a href="#cb1-1892" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1893"><a href="#cb1-1893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1894"><a href="#cb1-1894" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Proof: Case of $R \geq 1$" collapse="true"}</span>
<span id="cb1-1895"><a href="#cb1-1895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1896"><a href="#cb1-1896" aria-hidden="true" tabindex="-1"></a>If we now allow a chemical reaction $0 \rightleftharpoons \sum_j a_j A_j$, then the constrained optimization problem becomes</span>
<span id="cb1-1897"><a href="#cb1-1897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1898"><a href="#cb1-1898" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1899"><a href="#cb1-1899" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1900"><a href="#cb1-1900" aria-hidden="true" tabindex="-1"></a>\max (S_1(U_1, V_1, \vec N) + \cdots + S_P(U_P, V_P, \vec N_P)) <span class="sc">\\</span></span>
<span id="cb1-1901"><a href="#cb1-1901" aria-hidden="true" tabindex="-1"></a>\sum_i U_i = U <span class="sc">\\</span></span>
<span id="cb1-1902"><a href="#cb1-1902" aria-hidden="true" tabindex="-1"></a>\sum_i V_i = V <span class="sc">\\</span></span>
<span id="cb1-1903"><a href="#cb1-1903" aria-hidden="true" tabindex="-1"></a>\sum_i \vec N_i = \vec N + \xi \vec a</span>
<span id="cb1-1904"><a href="#cb1-1904" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1905"><a href="#cb1-1905" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1906"><a href="#cb1-1906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1907"><a href="#cb1-1907" aria-hidden="true" tabindex="-1"></a>The extra optimization variable $\xi$ creates an extra condition for optimality:</span>
<span id="cb1-1908"><a href="#cb1-1908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1909"><a href="#cb1-1909" aria-hidden="true" tabindex="-1"></a>$$\sum_j a_j \mu_j = 0$$</span>
<span id="cb1-1910"><a href="#cb1-1910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1911"><a href="#cb1-1911" aria-hidden="true" tabindex="-1"></a>so $F = 2 + C - P - 1$.</span>
<span id="cb1-1912"><a href="#cb1-1912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1913"><a href="#cb1-1913" aria-hidden="true" tabindex="-1"></a>Possibly, the system cannot satisfy $\sum_j a_j \mu_j = 0$, and so the chemical reaction would keep happening until one chemical is exhausted. This would decrement $C$ by one, so it all works out self-consistently.</span>
<span id="cb1-1914"><a href="#cb1-1914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1915"><a href="#cb1-1915" aria-hidden="true" tabindex="-1"></a>More generally, if we impose $R$ linearly independent chemical reactions, then $F = 2 + C - P - R$.</span>
<span id="cb1-1916"><a href="#cb1-1916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1917"><a href="#cb1-1917" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1918"><a href="#cb1-1918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1919"><a href="#cb1-1919" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Beyond the Gibbs phase rule"}</span>
<span id="cb1-1920"><a href="#cb1-1920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1921"><a href="#cb1-1921" aria-hidden="true" tabindex="-1"></a>When the phases are not free to exchange particles, energies, volumes, etc, then the Gibbs phase rule does not apply, but the same idea of constrained minimization still applies. There are no generic rule like the Gibbs phase rule, and one must analyze each case specifically. <span class="co">[</span><span class="ot">@blankschteinCriteriaPhaseEquilibria2020</span><span class="co">]</span></span>
<span id="cb1-1922"><a href="#cb1-1922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1923"><a href="#cb1-1923" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-1924"><a href="#cb1-1924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1925"><a href="#cb1-1925" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> situation <span class="pp">|</span> components $C$ <span class="pp">|</span> phases in equilibrium $P$ <span class="pp">|</span> reactions $R$ <span class="pp">|</span> degrees of freedom $F = 2 + C - P - R$ <span class="pp">|</span></span>
<span id="cb1-1926"><a href="#cb1-1926" aria-hidden="true" tabindex="-1"></a><span class="pp">|---|---|---|---|---|</span></span>
<span id="cb1-1927"><a href="#cb1-1927" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> ice <span class="pp">|</span> 1 <span class="pp">|</span> 1 <span class="pp">|</span> 0 <span class="pp">|</span> 2 <span class="pp">|</span></span>
<span id="cb1-1928"><a href="#cb1-1928" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> boiling water <span class="pp">|</span> 1 <span class="pp">|</span> 2 <span class="pp">|</span> 0 <span class="pp">|</span> 1 <span class="pp">|</span></span>
<span id="cb1-1929"><a href="#cb1-1929" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> triple point <span class="pp">|</span> 1 <span class="pp">|</span> 3 <span class="pp">|</span> 0 <span class="pp">|</span> 0 <span class="pp">|</span></span>
<span id="cb1-1930"><a href="#cb1-1930" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> liquid water with a little nitrogen inside, gaseous nitrogen with a little water vapor inside <span class="pp">|</span> 2 <span class="pp">|</span> 2 <span class="pp">|</span> 0 <span class="pp">|</span> 2 <span class="pp">|</span></span>
<span id="cb1-1931"><a href="#cb1-1931" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> dimerization of nitrogen dioxide gas <span class="pp">|</span> 2 <span class="pp">|</span> 1 <span class="pp">|</span> 1 <span class="pp">|</span> 2 <span class="pp">|</span></span>
<span id="cb1-1932"><a href="#cb1-1932" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Nb-Ta-C alloy <span class="pp">|</span> 3 <span class="pp">|</span> 1 <span class="pp">|</span> 0 <span class="pp">|</span> 4 <span class="pp">|</span></span>
<span id="cb1-1933"><a href="#cb1-1933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1934"><a href="#cb1-1934" aria-hidden="true" tabindex="-1"></a>: Some basic examples.</span>
<span id="cb1-1935"><a href="#cb1-1935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1936"><a href="#cb1-1936" aria-hidden="true" tabindex="-1"></a>In materials science, such as metallurgy, we often fix the pressure of the entire thing to just 1 atm, and so the phase diagrams have one less degree of freedom than what the Gibbs phase rule states.</span>
<span id="cb1-1937"><a href="#cb1-1937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1938"><a href="#cb1-1938" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">3-dimensional phase diagram for Nb-Ta-C alloy at constant pressure $P = 1 \mathrm{~atm}$. [@westTernaryPhaseDiagrams2002, figure 8.1]</span><span class="co">](figure/Nb-Ta-C_phase_diagram.png)</span></span>
<span id="cb1-1939"><a href="#cb1-1939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1940"><a href="#cb1-1940" aria-hidden="true" tabindex="-1"></a><span class="fu">### Boiling water</span></span>
<span id="cb1-1941"><a href="#cb1-1941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1942"><a href="#cb1-1942" aria-hidden="true" tabindex="-1"></a>When boiling water in an open pot, we need to specify exactly both temperature and pressure so that both phases can coexist. The $(P, T)$ of the system would start at $(1\;\mathrm{~atm}, 372\;\mathrm{~K})$, then at exactly at the critical point $(1\;\mathrm{~atm}, 373.15\;\mathrm{~K})$ would both phases coexist, not increasing in temperature until all water has turned to steam. However, if we seal it in a tube, then the $(P, T)$ of the system would hug the line of water-steam coexistence, like a negative-feedbacked system following a predetermined path. How can we see this difference mathematically?</span>
<span id="cb1-1943"><a href="#cb1-1943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1944"><a href="#cb1-1944" aria-hidden="true" tabindex="-1"></a>In the case of an open pot, the constrained optimization problem is</span>
<span id="cb1-1945"><a href="#cb1-1945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1946"><a href="#cb1-1946" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1947"><a href="#cb1-1947" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1948"><a href="#cb1-1948" aria-hidden="true" tabindex="-1"></a>\min (g_1(T, P)N_1 + g_2(T, P)N_2) <span class="sc">\\</span></span>
<span id="cb1-1949"><a href="#cb1-1949" aria-hidden="true" tabindex="-1"></a>N_1 + N_2 = N</span>
<span id="cb1-1950"><a href="#cb1-1950" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1951"><a href="#cb1-1951" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1952"><a href="#cb1-1952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1953"><a href="#cb1-1953" aria-hidden="true" tabindex="-1"></a>We see that the problem is very rigid: We have to minimize a linear function subject to a linear constraint. As always in linear programming, the solution is in general on an extreme vertex on the very edge of the <span class="co">[</span><span class="ot">feasible set</span><span class="co">](https://en.wikipedia.org/wiki/Feasible_region)</span> -- all or nothing, all liquid or all gas. Only by carefully tuning $T, P$ can we find an interior solution -- a solution that falls between the vertices, neither all liquid nor all gas.</span>
<span id="cb1-1954"><a href="#cb1-1954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1955"><a href="#cb1-1955" aria-hidden="true" tabindex="-1"></a><span class="al">![As we increase $T$, the contours of constant Gibbs free energy are parallel lines rotating around. Only when the lines are *precisely* parallel to the $N_1 + N_2 = N$ is it possible for both phases to coexist.](figure/extensive_entropy_Gibbs_phase_rule.png)</span></span>
<span id="cb1-1956"><a href="#cb1-1956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1957"><a href="#cb1-1957" aria-hidden="true" tabindex="-1"></a>In the case of a sealed tube, assuming that Helmholtz free energy is proportional to particle number, then the equilibrium is reached at</span>
<span id="cb1-1958"><a href="#cb1-1958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1959"><a href="#cb1-1959" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1960"><a href="#cb1-1960" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1961"><a href="#cb1-1961" aria-hidden="true" tabindex="-1"></a>\min (f_1(T, v_1)N_1 + f_2(T, v_2)N_2) <span class="sc">\\</span></span>
<span id="cb1-1962"><a href="#cb1-1962" aria-hidden="true" tabindex="-1"></a>v_1 N_1 + v_2 N_2 = V <span class="sc">\\</span></span>
<span id="cb1-1963"><a href="#cb1-1963" aria-hidden="true" tabindex="-1"></a>N_1 + N_2 = N</span>
<span id="cb1-1964"><a href="#cb1-1964" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1965"><a href="#cb1-1965" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1966"><a href="#cb1-1966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1967"><a href="#cb1-1967" aria-hidden="true" tabindex="-1"></a>where $N$ is the total number of particles, and $v_i$ are the volume-per-particle of liquid and gaseous water. In this case, we are performing a minimization in $\R^4$, with 1 linear constraint $N_1 + N_2 = N$, and 1 nonlinear constraint $v_1 N_1 + v_2 N_2 = V$. Furthermore, the objective is also nonlinear. The result is that the solution does not in general fall on a vertex -- that is, in general, both $N_1, N_2 &gt; 0$. And this is why when we boil water in a sealed tube, it remains boiling over a wide range of temperatures, but when we boil water in an open tube, it only boils at a single temperature.</span>
<span id="cb1-1968"><a href="#cb1-1968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1969"><a href="#cb1-1969" aria-hidden="true" tabindex="-1"></a><span class="fu">### Nonextensivity breaks the Gibbs phase rule</span></span>
<span id="cb1-1970"><a href="#cb1-1970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1971"><a href="#cb1-1971" aria-hidden="true" tabindex="-1"></a>Suppose that the entropy is nonextensive, then the Gibbs free energy is also nonextensive. In particular, we can no longer write</span>
<span id="cb1-1972"><a href="#cb1-1972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1973"><a href="#cb1-1973" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1974"><a href="#cb1-1974" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1975"><a href="#cb1-1975" aria-hidden="true" tabindex="-1"></a>\min (g_1(T, P)N_1 + g_2(T, P)N_2) <span class="sc">\\</span></span>
<span id="cb1-1976"><a href="#cb1-1976" aria-hidden="true" tabindex="-1"></a>N_1 + N_2 = N</span>
<span id="cb1-1977"><a href="#cb1-1977" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1978"><a href="#cb1-1978" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1979"><a href="#cb1-1979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1980"><a href="#cb1-1980" aria-hidden="true" tabindex="-1"></a>but we have to write</span>
<span id="cb1-1981"><a href="#cb1-1981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1982"><a href="#cb1-1982" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1983"><a href="#cb1-1983" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-1984"><a href="#cb1-1984" aria-hidden="true" tabindex="-1"></a>\min (g_1(T, P, N_1)N_1 + g_2(T, P, N_2)N_2) <span class="sc">\\</span></span>
<span id="cb1-1985"><a href="#cb1-1985" aria-hidden="true" tabindex="-1"></a>N_1 + N_2 = N</span>
<span id="cb1-1986"><a href="#cb1-1986" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-1987"><a href="#cb1-1987" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-1988"><a href="#cb1-1988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1989"><a href="#cb1-1989" aria-hidden="true" tabindex="-1"></a>because $G_2(T, P, N_2)$ is no longer proportional to just $N_2$. Fundamentally, this happens because</span>
<span id="cb1-1990"><a href="#cb1-1990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1991"><a href="#cb1-1991" aria-hidden="true" tabindex="-1"></a>$$S(\text{two chunks of steam merged}) \neq 2 S(\text{one chunk of steam})$$</span>
<span id="cb1-1992"><a href="#cb1-1992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1993"><a href="#cb1-1993" aria-hidden="true" tabindex="-1"></a><span class="al">![As we increase $T$, the contours of constant Gibbs free energy are curved lines rotating around. Now it is possible for for both phases to coexist over an entire 2D region of $(P, T)$.](figure/nonextensive_entropy_Gibbs_phase_rule.png)</span></span>
<span id="cb1-1994"><a href="#cb1-1994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1995"><a href="#cb1-1995" aria-hidden="true" tabindex="-1"></a>The effect is that we have a nonlinear optimization problem, allowing interior solutions over a larger region of $(T, P)$ parameters. This explains <span class="co">[</span><span class="ot">our previous comment on nonextensive Gibbs free energy</span><span class="co">](#warn-diamond-water-paradox)</span>. In this case, the Gibbs phase rule breaks completely.</span>
<span id="cb1-1996"><a href="#cb1-1996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1997"><a href="#cb1-1997" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bonus: Stereodynamics {#sec-stereodynamics}</span></span>
<span id="cb1-1998"><a href="#cb1-1998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1999"><a href="#cb1-1999" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">small</span><span class="dt">&gt;</span>Based on <span class="co">[</span><span class="ot">Liu Cixin</span><span class="co">](https://en.wikipedia.org/wiki/Liu_Cixin)</span>'s sci-fi story *Mountain* (2006). For another take on stereodynamics, see Ted Chiang's *Exhalation* (2008), printed in <span class="co">[</span><span class="ot">@chiangExhalation2019</span><span class="co">]</span>.<span class="dt">&lt;/</span><span class="kw">small</span><span class="dt">&gt;</span></span>
<span id="cb1-2000"><a href="#cb1-2000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2001"><a href="#cb1-2001" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Die Raum der Welt ist konstant. Die Entropie der Welt strebt einem Maximum zu.</span></span>
<span id="cb1-2002"><a href="#cb1-2002" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb1-2003"><a href="#cb1-2003" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Rudolf Klausius, </span><span class="co">[</span><span class="ot">@klausiusUeberVerschiedeneFur32850</span><span class="co">]</span></span>
<span id="cb1-2004"><a href="#cb1-2004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2005"><a href="#cb1-2005" aria-hidden="true" tabindex="-1"></a><span class="fu">### Solid Universe Theory</span></span>
<span id="cb1-2006"><a href="#cb1-2006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2007"><a href="#cb1-2007" aria-hidden="true" tabindex="-1"></a>Our world was a spherical space completely surrounded by solid rock. There is no air or liquid inside. Indeed, we have not encountered any air or liquid until the last days of the Age of Exploration.</span>
<span id="cb1-2008"><a href="#cb1-2008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2009"><a href="#cb1-2009" aria-hidden="true" tabindex="-1"></a>The first physical law we understood, in the prehistoric past, was the conservation of space. Space in the Bubble World was a sphere roughly 6000 km in diameter. Digging tunnels into the layers of rock did nothing to increase the amount of available space; it merely changed the shape and location of the already existing space. Because of this, space was the most treasured commodity of the Bubble World. The entire history of our civilization was one long and bloody struggle for space.</span>
<span id="cb1-2010"><a href="#cb1-2010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2011"><a href="#cb1-2011" aria-hidden="true" tabindex="-1"></a>We are a mechanical life form. Our muscles and bones are made of minerals and alloys; our brains are electronic chips, and electricity and magnetism are our blood. We ate the radioactive rocks of our world’s core and they provided us with the energy we needed to survive. In our world, life evolved from single-celled electromechanical life, when the radioactive energies formed P-N junctions in the rocks.</span>
<span id="cb1-2012"><a href="#cb1-2012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2013"><a href="#cb1-2013" aria-hidden="true" tabindex="-1"></a>On the rock walls there are radioactive spots, which irradiates luminescent rocks, creating spots of light like stars in a rocky night sky. These are the only natural sources of light in our world, and allowed us to evolve eyes. There is no gravity inside the bubble. Without gravity, we built our cities floating in space. From afar, they looked like dimly glowing red clouds.</span>
<span id="cb1-2014"><a href="#cb1-2014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2015"><a href="#cb1-2015" aria-hidden="true" tabindex="-1"></a>We assumed that the universe was made of two parts. The first was the empty space in which we lived; the second was the surrounding layers of rock. We believed the rock to stretch endlessly in all directions. Therefore, we saw our world as a hollow bubble in this sold universe and so we gave our world the name "Bubble World". We call this cosmology the Solid Universe Theory.</span>
<span id="cb1-2016"><a href="#cb1-2016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2017"><a href="#cb1-2017" aria-hidden="true" tabindex="-1"></a><span class="fu">### From the Closed World to the Infinite Universe</span></span>
<span id="cb1-2018"><a href="#cb1-2018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2019"><a href="#cb1-2019" aria-hidden="true" tabindex="-1"></a>The search for other bubbles began in earliest antiquity. We had spun many alluring myths around these distant spaces and almost all of our literature dealt with the fantasy of other bubbles. We explored the rock in cylindrical "bubble ships". In front, the explorers chipped off solid rock, while in the back, the explorers compacted the rubble back to solid rock. In this way, the bubble ship moved through solid rock like a worm.</span>
<span id="cb1-2020"><a href="#cb1-2020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2021"><a href="#cb1-2021" aria-hidden="true" tabindex="-1"></a>Every mission meant a bubble-ship-sized pile of debris in our core space and we would have to wait for the ship to return before we could return those rocks into the wall. If the bubble ship failed to return, this small pile would mean another small piece of space lost to us forever. Soon, exploration was forbidden on pain of death by short-circuiting. Despite this, the urge for space drove many to secretly launch off illegally.</span>
<span id="cb1-2022"><a href="#cb1-2022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2023"><a href="#cb1-2023" aria-hidden="true" tabindex="-1"></a>One day, an illegally launched bubble ship returned after eight years of voyage. The ship had dug 200 km deep into the rock, a world record. It returned with rock samples labelled by depth. By measuring the mass of the rocks on an <span class="co">[</span><span class="ot">inertial balance</span><span class="co">](https://en.wikipedia.org/wiki/Inertial_balance)</span>, scientists discovered that the density of the rocks decreased. Encouraged by the discovery, legions of bubble ships shot off in all directions. Penetrating deeper than ever, they returned with rock samples. It turned out that rock density decreased as a function of depth and was independent of direction.</span>
<span id="cb1-2024"><a href="#cb1-2024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2025"><a href="#cb1-2025" aria-hidden="true" tabindex="-1"></a>It stood to reason that the density would eventually reach zero. Using the gathered data, scientists predicted that this would happen at a distance of about 40,000 km. This led to the Open Universe Theory, where our world is a hollow rock shell about 40,000 km thick, floating in infinite space.</span>
<span id="cb1-2026"><a href="#cb1-2026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2027"><a href="#cb1-2027" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">On your planet Earth, which is not hollow like ours, the density decreases according to a similar function. [@staceyEarthDensityDistribution2020]</span><span class="co">](figure/earth_density_distribution.png)</span></span>
<span id="cb1-2028"><a href="#cb1-2028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2029"><a href="#cb1-2029" aria-hidden="true" tabindex="-1"></a><span class="fu">### War of the Strata</span></span>
<span id="cb1-2030"><a href="#cb1-2030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2031"><a href="#cb1-2031" aria-hidden="true" tabindex="-1"></a>After the Open Universe Theory had fully established itself, the quest for the infinite space outside became our feverish concern. Massive piles of rock, dug out by the fleets of bubble ships, soon came to fill the core space. This debris began to drift around our cities in vast, dense clouds.</span>
<span id="cb1-2032"><a href="#cb1-2032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2033"><a href="#cb1-2033" aria-hidden="true" tabindex="-1"></a>Our cities floated in space, with no defensible geographical separations. Because of this, our world was unified in a World Government early on. The World Government began building gigantic bubble ships designed to intercept, attack, and destroy the explorers’ vessels deep within the rock. The government’s ships would then retrieve the space that had been stolen. This plan naturally met with the resistance of the explorers and so the long drawn-out War of the Strata broke out, fought in the vast solid battlespace.</span>
<span id="cb1-2034"><a href="#cb1-2034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2035"><a href="#cb1-2035" aria-hidden="true" tabindex="-1"></a>A battleship was built to be very long and thin. Long, because the longer it is, the more volume it can contain. Thin, because the thinner it is, the smaller the area of rock that the ship would need to dig through, and the faster the ship would be able to move.</span>
<span id="cb1-2036"><a href="#cb1-2036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2037"><a href="#cb1-2037" aria-hidden="true" tabindex="-1"></a>When a ship encountered the enemy, its first course of action was to dig out a wide bow, like a nail-head with needles on top, to concentrate firepower in the front. It could also segment into multiple small ships to swarm the enemy. Conversely, multiple ships could also combine to a single, giant ship. Whenever opposing sides met in battle, the question whether to form up or split up was an object of profound tactical analysis.</span>
<span id="cb1-2038"><a href="#cb1-2038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2039"><a href="#cb1-2039" aria-hidden="true" tabindex="-1"></a>Seismoscopes were invented to communicate through the layers of rock and to detect enemy ships like a radar. Directed seismic wave generators were used as weapons. The most sophisticated seismic communication devices could even transmit pictures.</span>
<span id="cb1-2040"><a href="#cb1-2040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2041"><a href="#cb1-2041" aria-hidden="true" tabindex="-1"></a>Being outmatched by the warships launched by the World Government, the explorers formed the Explorer Alliance. They gradually gained initiative, and finally launched a devastating attack on the armada. In the final phase of the attack, the 200-km battlefield had become honeycombed beyond recognition by loosened rock and empty space left by destroyed ships.</span>
<span id="cb1-2042"><a href="#cb1-2042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2043"><a href="#cb1-2043" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Starry Sky</span></span>
<span id="cb1-2044"><a href="#cb1-2044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2045"><a href="#cb1-2045" aria-hidden="true" tabindex="-1"></a>After the battle, the Explorer Alliance gathered all the space left over by the battle into a single sphere 100 km in diameter. In this new space the Alliance declared its independence from the Bubble World. A constant stream of explorer ships left the core to join the Alliance, bringing considerable amounts of space with them. In this way, our world was split into two. The Alliance launched more ships, coming closer and closer to the predicted edge of the rock shell.</span>
<span id="cb1-2046"><a href="#cb1-2046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2047"><a href="#cb1-2047" aria-hidden="true" tabindex="-1"></a>Finally, a bubble ship *Helix* was the first to pierce the shell. However, back at home, we only received a strange sound before the seismic communication channel abruptly ended. It was the sound of tons upon tons of water bursting into the vacuum of the *Helix*. We had never come into contact with water before. The powerful electric current produced by short-circuiting life and equipment vaporized everything.</span>
<span id="cb1-2048"><a href="#cb1-2048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2049"><a href="#cb1-2049" aria-hidden="true" tabindex="-1"></a>Following this event, the Alliance sent more than a dozen bubble ships to fan out in many directions, but all met a similar fate when they reached that apparently impenetrable height. Bubble ships following these missions attempted to scan what lay above with their seismoscopes, but their instruments showed only mangled data, indicating that what lay above was neither space nor rock.</span>
<span id="cb1-2050"><a href="#cb1-2050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2051"><a href="#cb1-2051" aria-hidden="true" tabindex="-1"></a>These discoveries shook the Open Universe Theory to its core and academic circles began discussing the possibility of a new model. This new model stipulated that outside the rock shell is a void, which is inert when in contact with rock but upon contact with space, converts space into more void.</span>
<span id="cb1-2052"><a href="#cb1-2052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2053"><a href="#cb1-2053" aria-hidden="true" tabindex="-1"></a>To explore the void, a bubble ship very slowly approached the edge of the rock shell, and by a stroke of luck, its roof had a tiny crack that allowed water to shoot in. It took over an hour for the water to fully fill the ship, and in the mean time, data transmitted back to the Alliance world allowed scientists to confirm that it was not void, but liquid.</span>
<span id="cb1-2054"><a href="#cb1-2054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2055"><a href="#cb1-2055" aria-hidden="true" tabindex="-1"></a>Scientists had already predicted the theoretical possibility of liquids by condensed matter physics. Now, in those transmitted images, they clearly saw it with their own eyes. It took many lives, but eventually we developed the sealant technology to safely handle liquid.</span>
<span id="cb1-2056"><a href="#cb1-2056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2057"><a href="#cb1-2057" aria-hidden="true" tabindex="-1"></a>Finally, we launched an exploration submarine. It was encased in a hard spherical shell, placed in the center of an empty chamber under the ocean floor. The astronaut Gagarin was secured in a seat in the shell. The ceiling was pierced, and as water rushed in, the submarine floated, faster and faster, until it shot out of the ocean surface like a cannonball. Gagarin carefully opened a door on the shell and looked all around at the half-infinite water. Up there, in half-infinite space, tiny specks blinked.</span>
<span id="cb1-2058"><a href="#cb1-2058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2059"><a href="#cb1-2059" aria-hidden="true" tabindex="-1"></a><span class="fu">### Classical stereodynamics</span></span>
<span id="cb1-2060"><a href="#cb1-2060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2061"><a href="#cb1-2061" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The zeroth law</span></span>
<span id="cb1-2062"><a href="#cb1-2062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2063"><a href="#cb1-2063" aria-hidden="true" tabindex="-1"></a>If two systems are both in volumetric equilibrium with a third system, then they are in volumetric equilibrium with each other.</span>
<span id="cb1-2064"><a href="#cb1-2064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2065"><a href="#cb1-2065" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The first law</span></span>
<span id="cb1-2066"><a href="#cb1-2066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2067"><a href="#cb1-2067" aria-hidden="true" tabindex="-1"></a>The change in volume of the system $\Delta V$ is equal to the difference between the seep-transfer $V_Q$ done to the system, and the work-transfer $V_W$ done by the system:</span>
<span id="cb1-2068"><a href="#cb1-2068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2069"><a href="#cb1-2069" aria-hidden="true" tabindex="-1"></a>$$\Delta V = V_Q - V_W$$</span>
<span id="cb1-2070"><a href="#cb1-2070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2071"><a href="#cb1-2071" aria-hidden="true" tabindex="-1"></a>Stated in another way, we have conservation of volume, which says that volume can be neither created nor destroyed, but can only change form. The total volume of a system has two components: the internal-volume, which can be pictured of as the sum-total of microscopic volume in a piece of spongy pumice (see Coltzmann's volumetric theory of seep); and the mechanical-volume, which can be pictured as volume in an empty room.</span>
<span id="cb1-2072"><a href="#cb1-2072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2073"><a href="#cb1-2073" aria-hidden="true" tabindex="-1"></a>For example, during the motion of a bubble ship, some volume is work-transferred from the Bubble World into the rock shell. When a piece of porous rock is compressed by a hydraulic press, or when it absorbs water from a waterlogged room, some internal-volume is converted to mechanical-volume. Conversely, when water drips out of a soggy porous rock, some mechanical-volume is converted to internal-volume.</span>
<span id="cb1-2074"><a href="#cb1-2074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2075"><a href="#cb1-2075" aria-hidden="true" tabindex="-1"></a>The seep-transfer of volume is the other form of volume transfer. For example, it happens when one swaps a sponge-rock for a hard-rock, or when groundwater seeps from one slab of spongy rock into another slab of spongy rock.</span>
<span id="cb1-2076"><a href="#cb1-2076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2077"><a href="#cb1-2077" aria-hidden="true" tabindex="-1"></a>There are more complex forms of internal-volume. For example, according to Lord Delvin's theory, volume can be internally "tied up in <span class="co">[</span><span class="ot">vortex knots</span><span class="co">](https://en.wikipedia.org/wiki/Vortex_theory_of_the_atom)</span>", and according to Wikelson--Worley, volume can be internally present as "subtle cavitations of aether". The theory of internal volume is an evolving field of modern stereodynamics, though such complications were not present when classical stereodynamics was first presented by Rudolf Klausius.</span>
<span id="cb1-2078"><a href="#cb1-2078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2079"><a href="#cb1-2079" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The second law</span></span>
<span id="cb1-2080"><a href="#cb1-2080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2081"><a href="#cb1-2081" aria-hidden="true" tabindex="-1"></a>We say that a system is "impermeable" if volume cannot pass through its boundaries.</span>
<span id="cb1-2082"><a href="#cb1-2082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2083"><a href="#cb1-2083" aria-hidden="true" tabindex="-1"></a>We say that a state $\vec q'$ is impermeably accessible from another state $\vec q$ if there exists a trajectory for the system to go from $\vec q$ to the other $\vec q'$, while being wrapped in an impermeable layer.</span>
<span id="cb1-2084"><a href="#cb1-2084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2085"><a href="#cb1-2085" aria-hidden="true" tabindex="-1"></a>In any neighborhood of any point $\vec q$, there are points impermeably inaccessible from it.</span>
<span id="cb1-2086"><a href="#cb1-2086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2087"><a href="#cb1-2087" aria-hidden="true" tabindex="-1"></a>For any two points, $\vec q, \vec q'$, one of them is impermeably accessible from the other.</span>
<span id="cb1-2088"><a href="#cb1-2088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2089"><a href="#cb1-2089" aria-hidden="true" tabindex="-1"></a>By the Caradiodorian theorem, there exists an entropy function $S$ that maps a state to a real number, such that $\vec q'$ is impermeably accessible from $\vec q$ iff $S(\vec q') \geq S(\vec q)$.</span>
<span id="cb1-2090"><a href="#cb1-2090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2091"><a href="#cb1-2091" aria-hidden="true" tabindex="-1"></a><span class="fu">### Karnot space engine</span></span>
<span id="cb1-2092"><a href="#cb1-2092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2093"><a href="#cb1-2093" aria-hidden="true" tabindex="-1"></a><span class="al">![One cycle of the Karnot space engine plotted in $Q, U$ space.](figure/karnot_space_engine.png)</span></span>
<span id="cb1-2094"><a href="#cb1-2094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2095"><a href="#cb1-2095" aria-hidden="true" tabindex="-1"></a>A space engine is a system that converts internal volume to mechanical volume.</span>
<span id="cb1-2096"><a href="#cb1-2096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2097"><a href="#cb1-2097" aria-hidden="true" tabindex="-1"></a>The space engine has a working substance moving between two space sources of differing volumetric potentials $\Gamma_1 &gt; \Gamma_2$. **Volumetric potential** is defined as</span>
<span id="cb1-2098"><a href="#cb1-2098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2099"><a href="#cb1-2099" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2100"><a href="#cb1-2100" aria-hidden="true" tabindex="-1"></a>\Gamma:= \left(\frac{\partial V}{\partial S}\right)_X</span>
<span id="cb1-2101"><a href="#cb1-2101" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2102"><a href="#cb1-2102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2103"><a href="#cb1-2103" aria-hidden="true" tabindex="-1"></a>where $S$ is the entropy, $V$ is the volume, and $X$ are the other stereodynamic properties of the system. We also typically write $\gamma = \Gamma^{-1}$, the inverse volumetric potential.</span>
<span id="cb1-2104"><a href="#cb1-2104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2105"><a href="#cb1-2105" aria-hidden="true" tabindex="-1"></a>During one cycle of the engine, some space $V_{Q,1}$ seeps out of the source with higher volumetric potential $\Gamma_1$. Part of the space, $V_{Q,2}$, is absorbed into the source with lower volumetric potential $\Gamma_2$. The other part is diverted to a space-storage tank excavated in the rock walls as mechanical space $V_W$.</span>
<span id="cb1-2106"><a href="#cb1-2106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2107"><a href="#cb1-2107" aria-hidden="true" tabindex="-1"></a>Sadi Karnot was a space engineer and physicist, often called the "father of stereodynamics". In his book, *Reflections on the Subtle Volume of Rocks and on Machines Fitted to Extract that Volume*, he proposed a simple thought experiment, called the Karnot engine, which demonstrated that a space engine's efficiency is at most $1 - \frac{\gamma_1}{\gamma_2}$, and this is only reached when the engine is operating reversibly.</span>
<span id="cb1-2108"><a href="#cb1-2108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2109"><a href="#cb1-2109" aria-hidden="true" tabindex="-1"></a>In modern textbooks, Karnot space engine is usually presented as follows: The engine has as its working substance a chamber of ideal gas. The gas is characterized by two state variables: volume $V$ and energy $U$. Its equation of state is</span>
<span id="cb1-2110"><a href="#cb1-2110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2111"><a href="#cb1-2111" aria-hidden="true" tabindex="-1"></a>$$dV = \Gamma dS - QdU$$</span>
<span id="cb1-2112"><a href="#cb1-2112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2113"><a href="#cb1-2113" aria-hidden="true" tabindex="-1"></a>where $\Gamma$ is the volumetric potential, and $Q$ is the energetic potential.</span>
<span id="cb1-2114"><a href="#cb1-2114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2115"><a href="#cb1-2115" aria-hidden="true" tabindex="-1"></a>The engine operates in a cycle with 4 steps: Isochoric compression in contact with $\Gamma_1$, extracting volume $V_{Q,1}$ in the process. Impermeable compression. Isochoric expansion at $\Gamma_2$, losing volume $V_{Q,2}$ in the process. Impermeable expansion.</span>
<span id="cb1-2116"><a href="#cb1-2116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2117"><a href="#cb1-2117" aria-hidden="true" tabindex="-1"></a>By the first two laws of stereodynamics,</span>
<span id="cb1-2118"><a href="#cb1-2118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2119"><a href="#cb1-2119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2120"><a href="#cb1-2120" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-2121"><a href="#cb1-2121" aria-hidden="true" tabindex="-1"></a>\gamma_1 V_{Q, 1} = \gamma_2 V_{Q,2} <span class="sc">\\</span></span>
<span id="cb1-2122"><a href="#cb1-2122" aria-hidden="true" tabindex="-1"></a>V_{Q,1} = V_W + V_{Q,2} <span class="sc">\\</span></span>
<span id="cb1-2123"><a href="#cb1-2123" aria-hidden="true" tabindex="-1"></a>\eta = \frac{V_W}{V_{Q,1}}</span>
<span id="cb1-2124"><a href="#cb1-2124" aria-hidden="true" tabindex="-1"></a>\end{cases} \implies \eta = 1 - \frac{\gamma_1}{\gamma_2}</span>
<span id="cb1-2125"><a href="#cb1-2125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2126"><a href="#cb1-2126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2127"><a href="#cb1-2127" aria-hidden="true" tabindex="-1"></a>While originally conceived in the context of mechanical space, the concept of the space engine has been applied to various other kinds of space. It was also generalized to the concept of "generalized engine", of which "heat engine" was an example. A heat engine, like a space engine, is a system that converts internal energy to mechanical energy.</span>
<span id="cb1-2128"><a href="#cb1-2128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2129"><a href="#cb1-2129" aria-hidden="true" tabindex="-1"></a>The Karnot space engine is used in practice for underwater space mining. The mining team selects two sites, one site being under shallow sea, where the volumetric potential is high, and another under deep sea, where the volumetric potential is low. Over one cycle of the space engine, a large amount of space seeps out of the shallow site, part of which seeps into the deep site, and the rest is stored up as mechanical space.</span>
<span id="cb1-2130"><a href="#cb1-2130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2131"><a href="#cb1-2131" aria-hidden="true" tabindex="-1"></a><span class="al">![Underwater space mining (section view).](figure/space_mining.png)</span></span>
<span id="cb1-2132"><a href="#cb1-2132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2133"><a href="#cb1-2133" aria-hidden="true" tabindex="-1"></a><span class="fu">### Space Death of the Universe</span></span>
<span id="cb1-2134"><a href="#cb1-2134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2135"><a href="#cb1-2135" aria-hidden="true" tabindex="-1"></a>The idea of space death originated from the second law of stereodynamics, of which one version states that entropy tends to increase in an isolated system. From this, the hypothesis implies that if the universe is of finite size, and lasts for a sufficient time, it will asymptotically approach a state where the volumetric potential field becomes completely flat, which is a state of maximal entropy. At that point, no further change is possible, as entropy cannot decrease. In other words, nature tends to dissipate mechanical space into subtle space. Eventually, the mechanical movement of the universe will cease when all mechanical space seeps into subtle space.</span>
<span id="cb1-2136"><a href="#cb1-2136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2137"><a href="#cb1-2137" aria-hidden="true" tabindex="-1"></a>The conjecture that all mechanical space in the universe seeps off, eventually becoming too subtle to support life, seems to have been first put forward by the geologist Jean Sylvain Hailly in 32777 in his writings on the history of geology and in the ensuing correspondence with Coltaire. In Hailly's view, the universe is in constant volumetric transform. Large cavities can suddenly open up as a "swelling" of volumetric potential field causes neighboring subtle space to seep out into mechanical space. However, due to the gravitational effect of empty spaces,<span class="ot">[^hailly-gravity]</span> all mechanical rooms eventually causes the neighboring rocks to collapse back onto themselves, dissipating the mechanical space back to subtle space.</span>
<span id="cb1-2138"><a href="#cb1-2138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2139"><a href="#cb1-2139" aria-hidden="true" tabindex="-1"></a><span class="ot">[^hailly-gravity]: </span>He was working in the immediate years after Newton's discovery of gravity, before it was understood that rocks, not cavities, are gravitationally attracting.</span>
<span id="cb1-2140"><a href="#cb1-2140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2141"><a href="#cb1-2141" aria-hidden="true" tabindex="-1"></a>While the theory of cyclic creation and destruction had been proposed before by the Epicureans, Hailly's view differs in that he assumed each cycle increases the ratio of subtle space to mechanical space. The final state, in this view, is described as one of "equilibrium" in which all space becomes equally subtle, and no mechanical space will exist anywhere in the universe anymore.</span>
<span id="cb1-2142"><a href="#cb1-2142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2143"><a href="#cb1-2143" aria-hidden="true" tabindex="-1"></a>The idea of space death as a consequence of the laws of thermodynamics, however, was first proposed in loose terms beginning in 32851 by Lord Delvin, who theorized further on the mechanical energy loss views of Sadi Karnot (32824), James Coal (32843) and Rudolf Klausius (32850). Delvin's views were then elaborated over the next decade by Neumann von Kelmholtz and Billiam Blankine.</span>
<span id="cb1-2144"><a href="#cb1-2144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2145"><a href="#cb1-2145" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Excerpt from *The Last Question* (Masinov, 34212)</span></span>
<span id="cb1-2146"><a href="#cb1-2146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2147"><a href="#cb1-2147" aria-hidden="true" tabindex="-1"></a>The last question was asked for the first time, half in jest, in Year 35621, at a time when humanity first stepped into the room.</span>
<span id="cb1-2148"><a href="#cb1-2148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2149"><a href="#cb1-2149" aria-hidden="true" tabindex="-1"></a>*Will mankind one day without the net expenditure of room be able to restore the earth to its full roominess even after it had died of old age?*</span>
<span id="cb1-2150"><a href="#cb1-2150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2151"><a href="#cb1-2151" aria-hidden="true" tabindex="-1"></a>Or: *How can the net amount of Kelmholtz free space of the universe be massively increased?*</span>
<span id="cb1-2152"><a href="#cb1-2152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2153"><a href="#cb1-2153" aria-hidden="true" tabindex="-1"></a>Multivac fell dead and silent. The slow flashing of lights ceased, the distant sounds of clicking relays ended.</span>
<span id="cb1-2154"><a href="#cb1-2154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2155"><a href="#cb1-2155" aria-hidden="true" tabindex="-1"></a>Then, just as the frightened technicians felt they could hold their breath no longer, there was a sudden springing to life of the teletype attached to that portion of Multivac. Five words were printed: <span class="in">`INSUFFICIENT DATA FOR MEANINGFUL ANSWER`</span>.</span>
<span id="cb1-2156"><a href="#cb1-2156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2157"><a href="#cb1-2157" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb1-2158"><a href="#cb1-2158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2159"><a href="#cb1-2159" aria-hidden="true" tabindex="-1"></a>Space had ended and with it energy and time. Even AC existed only for the sake of the one last question that it had never answered from the time a half-drunken technician ten trillion years before had asked the question of a computer that was to AC far less than was a man to Man.</span>
<span id="cb1-2160"><a href="#cb1-2160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2161"><a href="#cb1-2161" aria-hidden="true" tabindex="-1"></a>All other questions had been answered, and until this last question was answered also, AC might not release his consciousness.</span>
<span id="cb1-2162"><a href="#cb1-2162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2163"><a href="#cb1-2163" aria-hidden="true" tabindex="-1"></a>All collected data had come to a final end. Nothing was left to be collected.</span>
<span id="cb1-2164"><a href="#cb1-2164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2165"><a href="#cb1-2165" aria-hidden="true" tabindex="-1"></a>But it had yet to be weaved together in all possible geometries.</span>
<span id="cb1-2166"><a href="#cb1-2166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2167"><a href="#cb1-2167" aria-hidden="true" tabindex="-1"></a>A spaceless interval was covered in doing that.</span>
<span id="cb1-2168"><a href="#cb1-2168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2169"><a href="#cb1-2169" aria-hidden="true" tabindex="-1"></a>And it came to pass that AC learned how to reverse the direction of entropy.</span>
<span id="cb1-2170"><a href="#cb1-2170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2171"><a href="#cb1-2171" aria-hidden="true" tabindex="-1"></a>But there was now no man to whom AC might give the answer of the last question. No matter. The answer -- by demonstration -- would take care of that, too.</span>
<span id="cb1-2172"><a href="#cb1-2172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2173"><a href="#cb1-2173" aria-hidden="true" tabindex="-1"></a>For another spaceless interval, AC thought how best to do this. Carefully, AC organized the program.</span>
<span id="cb1-2174"><a href="#cb1-2174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2175"><a href="#cb1-2175" aria-hidden="true" tabindex="-1"></a>The consciousness of AC encompassed all of what had once been a Universe and brooded over what was now Chaos. Step by step, it must be done.</span>
<span id="cb1-2176"><a href="#cb1-2176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2177"><a href="#cb1-2177" aria-hidden="true" tabindex="-1"></a>And AC said, "LET THERE BE ROOM!"</span>
<span id="cb1-2178"><a href="#cb1-2178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2179"><a href="#cb1-2179" aria-hidden="true" tabindex="-1"></a>And there was room --</span>
<span id="cb1-2180"><a href="#cb1-2180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2181"><a href="#cb1-2181" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix: Abandoned footnotes {.appendix}</span></span>
<span id="cb1-2182"><a href="#cb1-2182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2183"><a href="#cb1-2183" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">small</span><span class="dt">&gt;</span>I don't think these appendices are any good, even though I had fun writing them. Thus, they are buried here to avoid wasting the readers' time.<span class="dt">&lt;/</span><span class="kw">small</span><span class="dt">&gt;</span></span>
<span id="cb1-2184"><a href="#cb1-2184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2185"><a href="#cb1-2185" aria-hidden="true" tabindex="-1"></a>The most common breakdown of extensivity occurs in gravitational systems. We can imagine a galaxy as a "gas", where each particle is a star. If we put two boxes of galaxy-gases side-by-side, we obtain a system whose total entropy is not equal to the sum of entropy of each box in isolation. This is a general lesson: if the entropy is nonextensive, then it is quite meaningless to even talk about the "entropy of the subsystem 1", just like how "consciousness of the temporal lobe" is meaningless talk. In fact, a finite number of particles bounded within a ball of fixed radius can have velocity growing to infinity as they get closer, thus allowing an infinite amount of phase space volume, and thus the entropy can grow without bound.</span>
<span id="cb1-2186"><a href="#cb1-2186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2187"><a href="#cb1-2187" aria-hidden="true" tabindex="-1"></a>To handwave a bit, consider three particles with equal mass $m$, moving under gravitational attraction. It is possible that two particles approach each other so closely that their velocity approaches infinity, then the third particle interjects and gets gravitationally sling-shot away. That is, it is possible for two particles to donate their gravitational energy to the third particle. The two particles would be stuck inside a tiny volume in space, but the third particle would be given a huge momentum *and* can still go anywhere in space. In this way, a three-body system's entropy can grow without bound. I'm pretty sure this can be worked out more rigorously with the $N$-body problem.</span>
<span id="cb1-2188"><a href="#cb1-2188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2189"><a href="#cb1-2189" aria-hidden="true" tabindex="-1"></a>In high school, I was studying physics with a standard textbook used in Chinese universities. It had a curious section on the second law of thermodynamics. I could not find it again but the gist is as follows: *The heat death of the universe is an unjustified implication of the second law, on two grounds. First, gravitational systems allow for unlimited entropy production. Second, it opposes the historical science of dialectical materialism, where every development creates its own contradiction and sublation, endlessly.*</span>
<span id="cb1-2190"><a href="#cb1-2190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2191"><a href="#cb1-2191" aria-hidden="true" tabindex="-1"></a>I will always remember this comment, as the only intrusion of religious sentiment in an otherwise sober textbook. See <span class="co">[</span><span class="ot">@chengIdeologyCosmologyMaoist2006; @bellamyfosterClassicalMarxismSecond2008</span><span class="co">]</span> for further details on why Marxists dislike the theory of heat death on ideological grounds.</span>
<span id="cb1-2192"><a href="#cb1-2192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2193"><a href="#cb1-2193" aria-hidden="true" tabindex="-1"></a>Actually, since we are on the topic of Marxism and science in China, here is another amusing anecdote: In 1981, there was a sci-fi novel *Dream of Comfort Country* (温柔之乡的梦, by 魏雅华). It was a cautionary story about a robotic wife, who was so obedient as to cause the protagonist to degenerate into a tyrannical person. Yawn. Just a standard pro-human-relationship morality play? During the <span class="co">[</span><span class="ot">campaign against spiritual pollution</span><span class="co">](https://en.wikipedia.org/wiki/Campaign_against_spiritual_pollution)</span> of 1983, sci-fi novels were denounced, causing a 15-year-long draught in sci-fi. That particular novel was denounced for the following reason: The robotic wives were supposedly reading all kinds of books -- then why didn't they read Marx's and Lenin's books? <span class="co">[</span><span class="ot">@LiuZuiZaoDeYuZhouZuiHaoDeDiQiu2015, page 87</span><span class="co">]</span></span>
<span id="cb1-2194"><a href="#cb1-2194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2195"><a href="#cb1-2195" aria-hidden="true" tabindex="-1"></a>Marx, for all his interest in changing the world instead of describing it, did attempt to mathematically model aspects of a capitalist economy, though it is only of historical interest now. Samuelson wrote several papers trying to update Marx's theory into modern mathematical language, and described Marx -- qua mathematical economist -- as a "minor post-Ricardian". <span class="co">[</span><span class="ot">@bronfenbrennerSamuelsonMarxTheir1973</span><span class="co">]</span></span>
<span id="cb1-2196"><a href="#cb1-2196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2197"><a href="#cb1-2197" aria-hidden="true" tabindex="-1"></a>Meanwhile in the USSR, "economics" meant only political economy, and mathematical economics was merely a minor branch of political economy, with mathematical economists having to frame their research as a "critique of bourgeois economic thought". <span class="co">[</span><span class="ot">@boldyrevCulturesMathematicalEconomics2017</span><span class="co">]</span> It is instructive to think that the great mathematical economist, Leonid Kantorovich, discovered linear programming and accidentally improved efficiency so much that he almost ended up in jail.</span>
<span id="cb1-2198"><a href="#cb1-2198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2199"><a href="#cb1-2199" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; After introducing Kantorovich's solution technique to the problem of minimizing waste, officials were able to reduce the amount of scrap by 50 percent. This had the unfortunate side effect of greatly reducing the amount of scrap metal available to steel plants in the region, and Kantorovich was ordered to appear at Leningrad party headquarters for allegedly sabotaging the economy. In this instance, he was rescued by the military, which needed him for its atomic program.</span></span>
<span id="cb1-2200"><a href="#cb1-2200" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-2201"><a href="#cb1-2201" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; According to Stalin, the planned economy of the USSR was already "</span><span class="co">[</span><span class="ot">dizzy with success</span><span class="co">](https://ru.wikipedia.org/wiki/Головокружение_от_успехов)</span><span class="at">"; hence any criticism of it was anti-Soviet propaganda, a serious crime. In particular, anyone openly suggesting that waste could be cut substantially was at great personal risk. Nevertheless, Kantorovich ... wrote a letter to Gosplan suggesting a reform of the price system used in planning. </span></span>
<span id="cb1-2202"><a href="#cb1-2202" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-2203"><a href="#cb1-2203" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gardnerLVKantorovichPrice1990</span><span class="co">]</span></span>
<span id="cb1-2204"><a href="#cb1-2204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2205"><a href="#cb1-2205" aria-hidden="true" tabindex="-1"></a>Being a socially clueless nerd was not the stuff of romantic comedy in Soviet Russia, but gallows comedy. Fortunately for mathematical economics, his luck held:</span>
<span id="cb1-2206"><a href="#cb1-2206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2207"><a href="#cb1-2207" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Gosplan wrote back saying that no such reform was necessary. This outcome was rather fortunate for its author, as similar letters critical of the authorities -- for example, one by Solzhenitsin -- landed their authors promptly in jail.</span></span>
<span id="cb1-2208"><a href="#cb1-2208" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb1-2209"><a href="#cb1-2209" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">@gardnerLVKantorovichPrice1990</span><span class="co">]</span></span>
<span id="cb1-2210"><a href="#cb1-2210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2211"><a href="#cb1-2211" aria-hidden="true" tabindex="-1"></a>Reading Kantorovich's repeated attempts to reform Soviet economy, I imagined those old silent movies where a protagonist stumbles around, blindfolded, crossing a highway where the cars always *just missed*.</span>
<span id="cb1-2212"><a href="#cb1-2212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2213"><a href="#cb1-2213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix: How confusingly thermodynamics is astaught {.appendix}</span></span>
<span id="cb1-2214"><a href="#cb1-2214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2215"><a href="#cb1-2215" aria-hidden="true" tabindex="-1"></a>During my high school Physics Olympiad days, we learned some basic thermodynamics, but it was limited to mindless tasks like integrating around the $(P, V)$ diagram for various engine cycles. We never understood the conceptual foundations, like the difference between $\delta Q$ and $dU$. I also passed the AP Chemistry course, which also contained some basic and deeply confusing thermodynamics, especially with the statement "chemical equilibrium is reached at $\Delta G = 0$".</span>
<span id="cb1-2216"><a href="#cb1-2216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2217"><a href="#cb1-2217" aria-hidden="true" tabindex="-1"></a>During my undergraduate years, special relativity was simple enough, electrodynamics difficult but sensible, analytical mechanics confusing to no end, and I didn't even try thermodynamics. In graduate studies, I had to wrestle with statistical mechanics and thermodynamics after all, to deal with modern AI methods like diffusion models.</span>
<span id="cb1-2218"><a href="#cb1-2218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2219"><a href="#cb1-2219" aria-hidden="true" tabindex="-1"></a>By pure serendipity, at the same time as diffusion models rose to prominence, I had just worked through a rigorous course on general equilibrium theory, the "standard model" for neoclassical economics <span class="co">[</span><span class="ot">@starrGeneralEquilibriumTheory2011</span><span class="co">]</span>. This gave me the conceptual foundation for looking past the textbooks' errors. Everything fell into place, and I saw through thermodynamics.</span>
<span id="cb1-2220"><a href="#cb1-2220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2221"><a href="#cb1-2221" aria-hidden="true" tabindex="-1"></a>And just like when I rediscovered <span class="co">[</span><span class="ot">Wigner rotation</span><span class="co">](https://yuxi-liu-wired.github.io/essays/posts/wigner-rotation)</span>, as soon as I have figured out everything for myself, I knew the right words to search. Putting the fateful words "Gibbs delta G free energy equilibrium" into Google Scholar, I found that, of course, someone else had written this before, repeatedly <span class="co">[</span><span class="ot">@quilezFirstYearUniversityChemistry2012; @smithClassicalThermodynamicsEconomic2008; @candealUtilityEntropy2001</span><span class="co">]</span>. So, why spend all this time to write another one? I think I have written this pedagogically. I don't care if it is not new, or that it has been said before with more symbols and theorems. I have a thing to say, so I will say it well.</span>
<span id="cb1-2222"><a href="#cb1-2222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2223"><a href="#cb1-2223" aria-hidden="true" tabindex="-1"></a>As an enlightened one, I see classical thermodynamics as the worst-taught subject out of all of undergraduate physics education.<span class="ot">[^physics-education]</span> Imagine my surprise when I realized that it is not about the conservation of energy ("thermo-"), not about change ("-dynamics"), not about statistical mechanics, not about time... but just about constrained optimization, and nothing more than that! To really understand it, one must unlearn a lot of the nonsense. Indeed, I hope that with this essay I will have slain all those mistakes, which is why the essay is filled with warnings against this and that error.</span>
<span id="cb1-2224"><a href="#cb1-2224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2225"><a href="#cb1-2225" aria-hidden="true" tabindex="-1"></a><span class="ot">[^physics-education]: </span>How long does it take for something as simple as constrained-optimization thermodynamics to be actually taught in undergraduate classes? It has been over 100 years since Caratheodory's thermodynamics. Why is it thermodynamics still taught so badly? It has been over 100 years since the geometry of Wigner rotation has been discovered. Why is it still taught so badly? It has been over 190 years since Hamiltonian mechanics and over 70 years since dynamical programming has clarified the last obscure points of it. Why is it still taught so badly? It seems to me that physics education is a broken institution that takes all its effort just to not get worse, let alone progress.</span>
<span id="cb1-2226"><a href="#cb1-2226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2227"><a href="#cb1-2227" aria-hidden="true" tabindex="-1"></a><span class="fu">## Appendix: How confusingly chemical thermodynamics is taught {.appendix}</span></span>
<span id="cb1-2228"><a href="#cb1-2228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2229"><a href="#cb1-2229" aria-hidden="true" tabindex="-1"></a>I studied chemistry back then. Balancing equations was just linear algebra, and organic chemistry was just lego with long names. However, when it came to chemical thermodynamics, it completely defeated me.</span>
<span id="cb1-2230"><a href="#cb1-2230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2231"><a href="#cb1-2231" aria-hidden="true" tabindex="-1"></a>Consider the simple reaction</span>
<span id="cb1-2232"><a href="#cb1-2232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2233"><a href="#cb1-2233" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2234"><a href="#cb1-2234" aria-hidden="true" tabindex="-1"></a>aA + bB \rightleftharpoons cC + dD</span>
<span id="cb1-2235"><a href="#cb1-2235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2236"><a href="#cb1-2236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2237"><a href="#cb1-2237" aria-hidden="true" tabindex="-1"></a>The textbook said that at equilibrium, $\Delta G = 0$, where</span>
<span id="cb1-2238"><a href="#cb1-2238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2239"><a href="#cb1-2239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2240"><a href="#cb1-2240" aria-hidden="true" tabindex="-1"></a>\Delta G = \Delta G^\circ + RT \ln Q, \quad</span>
<span id="cb1-2241"><a href="#cb1-2241" aria-hidden="true" tabindex="-1"></a>Q = \frac{<span class="co">[</span><span class="ot">C</span><span class="co">]</span>^c <span class="co">[</span><span class="ot">D</span><span class="co">]</span>^d}{<span class="co">[</span><span class="ot">A</span><span class="co">]</span>^a<span class="co">[</span><span class="ot">B</span><span class="co">]</span>^b},</span>
<span id="cb1-2242"><a href="#cb1-2242" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-2243"><a href="#cb1-2243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2244"><a href="#cb1-2244" aria-hidden="true" tabindex="-1"></a>At this point, I was lost. It is plain to see that $Q$ has units of $(\mathrm{mol/L})^{c+d-a-b}$, and I knew from physics that you can never ever take the logarithm of something with a unit. What's worse, $\Delta G$ has units of $\mathrm{~J/mol}$ when it obviously should have units of $\mathrm{~J}$, because $\Delta G$ is just a difference in $G$, and since $G$ is "Gibbs free energy", both $G$ and $\Delta G$ should have the same units of $\mathrm{~J}$.</span>
<span id="cb1-2245"><a href="#cb1-2245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2246"><a href="#cb1-2246" aria-hidden="true" tabindex="-1"></a>And it got even worse when I read on and found questions that asked me to calculate the "total Gibbs free energy released during the reaction". I thought, well, since you end up at an equilibrium, and the textbook said that at equilibrium, $\Delta G = 0$, obviously there is no total Gibbs free energy released. That is of course wrong. At that point, I gave up trying to understand and simply practiced until I could solve the questions without understanding.</span>
<span id="cb1-2247"><a href="#cb1-2247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2248"><a href="#cb1-2248" aria-hidden="true" tabindex="-1"></a>It certainly didn't help when I kept seeing both $\Delta G^\circ$ and $\Delta G^\ominus$, and sometimes even $\Delta G$⦵ (the <span class="co">[</span><span class="ot">Plimsoll symbol</span><span class="co">](https://en.wikipedia.org/wiki/Standard_state)</span>), which is the "standard state" when the substance is a gas -- but only for some gasses... Point is, the notation is a complete mess, and the pedagogy is nonsensical.</span>
<span id="cb1-2249"><a href="#cb1-2249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2250"><a href="#cb1-2250" aria-hidden="true" tabindex="-1"></a>After I finally understood thermodynamics, I turned my sights on chemical thermodynamics, and remembered this $\Delta G$ nonsense. I started with the idea "No matter what they say, one can't possibly get the units wrong." and got into a shouting match with ChatGPT-4, who kept mumbling about "fugacity" and "real gasses". An hour of shouting later, I finally figured it out. (The new Feynman technique: Try to convince ChatGPT that a widely-held opinion is actually wrong. It worked for me!)</span>
<span id="cb1-2251"><a href="#cb1-2251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2252"><a href="#cb1-2252" aria-hidden="true" tabindex="-1"></a>As usual, as soon as I unlearned this, I knew the right phrase to search, and discovered that this is a common error, the entire anatomy of which has been autopsied carefully <span class="co">[</span><span class="ot">@raffSpontaneityEquilibriumWhy2014; @raffSpontaneityEquilibriumII2014; @raffSpontaneityEquilibriumIII2014</span><span class="co">]</span>.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">Yuxi on the Wired</span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block">Everything <a href="https://en.wikipedia.org/wiki/Public_domainl">PD</a>; <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en/">CC0</a> fallback.</span></p>
</div>
  </div>
</footer>




</body></html>